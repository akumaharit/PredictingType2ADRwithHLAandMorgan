{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchviz\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np      \n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from torch.utils.data import WeightedRandomSampler, RandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score, precision_recall_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import auc\n",
    "# import libraries ต่าง ๆ ที่จะใช้\n",
    "import torchviz\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # ใช้ในการแบ่งข้อมูล\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib import pyplot\n",
    "from torchmetrics.classification import MulticlassPrecisionRecallCurve\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(\"../3 - Cleaning & Transforming Data/2 cleaned_dataset_MERGED_DRUG(Mogran)_ALLELESEQ.csv\", index_col = None)\n",
    "\n",
    "if(df.isna().any().sum()) != 0:\n",
    "    raise Exception('There are still missing values in the dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drug\n",
      "Allele\n",
      "ADR_MPexanthema\n",
      "ADR_SJS\n",
      "ADR_TEN\n",
      "ADR\n",
      "Cohort ethnicity_Black\n",
      "Cohort ethnicity_Caucasian\n",
      "Cohort ethnicity_Diverse\n",
      "Cohort ethnicity_Mongol\n",
      "Cohort ethnicity\n",
      "No_ADR\n",
      "Yes_ADR\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "11\n",
      "20\n",
      "23\n",
      "30\n",
      "74\n",
      "80\n",
      "86\n",
      "122\n",
      "123\n",
      "130\n",
      "140\n",
      "151\n",
      "162\n",
      "175\n",
      "191\n",
      "204\n",
      "207\n",
      "245\n",
      "248\n",
      "264\n",
      "294\n",
      "297\n",
      "300\n",
      "314\n",
      "315\n",
      "319\n",
      "323\n",
      "333\n",
      "336\n",
      "338\n",
      "350\n",
      "352\n",
      "366\n",
      "371\n",
      "378\n",
      "381\n",
      "389\n",
      "405\n",
      "409\n",
      "426\n",
      "428\n",
      "435\n",
      "448\n",
      "456\n",
      "461\n",
      "469\n",
      "470\n",
      "485\n",
      "486\n",
      "501\n",
      "502\n",
      "511\n",
      "527\n",
      "530\n",
      "535\n",
      "547\n",
      "554\n",
      "556\n",
      "561\n",
      "588\n",
      "600\n",
      "609\n",
      "623\n",
      "624\n",
      "631\n",
      "637\n",
      "650\n",
      "656\n",
      "675\n",
      "679\n",
      "694\n",
      "713\n",
      "715\n",
      "725\n",
      "739\n",
      "745\n",
      "750\n",
      "751\n",
      "764\n",
      "770\n",
      "772\n",
      "780\n",
      "787\n",
      "794\n",
      "798\n",
      "806\n",
      "807\n",
      "833\n",
      "834\n",
      "843\n",
      "849\n",
      "872\n",
      "875\n",
      "882\n",
      "883\n",
      "884\n",
      "888\n",
      "926\n",
      "935\n",
      "952\n",
      "974\n",
      "984\n",
      "987\n",
      "990\n",
      "993\n",
      "1011\n",
      "1017\n",
      "1019\n",
      "1028\n",
      "1039\n",
      "1043\n",
      "1044\n",
      "1055\n",
      "1057\n",
      "1060\n",
      "1066\n",
      "1070\n",
      "1077\n",
      "1088\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1102\n",
      "1105\n",
      "1114\n",
      "1120\n",
      "1130\n",
      "1137\n",
      "1138\n",
      "1142\n",
      "1145\n",
      "1148\n",
      "1152\n",
      "1153\n",
      "1155\n",
      "1164\n",
      "1168\n",
      "1171\n",
      "1182\n",
      "1184\n",
      "1199\n",
      "1212\n",
      "1236\n",
      "1242\n",
      "1267\n",
      "1269\n",
      "1270\n",
      "1292\n",
      "1295\n",
      "1312\n",
      "1313\n",
      "1318\n",
      "1325\n",
      "1340\n",
      "1347\n",
      "1351\n",
      "1357\n",
      "1380\n",
      "1389\n",
      "1391\n",
      "1398\n",
      "1426\n",
      "1428\n",
      "1434\n",
      "1446\n",
      "1448\n",
      "1449\n",
      "1452\n",
      "1457\n",
      "1459\n",
      "1464\n",
      "1476\n",
      "1480\n",
      "1498\n",
      "1528\n",
      "1535\n",
      "1542\n",
      "1544\n",
      "1564\n",
      "1578\n",
      "1585\n",
      "1589\n",
      "1602\n",
      "1607\n",
      "1646\n",
      "1647\n",
      "1657\n",
      "1675\n",
      "1683\n",
      "1708\n",
      "1722\n",
      "1738\n",
      "1739\n",
      "1742\n",
      "1750\n",
      "1778\n",
      "1786\n",
      "1803\n",
      "1804\n",
      "1816\n",
      "1821\n",
      "1824\n",
      "1832\n",
      "1844\n",
      "1855\n",
      "1864\n",
      "1866\n",
      "1873\n",
      "1877\n",
      "1886\n",
      "1905\n",
      "1910\n",
      "1917\n",
      "1920\n",
      "1922\n",
      "1948\n",
      "1956\n",
      "1964\n",
      "1974\n",
      "1977\n",
      "1985\n",
      "2012\n",
      "2039\n",
      "2043\n",
      "p1-7-I\n",
      "p1-7-V\n",
      "p1-11-E\n",
      "p1-11-G\n",
      "p1-11-R\n",
      "p1-17-E\n",
      "p1-17-G\n",
      "p1-17-L\n",
      "p1-17-Q\n",
      "p1-17-R\n",
      "p1-18-E\n",
      "p1-18-N\n",
      "p1-18-Q\n",
      "p1-20-G\n",
      "p1-20-Q\n",
      "p1-20-R\n",
      "p1-22-I\n",
      "p1-22-K\n",
      "p1-22-N\n",
      "p1-23-C\n",
      "p1-23-F\n",
      "p1-23-M\n",
      "p1-23-S\n",
      "p1-23-V\n",
      "p1-23-Y\n",
      "p1-25-A\n",
      "p1-25-R\n",
      "p1-25-T\n",
      "p1-26-H\n",
      "p1-26-K\n",
      "p1-26-N\n",
      "p1-26-Q\n",
      "p1-26-S\n",
      "p1-27-A\n",
      "p1-27-S\n",
      "p1-27-T\n",
      "p1-29-A\n",
      "p1-29-I\n",
      "p1-29-T\n",
      "p1-30-D\n",
      "p1-30-G\n",
      "p1-30-H\n",
      "p1-30-N\n",
      "p1-30-Y\n",
      "p1-32-A\n",
      "p1-32-E\n",
      "p1-32-V\n",
      "p1-33-D\n",
      "p1-33-G\n",
      "p1-33-N\n",
      "p1-33-S\n",
      "p1-35-G\n",
      "p1-35-R\n",
      "p1-36--\n",
      "p1-36-I\n",
      "p1-37-A\n",
      "p1-37-I\n",
      "p1-37-K\n",
      "p1-37-N\n",
      "p1-37-T\n",
      "p1-38-A\n",
      "p1-38-L\n",
      "p1-39-L\n",
      "p1-39-R\n",
      "p1-40--\n",
      "p1-40-G\n",
      "p1-40-R\n",
      "p2-2-I\n",
      "p2-2-T\n",
      "p2-3-S\n",
      "p2-3-T\n",
      "p2-4-K\n",
      "p2-4-Q\n",
      "p2-5-H\n",
      "p2-5-L\n",
      "p2-5-R\n",
      "p2-7-L\n",
      "p2-7-W\n",
      "p2-9-A\n",
      "p2-9-T\n",
      "p2-10-A\n",
      "p2-10-V\n",
      "p2-11-H\n",
      "p2-11-R\n",
      "p2-12-A\n",
      "p2-12-E\n",
      "p2-12-R\n",
      "p2-12-V\n",
      "p2-12-W\n",
      "p2-16-D\n",
      "p2-16-L\n",
      "p2-16-Q\n",
      "p2-16-R\n",
      "p2-16-W\n",
      "p2-18-A\n",
      "p2-18-T\n",
      "p2-18-V\n",
      "p2-33-D\n",
      "p2-33-E\n",
      "p2-35-E\n",
      "p2-35-L\n",
      "p2-35-R\n",
      "p2-35-T\n",
      "p2-38-D\n",
      "p2-38-E\n",
      "p2-39-G\n",
      "p2-39-S\n",
      "p2-39-W\n",
      "p2-43-H\n",
      "p2-43-Y\n",
      "p2-48-E\n",
      "p2-48-K\n",
      "p2-52-D\n",
      "p2-52-E\n",
      "p2-52-K\n",
      "p2-53-K\n",
      "p2-53-T\n"
     ]
    }
   ],
   "source": [
    "# check ของแปลกที่หลุดเข้ามา\n",
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SJS            5805\n",
       "TEN            3738\n",
       "MPexanthema    3530\n",
       "Name: ADR, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ADR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_stratify = pd.DataFrame()\n",
    "df['ADR'] = df['ADR'].replace({'SJS': 0, 'TEN': 1, 'MPexanthema':2})#,'MPeruption':3})\n",
    "#df = df[df['ADR'].isin([0,1])] #ลบ MP ออก\n",
    "#df_stratify['Yes_ADR'] = df['ADR'].copy()\n",
    "#df_stratify = df_stratify.rename(columns={'Yes_ADR':'ADR'})\n",
    "df.drop(columns=['No_ADR','ADR','ADR_MPexanthema','ADR_SJS','ADR_TEN','Cohort ethnicity','Allele','Drug'], inplace=True) #'MPeruption' removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64    350\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select output columns and drop unnecessary columns\n",
    "df_output = df['Yes_ADR'].copy()\n",
    "df.drop(columns = ['Yes_ADR'], inplace = True)\n",
    "df_input = df.copy()\n",
    "# Check input dtypes\n",
    "df_input.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.0\n",
       "1        1.0\n",
       "2        1.0\n",
       "3        1.0\n",
       "4        1.0\n",
       "        ... \n",
       "13068    0.0\n",
       "13069    0.0\n",
       "13070    0.0\n",
       "13071    0.0\n",
       "13072    0.0\n",
       "Name: Yes_ADR, Length: 13073, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check ของแปลกที่หลุดเข้ามา\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohort ethnicity_Black\n",
      "Cohort ethnicity_Caucasian\n",
      "Cohort ethnicity_Diverse\n",
      "Cohort ethnicity_Mongol\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "11\n",
      "20\n",
      "23\n",
      "30\n",
      "74\n",
      "80\n",
      "86\n",
      "122\n",
      "123\n",
      "130\n",
      "140\n",
      "151\n",
      "162\n",
      "175\n",
      "191\n",
      "204\n",
      "207\n",
      "245\n",
      "248\n",
      "264\n",
      "294\n",
      "297\n",
      "300\n",
      "314\n",
      "315\n",
      "319\n",
      "323\n",
      "333\n",
      "336\n",
      "338\n",
      "350\n",
      "352\n",
      "366\n",
      "371\n",
      "378\n",
      "381\n",
      "389\n",
      "405\n",
      "409\n",
      "426\n",
      "428\n",
      "435\n",
      "448\n",
      "456\n",
      "461\n",
      "469\n",
      "470\n",
      "485\n",
      "486\n",
      "501\n",
      "502\n",
      "511\n",
      "527\n",
      "530\n",
      "535\n",
      "547\n",
      "554\n",
      "556\n",
      "561\n",
      "588\n",
      "600\n",
      "609\n",
      "623\n",
      "624\n",
      "631\n",
      "637\n",
      "650\n",
      "656\n",
      "675\n",
      "679\n",
      "694\n",
      "713\n",
      "715\n",
      "725\n",
      "739\n",
      "745\n",
      "750\n",
      "751\n",
      "764\n",
      "770\n",
      "772\n",
      "780\n",
      "787\n",
      "794\n",
      "798\n",
      "806\n",
      "807\n",
      "833\n",
      "834\n",
      "843\n",
      "849\n",
      "872\n",
      "875\n",
      "882\n",
      "883\n",
      "884\n",
      "888\n",
      "926\n",
      "935\n",
      "952\n",
      "974\n",
      "984\n",
      "987\n",
      "990\n",
      "993\n",
      "1011\n",
      "1017\n",
      "1019\n",
      "1028\n",
      "1039\n",
      "1043\n",
      "1044\n",
      "1055\n",
      "1057\n",
      "1060\n",
      "1066\n",
      "1070\n",
      "1077\n",
      "1088\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1102\n",
      "1105\n",
      "1114\n",
      "1120\n",
      "1130\n",
      "1137\n",
      "1138\n",
      "1142\n",
      "1145\n",
      "1148\n",
      "1152\n",
      "1153\n",
      "1155\n",
      "1164\n",
      "1168\n",
      "1171\n",
      "1182\n",
      "1184\n",
      "1199\n",
      "1212\n",
      "1236\n",
      "1242\n",
      "1267\n",
      "1269\n",
      "1270\n",
      "1292\n",
      "1295\n",
      "1312\n",
      "1313\n",
      "1318\n",
      "1325\n",
      "1340\n",
      "1347\n",
      "1351\n",
      "1357\n",
      "1380\n",
      "1389\n",
      "1391\n",
      "1398\n",
      "1426\n",
      "1428\n",
      "1434\n",
      "1446\n",
      "1448\n",
      "1449\n",
      "1452\n",
      "1457\n",
      "1459\n",
      "1464\n",
      "1476\n",
      "1480\n",
      "1498\n",
      "1528\n",
      "1535\n",
      "1542\n",
      "1544\n",
      "1564\n",
      "1578\n",
      "1585\n",
      "1589\n",
      "1602\n",
      "1607\n",
      "1646\n",
      "1647\n",
      "1657\n",
      "1675\n",
      "1683\n",
      "1708\n",
      "1722\n",
      "1738\n",
      "1739\n",
      "1742\n",
      "1750\n",
      "1778\n",
      "1786\n",
      "1803\n",
      "1804\n",
      "1816\n",
      "1821\n",
      "1824\n",
      "1832\n",
      "1844\n",
      "1855\n",
      "1864\n",
      "1866\n",
      "1873\n",
      "1877\n",
      "1886\n",
      "1905\n",
      "1910\n",
      "1917\n",
      "1920\n",
      "1922\n",
      "1948\n",
      "1956\n",
      "1964\n",
      "1974\n",
      "1977\n",
      "1985\n",
      "2012\n",
      "2039\n",
      "2043\n",
      "p1-7-I\n",
      "p1-7-V\n",
      "p1-11-E\n",
      "p1-11-G\n",
      "p1-11-R\n",
      "p1-17-E\n",
      "p1-17-G\n",
      "p1-17-L\n",
      "p1-17-Q\n",
      "p1-17-R\n",
      "p1-18-E\n",
      "p1-18-N\n",
      "p1-18-Q\n",
      "p1-20-G\n",
      "p1-20-Q\n",
      "p1-20-R\n",
      "p1-22-I\n",
      "p1-22-K\n",
      "p1-22-N\n",
      "p1-23-C\n",
      "p1-23-F\n",
      "p1-23-M\n",
      "p1-23-S\n",
      "p1-23-V\n",
      "p1-23-Y\n",
      "p1-25-A\n",
      "p1-25-R\n",
      "p1-25-T\n",
      "p1-26-H\n",
      "p1-26-K\n",
      "p1-26-N\n",
      "p1-26-Q\n",
      "p1-26-S\n",
      "p1-27-A\n",
      "p1-27-S\n",
      "p1-27-T\n",
      "p1-29-A\n",
      "p1-29-I\n",
      "p1-29-T\n",
      "p1-30-D\n",
      "p1-30-G\n",
      "p1-30-H\n",
      "p1-30-N\n",
      "p1-30-Y\n",
      "p1-32-A\n",
      "p1-32-E\n",
      "p1-32-V\n",
      "p1-33-D\n",
      "p1-33-G\n",
      "p1-33-N\n",
      "p1-33-S\n",
      "p1-35-G\n",
      "p1-35-R\n",
      "p1-36--\n",
      "p1-36-I\n",
      "p1-37-A\n",
      "p1-37-I\n",
      "p1-37-K\n",
      "p1-37-N\n",
      "p1-37-T\n",
      "p1-38-A\n",
      "p1-38-L\n",
      "p1-39-L\n",
      "p1-39-R\n",
      "p1-40--\n",
      "p1-40-G\n",
      "p1-40-R\n",
      "p2-2-I\n",
      "p2-2-T\n",
      "p2-3-S\n",
      "p2-3-T\n",
      "p2-4-K\n",
      "p2-4-Q\n",
      "p2-5-H\n",
      "p2-5-L\n",
      "p2-5-R\n",
      "p2-7-L\n",
      "p2-7-W\n",
      "p2-9-A\n",
      "p2-9-T\n",
      "p2-10-A\n",
      "p2-10-V\n",
      "p2-11-H\n",
      "p2-11-R\n",
      "p2-12-A\n",
      "p2-12-E\n",
      "p2-12-R\n",
      "p2-12-V\n",
      "p2-12-W\n",
      "p2-16-D\n",
      "p2-16-L\n",
      "p2-16-Q\n",
      "p2-16-R\n",
      "p2-16-W\n",
      "p2-18-A\n",
      "p2-18-T\n",
      "p2-18-V\n",
      "p2-33-D\n",
      "p2-33-E\n",
      "p2-35-E\n",
      "p2-35-L\n",
      "p2-35-R\n",
      "p2-35-T\n",
      "p2-38-D\n",
      "p2-38-E\n",
      "p2-39-G\n",
      "p2-39-S\n",
      "p2-39-W\n",
      "p2-43-H\n",
      "p2-43-Y\n",
      "p2-48-E\n",
      "p2-48-K\n",
      "p2-52-D\n",
      "p2-52-E\n",
      "p2-52-K\n",
      "p2-53-K\n",
      "p2-53-T\n"
     ]
    }
   ],
   "source": [
    "# check ของแปลกที่หลุดเข้ามา\n",
    "for x in df_input.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change all input dtypes to float64\n",
    "# df_input = df_input.astype('float64')\n",
    "# df_input.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "np_input = df_input.to_numpy()\n",
    "np_output = df_output.to_numpy()\n",
    "np_stratify = df_stratify.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np_stratify).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_input    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check dataloader classes distribution\n",
    "def get_dataloader_distribution(*args, label = None):\n",
    "    graph_no = len(args)\n",
    "    fig, ax = plt.subplots(graph_no,1)\n",
    "    \n",
    "    for index, dataloader in enumerate(args):\n",
    "        batch_no = [x+1 for x in range(len(dataloader))]\n",
    "        class_0_count = []\n",
    "        class_1_count = []\n",
    "        batch_count = []\n",
    "\n",
    "        for i, (data,target) in enumerate(dataloader):\n",
    "            tocount = pd.DataFrame(target.numpy()).value_counts()\n",
    "            batch_count.append(i+1)\n",
    "            try:\n",
    "                class_0_count.append(tocount[0])\n",
    "            except:\n",
    "                class_0_count.append(0)\n",
    "            try:\n",
    "                class_1_count.append(tocount[1])\n",
    "            except:\n",
    "                class_1_count.append(0)\n",
    "        X_axis = np.arange(len(batch_count))\n",
    "\n",
    "        \n",
    "        fig.set_figwidth(15)\n",
    "        fig.set_figheight(10)\n",
    "        ax[index].set_xlabel=\"Batch Number\"\n",
    "        ax[index].set_ylabel=\"No. Datapoints\"\n",
    "        ax[index].bar(X_axis+(1/3),class_0_count,width=(1/3) ,label = \"No ADR\",color='red',alpha=0.5)\n",
    "        ax[index].bar(X_axis,class_1_count,width=(1/3), label = 'Yes ADR',color='green',alpha=0.5)\n",
    "        #ax.set_xticks(X_axis+width)\n",
    "        ax[index].legend()\n",
    "    \n",
    "    ax[0].set_title(f\"{label} Train_Loader Label Distribution by Yes/No ADR (per batch)\")\n",
    "    ax[1].set_title(f\"{label} Test_loader Label Distribution by Yes/No ADR\")\n",
    "    ax[1].set_xticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13073, 350)\n",
      "(13073,)\n"
     ]
    }
   ],
   "source": [
    "print(np_input.shape)\n",
    "print(np_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "  '''\n",
    "    Try resetting model weights to avoid\n",
    "    weight leakage.\n",
    "  '''\n",
    "  for layer in m.children():\n",
    "   if hasattr(layer, 'reset_parameters'):\n",
    "    #print(f'Reset trainable parameters of layer = {layer}')\n",
    "    layer.reset_parameters()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network Classes\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, n_layers, n_first_units, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "    # Define Layers    \n",
    "        layers = []\n",
    "        in_features = np_input.shape[1]\n",
    "        out_features = n_first_units \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "        in_features = out_features\n",
    "        for i in range(n_layers): #i หมายถึงเลขชั้น hidden+1\n",
    "\n",
    "            layers.append(nn.BatchNorm1d(in_features))\n",
    "            out_features = int(in_features/2)\n",
    "            layers.append(nn.Linear(in_features, out_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            in_features = out_features\n",
    "        layers.append(nn.BatchNorm1d(out_features))\n",
    "        layers.append(nn.Linear(out_features, 1)) \n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "    # Define the forward pass\n",
    "    def forward(self,input):\n",
    "        output = self.layers(input)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Assign device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train function\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    \n",
    "    # Running Loss and Train Accuracy \n",
    "    running_loss = []\n",
    "    running_train_acc = []\n",
    "\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Loop through dataloader\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "\n",
    "        # Move data to device\n",
    "        data = data.float().to(device)\n",
    "        target = target.float().to(device)\n",
    "        \n",
    "        # Save Model Graph\n",
    "        # if batch_idx == 0:\n",
    "        #     dot = torchviz.make_dot(model(data), show_attrs=True, show_saved = True,params=dict(model.named_parameters()))\n",
    "        #     dot.render(f'{dir}/{name}')\n",
    "\n",
    "        # Zero out gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        \n",
    "        # Calculate loss\n",
    "        output = output.flatten()         \n",
    "        loss = loss_fn(output,target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save loss for each batch\n",
    "        running_loss.append(loss.item()) \n",
    "\n",
    "        # Calculate accuracy\n",
    "        with torch.no_grad():\n",
    "            target = target.flatten()\n",
    "            output = torch.round(output)\n",
    "            correct = (output == target).sum().item()\n",
    "            train_acc = correct/len(target)\n",
    "            train_acc = round(train_acc, 8)\n",
    "            running_train_acc.append(train_acc)\n",
    "\n",
    "    train_acc = np.mean(running_train_acc)\n",
    "    train_loss = np.mean(running_loss)\n",
    "    #print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "    return float(train_loss), float(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test function\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(dataloader):\n",
    "\n",
    "            # Move data to device\n",
    "            data = data.float().to(device)\n",
    "            target = target.float().to(device)    \n",
    "            \n",
    "            # Forward pass           \n",
    "            output = model(data)\n",
    "\n",
    "            # Calculate loss\n",
    "            output = output.flatten()\n",
    "            data = data.flatten()\n",
    "            \n",
    "            test_loss = loss_fn(output, target)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            output_notrounded = output\n",
    "            output = torch.round(output)\n",
    "            correct = (output == target).sum().item()\n",
    "        output_notrounded = output_notrounded.cpu().detach().numpy()\n",
    "        output = output.cpu().detach().numpy()\n",
    "        target = target.cpu().detach().numpy()\n",
    "\n",
    "        # Calculate metrics\n",
    "        test_acc = correct / len(dataloader.dataset)\n",
    "        test_loss = test_loss.cpu().detach().numpy()\n",
    "        test_precision = precision_score(output, target, zero_division=0)\n",
    "        test_f1_score = f1_score(output, target, zero_division=0)\n",
    "        test_recall_score = recall_score(output, target, zero_division=0)\n",
    "\n",
    "        # precision, recall, thresholds = precision_recall_curve(target, output_notrounded)\n",
    "        # F1Score =  (2*precision*recall) / (precision + recall)\n",
    "        # max_F1Score = np.max(F1Score)\n",
    "        # max_index_F1Score = np.argmax(F1Score)\n",
    "        # test_auc_score = auc(recall, precision)\n",
    "    #print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}, Test Precision: {test_precision:.4f}, Test Recall: {test_recall_score:.4f}, Test F1 Score: {test_f1_score:.4f}\")\n",
    "\n",
    "    return float(test_loss), float(test_acc), float(test_precision), float(test_recall_score), float(test_f1_score)#, float(test_auc_score), float(max_F1Score), float(thresholds[max_index_F1Score])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NOT Optimized Hyperparameters\n",
    "\n",
    "#epochs = 100\n",
    "# L2lambda = 0.01\n",
    "k_folds = 5\n",
    "DIR = os.getcwd()\n",
    "\n",
    "loss_fn = nn.BCELoss() # Binary Cross Entropy Loss\n",
    "\n",
    "epochs = 800\n",
    "dirname = \"optuna_run2\" \n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "n_layers = 2\n",
    "n_first_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Values\n",
    "L2lambda = 0.01\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:231: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "\u001b[32m[I 2023-04-20 11:53:01,122]\u001b[0m Using an existing study with name 'optuna_run2' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 - Fold 0 - Params: {'weightdecay': 'yes', 'batch_norm': 'no', 'dropout': 'no', 'L2lambda': 0.1}\n",
      "Additional Hyperparameters -> Weight Decay: 0.1\n",
      "FOLD 0\n",
      "--------\n",
      "epoch: 0, train loss: 0.6932, test loss: 0.6899, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 1, train loss: 0.6933, test loss: 0.6923, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 2, train loss: 0.6932, test loss: 0.6897, train acc: 0.5035, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 3, train loss: 0.6933, test loss: 0.6895, train acc: 0.4927, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 4, train loss: 0.6932, test loss: 0.6935, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 5, train loss: 0.6932, test loss: 0.6882, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 6, train loss: 0.6934, test loss: 0.6974, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 7, train loss: 0.6933, test loss: 0.6910, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 8, train loss: 0.6933, test loss: 0.6898, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 9, train loss: 0.6932, test loss: 0.6931, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 10, train loss: 0.6932, test loss: 0.6929, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 11, train loss: 0.6933, test loss: 0.6915, train acc: 0.4951, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 12, train loss: 0.6932, test loss: 0.6966, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 13, train loss: 0.6932, test loss: 0.6957, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 14, train loss: 0.6932, test loss: 0.6948, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 15, train loss: 0.6932, test loss: 0.6888, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 16, train loss: 0.6931, test loss: 0.6900, train acc: 0.5083, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 17, train loss: 0.6933, test loss: 0.6978, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 18, train loss: 0.6932, test loss: 0.6923, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 19, train loss: 0.6932, test loss: 0.6939, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 20, train loss: 0.6932, test loss: 0.6891, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 21, train loss: 0.6933, test loss: 0.6940, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 22, train loss: 0.6931, test loss: 0.6881, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 23, train loss: 0.6933, test loss: 0.6891, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 24, train loss: 0.6933, test loss: 0.6964, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 25, train loss: 0.6932, test loss: 0.7013, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 26, train loss: 0.6935, test loss: 0.6973, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 27, train loss: 0.6931, test loss: 0.6884, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 28, train loss: 0.6935, test loss: 0.6922, train acc: 0.4935, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 29, train loss: 0.6932, test loss: 0.6992, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 30, train loss: 0.6934, test loss: 0.6914, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 31, train loss: 0.6933, test loss: 0.6918, train acc: 0.4987, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 32, train loss: 0.6932, test loss: 0.6906, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 33, train loss: 0.6932, test loss: 0.6929, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 34, train loss: 0.6932, test loss: 0.6928, train acc: 0.4943, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 35, train loss: 0.6933, test loss: 0.6921, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 36, train loss: 0.6933, test loss: 0.6939, train acc: 0.4913, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 37, train loss: 0.6932, test loss: 0.6982, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 38, train loss: 0.6934, test loss: 0.6903, train acc: 0.4930, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 39, train loss: 0.6932, test loss: 0.6996, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 40, train loss: 0.6932, test loss: 0.6929, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 41, train loss: 0.6934, test loss: 0.6972, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 42, train loss: 0.6932, test loss: 0.6963, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 43, train loss: 0.6933, test loss: 0.6998, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 44, train loss: 0.6933, test loss: 0.6980, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 45, train loss: 0.6933, test loss: 0.6935, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 46, train loss: 0.6932, test loss: 0.6924, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 47, train loss: 0.6933, test loss: 0.6957, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 48, train loss: 0.6931, test loss: 0.6900, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 49, train loss: 0.6933, test loss: 0.6954, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 50, train loss: 0.6932, test loss: 0.6902, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 51, train loss: 0.6932, test loss: 0.6932, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 52, train loss: 0.6929, test loss: 0.6869, train acc: 0.5138, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 53, train loss: 0.6932, test loss: 0.6909, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 54, train loss: 0.6932, test loss: 0.6917, train acc: 0.4938, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 55, train loss: 0.6931, test loss: 0.6957, train acc: 0.5069, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 56, train loss: 0.6933, test loss: 0.6942, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 57, train loss: 0.6932, test loss: 0.6932, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 58, train loss: 0.6932, test loss: 0.6965, train acc: 0.4924, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 59, train loss: 0.6932, test loss: 0.6976, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 60, train loss: 0.6933, test loss: 0.6908, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 61, train loss: 0.6932, test loss: 0.6894, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 62, train loss: 0.6932, test loss: 0.6977, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 63, train loss: 0.6935, test loss: 0.6901, train acc: 0.4914, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 64, train loss: 0.6932, test loss: 0.6887, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 65, train loss: 0.6933, test loss: 0.6919, train acc: 0.4948, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 66, train loss: 0.6933, test loss: 0.6962, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 67, train loss: 0.6930, test loss: 0.6912, train acc: 0.5098, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 68, train loss: 0.6932, test loss: 0.6936, train acc: 0.5000, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 69, train loss: 0.6933, test loss: 0.6928, train acc: 0.4860, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 70, train loss: 0.6933, test loss: 0.6881, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 71, train loss: 0.6931, test loss: 0.7003, train acc: 0.5065, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 72, train loss: 0.6933, test loss: 0.6923, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 73, train loss: 0.6933, test loss: 0.6981, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 74, train loss: 0.6934, test loss: 0.6944, train acc: 0.4934, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 75, train loss: 0.6932, test loss: 0.6938, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 76, train loss: 0.6932, test loss: 0.6960, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 77, train loss: 0.6932, test loss: 0.6887, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 78, train loss: 0.6932, test loss: 0.6911, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 79, train loss: 0.6932, test loss: 0.6932, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 80, train loss: 0.6932, test loss: 0.6991, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 81, train loss: 0.6932, test loss: 0.6988, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 82, train loss: 0.6931, test loss: 0.6869, train acc: 0.5075, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 83, train loss: 0.6930, test loss: 0.6995, train acc: 0.5083, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 84, train loss: 0.6932, test loss: 0.6931, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 85, train loss: 0.6932, test loss: 0.6898, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 86, train loss: 0.6932, test loss: 0.6880, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 87, train loss: 0.6933, test loss: 0.6898, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 88, train loss: 0.6933, test loss: 0.6950, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 89, train loss: 0.6933, test loss: 0.6954, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 90, train loss: 0.6932, test loss: 0.6902, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 91, train loss: 0.6932, test loss: 0.6933, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 92, train loss: 0.6932, test loss: 0.6857, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 93, train loss: 0.6933, test loss: 0.6955, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 94, train loss: 0.6933, test loss: 0.6917, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 95, train loss: 0.6931, test loss: 0.6895, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 96, train loss: 0.6932, test loss: 0.6904, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 97, train loss: 0.6932, test loss: 0.6922, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 98, train loss: 0.6933, test loss: 0.6902, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 99, train loss: 0.6931, test loss: 0.6895, train acc: 0.5073, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 100, train loss: 0.6930, test loss: 0.7032, train acc: 0.5086, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 101, train loss: 0.6933, test loss: 0.6935, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 102, train loss: 0.6932, test loss: 0.6904, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 103, train loss: 0.6933, test loss: 0.6940, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 104, train loss: 0.6934, test loss: 0.6967, train acc: 0.4913, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 105, train loss: 0.6932, test loss: 0.6849, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 106, train loss: 0.6933, test loss: 0.6875, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 107, train loss: 0.6933, test loss: 0.6900, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 108, train loss: 0.6932, test loss: 0.6962, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 109, train loss: 0.6932, test loss: 0.6984, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 110, train loss: 0.6931, test loss: 0.6991, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 111, train loss: 0.6933, test loss: 0.6926, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 112, train loss: 0.6932, test loss: 0.6960, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 113, train loss: 0.6932, test loss: 0.6879, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 114, train loss: 0.6933, test loss: 0.6964, train acc: 0.5070, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 115, train loss: 0.6931, test loss: 0.6863, train acc: 0.5072, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 116, train loss: 0.6935, test loss: 0.6950, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 117, train loss: 0.6934, test loss: 0.6944, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 118, train loss: 0.6931, test loss: 0.6849, train acc: 0.5081, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 119, train loss: 0.6934, test loss: 0.6950, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 120, train loss: 0.6931, test loss: 0.6936, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 121, train loss: 0.6933, test loss: 0.6966, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 122, train loss: 0.6932, test loss: 0.6974, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 123, train loss: 0.6932, test loss: 0.6943, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 124, train loss: 0.6932, test loss: 0.6964, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 125, train loss: 0.6932, test loss: 0.7021, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 126, train loss: 0.6934, test loss: 0.6891, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 127, train loss: 0.6933, test loss: 0.6846, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 128, train loss: 0.6937, test loss: 0.6918, train acc: 0.4810, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 129, train loss: 0.6932, test loss: 0.6900, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 130, train loss: 0.6933, test loss: 0.6910, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 131, train loss: 0.6932, test loss: 0.6940, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 132, train loss: 0.6931, test loss: 0.6968, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 133, train loss: 0.6933, test loss: 0.6914, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 134, train loss: 0.6932, test loss: 0.6905, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 135, train loss: 0.6932, test loss: 0.6890, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 136, train loss: 0.6932, test loss: 0.6924, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 137, train loss: 0.6932, test loss: 0.6893, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 138, train loss: 0.6933, test loss: 0.7005, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 139, train loss: 0.6933, test loss: 0.7000, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 140, train loss: 0.6932, test loss: 0.6950, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 141, train loss: 0.6934, test loss: 0.6902, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 142, train loss: 0.6933, test loss: 0.6917, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 143, train loss: 0.6932, test loss: 0.6884, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 144, train loss: 0.6933, test loss: 0.6904, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 145, train loss: 0.6934, test loss: 0.6942, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 146, train loss: 0.6932, test loss: 0.6931, train acc: 0.4953, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 147, train loss: 0.6933, test loss: 0.6956, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 148, train loss: 0.6932, test loss: 0.6891, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 149, train loss: 0.6932, test loss: 0.6966, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 150, train loss: 0.6931, test loss: 0.6934, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 151, train loss: 0.6933, test loss: 0.6918, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 152, train loss: 0.6932, test loss: 0.6878, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 153, train loss: 0.6934, test loss: 0.6920, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 154, train loss: 0.6933, test loss: 0.6941, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 155, train loss: 0.6932, test loss: 0.6970, train acc: 0.5055, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 156, train loss: 0.6931, test loss: 0.6889, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 157, train loss: 0.6934, test loss: 0.6910, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 158, train loss: 0.6932, test loss: 0.6946, train acc: 0.4934, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 159, train loss: 0.6932, test loss: 0.6928, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 160, train loss: 0.6932, test loss: 0.7023, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 161, train loss: 0.6934, test loss: 0.6928, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 162, train loss: 0.6932, test loss: 0.6953, train acc: 0.5022, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 163, train loss: 0.6932, test loss: 0.6972, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 164, train loss: 0.6933, test loss: 0.6927, train acc: 0.4951, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 165, train loss: 0.6932, test loss: 0.6923, train acc: 0.4931, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 166, train loss: 0.6932, test loss: 0.6970, train acc: 0.5072, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 167, train loss: 0.6932, test loss: 0.6895, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 168, train loss: 0.6933, test loss: 0.6939, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 169, train loss: 0.6933, test loss: 0.6965, train acc: 0.4945, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 170, train loss: 0.6932, test loss: 0.6955, train acc: 0.5056, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 171, train loss: 0.6933, test loss: 0.6916, train acc: 0.4948, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 172, train loss: 0.6932, test loss: 0.6928, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 173, train loss: 0.6933, test loss: 0.6927, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 174, train loss: 0.6931, test loss: 0.7003, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 175, train loss: 0.6931, test loss: 0.6904, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 176, train loss: 0.6933, test loss: 0.6894, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 177, train loss: 0.6932, test loss: 0.6921, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 178, train loss: 0.6930, test loss: 0.7012, train acc: 0.5061, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 179, train loss: 0.6931, test loss: 0.6959, train acc: 0.5099, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 180, train loss: 0.6933, test loss: 0.6912, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 181, train loss: 0.6932, test loss: 0.6984, train acc: 0.4945, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 182, train loss: 0.6931, test loss: 0.6880, train acc: 0.5073, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 183, train loss: 0.6932, test loss: 0.6929, train acc: 0.4986, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 184, train loss: 0.6932, test loss: 0.6945, train acc: 0.4918, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 185, train loss: 0.6933, test loss: 0.6915, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 186, train loss: 0.6931, test loss: 0.6887, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 187, train loss: 0.6930, test loss: 0.6890, train acc: 0.5118, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 188, train loss: 0.6930, test loss: 0.7024, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 189, train loss: 0.6934, test loss: 0.6885, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 190, train loss: 0.6933, test loss: 0.6939, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 191, train loss: 0.6933, test loss: 0.6938, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 192, train loss: 0.6931, test loss: 0.6966, train acc: 0.5094, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 193, train loss: 0.6932, test loss: 0.6999, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 194, train loss: 0.6931, test loss: 0.6949, train acc: 0.5073, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 195, train loss: 0.6932, test loss: 0.6909, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 196, train loss: 0.6933, test loss: 0.6933, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 197, train loss: 0.6932, test loss: 0.6962, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 198, train loss: 0.6933, test loss: 0.6923, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 199, train loss: 0.6933, test loss: 0.6942, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 200, train loss: 0.6932, test loss: 0.6873, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 201, train loss: 0.6934, test loss: 0.6930, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 202, train loss: 0.6932, test loss: 0.6958, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 203, train loss: 0.6933, test loss: 0.6949, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 204, train loss: 0.6931, test loss: 0.6852, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 205, train loss: 0.6934, test loss: 0.6949, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 206, train loss: 0.6932, test loss: 0.6940, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 207, train loss: 0.6932, test loss: 0.6970, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 208, train loss: 0.6932, test loss: 0.6857, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 209, train loss: 0.6934, test loss: 0.6886, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 210, train loss: 0.6932, test loss: 0.6959, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 211, train loss: 0.6932, test loss: 0.6947, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 212, train loss: 0.6934, test loss: 0.6961, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 213, train loss: 0.6932, test loss: 0.6952, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 214, train loss: 0.6932, test loss: 0.6947, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 215, train loss: 0.6932, test loss: 0.6941, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 216, train loss: 0.6932, test loss: 0.6889, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 217, train loss: 0.6933, test loss: 0.6958, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 218, train loss: 0.6932, test loss: 0.6925, train acc: 0.4948, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 219, train loss: 0.6932, test loss: 0.6945, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 220, train loss: 0.6933, test loss: 0.6913, train acc: 0.4894, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 221, train loss: 0.6933, test loss: 0.6920, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 222, train loss: 0.6932, test loss: 0.6913, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 223, train loss: 0.6934, test loss: 0.6883, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 224, train loss: 0.6931, test loss: 0.6945, train acc: 0.5055, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 225, train loss: 0.6933, test loss: 0.6958, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 226, train loss: 0.6933, test loss: 0.6967, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 227, train loss: 0.6932, test loss: 0.6923, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 228, train loss: 0.6932, test loss: 0.6885, train acc: 0.5037, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 229, train loss: 0.6932, test loss: 0.6915, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 230, train loss: 0.6931, test loss: 0.6960, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 231, train loss: 0.6931, test loss: 0.6873, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 232, train loss: 0.6935, test loss: 0.6851, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 233, train loss: 0.6932, test loss: 0.6964, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 234, train loss: 0.6932, test loss: 0.6892, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 235, train loss: 0.6931, test loss: 0.6912, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 236, train loss: 0.6933, test loss: 0.6901, train acc: 0.4932, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 237, train loss: 0.6932, test loss: 0.6881, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 238, train loss: 0.6931, test loss: 0.6985, train acc: 0.5095, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 239, train loss: 0.6932, test loss: 0.6999, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 240, train loss: 0.6932, test loss: 0.6933, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 241, train loss: 0.6933, test loss: 0.6888, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 242, train loss: 0.6931, test loss: 0.6895, train acc: 0.5092, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 243, train loss: 0.6932, test loss: 0.6963, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 244, train loss: 0.6932, test loss: 0.6925, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 245, train loss: 0.6932, test loss: 0.6953, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 246, train loss: 0.6932, test loss: 0.6940, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 247, train loss: 0.6932, test loss: 0.6901, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 248, train loss: 0.6932, test loss: 0.6924, train acc: 0.4989, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 249, train loss: 0.6932, test loss: 0.6869, train acc: 0.4986, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 250, train loss: 0.6933, test loss: 0.6940, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 251, train loss: 0.6932, test loss: 0.6902, train acc: 0.5063, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 252, train loss: 0.6930, test loss: 0.6977, train acc: 0.5092, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 253, train loss: 0.6932, test loss: 0.6987, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 254, train loss: 0.6932, test loss: 0.6935, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 255, train loss: 0.6931, test loss: 0.6959, train acc: 0.5073, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 256, train loss: 0.6932, test loss: 0.6933, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 257, train loss: 0.6934, test loss: 0.6895, train acc: 0.4929, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 258, train loss: 0.6932, test loss: 0.6873, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 259, train loss: 0.6932, test loss: 0.6944, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 260, train loss: 0.6932, test loss: 0.6942, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 261, train loss: 0.6932, test loss: 0.6930, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 262, train loss: 0.6933, test loss: 0.6923, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 263, train loss: 0.6929, test loss: 0.6835, train acc: 0.5073, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 264, train loss: 0.6930, test loss: 0.6923, train acc: 0.5081, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 265, train loss: 0.6933, test loss: 0.6893, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 266, train loss: 0.6931, test loss: 0.6896, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 267, train loss: 0.6932, test loss: 0.6942, train acc: 0.5063, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 268, train loss: 0.6933, test loss: 0.6927, train acc: 0.4943, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 269, train loss: 0.6934, test loss: 0.6955, train acc: 0.4947, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 270, train loss: 0.6931, test loss: 0.6933, train acc: 0.5021, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 271, train loss: 0.6932, test loss: 0.6939, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 272, train loss: 0.6932, test loss: 0.6937, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 273, train loss: 0.6932, test loss: 0.6928, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 274, train loss: 0.6932, test loss: 0.6952, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 275, train loss: 0.6933, test loss: 0.6928, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 276, train loss: 0.6933, test loss: 0.6945, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 277, train loss: 0.6933, test loss: 0.6913, train acc: 0.4945, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 278, train loss: 0.6933, test loss: 0.7002, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 279, train loss: 0.6932, test loss: 0.6946, train acc: 0.5046, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 280, train loss: 0.6932, test loss: 0.6881, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 281, train loss: 0.6932, test loss: 0.6942, train acc: 0.5079, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 282, train loss: 0.6933, test loss: 0.6949, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 283, train loss: 0.6934, test loss: 0.6917, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 284, train loss: 0.6932, test loss: 0.6885, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 285, train loss: 0.6930, test loss: 0.6903, train acc: 0.5097, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 286, train loss: 0.6931, test loss: 0.6888, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 287, train loss: 0.6933, test loss: 0.6936, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 288, train loss: 0.6933, test loss: 0.6935, train acc: 0.4920, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 289, train loss: 0.6932, test loss: 0.6959, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 290, train loss: 0.6933, test loss: 0.6932, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 291, train loss: 0.6931, test loss: 0.6915, train acc: 0.5040, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 292, train loss: 0.6932, test loss: 0.6910, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 293, train loss: 0.6932, test loss: 0.6898, train acc: 0.4933, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 294, train loss: 0.6932, test loss: 0.6941, train acc: 0.4998, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 295, train loss: 0.6932, test loss: 0.6910, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 296, train loss: 0.6934, test loss: 0.6965, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 297, train loss: 0.6933, test loss: 0.6900, train acc: 0.4958, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 298, train loss: 0.6932, test loss: 0.6932, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 299, train loss: 0.6933, test loss: 0.6992, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 300, train loss: 0.6933, test loss: 0.6908, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 301, train loss: 0.6932, test loss: 0.6903, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 302, train loss: 0.6933, test loss: 0.6931, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 303, train loss: 0.6933, test loss: 0.6946, train acc: 0.4948, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 304, train loss: 0.6933, test loss: 0.6928, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 305, train loss: 0.6932, test loss: 0.6913, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 306, train loss: 0.6932, test loss: 0.6943, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 307, train loss: 0.6932, test loss: 0.6932, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 308, train loss: 0.6932, test loss: 0.6929, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 309, train loss: 0.6932, test loss: 0.6946, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 310, train loss: 0.6932, test loss: 0.6938, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 311, train loss: 0.6931, test loss: 0.7005, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 312, train loss: 0.6930, test loss: 0.6970, train acc: 0.5109, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 313, train loss: 0.6931, test loss: 0.6914, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 314, train loss: 0.6932, test loss: 0.6977, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 315, train loss: 0.6932, test loss: 0.6938, train acc: 0.4948, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 316, train loss: 0.6932, test loss: 0.6866, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 317, train loss: 0.6932, test loss: 0.6953, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 318, train loss: 0.6933, test loss: 0.6917, train acc: 0.4932, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 319, train loss: 0.6933, test loss: 0.6895, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 320, train loss: 0.6932, test loss: 0.6970, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 321, train loss: 0.6933, test loss: 0.6932, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 322, train loss: 0.6931, test loss: 0.7013, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 323, train loss: 0.6934, test loss: 0.6912, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 324, train loss: 0.6933, test loss: 0.6934, train acc: 0.4908, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 325, train loss: 0.6932, test loss: 0.6895, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 326, train loss: 0.6932, test loss: 0.6904, train acc: 0.4980, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 327, train loss: 0.6932, test loss: 0.6890, train acc: 0.5035, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 328, train loss: 0.6932, test loss: 0.6949, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 329, train loss: 0.6932, test loss: 0.6910, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 330, train loss: 0.6931, test loss: 0.6945, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 331, train loss: 0.6932, test loss: 0.6899, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 332, train loss: 0.6931, test loss: 0.6978, train acc: 0.5083, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 333, train loss: 0.6932, test loss: 0.6965, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 334, train loss: 0.6931, test loss: 0.7038, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 335, train loss: 0.6934, test loss: 0.6914, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 336, train loss: 0.6934, test loss: 0.6891, train acc: 0.4890, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 337, train loss: 0.6932, test loss: 0.6896, train acc: 0.4953, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 338, train loss: 0.6933, test loss: 0.6933, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 339, train loss: 0.6931, test loss: 0.6937, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 340, train loss: 0.6932, test loss: 0.6953, train acc: 0.4933, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 341, train loss: 0.6932, test loss: 0.6975, train acc: 0.5056, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 342, train loss: 0.6932, test loss: 0.6965, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 343, train loss: 0.6932, test loss: 0.6930, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 344, train loss: 0.6934, test loss: 0.6898, train acc: 0.4932, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 345, train loss: 0.6932, test loss: 0.6880, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 346, train loss: 0.6932, test loss: 0.6888, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 347, train loss: 0.6932, test loss: 0.6898, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 348, train loss: 0.6932, test loss: 0.6929, train acc: 0.5035, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 349, train loss: 0.6933, test loss: 0.6946, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 350, train loss: 0.6931, test loss: 0.6899, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 351, train loss: 0.6933, test loss: 0.6883, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 352, train loss: 0.6931, test loss: 0.6951, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 353, train loss: 0.6933, test loss: 0.6960, train acc: 0.4944, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 354, train loss: 0.6932, test loss: 0.6929, train acc: 0.5014, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 355, train loss: 0.6933, test loss: 0.6946, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 356, train loss: 0.6933, test loss: 0.6957, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 357, train loss: 0.6934, test loss: 0.6931, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 358, train loss: 0.6930, test loss: 0.6921, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 359, train loss: 0.6933, test loss: 0.6923, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 360, train loss: 0.6932, test loss: 0.6902, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 361, train loss: 0.6932, test loss: 0.6959, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 362, train loss: 0.6933, test loss: 0.6964, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 363, train loss: 0.6931, test loss: 0.6847, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 364, train loss: 0.6934, test loss: 0.6900, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 365, train loss: 0.6933, test loss: 0.6963, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 366, train loss: 0.6932, test loss: 0.6969, train acc: 0.5081, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 367, train loss: 0.6932, test loss: 0.6894, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 368, train loss: 0.6931, test loss: 0.6893, train acc: 0.5094, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 369, train loss: 0.6930, test loss: 0.6982, train acc: 0.5105, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 370, train loss: 0.6932, test loss: 0.6887, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 371, train loss: 0.6932, test loss: 0.6978, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 372, train loss: 0.6931, test loss: 0.6860, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 373, train loss: 0.6933, test loss: 0.6906, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 374, train loss: 0.6935, test loss: 0.6972, train acc: 0.4915, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 375, train loss: 0.6932, test loss: 0.6913, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 376, train loss: 0.6932, test loss: 0.6958, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 377, train loss: 0.6933, test loss: 0.6892, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 378, train loss: 0.6933, test loss: 0.6983, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 379, train loss: 0.6934, test loss: 0.6972, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 380, train loss: 0.6933, test loss: 0.6961, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 381, train loss: 0.6932, test loss: 0.6960, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 382, train loss: 0.6932, test loss: 0.6923, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 383, train loss: 0.6932, test loss: 0.6921, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 384, train loss: 0.6933, test loss: 0.6898, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 385, train loss: 0.6933, test loss: 0.6930, train acc: 0.4879, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 386, train loss: 0.6933, test loss: 0.6930, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 387, train loss: 0.6932, test loss: 0.6974, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 388, train loss: 0.6932, test loss: 0.6908, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 389, train loss: 0.6932, test loss: 0.6971, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 390, train loss: 0.6932, test loss: 0.6866, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 391, train loss: 0.6934, test loss: 0.6909, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 392, train loss: 0.6933, test loss: 0.6936, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 393, train loss: 0.6932, test loss: 0.6922, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 394, train loss: 0.6932, test loss: 0.6917, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 395, train loss: 0.6932, test loss: 0.6913, train acc: 0.4980, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 396, train loss: 0.6930, test loss: 0.6993, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 397, train loss: 0.6932, test loss: 0.6955, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 398, train loss: 0.6932, test loss: 0.6918, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 399, train loss: 0.6932, test loss: 0.6860, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 400, train loss: 0.6934, test loss: 0.6973, train acc: 0.4936, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 401, train loss: 0.6932, test loss: 0.6956, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 402, train loss: 0.6931, test loss: 0.6907, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 403, train loss: 0.6932, test loss: 0.6963, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 404, train loss: 0.6932, test loss: 0.6997, train acc: 0.5029, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 405, train loss: 0.6932, test loss: 0.6954, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 406, train loss: 0.6932, test loss: 0.6966, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 407, train loss: 0.6932, test loss: 0.6957, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 408, train loss: 0.6933, test loss: 0.6941, train acc: 0.4926, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 409, train loss: 0.6932, test loss: 0.6949, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 410, train loss: 0.6932, test loss: 0.6944, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 411, train loss: 0.6932, test loss: 0.7003, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 412, train loss: 0.6932, test loss: 0.6902, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 413, train loss: 0.6932, test loss: 0.6902, train acc: 0.5048, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 414, train loss: 0.6931, test loss: 0.6972, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 415, train loss: 0.6932, test loss: 0.6952, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 416, train loss: 0.6932, test loss: 0.6883, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 417, train loss: 0.6933, test loss: 0.6923, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 418, train loss: 0.6933, test loss: 0.6952, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 419, train loss: 0.6932, test loss: 0.6977, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 420, train loss: 0.6932, test loss: 0.6902, train acc: 0.4939, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 421, train loss: 0.6933, test loss: 0.6888, train acc: 0.4954, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 422, train loss: 0.6933, test loss: 0.6937, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 423, train loss: 0.6932, test loss: 0.6927, train acc: 0.4879, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 424, train loss: 0.6932, test loss: 0.6923, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 425, train loss: 0.6932, test loss: 0.6945, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 426, train loss: 0.6933, test loss: 0.6918, train acc: 0.4890, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 427, train loss: 0.6932, test loss: 0.6946, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 428, train loss: 0.6932, test loss: 0.6886, train acc: 0.5045, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 429, train loss: 0.6932, test loss: 0.6913, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 430, train loss: 0.6932, test loss: 0.6903, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 431, train loss: 0.6932, test loss: 0.6966, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 432, train loss: 0.6932, test loss: 0.6936, train acc: 0.5041, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 433, train loss: 0.6932, test loss: 0.6958, train acc: 0.4929, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 434, train loss: 0.6933, test loss: 0.6938, train acc: 0.4857, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 435, train loss: 0.6932, test loss: 0.6988, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 436, train loss: 0.6933, test loss: 0.6929, train acc: 0.4936, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 437, train loss: 0.6932, test loss: 0.6958, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 438, train loss: 0.6932, test loss: 0.6923, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 439, train loss: 0.6932, test loss: 0.6961, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 440, train loss: 0.6932, test loss: 0.6904, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 441, train loss: 0.6931, test loss: 0.6963, train acc: 0.5066, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 442, train loss: 0.6933, test loss: 0.6951, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 443, train loss: 0.6933, test loss: 0.6932, train acc: 0.4911, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 444, train loss: 0.6933, test loss: 0.6913, train acc: 0.4938, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 445, train loss: 0.6932, test loss: 0.6913, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 446, train loss: 0.6932, test loss: 0.6938, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 447, train loss: 0.6933, test loss: 0.6904, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 448, train loss: 0.6932, test loss: 0.6911, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 449, train loss: 0.6933, test loss: 0.6913, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 450, train loss: 0.6932, test loss: 0.6924, train acc: 0.4929, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 451, train loss: 0.6932, test loss: 0.6998, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 452, train loss: 0.6934, test loss: 0.6913, train acc: 0.4942, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 453, train loss: 0.6932, test loss: 0.6901, train acc: 0.4936, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 454, train loss: 0.6933, test loss: 0.6868, train acc: 0.5006, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 455, train loss: 0.6933, test loss: 0.6928, train acc: 0.4951, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 456, train loss: 0.6930, test loss: 0.6867, train acc: 0.5114, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 457, train loss: 0.6933, test loss: 0.6938, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 458, train loss: 0.6932, test loss: 0.6903, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 459, train loss: 0.6931, test loss: 0.6870, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 460, train loss: 0.6933, test loss: 0.6979, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 461, train loss: 0.6932, test loss: 0.6901, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 462, train loss: 0.6932, test loss: 0.6964, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 463, train loss: 0.6934, test loss: 0.6895, train acc: 0.4876, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 464, train loss: 0.6933, test loss: 0.6958, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 465, train loss: 0.6932, test loss: 0.6938, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 466, train loss: 0.6932, test loss: 0.6895, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 467, train loss: 0.6932, test loss: 0.6927, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 468, train loss: 0.6932, test loss: 0.6952, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 469, train loss: 0.6932, test loss: 0.6917, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 470, train loss: 0.6933, test loss: 0.6935, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 471, train loss: 0.6932, test loss: 0.6897, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 472, train loss: 0.6932, test loss: 0.6915, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 473, train loss: 0.6933, test loss: 0.6907, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 474, train loss: 0.6931, test loss: 0.6897, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 475, train loss: 0.6935, test loss: 0.6944, train acc: 0.4923, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 476, train loss: 0.6932, test loss: 0.6951, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 477, train loss: 0.6932, test loss: 0.6884, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 478, train loss: 0.6934, test loss: 0.6919, train acc: 0.4961, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 479, train loss: 0.6933, test loss: 0.6913, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 480, train loss: 0.6932, test loss: 0.6922, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 481, train loss: 0.6933, test loss: 0.6908, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 482, train loss: 0.6931, test loss: 0.6962, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 483, train loss: 0.6931, test loss: 0.7000, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 484, train loss: 0.6931, test loss: 0.6890, train acc: 0.5058, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 485, train loss: 0.6933, test loss: 0.6891, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 486, train loss: 0.6933, test loss: 0.6855, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 487, train loss: 0.6934, test loss: 0.6879, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 488, train loss: 0.6935, test loss: 0.6943, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 489, train loss: 0.6932, test loss: 0.6942, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 490, train loss: 0.6932, test loss: 0.6945, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 491, train loss: 0.6933, test loss: 0.6929, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 492, train loss: 0.6933, test loss: 0.6953, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 493, train loss: 0.6933, test loss: 0.6964, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 494, train loss: 0.6932, test loss: 0.6972, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 495, train loss: 0.6932, test loss: 0.6901, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 496, train loss: 0.6932, test loss: 0.6958, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 497, train loss: 0.6931, test loss: 0.7033, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 498, train loss: 0.6933, test loss: 0.6970, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 499, train loss: 0.6931, test loss: 0.6904, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 500, train loss: 0.6933, test loss: 0.6895, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 501, train loss: 0.6931, test loss: 0.6924, train acc: 0.5086, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 502, train loss: 0.6933, test loss: 0.6949, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 503, train loss: 0.6932, test loss: 0.6915, train acc: 0.4973, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 504, train loss: 0.6932, test loss: 0.6969, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 505, train loss: 0.6932, test loss: 0.7012, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 506, train loss: 0.6933, test loss: 0.6897, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 507, train loss: 0.6934, test loss: 0.6916, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 508, train loss: 0.6933, test loss: 0.6996, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 509, train loss: 0.6934, test loss: 0.6917, train acc: 0.5006, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 510, train loss: 0.6933, test loss: 0.6977, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 511, train loss: 0.6933, test loss: 0.6963, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 512, train loss: 0.6932, test loss: 0.6949, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 513, train loss: 0.6932, test loss: 0.6970, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 514, train loss: 0.6932, test loss: 0.6929, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 515, train loss: 0.6932, test loss: 0.6969, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 516, train loss: 0.6932, test loss: 0.6940, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 517, train loss: 0.6932, test loss: 0.6962, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 518, train loss: 0.6930, test loss: 0.6830, train acc: 0.5106, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 519, train loss: 0.6933, test loss: 0.6862, train acc: 0.5028, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 520, train loss: 0.6934, test loss: 0.6941, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 521, train loss: 0.6933, test loss: 0.6926, train acc: 0.4896, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 522, train loss: 0.6931, test loss: 0.6879, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 523, train loss: 0.6932, test loss: 0.6929, train acc: 0.4961, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 524, train loss: 0.6932, test loss: 0.6914, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 525, train loss: 0.6932, test loss: 0.6968, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 526, train loss: 0.6934, test loss: 0.6924, train acc: 0.4930, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 527, train loss: 0.6933, test loss: 0.6895, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 528, train loss: 0.6932, test loss: 0.6927, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 529, train loss: 0.6931, test loss: 0.6974, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 530, train loss: 0.6934, test loss: 0.6872, train acc: 0.4910, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 531, train loss: 0.6932, test loss: 0.6866, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 532, train loss: 0.6933, test loss: 0.6959, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 533, train loss: 0.6931, test loss: 0.6880, train acc: 0.5067, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 534, train loss: 0.6932, test loss: 0.6959, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 535, train loss: 0.6932, test loss: 0.6935, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 536, train loss: 0.6932, test loss: 0.6982, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 537, train loss: 0.6933, test loss: 0.6903, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 538, train loss: 0.6933, test loss: 0.6960, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 539, train loss: 0.6933, test loss: 0.6962, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 540, train loss: 0.6931, test loss: 0.6974, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 541, train loss: 0.6932, test loss: 0.6982, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 542, train loss: 0.6933, test loss: 0.6943, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 543, train loss: 0.6932, test loss: 0.6892, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 544, train loss: 0.6932, test loss: 0.6906, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 545, train loss: 0.6932, test loss: 0.6911, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 546, train loss: 0.6932, test loss: 0.6922, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 547, train loss: 0.6933, test loss: 0.6936, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 548, train loss: 0.6931, test loss: 0.6867, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 549, train loss: 0.6931, test loss: 0.6932, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 550, train loss: 0.6933, test loss: 0.6953, train acc: 0.4960, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 551, train loss: 0.6931, test loss: 0.6916, train acc: 0.5089, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 552, train loss: 0.6932, test loss: 0.6977, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 553, train loss: 0.6932, test loss: 0.6892, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 554, train loss: 0.6932, test loss: 0.6931, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 555, train loss: 0.6933, test loss: 0.6927, train acc: 0.4935, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 556, train loss: 0.6932, test loss: 0.6939, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 557, train loss: 0.6932, test loss: 0.6929, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 558, train loss: 0.6933, test loss: 0.6962, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 559, train loss: 0.6930, test loss: 0.6973, train acc: 0.5071, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 560, train loss: 0.6931, test loss: 0.6897, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 561, train loss: 0.6932, test loss: 0.6935, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 562, train loss: 0.6932, test loss: 0.6886, train acc: 0.5072, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 563, train loss: 0.6933, test loss: 0.6914, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 564, train loss: 0.6933, test loss: 0.6916, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 565, train loss: 0.6930, test loss: 0.6894, train acc: 0.5119, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 566, train loss: 0.6934, test loss: 0.6956, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 567, train loss: 0.6933, test loss: 0.6993, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 568, train loss: 0.6932, test loss: 0.6945, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 569, train loss: 0.6932, test loss: 0.6859, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 570, train loss: 0.6929, test loss: 0.7037, train acc: 0.5123, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 571, train loss: 0.6932, test loss: 0.6948, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 572, train loss: 0.6930, test loss: 0.6910, train acc: 0.5126, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 573, train loss: 0.6933, test loss: 0.6943, train acc: 0.4933, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 574, train loss: 0.6932, test loss: 0.6950, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 575, train loss: 0.6933, test loss: 0.6911, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 576, train loss: 0.6931, test loss: 0.7007, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 577, train loss: 0.6933, test loss: 0.6960, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 578, train loss: 0.6933, test loss: 0.6956, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 579, train loss: 0.6934, test loss: 0.6939, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 580, train loss: 0.6933, test loss: 0.6916, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 581, train loss: 0.6932, test loss: 0.6952, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 582, train loss: 0.6932, test loss: 0.6875, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 583, train loss: 0.6934, test loss: 0.6981, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 584, train loss: 0.6930, test loss: 0.6959, train acc: 0.5127, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 585, train loss: 0.6932, test loss: 0.6937, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 586, train loss: 0.6932, test loss: 0.6963, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 587, train loss: 0.6933, test loss: 0.6962, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 588, train loss: 0.6932, test loss: 0.6911, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 589, train loss: 0.6933, test loss: 0.6904, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 590, train loss: 0.6933, test loss: 0.6917, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 591, train loss: 0.6932, test loss: 0.6978, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 592, train loss: 0.6931, test loss: 0.6864, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 593, train loss: 0.6933, test loss: 0.6943, train acc: 0.4948, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 594, train loss: 0.6931, test loss: 0.6864, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 595, train loss: 0.6931, test loss: 0.6969, train acc: 0.5055, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 596, train loss: 0.6931, test loss: 0.6888, train acc: 0.5119, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 597, train loss: 0.6934, test loss: 0.6896, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 598, train loss: 0.6932, test loss: 0.6917, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 599, train loss: 0.6932, test loss: 0.6934, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 600, train loss: 0.6931, test loss: 0.6932, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 601, train loss: 0.6932, test loss: 0.6912, train acc: 0.5050, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 602, train loss: 0.6931, test loss: 0.6893, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 603, train loss: 0.6933, test loss: 0.6972, train acc: 0.4953, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 604, train loss: 0.6931, test loss: 0.6929, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 605, train loss: 0.6932, test loss: 0.6938, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 606, train loss: 0.6933, test loss: 0.6941, train acc: 0.4953, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 607, train loss: 0.6932, test loss: 0.6865, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 608, train loss: 0.6931, test loss: 0.6906, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 609, train loss: 0.6932, test loss: 0.6880, train acc: 0.5006, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 610, train loss: 0.6932, test loss: 0.6893, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 611, train loss: 0.6933, test loss: 0.6973, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 612, train loss: 0.6934, test loss: 0.6962, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 613, train loss: 0.6932, test loss: 0.7005, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 614, train loss: 0.6932, test loss: 0.6980, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 615, train loss: 0.6931, test loss: 0.6940, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 616, train loss: 0.6932, test loss: 0.6894, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 617, train loss: 0.6932, test loss: 0.6958, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 618, train loss: 0.6934, test loss: 0.6921, train acc: 0.4862, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 619, train loss: 0.6933, test loss: 0.6909, train acc: 0.5006, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 620, train loss: 0.6933, test loss: 0.6945, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 621, train loss: 0.6933, test loss: 0.6943, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 622, train loss: 0.6932, test loss: 0.6978, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 623, train loss: 0.6932, test loss: 0.6946, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 624, train loss: 0.6932, test loss: 0.6944, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 625, train loss: 0.6930, test loss: 0.6886, train acc: 0.5083, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 626, train loss: 0.6934, test loss: 0.6918, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 627, train loss: 0.6932, test loss: 0.6870, train acc: 0.5037, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 628, train loss: 0.6933, test loss: 0.6874, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 629, train loss: 0.6931, test loss: 0.6975, train acc: 0.5051, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 630, train loss: 0.6932, test loss: 0.6964, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 631, train loss: 0.6925, test loss: 0.6771, train acc: 0.5162, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 632, train loss: 0.6932, test loss: 0.6918, train acc: 0.5075, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 633, train loss: 0.6932, test loss: 0.6934, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 634, train loss: 0.6934, test loss: 0.6920, train acc: 0.4953, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 635, train loss: 0.6933, test loss: 0.6899, train acc: 0.4925, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 636, train loss: 0.6931, test loss: 0.6901, train acc: 0.5094, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 637, train loss: 0.6933, test loss: 0.6939, train acc: 0.4884, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 638, train loss: 0.6932, test loss: 0.6923, train acc: 0.4986, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 639, train loss: 0.6932, test loss: 0.6971, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 640, train loss: 0.6932, test loss: 0.6881, train acc: 0.5040, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 641, train loss: 0.6933, test loss: 0.6894, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 642, train loss: 0.6932, test loss: 0.6950, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 643, train loss: 0.6933, test loss: 0.6974, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 644, train loss: 0.6931, test loss: 0.6868, train acc: 0.5080, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 645, train loss: 0.6933, test loss: 0.6913, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 646, train loss: 0.6932, test loss: 0.6930, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 647, train loss: 0.6931, test loss: 0.6932, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 648, train loss: 0.6931, test loss: 0.6861, train acc: 0.5069, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 649, train loss: 0.6932, test loss: 0.6900, train acc: 0.4980, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 650, train loss: 0.6933, test loss: 0.6898, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 651, train loss: 0.6932, test loss: 0.6891, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 652, train loss: 0.6932, test loss: 0.6891, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 653, train loss: 0.6933, test loss: 0.6907, train acc: 0.4920, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 654, train loss: 0.6932, test loss: 0.6942, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 655, train loss: 0.6932, test loss: 0.6965, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 656, train loss: 0.6933, test loss: 0.6934, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 657, train loss: 0.6931, test loss: 0.6887, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 658, train loss: 0.6933, test loss: 0.6963, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 659, train loss: 0.6930, test loss: 0.6843, train acc: 0.5085, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 660, train loss: 0.6930, test loss: 0.6929, train acc: 0.5091, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 661, train loss: 0.6932, test loss: 0.6995, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 662, train loss: 0.6934, test loss: 0.6937, train acc: 0.4948, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 663, train loss: 0.6933, test loss: 0.6917, train acc: 0.4932, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 664, train loss: 0.6932, test loss: 0.6969, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 665, train loss: 0.6933, test loss: 0.6935, train acc: 0.4953, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 666, train loss: 0.6932, test loss: 0.6924, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 667, train loss: 0.6932, test loss: 0.6883, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 668, train loss: 0.6933, test loss: 0.6954, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 669, train loss: 0.6933, test loss: 0.6935, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 670, train loss: 0.6932, test loss: 0.6978, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 671, train loss: 0.6931, test loss: 0.6938, train acc: 0.5041, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 672, train loss: 0.6933, test loss: 0.6925, train acc: 0.4953, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 673, train loss: 0.6932, test loss: 0.6977, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 674, train loss: 0.6931, test loss: 0.6894, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 675, train loss: 0.6928, test loss: 0.6858, train acc: 0.5155, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 676, train loss: 0.6932, test loss: 0.6980, train acc: 0.5049, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 677, train loss: 0.6933, test loss: 0.6904, train acc: 0.5006, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 678, train loss: 0.6933, test loss: 0.6958, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 679, train loss: 0.6931, test loss: 0.6881, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 680, train loss: 0.6933, test loss: 0.6876, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 681, train loss: 0.6931, test loss: 0.6866, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 682, train loss: 0.6932, test loss: 0.6951, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 683, train loss: 0.6934, test loss: 0.6962, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 684, train loss: 0.6933, test loss: 0.6912, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 685, train loss: 0.6933, test loss: 0.6918, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 686, train loss: 0.6934, test loss: 0.6914, train acc: 0.4926, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 687, train loss: 0.6932, test loss: 0.6993, train acc: 0.5046, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 688, train loss: 0.6932, test loss: 0.6958, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 689, train loss: 0.6933, test loss: 0.6943, train acc: 0.4936, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 690, train loss: 0.6932, test loss: 0.6924, train acc: 0.5076, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 691, train loss: 0.6933, test loss: 0.6915, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 692, train loss: 0.6933, test loss: 0.6963, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 693, train loss: 0.6932, test loss: 0.6929, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 694, train loss: 0.6932, test loss: 0.6930, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 695, train loss: 0.6933, test loss: 0.6936, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 696, train loss: 0.6932, test loss: 0.6980, train acc: 0.5021, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 697, train loss: 0.6932, test loss: 0.6928, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 698, train loss: 0.6932, test loss: 0.6944, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 699, train loss: 0.6932, test loss: 0.6952, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 700, train loss: 0.6933, test loss: 0.6962, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 701, train loss: 0.6932, test loss: 0.6859, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 702, train loss: 0.6931, test loss: 0.6974, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 703, train loss: 0.6929, test loss: 0.7024, train acc: 0.5128, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 704, train loss: 0.6934, test loss: 0.6907, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 705, train loss: 0.6932, test loss: 0.6950, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 706, train loss: 0.6935, test loss: 0.6904, train acc: 0.4973, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 707, train loss: 0.6932, test loss: 0.6999, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 708, train loss: 0.6934, test loss: 0.6918, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 709, train loss: 0.6931, test loss: 0.7020, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 710, train loss: 0.6932, test loss: 0.6907, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 711, train loss: 0.6934, test loss: 0.6928, train acc: 0.4844, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 712, train loss: 0.6933, test loss: 0.6942, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 713, train loss: 0.6932, test loss: 0.6920, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 714, train loss: 0.6933, test loss: 0.6944, train acc: 0.4945, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 715, train loss: 0.6932, test loss: 0.7013, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 716, train loss: 0.6934, test loss: 0.6976, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 717, train loss: 0.6933, test loss: 0.6939, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 718, train loss: 0.6933, test loss: 0.6886, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 719, train loss: 0.6932, test loss: 0.6926, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 720, train loss: 0.6932, test loss: 0.6917, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 721, train loss: 0.6932, test loss: 0.6909, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 722, train loss: 0.6933, test loss: 0.6929, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 723, train loss: 0.6932, test loss: 0.6950, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 724, train loss: 0.6932, test loss: 0.6926, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 725, train loss: 0.6933, test loss: 0.6919, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 726, train loss: 0.6932, test loss: 0.6927, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 727, train loss: 0.6929, test loss: 0.7045, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 728, train loss: 0.6933, test loss: 0.6914, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 729, train loss: 0.6933, test loss: 0.6901, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 730, train loss: 0.6931, test loss: 0.6936, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 731, train loss: 0.6930, test loss: 0.7036, train acc: 0.5062, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 732, train loss: 0.6933, test loss: 0.6946, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 733, train loss: 0.6932, test loss: 0.6919, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 734, train loss: 0.6932, test loss: 0.6905, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 735, train loss: 0.6933, test loss: 0.6955, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 736, train loss: 0.6931, test loss: 0.6893, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 737, train loss: 0.6935, test loss: 0.6990, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 738, train loss: 0.6932, test loss: 0.6919, train acc: 0.5014, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 739, train loss: 0.6932, test loss: 0.6964, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 740, train loss: 0.6931, test loss: 0.6899, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 741, train loss: 0.6932, test loss: 0.6978, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 742, train loss: 0.6932, test loss: 0.7005, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 743, train loss: 0.6933, test loss: 0.6924, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 744, train loss: 0.6933, test loss: 0.6929, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 745, train loss: 0.6931, test loss: 0.6917, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 746, train loss: 0.6932, test loss: 0.6978, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 747, train loss: 0.6932, test loss: 0.6915, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 748, train loss: 0.6932, test loss: 0.6924, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 749, train loss: 0.6932, test loss: 0.6884, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 750, train loss: 0.6933, test loss: 0.6893, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 751, train loss: 0.6931, test loss: 0.6922, train acc: 0.5062, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 752, train loss: 0.6933, test loss: 0.6917, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 753, train loss: 0.6932, test loss: 0.6932, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 754, train loss: 0.6932, test loss: 0.6892, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 755, train loss: 0.6931, test loss: 0.6885, train acc: 0.5097, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 756, train loss: 0.6931, test loss: 0.6934, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 757, train loss: 0.6932, test loss: 0.6893, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 758, train loss: 0.6929, test loss: 0.6992, train acc: 0.5092, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 759, train loss: 0.6932, test loss: 0.6932, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 760, train loss: 0.6932, test loss: 0.6984, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 761, train loss: 0.6932, test loss: 0.6909, train acc: 0.4918, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 762, train loss: 0.6932, test loss: 0.6905, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 763, train loss: 0.6932, test loss: 0.6991, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 764, train loss: 0.6934, test loss: 0.6904, train acc: 0.4917, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 765, train loss: 0.6932, test loss: 0.6915, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 766, train loss: 0.6932, test loss: 0.6925, train acc: 0.5028, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 767, train loss: 0.6933, test loss: 0.6969, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 768, train loss: 0.6932, test loss: 0.6952, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 769, train loss: 0.6933, test loss: 0.6956, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 770, train loss: 0.6933, test loss: 0.6936, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 771, train loss: 0.6931, test loss: 0.6932, train acc: 0.5092, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 772, train loss: 0.6932, test loss: 0.6908, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 773, train loss: 0.6932, test loss: 0.6965, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 774, train loss: 0.6932, test loss: 0.6932, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 775, train loss: 0.6933, test loss: 0.6923, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 776, train loss: 0.6932, test loss: 0.6889, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 777, train loss: 0.6934, test loss: 0.6982, train acc: 0.4940, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 778, train loss: 0.6931, test loss: 0.6946, train acc: 0.5061, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 779, train loss: 0.6932, test loss: 0.6876, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 780, train loss: 0.6932, test loss: 0.6889, train acc: 0.5066, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 781, train loss: 0.6933, test loss: 0.6954, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 782, train loss: 0.6932, test loss: 0.6918, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 783, train loss: 0.6931, test loss: 0.6926, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 784, train loss: 0.6931, test loss: 0.6938, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 785, train loss: 0.6932, test loss: 0.6929, train acc: 0.4911, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 786, train loss: 0.6933, test loss: 0.6882, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 787, train loss: 0.6931, test loss: 0.6968, train acc: 0.5069, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 788, train loss: 0.6933, test loss: 0.6924, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 789, train loss: 0.6932, test loss: 0.6937, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 790, train loss: 0.6933, test loss: 0.6969, train acc: 0.4952, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 791, train loss: 0.6931, test loss: 0.6882, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 792, train loss: 0.6932, test loss: 0.6986, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 793, train loss: 0.6934, test loss: 0.6991, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 794, train loss: 0.6930, test loss: 0.7019, train acc: 0.5062, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 795, train loss: 0.6933, test loss: 0.7009, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 796, train loss: 0.6931, test loss: 0.6911, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 797, train loss: 0.6933, test loss: 0.6921, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 798, train loss: 0.6932, test loss: 0.6869, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 799, train loss: 0.6931, test loss: 0.6969, train acc: 0.5073, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "Trial 1 - Fold 1 - Params: {'weightdecay': 'yes', 'batch_norm': 'no', 'dropout': 'no', 'L2lambda': 0.1}\n",
      "Additional Hyperparameters -> Weight Decay: 0.1\n",
      "FOLD 1\n",
      "--------\n",
      "epoch: 0, train loss: 0.6932, test loss: 0.6901, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 1, train loss: 0.6932, test loss: 0.6941, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 2, train loss: 0.6932, test loss: 0.6932, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 3, train loss: 0.6933, test loss: 0.6963, train acc: 0.4925, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 4, train loss: 0.6933, test loss: 0.6901, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 5, train loss: 0.6932, test loss: 0.6940, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 6, train loss: 0.6933, test loss: 0.6935, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 7, train loss: 0.6933, test loss: 0.6956, train acc: 0.4891, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 8, train loss: 0.6932, test loss: 0.7009, train acc: 0.5060, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 9, train loss: 0.6933, test loss: 0.7014, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 10, train loss: 0.6933, test loss: 0.6938, train acc: 0.4905, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 11, train loss: 0.6933, test loss: 0.6913, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 12, train loss: 0.6932, test loss: 0.6964, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 13, train loss: 0.6932, test loss: 0.6879, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 14, train loss: 0.6933, test loss: 0.6991, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 15, train loss: 0.6931, test loss: 0.6909, train acc: 0.5083, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 16, train loss: 0.6932, test loss: 0.6917, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 17, train loss: 0.6933, test loss: 0.6943, train acc: 0.4916, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 18, train loss: 0.6933, test loss: 0.6927, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 19, train loss: 0.6933, test loss: 0.6887, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 20, train loss: 0.6932, test loss: 0.6870, train acc: 0.5058, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 21, train loss: 0.6932, test loss: 0.6995, train acc: 0.5065, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 22, train loss: 0.6933, test loss: 0.6949, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 23, train loss: 0.6932, test loss: 0.6927, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 24, train loss: 0.6933, test loss: 0.6917, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 25, train loss: 0.6932, test loss: 0.6930, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 26, train loss: 0.6933, test loss: 0.6934, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 27, train loss: 0.6932, test loss: 0.6937, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 28, train loss: 0.6931, test loss: 0.6938, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 29, train loss: 0.6931, test loss: 0.6983, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 30, train loss: 0.6933, test loss: 0.6899, train acc: 0.4912, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 31, train loss: 0.6931, test loss: 0.6965, train acc: 0.5084, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 32, train loss: 0.6932, test loss: 0.6950, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 33, train loss: 0.6931, test loss: 0.6882, train acc: 0.5072, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 34, train loss: 0.6933, test loss: 0.6954, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 35, train loss: 0.6932, test loss: 0.6967, train acc: 0.4960, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 36, train loss: 0.6932, test loss: 0.6990, train acc: 0.4998, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 37, train loss: 0.6933, test loss: 0.6957, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 38, train loss: 0.6931, test loss: 0.6997, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 39, train loss: 0.6933, test loss: 0.6900, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 40, train loss: 0.6933, test loss: 0.6939, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 41, train loss: 0.6932, test loss: 0.6892, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 42, train loss: 0.6933, test loss: 0.6935, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 43, train loss: 0.6932, test loss: 0.6868, train acc: 0.4926, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 44, train loss: 0.6929, test loss: 0.6860, train acc: 0.5150, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 45, train loss: 0.6932, test loss: 0.6900, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 46, train loss: 0.6933, test loss: 0.6916, train acc: 0.5014, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 47, train loss: 0.6932, test loss: 0.6930, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 48, train loss: 0.6930, test loss: 0.6836, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 49, train loss: 0.6934, test loss: 0.6937, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 50, train loss: 0.6932, test loss: 0.6919, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 51, train loss: 0.6932, test loss: 0.6964, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 52, train loss: 0.6931, test loss: 0.7003, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 53, train loss: 0.6931, test loss: 0.6968, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 54, train loss: 0.6933, test loss: 0.6941, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 55, train loss: 0.6932, test loss: 0.6891, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 56, train loss: 0.6933, test loss: 0.6905, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 57, train loss: 0.6933, test loss: 0.6937, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 58, train loss: 0.6932, test loss: 0.6948, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 59, train loss: 0.6931, test loss: 0.6909, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 60, train loss: 0.6932, test loss: 0.6960, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 61, train loss: 0.6933, test loss: 0.6981, train acc: 0.4998, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 62, train loss: 0.6933, test loss: 0.6948, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 63, train loss: 0.6932, test loss: 0.6922, train acc: 0.4942, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 64, train loss: 0.6932, test loss: 0.6957, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 65, train loss: 0.6933, test loss: 0.6907, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 66, train loss: 0.6932, test loss: 0.6959, train acc: 0.5058, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 67, train loss: 0.6932, test loss: 0.6952, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 68, train loss: 0.6933, test loss: 0.6916, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 69, train loss: 0.6932, test loss: 0.6945, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 70, train loss: 0.6933, test loss: 0.6971, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 71, train loss: 0.6933, test loss: 0.6951, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 72, train loss: 0.6932, test loss: 0.6923, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 73, train loss: 0.6932, test loss: 0.6930, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 74, train loss: 0.6931, test loss: 0.6865, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 75, train loss: 0.6932, test loss: 0.6869, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 76, train loss: 0.6933, test loss: 0.6910, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 77, train loss: 0.6934, test loss: 0.6887, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 78, train loss: 0.6932, test loss: 0.6918, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 79, train loss: 0.6931, test loss: 0.6936, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 80, train loss: 0.6933, test loss: 0.6923, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 81, train loss: 0.6932, test loss: 0.6901, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 82, train loss: 0.6933, test loss: 0.6889, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 83, train loss: 0.6932, test loss: 0.6955, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 84, train loss: 0.6933, test loss: 0.6934, train acc: 0.4933, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 85, train loss: 0.6933, test loss: 0.6928, train acc: 0.4915, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 86, train loss: 0.6932, test loss: 0.6971, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 87, train loss: 0.6933, test loss: 0.6942, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 88, train loss: 0.6932, test loss: 0.6962, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 89, train loss: 0.6932, test loss: 0.6968, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 90, train loss: 0.6933, test loss: 0.6941, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 91, train loss: 0.6932, test loss: 0.6922, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 92, train loss: 0.6932, test loss: 0.6892, train acc: 0.5059, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 93, train loss: 0.6933, test loss: 0.6972, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 94, train loss: 0.6933, test loss: 0.6893, train acc: 0.4907, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 95, train loss: 0.6932, test loss: 0.6963, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 96, train loss: 0.6933, test loss: 0.6969, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 97, train loss: 0.6933, test loss: 0.6932, train acc: 0.4900, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 98, train loss: 0.6933, test loss: 0.6933, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 99, train loss: 0.6933, test loss: 0.6925, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 100, train loss: 0.6932, test loss: 0.6906, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 101, train loss: 0.6931, test loss: 0.6971, train acc: 0.5072, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 102, train loss: 0.6932, test loss: 0.6930, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 103, train loss: 0.6934, test loss: 0.6939, train acc: 0.4914, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 104, train loss: 0.6932, test loss: 0.6899, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 105, train loss: 0.6932, test loss: 0.6896, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 106, train loss: 0.6933, test loss: 0.6971, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 107, train loss: 0.6933, test loss: 0.6951, train acc: 0.4970, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 108, train loss: 0.6932, test loss: 0.6957, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 109, train loss: 0.6933, test loss: 0.6901, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 110, train loss: 0.6932, test loss: 0.6917, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 111, train loss: 0.6932, test loss: 0.6930, train acc: 0.5037, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 112, train loss: 0.6932, test loss: 0.6916, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 113, train loss: 0.6932, test loss: 0.6865, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 114, train loss: 0.6933, test loss: 0.6918, train acc: 0.5003, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 115, train loss: 0.6933, test loss: 0.6908, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 116, train loss: 0.6931, test loss: 0.6981, train acc: 0.5060, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 117, train loss: 0.6933, test loss: 0.6946, train acc: 0.4959, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 118, train loss: 0.6932, test loss: 0.6979, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 119, train loss: 0.6931, test loss: 0.6885, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 120, train loss: 0.6930, test loss: 0.6920, train acc: 0.5085, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 121, train loss: 0.6931, test loss: 0.6977, train acc: 0.5075, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 122, train loss: 0.6932, test loss: 0.6955, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 123, train loss: 0.6932, test loss: 0.6969, train acc: 0.4936, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 124, train loss: 0.6931, test loss: 0.7025, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 125, train loss: 0.6936, test loss: 0.6894, train acc: 0.4876, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 126, train loss: 0.6932, test loss: 0.6943, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 127, train loss: 0.6929, test loss: 0.6862, train acc: 0.5082, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 128, train loss: 0.6934, test loss: 0.6898, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 129, train loss: 0.6933, test loss: 0.6966, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 130, train loss: 0.6932, test loss: 0.6925, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 131, train loss: 0.6932, test loss: 0.6955, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 132, train loss: 0.6932, test loss: 0.6958, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 133, train loss: 0.6931, test loss: 0.6952, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 134, train loss: 0.6933, test loss: 0.6920, train acc: 0.4945, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 135, train loss: 0.6934, test loss: 0.6959, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 136, train loss: 0.6933, test loss: 0.6964, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 137, train loss: 0.6932, test loss: 0.6927, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 138, train loss: 0.6932, test loss: 0.6930, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 139, train loss: 0.6927, test loss: 0.6817, train acc: 0.5139, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 140, train loss: 0.6931, test loss: 0.6914, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 141, train loss: 0.6933, test loss: 0.6941, train acc: 0.4929, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 142, train loss: 0.6933, test loss: 0.6951, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 143, train loss: 0.6932, test loss: 0.6893, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 144, train loss: 0.6931, test loss: 0.6939, train acc: 0.5065, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 145, train loss: 0.6932, test loss: 0.6970, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 146, train loss: 0.6933, test loss: 0.6892, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 147, train loss: 0.6933, test loss: 0.6933, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 148, train loss: 0.6932, test loss: 0.6967, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 149, train loss: 0.6932, test loss: 0.6900, train acc: 0.4942, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 150, train loss: 0.6932, test loss: 0.6866, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 151, train loss: 0.6934, test loss: 0.6904, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 152, train loss: 0.6932, test loss: 0.6928, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 153, train loss: 0.6932, test loss: 0.6877, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 154, train loss: 0.6934, test loss: 0.6917, train acc: 0.4899, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 155, train loss: 0.6931, test loss: 0.6844, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 156, train loss: 0.6934, test loss: 0.6974, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 157, train loss: 0.6931, test loss: 0.6900, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 158, train loss: 0.6930, test loss: 0.6846, train acc: 0.5104, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 159, train loss: 0.6934, test loss: 0.6956, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 160, train loss: 0.6931, test loss: 0.6855, train acc: 0.5066, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 161, train loss: 0.6933, test loss: 0.6909, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 162, train loss: 0.6932, test loss: 0.6974, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 163, train loss: 0.6933, test loss: 0.6930, train acc: 0.4929, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 164, train loss: 0.6932, test loss: 0.6924, train acc: 0.4939, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 165, train loss: 0.6932, test loss: 0.7004, train acc: 0.4983, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 166, train loss: 0.6932, test loss: 0.6878, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 167, train loss: 0.6932, test loss: 0.6932, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 168, train loss: 0.6932, test loss: 0.6982, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 169, train loss: 0.6933, test loss: 0.6922, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 170, train loss: 0.6935, test loss: 0.6928, train acc: 0.4892, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 171, train loss: 0.6932, test loss: 0.6928, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 172, train loss: 0.6933, test loss: 0.6926, train acc: 0.4943, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 173, train loss: 0.6932, test loss: 0.6964, train acc: 0.5082, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 174, train loss: 0.6933, test loss: 0.6971, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 175, train loss: 0.6932, test loss: 0.6921, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 176, train loss: 0.6935, test loss: 0.6975, train acc: 0.4901, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 177, train loss: 0.6934, test loss: 0.6936, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 178, train loss: 0.6932, test loss: 0.6966, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 179, train loss: 0.6932, test loss: 0.6937, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 180, train loss: 0.6933, test loss: 0.6956, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 181, train loss: 0.6931, test loss: 0.6975, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 182, train loss: 0.6934, test loss: 0.6911, train acc: 0.4920, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 183, train loss: 0.6930, test loss: 0.6985, train acc: 0.5088, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 184, train loss: 0.6933, test loss: 0.6991, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 185, train loss: 0.6934, test loss: 0.6938, train acc: 0.4960, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 186, train loss: 0.6931, test loss: 0.6871, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 187, train loss: 0.6932, test loss: 0.6928, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 188, train loss: 0.6931, test loss: 0.6961, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 189, train loss: 0.6932, test loss: 0.6989, train acc: 0.4942, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 190, train loss: 0.6933, test loss: 0.6937, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 191, train loss: 0.6932, test loss: 0.6977, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 192, train loss: 0.6931, test loss: 0.6853, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 193, train loss: 0.6932, test loss: 0.6965, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 194, train loss: 0.6933, test loss: 0.6926, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 195, train loss: 0.6932, test loss: 0.6950, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 196, train loss: 0.6932, test loss: 0.6928, train acc: 0.4885, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 197, train loss: 0.6933, test loss: 0.6934, train acc: 0.4918, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 198, train loss: 0.6932, test loss: 0.6901, train acc: 0.5083, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 199, train loss: 0.6932, test loss: 0.6911, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 200, train loss: 0.6933, test loss: 0.6914, train acc: 0.4946, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 201, train loss: 0.6932, test loss: 0.6919, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 202, train loss: 0.6931, test loss: 0.6989, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 203, train loss: 0.6931, test loss: 0.6869, train acc: 0.5082, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 204, train loss: 0.6932, test loss: 0.6954, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 205, train loss: 0.6932, test loss: 0.6893, train acc: 0.5059, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 206, train loss: 0.6932, test loss: 0.6886, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 207, train loss: 0.6933, test loss: 0.6843, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 208, train loss: 0.6932, test loss: 0.6985, train acc: 0.5072, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 209, train loss: 0.6933, test loss: 0.6888, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 210, train loss: 0.6934, test loss: 0.6904, train acc: 0.4891, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 211, train loss: 0.6932, test loss: 0.6887, train acc: 0.5051, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 212, train loss: 0.6932, test loss: 0.6935, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 213, train loss: 0.6932, test loss: 0.6927, train acc: 0.4908, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 214, train loss: 0.6931, test loss: 0.6902, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 215, train loss: 0.6933, test loss: 0.6892, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 216, train loss: 0.6932, test loss: 0.6966, train acc: 0.5046, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 217, train loss: 0.6933, test loss: 0.6948, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 218, train loss: 0.6931, test loss: 0.6874, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 219, train loss: 0.6931, test loss: 0.6968, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 220, train loss: 0.6932, test loss: 0.6932, train acc: 0.5046, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 221, train loss: 0.6933, test loss: 0.6927, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 222, train loss: 0.6933, test loss: 0.6932, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 223, train loss: 0.6932, test loss: 0.6901, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 224, train loss: 0.6933, test loss: 0.6908, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 225, train loss: 0.6931, test loss: 0.6991, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 226, train loss: 0.6932, test loss: 0.6946, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 227, train loss: 0.6933, test loss: 0.6987, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 228, train loss: 0.6933, test loss: 0.6882, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 229, train loss: 0.6934, test loss: 0.6948, train acc: 0.4911, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 230, train loss: 0.6932, test loss: 0.6977, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 231, train loss: 0.6933, test loss: 0.6905, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 232, train loss: 0.6933, test loss: 0.6940, train acc: 0.4937, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 233, train loss: 0.6932, test loss: 0.6926, train acc: 0.5045, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 234, train loss: 0.6932, test loss: 0.6918, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 235, train loss: 0.6931, test loss: 0.6985, train acc: 0.5058, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 236, train loss: 0.6932, test loss: 0.6936, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 237, train loss: 0.6932, test loss: 0.6943, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 238, train loss: 0.6932, test loss: 0.6902, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 239, train loss: 0.6931, test loss: 0.6970, train acc: 0.5085, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 240, train loss: 0.6933, test loss: 0.6939, train acc: 0.4911, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 241, train loss: 0.6933, test loss: 0.6977, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 242, train loss: 0.6932, test loss: 0.6955, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 243, train loss: 0.6932, test loss: 0.6952, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 244, train loss: 0.6932, test loss: 0.6930, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 245, train loss: 0.6932, test loss: 0.6881, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 246, train loss: 0.6933, test loss: 0.6890, train acc: 0.4895, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 247, train loss: 0.6933, test loss: 0.6922, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 248, train loss: 0.6932, test loss: 0.6976, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 249, train loss: 0.6931, test loss: 0.6867, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 250, train loss: 0.6934, test loss: 0.7007, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 251, train loss: 0.6931, test loss: 0.6876, train acc: 0.5086, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 252, train loss: 0.6932, test loss: 0.6954, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 253, train loss: 0.6934, test loss: 0.6937, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 254, train loss: 0.6933, test loss: 0.6916, train acc: 0.4887, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 255, train loss: 0.6933, test loss: 0.6929, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 256, train loss: 0.6932, test loss: 0.6933, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 257, train loss: 0.6932, test loss: 0.6880, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 258, train loss: 0.6932, test loss: 0.6925, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 259, train loss: 0.6933, test loss: 0.6896, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 260, train loss: 0.6931, test loss: 0.7022, train acc: 0.5098, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 261, train loss: 0.6932, test loss: 0.6960, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 262, train loss: 0.6933, test loss: 0.6940, train acc: 0.4952, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 263, train loss: 0.6932, test loss: 0.6896, train acc: 0.5076, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 264, train loss: 0.6932, test loss: 0.6938, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 265, train loss: 0.6933, test loss: 0.6935, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 266, train loss: 0.6933, test loss: 0.6910, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 267, train loss: 0.6933, test loss: 0.6914, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 268, train loss: 0.6933, test loss: 0.6886, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 269, train loss: 0.6932, test loss: 0.6917, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 270, train loss: 0.6932, test loss: 0.6943, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 271, train loss: 0.6933, test loss: 0.6931, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 272, train loss: 0.6932, test loss: 0.6952, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 273, train loss: 0.6932, test loss: 0.6921, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 274, train loss: 0.6930, test loss: 0.6956, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 275, train loss: 0.6933, test loss: 0.6880, train acc: 0.5091, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 276, train loss: 0.6933, test loss: 0.6892, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 277, train loss: 0.6933, test loss: 0.6940, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 278, train loss: 0.6932, test loss: 0.6977, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 279, train loss: 0.6932, test loss: 0.6975, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 280, train loss: 0.6934, test loss: 0.6877, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 281, train loss: 0.6933, test loss: 0.6908, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 282, train loss: 0.6932, test loss: 0.6854, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 283, train loss: 0.6933, test loss: 0.6906, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 284, train loss: 0.6933, test loss: 0.6922, train acc: 0.4909, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 285, train loss: 0.6932, test loss: 0.6941, train acc: 0.4932, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 286, train loss: 0.6932, test loss: 0.6908, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 287, train loss: 0.6932, test loss: 0.7007, train acc: 0.4973, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 288, train loss: 0.6933, test loss: 0.6946, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 289, train loss: 0.6931, test loss: 0.7007, train acc: 0.5070, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 290, train loss: 0.6931, test loss: 0.6860, train acc: 0.5068, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 291, train loss: 0.6933, test loss: 0.6957, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 292, train loss: 0.6933, test loss: 0.6975, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 293, train loss: 0.6933, test loss: 0.6942, train acc: 0.4914, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 294, train loss: 0.6932, test loss: 0.6955, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 295, train loss: 0.6932, test loss: 0.6979, train acc: 0.4947, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 296, train loss: 0.6932, test loss: 0.6970, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 297, train loss: 0.6931, test loss: 0.6959, train acc: 0.5058, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 298, train loss: 0.6932, test loss: 0.6971, train acc: 0.5078, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 299, train loss: 0.6933, test loss: 0.6904, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 300, train loss: 0.6931, test loss: 0.6932, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 301, train loss: 0.6933, test loss: 0.6931, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 302, train loss: 0.6934, test loss: 0.6905, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 303, train loss: 0.6932, test loss: 0.6992, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 304, train loss: 0.6933, test loss: 0.6917, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 305, train loss: 0.6931, test loss: 0.6886, train acc: 0.5084, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 306, train loss: 0.6932, test loss: 0.6910, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 307, train loss: 0.6933, test loss: 0.6904, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 308, train loss: 0.6932, test loss: 0.6994, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 309, train loss: 0.6932, test loss: 0.6924, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 310, train loss: 0.6933, test loss: 0.6926, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 311, train loss: 0.6932, test loss: 0.6893, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 312, train loss: 0.6932, test loss: 0.6919, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 313, train loss: 0.6932, test loss: 0.6996, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 314, train loss: 0.6933, test loss: 0.6884, train acc: 0.4973, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 315, train loss: 0.6931, test loss: 0.7044, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 316, train loss: 0.6931, test loss: 0.6925, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 317, train loss: 0.6932, test loss: 0.6899, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 318, train loss: 0.6932, test loss: 0.6928, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 319, train loss: 0.6932, test loss: 0.6917, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 320, train loss: 0.6933, test loss: 0.6947, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 321, train loss: 0.6932, test loss: 0.6953, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 322, train loss: 0.6933, test loss: 0.6951, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 323, train loss: 0.6934, test loss: 0.6956, train acc: 0.4903, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 324, train loss: 0.6932, test loss: 0.6923, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 325, train loss: 0.6932, test loss: 0.6882, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 326, train loss: 0.6933, test loss: 0.6956, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 327, train loss: 0.6933, test loss: 0.6933, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 328, train loss: 0.6933, test loss: 0.6932, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 329, train loss: 0.6933, test loss: 0.6895, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 330, train loss: 0.6932, test loss: 0.6900, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 331, train loss: 0.6931, test loss: 0.6909, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 332, train loss: 0.6932, test loss: 0.6872, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 333, train loss: 0.6931, test loss: 0.6983, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 334, train loss: 0.6931, test loss: 0.6877, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 335, train loss: 0.6932, test loss: 0.6943, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 336, train loss: 0.6933, test loss: 0.6937, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 337, train loss: 0.6931, test loss: 0.6863, train acc: 0.5069, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 338, train loss: 0.6932, test loss: 0.6949, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 339, train loss: 0.6933, test loss: 0.6946, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 340, train loss: 0.6930, test loss: 0.6992, train acc: 0.5074, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 341, train loss: 0.6933, test loss: 0.6927, train acc: 0.4936, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 342, train loss: 0.6932, test loss: 0.6892, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 343, train loss: 0.6933, test loss: 0.6986, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 344, train loss: 0.6932, test loss: 0.6883, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 345, train loss: 0.6933, test loss: 0.6891, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 346, train loss: 0.6931, test loss: 0.6981, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 347, train loss: 0.6934, test loss: 0.6936, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 348, train loss: 0.6933, test loss: 0.6920, train acc: 0.4945, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 349, train loss: 0.6931, test loss: 0.6908, train acc: 0.5060, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 350, train loss: 0.6932, test loss: 0.6939, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 351, train loss: 0.6931, test loss: 0.6859, train acc: 0.5077, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 352, train loss: 0.6933, test loss: 0.6966, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 353, train loss: 0.6932, test loss: 0.6908, train acc: 0.5056, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 354, train loss: 0.6933, test loss: 0.6936, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 355, train loss: 0.6931, test loss: 0.6935, train acc: 0.5089, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 356, train loss: 0.6932, test loss: 0.6986, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 357, train loss: 0.6930, test loss: 0.7021, train acc: 0.5064, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 358, train loss: 0.6932, test loss: 0.6922, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 359, train loss: 0.6932, test loss: 0.6948, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 360, train loss: 0.6932, test loss: 0.6878, train acc: 0.5048, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 361, train loss: 0.6931, test loss: 0.6958, train acc: 0.5073, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 362, train loss: 0.6932, test loss: 0.6878, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 363, train loss: 0.6931, test loss: 0.6876, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 364, train loss: 0.6932, test loss: 0.6965, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 365, train loss: 0.6932, test loss: 0.6979, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 366, train loss: 0.6932, test loss: 0.6951, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 367, train loss: 0.6932, test loss: 0.6934, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 368, train loss: 0.6932, test loss: 0.6921, train acc: 0.4921, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 369, train loss: 0.6932, test loss: 0.6873, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 370, train loss: 0.6933, test loss: 0.6908, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 371, train loss: 0.6932, test loss: 0.6991, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 372, train loss: 0.6931, test loss: 0.6924, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 373, train loss: 0.6931, test loss: 0.6901, train acc: 0.5080, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 374, train loss: 0.6933, test loss: 0.6936, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 375, train loss: 0.6932, test loss: 0.6906, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 376, train loss: 0.6932, test loss: 0.6890, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 377, train loss: 0.6932, test loss: 0.6943, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 378, train loss: 0.6932, test loss: 0.6915, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 379, train loss: 0.6933, test loss: 0.6914, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 380, train loss: 0.6932, test loss: 0.6963, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 381, train loss: 0.6932, test loss: 0.6981, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 382, train loss: 0.6929, test loss: 0.6855, train acc: 0.5099, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 383, train loss: 0.6934, test loss: 0.6930, train acc: 0.4958, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 384, train loss: 0.6932, test loss: 0.7014, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 385, train loss: 0.6931, test loss: 0.6891, train acc: 0.5062, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 386, train loss: 0.6931, test loss: 0.6965, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 387, train loss: 0.6932, test loss: 0.6893, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 388, train loss: 0.6933, test loss: 0.6964, train acc: 0.4930, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 389, train loss: 0.6934, test loss: 0.6956, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 390, train loss: 0.6934, test loss: 0.6906, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 391, train loss: 0.6932, test loss: 0.6913, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 392, train loss: 0.6932, test loss: 0.6926, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 393, train loss: 0.6932, test loss: 0.6924, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 394, train loss: 0.6933, test loss: 0.6913, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 395, train loss: 0.6932, test loss: 0.6943, train acc: 0.5000, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 396, train loss: 0.6933, test loss: 0.6946, train acc: 0.4944, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 397, train loss: 0.6931, test loss: 0.6969, train acc: 0.5041, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 398, train loss: 0.6933, test loss: 0.6904, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 399, train loss: 0.6932, test loss: 0.6996, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 400, train loss: 0.6933, test loss: 0.6950, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 401, train loss: 0.6932, test loss: 0.6965, train acc: 0.4917, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 402, train loss: 0.6931, test loss: 0.6993, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 403, train loss: 0.6930, test loss: 0.6890, train acc: 0.5071, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 404, train loss: 0.6931, test loss: 0.6982, train acc: 0.5087, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 405, train loss: 0.6932, test loss: 0.6931, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 406, train loss: 0.6931, test loss: 0.6938, train acc: 0.5066, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 407, train loss: 0.6930, test loss: 0.6947, train acc: 0.5108, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 408, train loss: 0.6932, test loss: 0.6950, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 409, train loss: 0.6930, test loss: 0.7003, train acc: 0.5134, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 410, train loss: 0.6933, test loss: 0.6956, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 411, train loss: 0.6931, test loss: 0.6839, train acc: 0.5078, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 412, train loss: 0.6932, test loss: 0.6986, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 413, train loss: 0.6933, test loss: 0.6936, train acc: 0.4930, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 414, train loss: 0.6933, test loss: 0.6926, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 415, train loss: 0.6932, test loss: 0.6949, train acc: 0.4928, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 416, train loss: 0.6931, test loss: 0.6965, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 417, train loss: 0.6933, test loss: 0.6943, train acc: 0.4911, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 418, train loss: 0.6933, test loss: 0.6908, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 419, train loss: 0.6931, test loss: 0.6933, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 420, train loss: 0.6932, test loss: 0.6913, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 421, train loss: 0.6933, test loss: 0.6939, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 422, train loss: 0.6933, test loss: 0.6906, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 423, train loss: 0.6932, test loss: 0.6855, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 424, train loss: 0.6932, test loss: 0.6944, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 425, train loss: 0.6931, test loss: 0.6885, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 426, train loss: 0.6933, test loss: 0.6892, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 427, train loss: 0.6935, test loss: 0.6977, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 428, train loss: 0.6933, test loss: 0.6920, train acc: 0.4946, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 429, train loss: 0.6932, test loss: 0.6890, train acc: 0.5035, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 430, train loss: 0.6932, test loss: 0.6875, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 431, train loss: 0.6932, test loss: 0.6942, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 432, train loss: 0.6932, test loss: 0.6940, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 433, train loss: 0.6931, test loss: 0.6971, train acc: 0.5076, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 434, train loss: 0.6933, test loss: 0.6888, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 435, train loss: 0.6933, test loss: 0.6950, train acc: 0.4908, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 436, train loss: 0.6932, test loss: 0.6963, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 437, train loss: 0.6931, test loss: 0.6968, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 438, train loss: 0.6933, test loss: 0.6974, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 439, train loss: 0.6931, test loss: 0.6948, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 440, train loss: 0.6933, test loss: 0.6955, train acc: 0.4916, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 441, train loss: 0.6932, test loss: 0.6919, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 442, train loss: 0.6932, test loss: 0.7022, train acc: 0.5056, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 443, train loss: 0.6932, test loss: 0.6976, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 444, train loss: 0.6934, test loss: 0.6875, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 445, train loss: 0.6933, test loss: 0.6888, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 446, train loss: 0.6932, test loss: 0.6931, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 447, train loss: 0.6932, test loss: 0.6934, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 448, train loss: 0.6933, test loss: 0.6902, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 449, train loss: 0.6932, test loss: 0.6897, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 450, train loss: 0.6932, test loss: 0.6894, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 451, train loss: 0.6932, test loss: 0.6931, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 452, train loss: 0.6932, test loss: 0.6892, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 453, train loss: 0.6931, test loss: 0.6896, train acc: 0.5076, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 454, train loss: 0.6934, test loss: 0.6919, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 455, train loss: 0.6933, test loss: 0.6923, train acc: 0.4936, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 456, train loss: 0.6933, test loss: 0.6906, train acc: 0.4920, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 457, train loss: 0.6931, test loss: 0.6850, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 458, train loss: 0.6934, test loss: 0.6882, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 459, train loss: 0.6932, test loss: 0.6967, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 460, train loss: 0.6932, test loss: 0.6918, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 461, train loss: 0.6932, test loss: 0.6908, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 462, train loss: 0.6933, test loss: 0.6904, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 463, train loss: 0.6934, test loss: 0.6986, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 464, train loss: 0.6933, test loss: 0.6904, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 465, train loss: 0.6932, test loss: 0.6909, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 466, train loss: 0.6932, test loss: 0.6936, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 467, train loss: 0.6931, test loss: 0.6954, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 468, train loss: 0.6932, test loss: 0.6973, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 469, train loss: 0.6933, test loss: 0.6878, train acc: 0.4954, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 470, train loss: 0.6932, test loss: 0.6874, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 471, train loss: 0.6934, test loss: 0.6884, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 472, train loss: 0.6932, test loss: 0.6902, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 473, train loss: 0.6932, test loss: 0.6995, train acc: 0.5062, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 474, train loss: 0.6933, test loss: 0.6932, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 475, train loss: 0.6932, test loss: 0.6898, train acc: 0.4986, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 476, train loss: 0.6933, test loss: 0.6931, train acc: 0.4879, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 477, train loss: 0.6933, test loss: 0.6941, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 478, train loss: 0.6932, test loss: 0.6899, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 479, train loss: 0.6932, test loss: 0.6876, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 480, train loss: 0.6933, test loss: 0.6916, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 481, train loss: 0.6932, test loss: 0.6947, train acc: 0.4953, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 482, train loss: 0.6932, test loss: 0.6926, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 483, train loss: 0.6933, test loss: 0.6927, train acc: 0.4803, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 484, train loss: 0.6932, test loss: 0.6907, train acc: 0.4962, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 485, train loss: 0.6934, test loss: 0.6877, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 486, train loss: 0.6930, test loss: 0.6840, train acc: 0.5068, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 487, train loss: 0.6932, test loss: 0.6969, train acc: 0.5077, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 488, train loss: 0.6934, test loss: 0.6934, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 489, train loss: 0.6932, test loss: 0.6869, train acc: 0.4942, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 490, train loss: 0.6933, test loss: 0.6944, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 491, train loss: 0.6932, test loss: 0.6967, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 492, train loss: 0.6931, test loss: 0.6963, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 493, train loss: 0.6933, test loss: 0.6985, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 494, train loss: 0.6933, test loss: 0.6903, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 495, train loss: 0.6932, test loss: 0.6850, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 496, train loss: 0.6933, test loss: 0.6927, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 497, train loss: 0.6933, test loss: 0.6912, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 498, train loss: 0.6932, test loss: 0.6878, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 499, train loss: 0.6933, test loss: 0.6927, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 500, train loss: 0.6932, test loss: 0.6889, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 501, train loss: 0.6933, test loss: 0.6912, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 502, train loss: 0.6931, test loss: 0.6914, train acc: 0.5094, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 503, train loss: 0.6933, test loss: 0.6894, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 504, train loss: 0.6931, test loss: 0.7030, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 505, train loss: 0.6935, test loss: 0.6944, train acc: 0.4924, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 506, train loss: 0.6933, test loss: 0.6976, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 507, train loss: 0.6932, test loss: 0.6943, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 508, train loss: 0.6931, test loss: 0.6992, train acc: 0.5089, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 509, train loss: 0.6932, test loss: 0.6903, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 510, train loss: 0.6931, test loss: 0.6905, train acc: 0.5101, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 511, train loss: 0.6933, test loss: 0.6958, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 512, train loss: 0.6931, test loss: 0.7004, train acc: 0.5041, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 513, train loss: 0.6931, test loss: 0.6985, train acc: 0.5096, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 514, train loss: 0.6933, test loss: 0.6926, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 515, train loss: 0.6932, test loss: 0.6916, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 516, train loss: 0.6932, test loss: 0.6917, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 517, train loss: 0.6932, test loss: 0.6919, train acc: 0.4910, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 518, train loss: 0.6932, test loss: 0.6886, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 519, train loss: 0.6934, test loss: 0.6869, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 520, train loss: 0.6932, test loss: 0.6914, train acc: 0.5082, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 521, train loss: 0.6933, test loss: 0.6968, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 522, train loss: 0.6933, test loss: 0.6910, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 523, train loss: 0.6932, test loss: 0.6893, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 524, train loss: 0.6933, test loss: 0.6925, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 525, train loss: 0.6933, test loss: 0.6952, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 526, train loss: 0.6932, test loss: 0.6881, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 527, train loss: 0.6933, test loss: 0.6941, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 528, train loss: 0.6930, test loss: 0.6982, train acc: 0.5109, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 529, train loss: 0.6933, test loss: 0.6891, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 530, train loss: 0.6932, test loss: 0.6884, train acc: 0.5037, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 531, train loss: 0.6932, test loss: 0.6923, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 532, train loss: 0.6932, test loss: 0.6938, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 533, train loss: 0.6932, test loss: 0.6929, train acc: 0.4927, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 534, train loss: 0.6932, test loss: 0.7007, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 535, train loss: 0.6933, test loss: 0.6944, train acc: 0.4954, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 536, train loss: 0.6931, test loss: 0.6889, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 537, train loss: 0.6932, test loss: 0.6972, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 538, train loss: 0.6932, test loss: 0.6991, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 539, train loss: 0.6930, test loss: 0.6989, train acc: 0.5072, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 540, train loss: 0.6934, test loss: 0.6961, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 541, train loss: 0.6931, test loss: 0.6932, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 542, train loss: 0.6933, test loss: 0.6910, train acc: 0.5073, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 543, train loss: 0.6931, test loss: 0.6986, train acc: 0.5063, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 544, train loss: 0.6932, test loss: 0.6927, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 545, train loss: 0.6933, test loss: 0.6916, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 546, train loss: 0.6932, test loss: 0.6924, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 547, train loss: 0.6932, test loss: 0.6903, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 548, train loss: 0.6933, test loss: 0.6941, train acc: 0.5000, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 549, train loss: 0.6930, test loss: 0.6925, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 550, train loss: 0.6933, test loss: 0.6954, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 551, train loss: 0.6933, test loss: 0.6941, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 552, train loss: 0.6932, test loss: 0.6935, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 553, train loss: 0.6933, test loss: 0.6897, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 554, train loss: 0.6933, test loss: 0.6893, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 555, train loss: 0.6934, test loss: 0.6932, train acc: 0.4889, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 556, train loss: 0.6934, test loss: 0.6900, train acc: 0.4886, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 557, train loss: 0.6932, test loss: 0.6884, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 558, train loss: 0.6932, test loss: 0.6878, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 559, train loss: 0.6933, test loss: 0.6900, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 560, train loss: 0.6933, test loss: 0.6969, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 561, train loss: 0.6931, test loss: 0.7011, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 562, train loss: 0.6930, test loss: 0.6946, train acc: 0.5085, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 563, train loss: 0.6932, test loss: 0.6933, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 564, train loss: 0.6932, test loss: 0.6943, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 565, train loss: 0.6935, test loss: 0.6925, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 566, train loss: 0.6932, test loss: 0.6978, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 567, train loss: 0.6933, test loss: 0.6905, train acc: 0.4961, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 568, train loss: 0.6931, test loss: 0.6974, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 569, train loss: 0.6932, test loss: 0.6929, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 570, train loss: 0.6933, test loss: 0.6909, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 571, train loss: 0.6932, test loss: 0.6917, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 572, train loss: 0.6932, test loss: 0.6905, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 573, train loss: 0.6933, test loss: 0.6912, train acc: 0.4921, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 574, train loss: 0.6933, test loss: 0.6922, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 575, train loss: 0.6932, test loss: 0.6933, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 576, train loss: 0.6932, test loss: 0.6960, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 577, train loss: 0.6931, test loss: 0.6870, train acc: 0.5075, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 578, train loss: 0.6933, test loss: 0.6908, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 579, train loss: 0.6931, test loss: 0.6900, train acc: 0.5066, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 580, train loss: 0.6932, test loss: 0.6864, train acc: 0.4980, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 581, train loss: 0.6934, test loss: 0.6906, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 582, train loss: 0.6932, test loss: 0.6894, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 583, train loss: 0.6933, test loss: 0.6891, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 584, train loss: 0.6935, test loss: 0.6899, train acc: 0.4954, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 585, train loss: 0.6932, test loss: 0.7018, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 586, train loss: 0.6933, test loss: 0.6883, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 587, train loss: 0.6933, test loss: 0.6924, train acc: 0.4949, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 588, train loss: 0.6932, test loss: 0.6935, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 589, train loss: 0.6931, test loss: 0.6911, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 590, train loss: 0.6932, test loss: 0.6903, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 591, train loss: 0.6932, test loss: 0.6898, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 592, train loss: 0.6933, test loss: 0.6894, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 593, train loss: 0.6932, test loss: 0.6961, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 594, train loss: 0.6932, test loss: 0.6919, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 595, train loss: 0.6933, test loss: 0.6971, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 596, train loss: 0.6930, test loss: 0.6883, train acc: 0.5113, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 597, train loss: 0.6933, test loss: 0.6935, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 598, train loss: 0.6932, test loss: 0.6924, train acc: 0.4930, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 599, train loss: 0.6932, test loss: 0.6942, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 600, train loss: 0.6932, test loss: 0.6963, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 601, train loss: 0.6932, test loss: 0.6910, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 602, train loss: 0.6932, test loss: 0.6966, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 603, train loss: 0.6930, test loss: 0.6909, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 604, train loss: 0.6932, test loss: 0.6898, train acc: 0.4980, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 605, train loss: 0.6932, test loss: 0.6988, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 606, train loss: 0.6932, test loss: 0.6969, train acc: 0.4998, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 607, train loss: 0.6932, test loss: 0.6928, train acc: 0.4903, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 608, train loss: 0.6932, test loss: 0.6915, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 609, train loss: 0.6933, test loss: 0.6935, train acc: 0.4970, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 610, train loss: 0.6933, test loss: 0.6951, train acc: 0.4940, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 611, train loss: 0.6931, test loss: 0.6992, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 612, train loss: 0.6932, test loss: 0.6947, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 613, train loss: 0.6932, test loss: 0.6934, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 614, train loss: 0.6931, test loss: 0.6865, train acc: 0.5076, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 615, train loss: 0.6931, test loss: 0.6975, train acc: 0.5049, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 616, train loss: 0.6933, test loss: 0.6931, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 617, train loss: 0.6932, test loss: 0.6952, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 618, train loss: 0.6932, test loss: 0.6944, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 619, train loss: 0.6932, test loss: 0.6871, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 620, train loss: 0.6934, test loss: 0.7000, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 621, train loss: 0.6932, test loss: 0.6874, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 622, train loss: 0.6934, test loss: 0.6959, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 623, train loss: 0.6933, test loss: 0.6930, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 624, train loss: 0.6932, test loss: 0.6990, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 625, train loss: 0.6932, test loss: 0.6969, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 626, train loss: 0.6932, test loss: 0.6969, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 627, train loss: 0.6933, test loss: 0.6925, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 628, train loss: 0.6932, test loss: 0.6908, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 629, train loss: 0.6932, test loss: 0.6985, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 630, train loss: 0.6934, test loss: 0.6936, train acc: 0.4889, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 631, train loss: 0.6931, test loss: 0.6962, train acc: 0.5094, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 632, train loss: 0.6932, test loss: 0.7025, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 633, train loss: 0.6934, test loss: 0.6969, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 634, train loss: 0.6932, test loss: 0.6941, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 635, train loss: 0.6932, test loss: 0.6906, train acc: 0.5051, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 636, train loss: 0.6933, test loss: 0.6914, train acc: 0.4925, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 637, train loss: 0.6932, test loss: 0.6895, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 638, train loss: 0.6933, test loss: 0.6928, train acc: 0.4911, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 639, train loss: 0.6932, test loss: 0.6909, train acc: 0.4985, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 640, train loss: 0.6932, test loss: 0.6965, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 641, train loss: 0.6931, test loss: 0.6883, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 642, train loss: 0.6932, test loss: 0.6972, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 643, train loss: 0.6934, test loss: 0.6941, train acc: 0.4937, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 644, train loss: 0.6933, test loss: 0.6996, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 645, train loss: 0.6932, test loss: 0.6951, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 646, train loss: 0.6932, test loss: 0.6917, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 647, train loss: 0.6932, test loss: 0.6996, train acc: 0.4970, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 648, train loss: 0.6933, test loss: 0.6914, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 649, train loss: 0.6932, test loss: 0.6923, train acc: 0.5054, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 650, train loss: 0.6933, test loss: 0.6940, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 651, train loss: 0.6934, test loss: 0.6959, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 652, train loss: 0.6932, test loss: 0.6937, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 653, train loss: 0.6931, test loss: 0.6986, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 654, train loss: 0.6933, test loss: 0.6924, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 655, train loss: 0.6932, test loss: 0.6947, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 656, train loss: 0.6932, test loss: 0.6917, train acc: 0.4932, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 657, train loss: 0.6930, test loss: 0.6957, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 658, train loss: 0.6932, test loss: 0.6891, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 659, train loss: 0.6930, test loss: 0.6975, train acc: 0.5106, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 660, train loss: 0.6932, test loss: 0.6938, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 661, train loss: 0.6931, test loss: 0.6948, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 662, train loss: 0.6932, test loss: 0.6950, train acc: 0.4973, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 663, train loss: 0.6933, test loss: 0.6906, train acc: 0.4894, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 664, train loss: 0.6932, test loss: 0.6916, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 665, train loss: 0.6932, test loss: 0.6942, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 666, train loss: 0.6931, test loss: 0.6944, train acc: 0.5079, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 667, train loss: 0.6933, test loss: 0.6918, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 668, train loss: 0.6933, test loss: 0.6920, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 669, train loss: 0.6931, test loss: 0.6997, train acc: 0.5069, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 670, train loss: 0.6934, test loss: 0.6976, train acc: 0.4916, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 671, train loss: 0.6931, test loss: 0.6965, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 672, train loss: 0.6932, test loss: 0.6889, train acc: 0.5071, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 673, train loss: 0.6933, test loss: 0.6933, train acc: 0.4911, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 674, train loss: 0.6931, test loss: 0.6879, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 675, train loss: 0.6932, test loss: 0.6861, train acc: 0.5037, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 676, train loss: 0.6931, test loss: 0.6867, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 677, train loss: 0.6935, test loss: 0.6929, train acc: 0.4868, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 678, train loss: 0.6932, test loss: 0.6924, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 679, train loss: 0.6932, test loss: 0.6944, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 680, train loss: 0.6932, test loss: 0.6935, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 681, train loss: 0.6928, test loss: 0.6896, train acc: 0.5158, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 682, train loss: 0.6934, test loss: 0.6940, train acc: 0.4918, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 683, train loss: 0.6932, test loss: 0.6956, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 684, train loss: 0.6932, test loss: 0.6933, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 685, train loss: 0.6931, test loss: 0.7028, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 686, train loss: 0.6936, test loss: 0.6917, train acc: 0.4851, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 687, train loss: 0.6932, test loss: 0.6975, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 688, train loss: 0.6933, test loss: 0.6903, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 689, train loss: 0.6934, test loss: 0.6966, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 690, train loss: 0.6934, test loss: 0.6959, train acc: 0.4917, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 691, train loss: 0.6932, test loss: 0.6931, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 692, train loss: 0.6932, test loss: 0.7005, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 693, train loss: 0.6930, test loss: 0.6935, train acc: 0.5071, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 694, train loss: 0.6932, test loss: 0.6975, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 695, train loss: 0.6932, test loss: 0.6953, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 696, train loss: 0.6933, test loss: 0.6930, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 697, train loss: 0.6933, test loss: 0.6914, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 698, train loss: 0.6933, test loss: 0.6982, train acc: 0.4899, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 699, train loss: 0.6932, test loss: 0.6950, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 700, train loss: 0.6933, test loss: 0.6917, train acc: 0.4940, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 701, train loss: 0.6932, test loss: 0.6989, train acc: 0.4986, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 702, train loss: 0.6932, test loss: 0.6971, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 703, train loss: 0.6931, test loss: 0.6935, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 704, train loss: 0.6932, test loss: 0.6943, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 705, train loss: 0.6933, test loss: 0.6930, train acc: 0.4911, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 706, train loss: 0.6933, test loss: 0.6907, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 707, train loss: 0.6931, test loss: 0.6950, train acc: 0.5079, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 708, train loss: 0.6934, test loss: 0.6916, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 709, train loss: 0.6933, test loss: 0.6891, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 710, train loss: 0.6933, test loss: 0.6974, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 711, train loss: 0.6933, test loss: 0.6983, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 712, train loss: 0.6933, test loss: 0.6965, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 713, train loss: 0.6931, test loss: 0.6908, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 714, train loss: 0.6933, test loss: 0.6944, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 715, train loss: 0.6933, test loss: 0.6898, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 716, train loss: 0.6931, test loss: 0.6936, train acc: 0.5073, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 717, train loss: 0.6932, test loss: 0.6901, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 718, train loss: 0.6931, test loss: 0.6861, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 719, train loss: 0.6932, test loss: 0.6996, train acc: 0.5045, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 720, train loss: 0.6932, test loss: 0.6973, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 721, train loss: 0.6932, test loss: 0.6925, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 722, train loss: 0.6933, test loss: 0.6932, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 723, train loss: 0.6933, test loss: 0.6967, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 724, train loss: 0.6932, test loss: 0.6974, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 725, train loss: 0.6932, test loss: 0.6885, train acc: 0.5056, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 726, train loss: 0.6931, test loss: 0.6912, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 727, train loss: 0.6932, test loss: 0.6969, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 728, train loss: 0.6933, test loss: 0.6898, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 729, train loss: 0.6934, test loss: 0.6923, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 730, train loss: 0.6932, test loss: 0.6926, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 731, train loss: 0.6933, test loss: 0.6935, train acc: 0.4898, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 732, train loss: 0.6932, test loss: 0.6876, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 733, train loss: 0.6932, test loss: 0.6899, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 734, train loss: 0.6931, test loss: 0.6964, train acc: 0.5052, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 735, train loss: 0.6931, test loss: 0.6882, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 736, train loss: 0.6932, test loss: 0.6943, train acc: 0.5004, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 737, train loss: 0.6934, test loss: 0.6925, train acc: 0.4923, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 738, train loss: 0.6932, test loss: 0.6988, train acc: 0.4998, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 739, train loss: 0.6930, test loss: 0.7025, train acc: 0.5074, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 740, train loss: 0.6931, test loss: 0.6886, train acc: 0.5082, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 741, train loss: 0.6932, test loss: 0.6857, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 742, train loss: 0.6934, test loss: 0.6950, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 743, train loss: 0.6933, test loss: 0.6912, train acc: 0.4916, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 744, train loss: 0.6933, test loss: 0.6931, train acc: 0.4914, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 745, train loss: 0.6933, test loss: 0.6914, train acc: 0.4913, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 746, train loss: 0.6933, test loss: 0.6915, train acc: 0.4895, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 747, train loss: 0.6933, test loss: 0.6958, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 748, train loss: 0.6934, test loss: 0.6902, train acc: 0.4934, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 749, train loss: 0.6932, test loss: 0.6973, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 750, train loss: 0.6930, test loss: 0.6975, train acc: 0.5105, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 751, train loss: 0.6933, test loss: 0.6939, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 752, train loss: 0.6932, test loss: 0.6865, train acc: 0.5080, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 753, train loss: 0.6932, test loss: 0.6900, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 754, train loss: 0.6932, test loss: 0.6885, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 755, train loss: 0.6933, test loss: 0.6898, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 756, train loss: 0.6931, test loss: 0.7010, train acc: 0.5060, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 757, train loss: 0.6932, test loss: 0.6880, train acc: 0.5069, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 758, train loss: 0.6933, test loss: 0.6929, train acc: 0.4913, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 759, train loss: 0.6932, test loss: 0.6930, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 760, train loss: 0.6931, test loss: 0.6933, train acc: 0.5080, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 761, train loss: 0.6933, test loss: 0.6944, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 762, train loss: 0.6931, test loss: 0.6993, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 763, train loss: 0.6933, test loss: 0.7000, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 764, train loss: 0.6932, test loss: 0.6889, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 765, train loss: 0.6932, test loss: 0.6977, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 766, train loss: 0.6933, test loss: 0.6931, train acc: 0.4921, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 767, train loss: 0.6934, test loss: 0.6914, train acc: 0.5020, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 768, train loss: 0.6933, test loss: 0.6899, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 769, train loss: 0.6932, test loss: 0.6915, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 770, train loss: 0.6932, test loss: 0.6940, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 771, train loss: 0.6932, test loss: 0.6920, train acc: 0.4939, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 772, train loss: 0.6933, test loss: 0.6977, train acc: 0.4982, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 773, train loss: 0.6933, test loss: 0.6891, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 774, train loss: 0.6932, test loss: 0.6950, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 775, train loss: 0.6933, test loss: 0.6944, train acc: 0.4973, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 776, train loss: 0.6932, test loss: 0.6906, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 777, train loss: 0.6933, test loss: 0.6973, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 778, train loss: 0.6932, test loss: 0.6929, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 779, train loss: 0.6932, test loss: 0.6879, train acc: 0.5045, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 780, train loss: 0.6931, test loss: 0.6899, train acc: 0.5083, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 781, train loss: 0.6932, test loss: 0.7023, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 782, train loss: 0.6932, test loss: 0.6958, train acc: 0.5064, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 783, train loss: 0.6931, test loss: 0.6879, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 784, train loss: 0.6932, test loss: 0.6994, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 785, train loss: 0.6934, test loss: 0.6918, train acc: 0.4925, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 786, train loss: 0.6933, test loss: 0.6986, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 787, train loss: 0.6933, test loss: 0.6938, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 788, train loss: 0.6932, test loss: 0.6937, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 789, train loss: 0.6932, test loss: 0.6960, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 790, train loss: 0.6933, test loss: 0.6877, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 791, train loss: 0.6933, test loss: 0.6892, train acc: 0.4973, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 792, train loss: 0.6932, test loss: 0.6875, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 793, train loss: 0.6933, test loss: 0.6903, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 794, train loss: 0.6933, test loss: 0.6895, train acc: 0.4929, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 795, train loss: 0.6932, test loss: 0.6955, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 796, train loss: 0.6933, test loss: 0.6916, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 797, train loss: 0.6931, test loss: 0.6837, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 798, train loss: 0.6933, test loss: 0.6969, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 799, train loss: 0.6932, test loss: 0.6899, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "Trial 1 - Fold 2 - Params: {'weightdecay': 'yes', 'batch_norm': 'no', 'dropout': 'no', 'L2lambda': 0.1}\n",
      "Additional Hyperparameters -> Weight Decay: 0.1\n",
      "FOLD 2\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\trial\\_trial.py:492: UserWarning: The reported value is ignored because this `step` 799 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.6933, test loss: 0.6984, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 1, train loss: 0.6933, test loss: 0.6933, train acc: 0.4976, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 2, train loss: 0.6932, test loss: 0.6873, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 3, train loss: 0.6931, test loss: 0.6968, train acc: 0.5061, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 4, train loss: 0.6932, test loss: 0.6913, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 5, train loss: 0.6932, test loss: 0.6918, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 6, train loss: 0.6931, test loss: 0.6928, train acc: 0.5073, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 7, train loss: 0.6932, test loss: 0.6964, train acc: 0.4983, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 8, train loss: 0.6932, test loss: 0.6949, train acc: 0.5063, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 9, train loss: 0.6933, test loss: 0.6924, train acc: 0.4927, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 10, train loss: 0.6932, test loss: 0.6947, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 11, train loss: 0.6931, test loss: 0.6996, train acc: 0.5076, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 12, train loss: 0.6932, test loss: 0.6941, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 13, train loss: 0.6932, test loss: 0.6944, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 14, train loss: 0.6932, test loss: 0.6903, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 15, train loss: 0.6932, test loss: 0.6888, train acc: 0.4928, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 16, train loss: 0.6932, test loss: 0.6991, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 17, train loss: 0.6932, test loss: 0.6970, train acc: 0.4961, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 18, train loss: 0.6932, test loss: 0.6959, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 19, train loss: 0.6933, test loss: 0.6903, train acc: 0.4945, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 20, train loss: 0.6932, test loss: 0.6929, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 21, train loss: 0.6932, test loss: 0.6975, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 22, train loss: 0.6931, test loss: 0.6907, train acc: 0.5051, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 23, train loss: 0.6933, test loss: 0.6934, train acc: 0.4916, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 24, train loss: 0.6933, test loss: 0.6908, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 25, train loss: 0.6932, test loss: 0.6990, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 26, train loss: 0.6935, test loss: 0.6945, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 27, train loss: 0.6932, test loss: 0.6941, train acc: 0.4949, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 28, train loss: 0.6931, test loss: 0.6852, train acc: 0.5100, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 29, train loss: 0.6933, test loss: 0.6973, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 30, train loss: 0.6933, test loss: 0.6917, train acc: 0.4958, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 31, train loss: 0.6931, test loss: 0.6880, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 32, train loss: 0.6931, test loss: 0.6920, train acc: 0.5070, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 33, train loss: 0.6933, test loss: 0.6938, train acc: 0.4884, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 34, train loss: 0.6931, test loss: 0.6894, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 35, train loss: 0.6932, test loss: 0.6960, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 36, train loss: 0.6933, test loss: 0.6929, train acc: 0.4943, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 37, train loss: 0.6932, test loss: 0.6932, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 38, train loss: 0.6933, test loss: 0.6923, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 39, train loss: 0.6931, test loss: 0.6891, train acc: 0.5074, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 40, train loss: 0.6933, test loss: 0.6902, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 41, train loss: 0.6933, test loss: 0.6897, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 42, train loss: 0.6932, test loss: 0.6946, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 43, train loss: 0.6932, test loss: 0.6894, train acc: 0.5051, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 44, train loss: 0.6932, test loss: 0.6951, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 45, train loss: 0.6932, test loss: 0.6935, train acc: 0.4966, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 46, train loss: 0.6932, test loss: 0.6971, train acc: 0.5020, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 47, train loss: 0.6933, test loss: 0.6986, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 48, train loss: 0.6932, test loss: 0.6986, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 49, train loss: 0.6932, test loss: 0.6995, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 50, train loss: 0.6933, test loss: 0.6977, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 51, train loss: 0.6932, test loss: 0.6905, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 52, train loss: 0.6932, test loss: 0.6914, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 53, train loss: 0.6932, test loss: 0.6946, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 54, train loss: 0.6933, test loss: 0.6895, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 55, train loss: 0.6932, test loss: 0.6992, train acc: 0.5045, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 56, train loss: 0.6932, test loss: 0.6946, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 57, train loss: 0.6935, test loss: 0.6879, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 58, train loss: 0.6933, test loss: 0.6914, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 59, train loss: 0.6932, test loss: 0.6961, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 60, train loss: 0.6932, test loss: 0.6919, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 61, train loss: 0.6933, test loss: 0.6900, train acc: 0.4925, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 62, train loss: 0.6932, test loss: 0.6851, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 63, train loss: 0.6933, test loss: 0.6947, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 64, train loss: 0.6933, test loss: 0.6935, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 65, train loss: 0.6932, test loss: 0.6991, train acc: 0.5065, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 66, train loss: 0.6932, test loss: 0.6904, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 67, train loss: 0.6932, test loss: 0.6942, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 68, train loss: 0.6930, test loss: 0.6881, train acc: 0.5120, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 69, train loss: 0.6933, test loss: 0.6947, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 70, train loss: 0.6930, test loss: 0.6951, train acc: 0.5086, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 71, train loss: 0.6932, test loss: 0.6855, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 72, train loss: 0.6932, test loss: 0.6916, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 73, train loss: 0.6932, test loss: 0.6956, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 74, train loss: 0.6932, test loss: 0.6921, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 75, train loss: 0.6933, test loss: 0.6962, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 76, train loss: 0.6933, test loss: 0.6908, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 77, train loss: 0.6932, test loss: 0.6994, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 78, train loss: 0.6933, test loss: 0.6997, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 79, train loss: 0.6933, test loss: 0.6931, train acc: 0.4942, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 80, train loss: 0.6933, test loss: 0.6917, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 81, train loss: 0.6933, test loss: 0.6938, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 82, train loss: 0.6931, test loss: 0.6906, train acc: 0.5068, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 83, train loss: 0.6932, test loss: 0.6930, train acc: 0.4945, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 84, train loss: 0.6933, test loss: 0.6943, train acc: 0.4933, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 85, train loss: 0.6932, test loss: 0.6938, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 86, train loss: 0.6931, test loss: 0.6862, train acc: 0.5089, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 87, train loss: 0.6932, test loss: 0.6908, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 88, train loss: 0.6933, test loss: 0.6956, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 89, train loss: 0.6932, test loss: 0.6904, train acc: 0.5035, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 90, train loss: 0.6933, test loss: 0.6961, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 91, train loss: 0.6932, test loss: 0.6907, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 92, train loss: 0.6933, test loss: 0.6925, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 93, train loss: 0.6931, test loss: 0.6894, train acc: 0.5094, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 94, train loss: 0.6933, test loss: 0.6939, train acc: 0.4942, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 95, train loss: 0.6933, test loss: 0.6924, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 96, train loss: 0.6932, test loss: 0.6871, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 97, train loss: 0.6930, test loss: 0.6971, train acc: 0.5097, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 98, train loss: 0.6932, test loss: 0.6859, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 99, train loss: 0.6932, test loss: 0.6905, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 100, train loss: 0.6932, test loss: 0.6970, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 101, train loss: 0.6933, test loss: 0.6917, train acc: 0.4933, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 102, train loss: 0.6931, test loss: 0.6944, train acc: 0.5065, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 103, train loss: 0.6930, test loss: 0.6930, train acc: 0.5076, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 104, train loss: 0.6931, test loss: 0.6865, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 105, train loss: 0.6930, test loss: 0.6907, train acc: 0.5121, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 106, train loss: 0.6932, test loss: 0.6877, train acc: 0.5063, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 107, train loss: 0.6931, test loss: 0.6898, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 108, train loss: 0.6933, test loss: 0.6943, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 109, train loss: 0.6933, test loss: 0.6956, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 110, train loss: 0.6932, test loss: 0.6895, train acc: 0.5063, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 111, train loss: 0.6932, test loss: 0.6834, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 112, train loss: 0.6933, test loss: 0.6980, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 113, train loss: 0.6933, test loss: 0.6919, train acc: 0.4953, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 114, train loss: 0.6933, test loss: 0.6905, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 115, train loss: 0.6933, test loss: 0.6920, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 116, train loss: 0.6932, test loss: 0.6904, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 117, train loss: 0.6932, test loss: 0.6937, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 118, train loss: 0.6932, test loss: 0.6964, train acc: 0.5052, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 119, train loss: 0.6932, test loss: 0.6872, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 120, train loss: 0.6930, test loss: 0.6978, train acc: 0.5089, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 121, train loss: 0.6933, test loss: 0.6973, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 122, train loss: 0.6934, test loss: 0.6933, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 123, train loss: 0.6932, test loss: 0.6976, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 124, train loss: 0.6933, test loss: 0.6932, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 125, train loss: 0.6933, test loss: 0.6948, train acc: 0.4920, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 126, train loss: 0.6931, test loss: 0.6958, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 127, train loss: 0.6932, test loss: 0.6900, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 128, train loss: 0.6933, test loss: 0.6922, train acc: 0.4900, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 129, train loss: 0.6932, test loss: 0.6881, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 130, train loss: 0.6932, test loss: 0.6902, train acc: 0.5068, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 131, train loss: 0.6932, test loss: 0.6880, train acc: 0.5028, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 132, train loss: 0.6933, test loss: 0.6900, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 133, train loss: 0.6932, test loss: 0.6861, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 134, train loss: 0.6933, test loss: 0.6939, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 135, train loss: 0.6933, test loss: 0.6903, train acc: 0.4958, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 136, train loss: 0.6932, test loss: 0.6964, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 137, train loss: 0.6931, test loss: 0.6925, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 138, train loss: 0.6933, test loss: 0.6939, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 139, train loss: 0.6931, test loss: 0.6902, train acc: 0.5087, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 140, train loss: 0.6933, test loss: 0.6863, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 141, train loss: 0.6930, test loss: 0.6960, train acc: 0.5071, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 142, train loss: 0.6933, test loss: 0.6950, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 143, train loss: 0.6931, test loss: 0.6942, train acc: 0.5076, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 144, train loss: 0.6932, test loss: 0.6934, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 145, train loss: 0.6932, test loss: 0.6957, train acc: 0.4954, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 146, train loss: 0.6932, test loss: 0.6982, train acc: 0.5051, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 147, train loss: 0.6933, test loss: 0.6920, train acc: 0.4989, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 148, train loss: 0.6931, test loss: 0.6889, train acc: 0.5059, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 149, train loss: 0.6931, test loss: 0.6965, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 150, train loss: 0.6933, test loss: 0.6920, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 151, train loss: 0.6932, test loss: 0.6962, train acc: 0.5054, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 152, train loss: 0.6933, test loss: 0.6886, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 153, train loss: 0.6931, test loss: 0.6995, train acc: 0.5078, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 154, train loss: 0.6933, test loss: 0.6889, train acc: 0.5045, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 155, train loss: 0.6934, test loss: 0.6933, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 156, train loss: 0.6933, test loss: 0.6945, train acc: 0.4944, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 157, train loss: 0.6931, test loss: 0.6880, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 158, train loss: 0.6932, test loss: 0.6962, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 159, train loss: 0.6932, test loss: 0.7004, train acc: 0.4929, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 160, train loss: 0.6933, test loss: 0.6996, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 161, train loss: 0.6932, test loss: 0.6902, train acc: 0.5008, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 162, train loss: 0.6932, test loss: 0.6944, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 163, train loss: 0.6932, test loss: 0.6940, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 164, train loss: 0.6933, test loss: 0.6924, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 165, train loss: 0.6932, test loss: 0.6989, train acc: 0.5071, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 166, train loss: 0.6935, test loss: 0.6963, train acc: 0.4968, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 167, train loss: 0.6933, test loss: 0.6976, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 168, train loss: 0.6933, test loss: 0.6922, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 169, train loss: 0.6931, test loss: 0.6936, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 170, train loss: 0.6932, test loss: 0.6912, train acc: 0.5013, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 171, train loss: 0.6929, test loss: 0.6918, train acc: 0.5106, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 172, train loss: 0.6933, test loss: 0.6899, train acc: 0.4922, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 173, train loss: 0.6934, test loss: 0.6940, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 174, train loss: 0.6934, test loss: 0.6892, train acc: 0.4935, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 175, train loss: 0.6933, test loss: 0.6961, train acc: 0.4944, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 176, train loss: 0.6933, test loss: 0.6904, train acc: 0.5021, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 177, train loss: 0.6931, test loss: 0.6911, train acc: 0.5063, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 178, train loss: 0.6931, test loss: 0.7025, train acc: 0.5102, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 179, train loss: 0.6934, test loss: 0.6929, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 180, train loss: 0.6932, test loss: 0.6909, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 181, train loss: 0.6933, test loss: 0.6896, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 182, train loss: 0.6934, test loss: 0.6965, train acc: 0.4973, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 183, train loss: 0.6932, test loss: 0.6927, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 184, train loss: 0.6933, test loss: 0.6991, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 185, train loss: 0.6932, test loss: 0.6968, train acc: 0.4952, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 186, train loss: 0.6931, test loss: 0.6954, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 187, train loss: 0.6933, test loss: 0.6915, train acc: 0.4919, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 188, train loss: 0.6932, test loss: 0.6943, train acc: 0.4959, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 189, train loss: 0.6932, test loss: 0.6978, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 190, train loss: 0.6932, test loss: 0.6928, train acc: 0.4961, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 191, train loss: 0.6932, test loss: 0.6896, train acc: 0.4924, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 192, train loss: 0.6933, test loss: 0.6927, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 193, train loss: 0.6932, test loss: 0.6945, train acc: 0.4995, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 194, train loss: 0.6933, test loss: 0.6976, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 195, train loss: 0.6934, test loss: 0.6944, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 196, train loss: 0.6931, test loss: 0.6904, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 197, train loss: 0.6932, test loss: 0.6912, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 198, train loss: 0.6931, test loss: 0.6977, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 199, train loss: 0.6933, test loss: 0.6938, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 200, train loss: 0.6933, test loss: 0.6979, train acc: 0.4914, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 201, train loss: 0.6933, test loss: 0.6930, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 202, train loss: 0.6932, test loss: 0.6911, train acc: 0.5034, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 203, train loss: 0.6934, test loss: 0.6918, train acc: 0.4944, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 204, train loss: 0.6932, test loss: 0.6937, train acc: 0.4997, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 205, train loss: 0.6931, test loss: 0.6886, train acc: 0.5066, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 206, train loss: 0.6933, test loss: 0.6930, train acc: 0.4909, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 207, train loss: 0.6932, test loss: 0.6909, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 208, train loss: 0.6931, test loss: 0.6899, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 209, train loss: 0.6933, test loss: 0.6919, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 210, train loss: 0.6929, test loss: 0.6934, train acc: 0.5084, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 211, train loss: 0.6933, test loss: 0.6928, train acc: 0.4864, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 212, train loss: 0.6929, test loss: 0.6846, train acc: 0.5101, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 213, train loss: 0.6934, test loss: 0.6948, train acc: 0.4942, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 214, train loss: 0.6931, test loss: 0.6866, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 215, train loss: 0.6931, test loss: 0.6996, train acc: 0.5067, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 216, train loss: 0.6932, test loss: 0.6953, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 217, train loss: 0.6932, test loss: 0.6923, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 218, train loss: 0.6932, test loss: 0.6976, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 219, train loss: 0.6932, test loss: 0.6959, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 220, train loss: 0.6932, test loss: 0.6885, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 221, train loss: 0.6931, test loss: 0.6923, train acc: 0.5056, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 222, train loss: 0.6932, test loss: 0.6986, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 223, train loss: 0.6932, test loss: 0.6928, train acc: 0.4998, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 224, train loss: 0.6932, test loss: 0.6947, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 225, train loss: 0.6932, test loss: 0.6901, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 226, train loss: 0.6933, test loss: 0.6917, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 227, train loss: 0.6931, test loss: 0.6899, train acc: 0.5109, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 228, train loss: 0.6931, test loss: 0.6981, train acc: 0.5083, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 229, train loss: 0.6933, test loss: 0.6947, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 230, train loss: 0.6932, test loss: 0.6923, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 231, train loss: 0.6933, test loss: 0.6937, train acc: 0.4896, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 232, train loss: 0.6931, test loss: 0.6970, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 233, train loss: 0.6933, test loss: 0.6911, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 234, train loss: 0.6929, test loss: 0.6935, train acc: 0.5110, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 235, train loss: 0.6933, test loss: 0.6937, train acc: 0.4914, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 236, train loss: 0.6932, test loss: 0.6968, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 237, train loss: 0.6934, test loss: 0.6894, train acc: 0.4951, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 238, train loss: 0.6934, test loss: 0.6937, train acc: 0.4906, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 239, train loss: 0.6932, test loss: 0.6939, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 240, train loss: 0.6932, test loss: 0.6912, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 241, train loss: 0.6932, test loss: 0.6938, train acc: 0.4898, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 242, train loss: 0.6932, test loss: 0.6905, train acc: 0.4910, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 243, train loss: 0.6933, test loss: 0.6906, train acc: 0.4935, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 244, train loss: 0.6934, test loss: 0.6934, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 245, train loss: 0.6932, test loss: 0.6958, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 246, train loss: 0.6933, test loss: 0.6925, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 247, train loss: 0.6932, test loss: 0.6958, train acc: 0.5052, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 248, train loss: 0.6932, test loss: 0.6899, train acc: 0.5043, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 249, train loss: 0.6932, test loss: 0.6980, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 250, train loss: 0.6932, test loss: 0.6920, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 251, train loss: 0.6931, test loss: 0.6906, train acc: 0.5091, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 252, train loss: 0.6931, test loss: 0.6918, train acc: 0.5070, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 253, train loss: 0.6933, test loss: 0.6979, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 254, train loss: 0.6932, test loss: 0.6967, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 255, train loss: 0.6932, test loss: 0.6938, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 256, train loss: 0.6933, test loss: 0.6930, train acc: 0.4916, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 257, train loss: 0.6931, test loss: 0.6957, train acc: 0.5097, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 258, train loss: 0.6933, test loss: 0.6978, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 259, train loss: 0.6934, test loss: 0.6924, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 260, train loss: 0.6933, test loss: 0.6975, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 261, train loss: 0.6931, test loss: 0.6900, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 262, train loss: 0.6931, test loss: 0.6998, train acc: 0.5045, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 263, train loss: 0.6933, test loss: 0.6954, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 264, train loss: 0.6932, test loss: 0.6962, train acc: 0.5029, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 265, train loss: 0.6932, test loss: 0.6958, train acc: 0.4914, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 266, train loss: 0.6931, test loss: 0.6872, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 267, train loss: 0.6935, test loss: 0.6959, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 268, train loss: 0.6932, test loss: 0.6967, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 269, train loss: 0.6933, test loss: 0.6916, train acc: 0.5032, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 270, train loss: 0.6932, test loss: 0.6875, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 271, train loss: 0.6932, test loss: 0.6973, train acc: 0.5042, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 272, train loss: 0.6933, test loss: 0.6977, train acc: 0.4951, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 273, train loss: 0.6931, test loss: 0.6892, train acc: 0.5065, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 274, train loss: 0.6932, test loss: 0.6907, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 275, train loss: 0.6932, test loss: 0.6895, train acc: 0.4939, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 276, train loss: 0.6932, test loss: 0.6958, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 277, train loss: 0.6931, test loss: 0.6865, train acc: 0.5071, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 278, train loss: 0.6934, test loss: 0.6936, train acc: 0.4949, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 279, train loss: 0.6932, test loss: 0.6888, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 280, train loss: 0.6933, test loss: 0.6896, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 281, train loss: 0.6933, test loss: 0.6931, train acc: 0.4914, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 282, train loss: 0.6932, test loss: 0.6937, train acc: 0.4919, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 283, train loss: 0.6932, test loss: 0.6907, train acc: 0.5042, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 284, train loss: 0.6932, test loss: 0.6877, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 285, train loss: 0.6934, test loss: 0.6990, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 286, train loss: 0.6933, test loss: 0.6988, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 287, train loss: 0.6931, test loss: 0.6986, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 288, train loss: 0.6933, test loss: 0.6954, train acc: 0.4949, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 289, train loss: 0.6933, test loss: 0.6896, train acc: 0.4951, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 290, train loss: 0.6933, test loss: 0.6938, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 291, train loss: 0.6931, test loss: 0.6899, train acc: 0.5087, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 292, train loss: 0.6931, test loss: 0.6915, train acc: 0.5059, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 293, train loss: 0.6931, test loss: 0.6856, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 294, train loss: 0.6933, test loss: 0.6924, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 295, train loss: 0.6932, test loss: 0.6890, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 296, train loss: 0.6933, test loss: 0.6942, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 297, train loss: 0.6932, test loss: 0.6925, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 298, train loss: 0.6932, test loss: 0.6908, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 299, train loss: 0.6931, test loss: 0.6927, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 300, train loss: 0.6931, test loss: 0.6990, train acc: 0.5078, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 301, train loss: 0.6933, test loss: 0.6976, train acc: 0.4944, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 302, train loss: 0.6933, test loss: 0.6929, train acc: 0.4885, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 303, train loss: 0.6933, test loss: 0.6945, train acc: 0.4960, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 304, train loss: 0.6932, test loss: 0.6933, train acc: 0.5028, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 305, train loss: 0.6932, test loss: 0.6932, train acc: 0.4982, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 306, train loss: 0.6932, test loss: 0.6956, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 307, train loss: 0.6933, test loss: 0.6939, train acc: 0.4931, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 308, train loss: 0.6932, test loss: 0.6928, train acc: 0.4961, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 309, train loss: 0.6933, test loss: 0.6966, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 310, train loss: 0.6932, test loss: 0.6916, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 311, train loss: 0.6932, test loss: 0.6941, train acc: 0.5022, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 312, train loss: 0.6932, test loss: 0.6918, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 313, train loss: 0.6934, test loss: 0.6895, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 314, train loss: 0.6931, test loss: 0.7004, train acc: 0.5086, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 315, train loss: 0.6932, test loss: 0.6964, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 316, train loss: 0.6932, test loss: 0.6919, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 317, train loss: 0.6932, test loss: 0.6923, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 318, train loss: 0.6932, test loss: 0.6959, train acc: 0.4915, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 319, train loss: 0.6932, test loss: 0.6946, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 320, train loss: 0.6933, test loss: 0.6908, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 321, train loss: 0.6932, test loss: 0.6968, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 322, train loss: 0.6930, test loss: 0.6908, train acc: 0.5078, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 323, train loss: 0.6934, test loss: 0.6934, train acc: 0.4940, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 324, train loss: 0.6933, test loss: 0.6876, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 325, train loss: 0.6933, test loss: 0.6871, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 326, train loss: 0.6931, test loss: 0.7001, train acc: 0.5075, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 327, train loss: 0.6932, test loss: 0.6931, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 328, train loss: 0.6933, test loss: 0.6864, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 329, train loss: 0.6932, test loss: 0.6898, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 330, train loss: 0.6932, test loss: 0.6942, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 331, train loss: 0.6932, test loss: 0.6832, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 332, train loss: 0.6933, test loss: 0.6960, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 333, train loss: 0.6933, test loss: 0.6952, train acc: 0.4903, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 334, train loss: 0.6935, test loss: 0.6931, train acc: 0.4880, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 335, train loss: 0.6933, test loss: 0.6939, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 336, train loss: 0.6932, test loss: 0.6919, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 337, train loss: 0.6932, test loss: 0.6940, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 338, train loss: 0.6933, test loss: 0.6940, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 339, train loss: 0.6932, test loss: 0.6896, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 340, train loss: 0.6933, test loss: 0.6953, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 341, train loss: 0.6932, test loss: 0.6950, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 342, train loss: 0.6931, test loss: 0.6926, train acc: 0.5047, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 343, train loss: 0.6930, test loss: 0.6860, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 344, train loss: 0.6933, test loss: 0.6988, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 345, train loss: 0.6932, test loss: 0.6885, train acc: 0.4974, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 346, train loss: 0.6932, test loss: 0.6974, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 347, train loss: 0.6932, test loss: 0.6925, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 348, train loss: 0.6931, test loss: 0.6895, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 349, train loss: 0.6933, test loss: 0.6950, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 350, train loss: 0.6934, test loss: 0.6921, train acc: 0.4912, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 351, train loss: 0.6932, test loss: 0.6913, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 352, train loss: 0.6932, test loss: 0.6904, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 353, train loss: 0.6932, test loss: 0.6895, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 354, train loss: 0.6932, test loss: 0.6951, train acc: 0.5008, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 355, train loss: 0.6932, test loss: 0.6939, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 356, train loss: 0.6932, test loss: 0.6884, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 357, train loss: 0.6933, test loss: 0.6970, train acc: 0.4900, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 358, train loss: 0.6934, test loss: 0.6938, train acc: 0.4939, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 359, train loss: 0.6933, test loss: 0.6889, train acc: 0.4940, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 360, train loss: 0.6933, test loss: 0.6927, train acc: 0.4930, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 361, train loss: 0.6932, test loss: 0.6939, train acc: 0.5031, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 362, train loss: 0.6932, test loss: 0.6933, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 363, train loss: 0.6932, test loss: 0.6951, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 364, train loss: 0.6932, test loss: 0.6932, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 365, train loss: 0.6932, test loss: 0.6934, train acc: 0.5025, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 366, train loss: 0.6932, test loss: 0.6857, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 367, train loss: 0.6931, test loss: 0.6935, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 368, train loss: 0.6932, test loss: 0.6867, train acc: 0.4949, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 369, train loss: 0.6932, test loss: 0.6950, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 370, train loss: 0.6932, test loss: 0.6986, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 371, train loss: 0.6932, test loss: 0.6882, train acc: 0.5069, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 372, train loss: 0.6933, test loss: 0.6855, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 373, train loss: 0.6932, test loss: 0.6988, train acc: 0.5029, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 374, train loss: 0.6931, test loss: 0.6941, train acc: 0.5064, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 375, train loss: 0.6932, test loss: 0.6902, train acc: 0.5046, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 376, train loss: 0.6932, test loss: 0.6940, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 377, train loss: 0.6933, test loss: 0.6943, train acc: 0.5022, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 378, train loss: 0.6935, test loss: 0.6979, train acc: 0.4889, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 379, train loss: 0.6932, test loss: 0.7005, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 380, train loss: 0.6933, test loss: 0.6934, train acc: 0.5000, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 381, train loss: 0.6933, test loss: 0.6927, train acc: 0.4909, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 382, train loss: 0.6932, test loss: 0.6915, train acc: 0.4991, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 383, train loss: 0.6932, test loss: 0.6875, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 384, train loss: 0.6933, test loss: 0.6925, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 385, train loss: 0.6933, test loss: 0.6970, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 386, train loss: 0.6934, test loss: 0.6964, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 387, train loss: 0.6933, test loss: 0.6920, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 388, train loss: 0.6932, test loss: 0.7000, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 389, train loss: 0.6934, test loss: 0.6896, train acc: 0.4954, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 390, train loss: 0.6932, test loss: 0.6902, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 391, train loss: 0.6933, test loss: 0.6925, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 392, train loss: 0.6931, test loss: 0.6941, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 393, train loss: 0.6932, test loss: 0.6878, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 394, train loss: 0.6933, test loss: 0.6921, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 395, train loss: 0.6933, test loss: 0.6975, train acc: 0.4921, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 396, train loss: 0.6933, test loss: 0.6957, train acc: 0.5009, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 397, train loss: 0.6931, test loss: 0.7044, train acc: 0.5061, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 398, train loss: 0.6935, test loss: 0.6983, train acc: 0.4950, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 399, train loss: 0.6932, test loss: 0.6934, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 400, train loss: 0.6931, test loss: 0.6979, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 401, train loss: 0.6933, test loss: 0.6931, train acc: 0.4948, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 402, train loss: 0.6932, test loss: 0.6968, train acc: 0.4973, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 403, train loss: 0.6932, test loss: 0.6958, train acc: 0.4981, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 404, train loss: 0.6932, test loss: 0.6905, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 405, train loss: 0.6932, test loss: 0.6890, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 406, train loss: 0.6933, test loss: 0.6885, train acc: 0.4993, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 407, train loss: 0.6933, test loss: 0.6935, train acc: 0.4887, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 408, train loss: 0.6932, test loss: 0.7010, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 409, train loss: 0.6931, test loss: 0.6881, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 410, train loss: 0.6932, test loss: 0.6947, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 411, train loss: 0.6933, test loss: 0.6935, train acc: 0.4975, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 412, train loss: 0.6933, test loss: 0.6901, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 413, train loss: 0.6932, test loss: 0.6906, train acc: 0.5031, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 414, train loss: 0.6932, test loss: 0.6932, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 415, train loss: 0.6932, test loss: 0.6976, train acc: 0.5052, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 416, train loss: 0.6933, test loss: 0.6934, train acc: 0.4922, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 417, train loss: 0.6932, test loss: 0.6912, train acc: 0.5004, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 418, train loss: 0.6932, test loss: 0.6932, train acc: 0.4952, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 419, train loss: 0.6933, test loss: 0.6884, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 420, train loss: 0.6933, test loss: 0.6919, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 421, train loss: 0.6932, test loss: 0.6927, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 422, train loss: 0.6932, test loss: 0.6932, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 423, train loss: 0.6932, test loss: 0.6901, train acc: 0.5012, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 424, train loss: 0.6929, test loss: 0.6847, train acc: 0.5140, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 425, train loss: 0.6934, test loss: 0.6958, train acc: 0.4938, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 426, train loss: 0.6932, test loss: 0.6974, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 427, train loss: 0.6932, test loss: 0.6928, train acc: 0.4981, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 428, train loss: 0.6932, test loss: 0.6942, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 429, train loss: 0.6932, test loss: 0.6904, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 430, train loss: 0.6930, test loss: 0.6947, train acc: 0.5081, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 431, train loss: 0.6932, test loss: 0.6980, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 432, train loss: 0.6932, test loss: 0.6914, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 433, train loss: 0.6931, test loss: 0.6861, train acc: 0.5086, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 434, train loss: 0.6930, test loss: 0.7011, train acc: 0.5083, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 435, train loss: 0.6933, test loss: 0.6872, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 436, train loss: 0.6932, test loss: 0.6901, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 437, train loss: 0.6933, test loss: 0.6913, train acc: 0.4948, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 438, train loss: 0.6933, test loss: 0.6922, train acc: 0.4909, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 439, train loss: 0.6932, test loss: 0.6936, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 440, train loss: 0.6932, test loss: 0.6876, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 441, train loss: 0.6933, test loss: 0.6922, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 442, train loss: 0.6933, test loss: 0.6878, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 443, train loss: 0.6932, test loss: 0.6935, train acc: 0.4987, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 444, train loss: 0.6932, test loss: 0.6922, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 445, train loss: 0.6932, test loss: 0.6967, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 446, train loss: 0.6933, test loss: 0.6911, train acc: 0.4983, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 447, train loss: 0.6932, test loss: 0.6972, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 448, train loss: 0.6934, test loss: 0.6934, train acc: 0.4994, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 449, train loss: 0.6932, test loss: 0.6937, train acc: 0.5007, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 450, train loss: 0.6931, test loss: 0.6997, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 451, train loss: 0.6932, test loss: 0.6951, train acc: 0.5059, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 452, train loss: 0.6930, test loss: 0.6908, train acc: 0.5077, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 453, train loss: 0.6933, test loss: 0.6919, train acc: 0.4987, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 454, train loss: 0.6932, test loss: 0.6933, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 455, train loss: 0.6933, test loss: 0.6957, train acc: 0.4959, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 456, train loss: 0.6931, test loss: 0.6977, train acc: 0.5096, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 457, train loss: 0.6931, test loss: 0.6942, train acc: 0.4996, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 458, train loss: 0.6932, test loss: 0.6890, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 459, train loss: 0.6933, test loss: 0.6951, train acc: 0.4985, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 460, train loss: 0.6933, test loss: 0.6891, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 461, train loss: 0.6933, test loss: 0.6964, train acc: 0.4948, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 462, train loss: 0.6932, test loss: 0.6981, train acc: 0.4990, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 463, train loss: 0.6933, test loss: 0.6879, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 464, train loss: 0.6932, test loss: 0.6878, train acc: 0.5028, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 465, train loss: 0.6932, test loss: 0.6952, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 466, train loss: 0.6931, test loss: 0.6910, train acc: 0.5079, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 467, train loss: 0.6933, test loss: 0.6911, train acc: 0.4895, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 468, train loss: 0.6933, test loss: 0.6945, train acc: 0.4930, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 469, train loss: 0.6933, test loss: 0.6965, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 470, train loss: 0.6934, test loss: 0.6865, train acc: 0.4964, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 471, train loss: 0.6932, test loss: 0.7009, train acc: 0.5066, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 472, train loss: 0.6933, test loss: 0.6978, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 473, train loss: 0.6933, test loss: 0.6958, train acc: 0.4904, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 474, train loss: 0.6932, test loss: 0.6940, train acc: 0.5019, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 475, train loss: 0.6932, test loss: 0.6866, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 476, train loss: 0.6932, test loss: 0.6900, train acc: 0.5030, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 477, train loss: 0.6934, test loss: 0.6944, train acc: 0.5021, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 478, train loss: 0.6933, test loss: 0.6920, train acc: 0.4955, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 479, train loss: 0.6933, test loss: 0.6963, train acc: 0.4943, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 480, train loss: 0.6933, test loss: 0.6937, train acc: 0.4970, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 481, train loss: 0.6931, test loss: 0.6986, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 482, train loss: 0.6932, test loss: 0.6885, train acc: 0.5061, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 483, train loss: 0.6932, test loss: 0.6868, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 484, train loss: 0.6931, test loss: 0.6911, train acc: 0.5080, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 485, train loss: 0.6933, test loss: 0.6930, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 486, train loss: 0.6933, test loss: 0.6945, train acc: 0.5043, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 487, train loss: 0.6933, test loss: 0.7034, train acc: 0.4957, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 488, train loss: 0.6931, test loss: 0.6943, train acc: 0.5021, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 489, train loss: 0.6934, test loss: 0.6913, train acc: 0.4915, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 490, train loss: 0.6931, test loss: 0.7019, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 491, train loss: 0.6936, test loss: 0.6944, train acc: 0.4912, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 492, train loss: 0.6932, test loss: 0.6962, train acc: 0.4955, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 493, train loss: 0.6934, test loss: 0.6953, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 494, train loss: 0.6933, test loss: 0.6929, train acc: 0.4899, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 495, train loss: 0.6931, test loss: 0.7016, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 496, train loss: 0.6933, test loss: 0.6945, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 497, train loss: 0.6932, test loss: 0.6947, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 498, train loss: 0.6932, test loss: 0.6940, train acc: 0.5071, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 499, train loss: 0.6933, test loss: 0.6911, train acc: 0.4952, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 500, train loss: 0.6932, test loss: 0.6901, train acc: 0.4970, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 501, train loss: 0.6933, test loss: 0.6927, train acc: 0.4917, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 502, train loss: 0.6933, test loss: 0.6947, train acc: 0.4979, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 503, train loss: 0.6933, test loss: 0.6947, train acc: 0.4984, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 504, train loss: 0.6932, test loss: 0.6911, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 505, train loss: 0.6934, test loss: 0.6992, train acc: 0.4924, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 506, train loss: 0.6932, test loss: 0.6955, train acc: 0.5047, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 507, train loss: 0.6933, test loss: 0.6931, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 508, train loss: 0.6932, test loss: 0.6905, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 509, train loss: 0.6931, test loss: 0.6878, train acc: 0.5026, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 510, train loss: 0.6931, test loss: 0.6865, train acc: 0.5096, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 511, train loss: 0.6932, test loss: 0.6929, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 512, train loss: 0.6932, test loss: 0.6911, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 513, train loss: 0.6932, test loss: 0.6961, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 514, train loss: 0.6934, test loss: 0.6951, train acc: 0.4869, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 515, train loss: 0.6933, test loss: 0.6927, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 516, train loss: 0.6932, test loss: 0.6948, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 517, train loss: 0.6933, test loss: 0.6932, train acc: 0.5018, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 518, train loss: 0.6931, test loss: 0.6845, train acc: 0.4997, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 519, train loss: 0.6932, test loss: 0.6989, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 520, train loss: 0.6932, test loss: 0.6908, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 521, train loss: 0.6932, test loss: 0.6871, train acc: 0.5010, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 522, train loss: 0.6932, test loss: 0.6925, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 523, train loss: 0.6933, test loss: 0.6908, train acc: 0.4933, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 524, train loss: 0.6933, test loss: 0.6911, train acc: 0.4969, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 525, train loss: 0.6931, test loss: 0.6950, train acc: 0.5089, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 526, train loss: 0.6931, test loss: 0.6942, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 527, train loss: 0.6932, test loss: 0.6963, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 528, train loss: 0.6933, test loss: 0.6954, train acc: 0.4936, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 529, train loss: 0.6933, test loss: 0.6964, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 530, train loss: 0.6932, test loss: 0.6931, train acc: 0.4928, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 531, train loss: 0.6931, test loss: 0.6864, train acc: 0.5040, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 532, train loss: 0.6933, test loss: 0.6931, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 533, train loss: 0.6932, test loss: 0.6908, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 534, train loss: 0.6933, test loss: 0.6904, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 535, train loss: 0.6932, test loss: 0.6969, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 536, train loss: 0.6932, test loss: 0.6902, train acc: 0.4923, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 537, train loss: 0.6932, test loss: 0.6944, train acc: 0.5002, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 538, train loss: 0.6933, test loss: 0.6950, train acc: 0.4945, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 539, train loss: 0.6932, test loss: 0.6852, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 540, train loss: 0.6931, test loss: 0.6948, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 541, train loss: 0.6931, test loss: 0.6875, train acc: 0.5002, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 542, train loss: 0.6933, test loss: 0.6897, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 543, train loss: 0.6933, test loss: 0.6938, train acc: 0.4958, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 544, train loss: 0.6932, test loss: 0.6897, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 545, train loss: 0.6933, test loss: 0.6943, train acc: 0.4971, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 546, train loss: 0.6932, test loss: 0.6968, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 547, train loss: 0.6932, test loss: 0.6913, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 548, train loss: 0.6933, test loss: 0.6888, train acc: 0.4931, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 549, train loss: 0.6933, test loss: 0.6920, train acc: 0.4966, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 550, train loss: 0.6933, test loss: 0.6927, train acc: 0.4976, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 551, train loss: 0.6932, test loss: 0.6924, train acc: 0.4920, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 552, train loss: 0.6931, test loss: 0.6932, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 553, train loss: 0.6933, test loss: 0.6938, train acc: 0.4946, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 554, train loss: 0.6933, test loss: 0.6942, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 555, train loss: 0.6934, test loss: 0.6964, train acc: 0.4917, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 556, train loss: 0.6933, test loss: 0.6939, train acc: 0.4931, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 557, train loss: 0.6933, test loss: 0.6966, train acc: 0.4980, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 558, train loss: 0.6931, test loss: 0.6894, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 559, train loss: 0.6932, test loss: 0.6937, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 560, train loss: 0.6932, test loss: 0.6898, train acc: 0.4977, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 561, train loss: 0.6932, test loss: 0.6930, train acc: 0.5066, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 562, train loss: 0.6932, test loss: 0.6944, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 563, train loss: 0.6929, test loss: 0.6861, train acc: 0.5127, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 564, train loss: 0.6933, test loss: 0.6973, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 565, train loss: 0.6931, test loss: 0.6885, train acc: 0.5070, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 566, train loss: 0.6933, test loss: 0.6917, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 567, train loss: 0.6931, test loss: 0.6890, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 568, train loss: 0.6934, test loss: 0.6930, train acc: 0.4979, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 569, train loss: 0.6932, test loss: 0.6939, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 570, train loss: 0.6932, test loss: 0.6956, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 571, train loss: 0.6932, test loss: 0.6908, train acc: 0.5022, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 572, train loss: 0.6933, test loss: 0.6939, train acc: 0.4941, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 573, train loss: 0.6932, test loss: 0.6957, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 574, train loss: 0.6932, test loss: 0.6979, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 575, train loss: 0.6932, test loss: 0.6908, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 576, train loss: 0.6933, test loss: 0.6975, train acc: 0.4964, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 577, train loss: 0.6933, test loss: 0.6941, train acc: 0.4982, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 578, train loss: 0.6932, test loss: 0.6871, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 579, train loss: 0.6933, test loss: 0.6915, train acc: 0.4987, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 580, train loss: 0.6931, test loss: 0.6873, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 581, train loss: 0.6932, test loss: 0.6895, train acc: 0.4999, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 582, train loss: 0.6932, test loss: 0.6962, train acc: 0.5033, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 583, train loss: 0.6932, test loss: 0.6955, train acc: 0.4989, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 584, train loss: 0.6932, test loss: 0.6905, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 585, train loss: 0.6933, test loss: 0.6920, train acc: 0.4913, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 586, train loss: 0.6934, test loss: 0.6981, train acc: 0.4937, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 587, train loss: 0.6932, test loss: 0.6964, train acc: 0.5093, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 588, train loss: 0.6932, test loss: 0.6897, train acc: 0.5057, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 589, train loss: 0.6931, test loss: 0.6928, train acc: 0.5016, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 590, train loss: 0.6931, test loss: 0.6867, train acc: 0.5040, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 591, train loss: 0.6933, test loss: 0.6947, train acc: 0.4962, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 592, train loss: 0.6933, test loss: 0.6950, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 593, train loss: 0.6932, test loss: 0.6891, train acc: 0.4988, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 594, train loss: 0.6931, test loss: 0.6974, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 595, train loss: 0.6932, test loss: 0.6910, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 596, train loss: 0.6932, test loss: 0.6921, train acc: 0.4975, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 597, train loss: 0.6932, test loss: 0.6957, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 598, train loss: 0.6932, test loss: 0.6934, train acc: 0.4956, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 599, train loss: 0.6932, test loss: 0.6899, train acc: 0.5044, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 600, train loss: 0.6932, test loss: 0.6881, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 601, train loss: 0.6931, test loss: 0.6890, train acc: 0.5096, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 602, train loss: 0.6931, test loss: 0.6983, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 603, train loss: 0.6934, test loss: 0.6955, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 604, train loss: 0.6931, test loss: 0.6985, train acc: 0.5036, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 605, train loss: 0.6932, test loss: 0.6919, train acc: 0.5033, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 606, train loss: 0.6932, test loss: 0.6965, train acc: 0.5048, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 607, train loss: 0.6930, test loss: 0.6992, train acc: 0.5116, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 608, train loss: 0.6932, test loss: 0.6935, train acc: 0.5022, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 609, train loss: 0.6932, test loss: 0.6939, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 610, train loss: 0.6930, test loss: 0.6850, train acc: 0.5094, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 611, train loss: 0.6932, test loss: 0.6959, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 612, train loss: 0.6932, test loss: 0.6912, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 613, train loss: 0.6933, test loss: 0.6911, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 614, train loss: 0.6932, test loss: 0.6945, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 615, train loss: 0.6933, test loss: 0.6902, train acc: 0.4920, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 616, train loss: 0.6932, test loss: 0.6901, train acc: 0.5011, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 617, train loss: 0.6932, test loss: 0.6944, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 618, train loss: 0.6932, test loss: 0.6984, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 619, train loss: 0.6931, test loss: 0.6920, train acc: 0.5025, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 620, train loss: 0.6930, test loss: 0.7016, train acc: 0.5104, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 621, train loss: 0.6931, test loss: 0.6958, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 622, train loss: 0.6929, test loss: 0.6944, train acc: 0.5108, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 623, train loss: 0.6933, test loss: 0.6940, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 624, train loss: 0.6933, test loss: 0.6941, train acc: 0.4965, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 625, train loss: 0.6931, test loss: 0.6998, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 626, train loss: 0.6934, test loss: 0.6923, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 627, train loss: 0.6932, test loss: 0.6914, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 628, train loss: 0.6932, test loss: 0.6852, train acc: 0.4956, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 629, train loss: 0.6933, test loss: 0.6964, train acc: 0.4972, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 630, train loss: 0.6932, test loss: 0.6902, train acc: 0.5049, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 631, train loss: 0.6931, test loss: 0.6972, train acc: 0.5069, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 632, train loss: 0.6932, test loss: 0.6867, train acc: 0.5036, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 633, train loss: 0.6932, test loss: 0.6939, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 634, train loss: 0.6932, test loss: 0.6969, train acc: 0.5040, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 635, train loss: 0.6934, test loss: 0.6901, train acc: 0.4884, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 636, train loss: 0.6932, test loss: 0.6912, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 637, train loss: 0.6932, test loss: 0.6903, train acc: 0.5015, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 638, train loss: 0.6932, test loss: 0.6968, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 639, train loss: 0.6930, test loss: 0.6851, train acc: 0.5079, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 640, train loss: 0.6934, test loss: 0.7000, train acc: 0.5017, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 641, train loss: 0.6934, test loss: 0.6928, train acc: 0.4900, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 642, train loss: 0.6933, test loss: 0.6932, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 643, train loss: 0.6932, test loss: 0.6960, train acc: 0.5064, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 644, train loss: 0.6933, test loss: 0.6894, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 645, train loss: 0.6931, test loss: 0.7033, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 646, train loss: 0.6934, test loss: 0.6971, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 647, train loss: 0.6933, test loss: 0.6956, train acc: 0.4974, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 648, train loss: 0.6931, test loss: 0.6866, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 649, train loss: 0.6931, test loss: 0.6853, train acc: 0.5071, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 650, train loss: 0.6934, test loss: 0.6927, train acc: 0.4947, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 651, train loss: 0.6933, test loss: 0.6915, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 652, train loss: 0.6932, test loss: 0.6975, train acc: 0.4952, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 653, train loss: 0.6934, test loss: 0.6971, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 654, train loss: 0.6932, test loss: 0.6896, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 655, train loss: 0.6933, test loss: 0.6898, train acc: 0.4984, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 656, train loss: 0.6931, test loss: 0.6895, train acc: 0.5063, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 657, train loss: 0.6929, test loss: 0.6937, train acc: 0.5066, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 658, train loss: 0.6932, test loss: 0.6925, train acc: 0.4989, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 659, train loss: 0.6932, test loss: 0.6927, train acc: 0.4982, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 660, train loss: 0.6932, test loss: 0.6979, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 661, train loss: 0.6932, test loss: 0.6898, train acc: 0.5007, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 662, train loss: 0.6933, test loss: 0.6896, train acc: 0.4994, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 663, train loss: 0.6929, test loss: 0.6951, train acc: 0.5097, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 664, train loss: 0.6933, test loss: 0.6976, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 665, train loss: 0.6932, test loss: 0.6968, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 666, train loss: 0.6932, test loss: 0.6966, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 667, train loss: 0.6931, test loss: 0.6896, train acc: 0.5038, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 668, train loss: 0.6932, test loss: 0.6867, train acc: 0.5017, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 669, train loss: 0.6934, test loss: 0.6940, train acc: 0.4936, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 670, train loss: 0.6932, test loss: 0.6919, train acc: 0.5001, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 671, train loss: 0.6933, test loss: 0.6911, train acc: 0.4928, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 672, train loss: 0.6932, test loss: 0.6959, train acc: 0.5052, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 673, train loss: 0.6931, test loss: 0.6932, train acc: 0.5046, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 674, train loss: 0.6933, test loss: 0.6917, train acc: 0.4971, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 675, train loss: 0.6932, test loss: 0.6915, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 676, train loss: 0.6933, test loss: 0.6934, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 677, train loss: 0.6932, test loss: 0.6981, train acc: 0.5050, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 678, train loss: 0.6932, test loss: 0.6930, train acc: 0.5003, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 679, train loss: 0.6932, test loss: 0.6960, train acc: 0.5027, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 680, train loss: 0.6932, test loss: 0.6900, train acc: 0.5023, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 681, train loss: 0.6932, test loss: 0.6922, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 682, train loss: 0.6932, test loss: 0.6982, train acc: 0.5010, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 683, train loss: 0.6935, test loss: 0.6887, train acc: 0.4912, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 684, train loss: 0.6930, test loss: 0.6951, train acc: 0.5092, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 685, train loss: 0.6932, test loss: 0.6954, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 686, train loss: 0.6933, test loss: 0.6915, train acc: 0.4936, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 687, train loss: 0.6932, test loss: 0.6926, train acc: 0.5069, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 688, train loss: 0.6933, test loss: 0.6897, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 689, train loss: 0.6932, test loss: 0.6950, train acc: 0.5001, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 690, train loss: 0.6933, test loss: 0.6867, train acc: 0.5014, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 691, train loss: 0.6932, test loss: 0.6926, train acc: 0.5005, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 692, train loss: 0.6932, test loss: 0.6923, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 693, train loss: 0.6932, test loss: 0.6917, train acc: 0.4995, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 694, train loss: 0.6931, test loss: 0.6944, train acc: 0.5035, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 695, train loss: 0.6932, test loss: 0.6888, train acc: 0.4962, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 696, train loss: 0.6931, test loss: 0.6952, train acc: 0.5044, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 697, train loss: 0.6932, test loss: 0.6891, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 698, train loss: 0.6933, test loss: 0.6916, train acc: 0.4947, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 699, train loss: 0.6933, test loss: 0.6956, train acc: 0.4926, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 700, train loss: 0.6932, test loss: 0.6986, train acc: 0.5032, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 701, train loss: 0.6932, test loss: 0.6897, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 702, train loss: 0.6933, test loss: 0.6886, train acc: 0.4963, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 703, train loss: 0.6933, test loss: 0.6891, train acc: 0.4986, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 704, train loss: 0.6932, test loss: 0.6943, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 705, train loss: 0.6933, test loss: 0.6910, train acc: 0.5028, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 706, train loss: 0.6932, test loss: 0.6879, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 707, train loss: 0.6932, test loss: 0.6907, train acc: 0.5055, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 708, train loss: 0.6931, test loss: 0.6855, train acc: 0.5064, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 709, train loss: 0.6933, test loss: 0.6934, train acc: 0.4945, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 710, train loss: 0.6932, test loss: 0.6910, train acc: 0.4946, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 711, train loss: 0.6932, test loss: 0.6949, train acc: 0.5005, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 712, train loss: 0.6933, test loss: 0.6920, train acc: 0.4926, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 713, train loss: 0.6932, test loss: 0.6915, train acc: 0.5054, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 714, train loss: 0.6930, test loss: 0.6866, train acc: 0.5117, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 715, train loss: 0.6934, test loss: 0.6913, train acc: 0.4949, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 716, train loss: 0.6931, test loss: 0.6929, train acc: 0.5072, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 717, train loss: 0.6932, test loss: 0.6954, train acc: 0.5011, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 718, train loss: 0.6932, test loss: 0.6921, train acc: 0.5029, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 719, train loss: 0.6932, test loss: 0.6934, train acc: 0.5026, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 720, train loss: 0.6932, test loss: 0.6939, train acc: 0.4967, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 721, train loss: 0.6932, test loss: 0.6893, train acc: 0.4965, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 722, train loss: 0.6932, test loss: 0.6927, train acc: 0.5052, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 723, train loss: 0.6932, test loss: 0.6907, train acc: 0.4996, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 724, train loss: 0.6932, test loss: 0.6947, train acc: 0.5013, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 725, train loss: 0.6932, test loss: 0.6994, train acc: 0.4978, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 726, train loss: 0.6932, test loss: 0.6967, train acc: 0.4999, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 727, train loss: 0.6932, test loss: 0.6890, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 728, train loss: 0.6932, test loss: 0.6947, train acc: 0.4992, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 729, train loss: 0.6933, test loss: 0.7008, train acc: 0.5030, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 730, train loss: 0.6933, test loss: 0.6933, train acc: 0.4875, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 731, train loss: 0.6932, test loss: 0.6961, train acc: 0.5012, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 732, train loss: 0.6932, test loss: 0.6844, train acc: 0.4978, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 733, train loss: 0.6933, test loss: 0.6939, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 734, train loss: 0.6931, test loss: 0.6874, train acc: 0.5103, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 735, train loss: 0.6933, test loss: 0.6950, train acc: 0.5003, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 736, train loss: 0.6931, test loss: 0.6879, train acc: 0.5053, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 737, train loss: 0.6931, test loss: 0.6916, train acc: 0.5101, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 738, train loss: 0.6933, test loss: 0.6911, train acc: 0.4940, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 739, train loss: 0.6932, test loss: 0.7001, train acc: 0.5058, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 740, train loss: 0.6934, test loss: 0.6976, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 741, train loss: 0.6932, test loss: 0.6932, train acc: 0.4991, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 742, train loss: 0.6931, test loss: 0.6989, train acc: 0.5090, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 743, train loss: 0.6931, test loss: 0.6952, train acc: 0.5049, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 744, train loss: 0.6933, test loss: 0.6930, train acc: 0.4968, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 745, train loss: 0.6931, test loss: 0.6977, train acc: 0.5060, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 746, train loss: 0.6933, test loss: 0.6936, train acc: 0.4881, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 747, train loss: 0.6933, test loss: 0.6958, train acc: 0.5034, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 748, train loss: 0.6932, test loss: 0.6919, train acc: 0.5009, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 749, train loss: 0.6930, test loss: 0.6904, train acc: 0.5124, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 750, train loss: 0.6933, test loss: 0.6951, train acc: 0.4983, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 751, train loss: 0.6933, test loss: 0.6905, train acc: 0.4957, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 752, train loss: 0.6933, test loss: 0.6966, train acc: 0.4953, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 753, train loss: 0.6932, test loss: 0.6986, train acc: 0.5022, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 754, train loss: 0.6933, test loss: 0.6948, train acc: 0.4927, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 755, train loss: 0.6932, test loss: 0.6951, train acc: 0.5006, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 756, train loss: 0.6932, test loss: 0.6899, train acc: 0.4959, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 757, train loss: 0.6932, test loss: 0.6865, train acc: 0.5019, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 758, train loss: 0.6933, test loss: 0.6932, train acc: 0.4993, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 759, train loss: 0.6933, test loss: 0.6993, train acc: 0.5053, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 760, train loss: 0.6933, test loss: 0.6897, train acc: 0.4967, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 761, train loss: 0.6930, test loss: 0.6978, train acc: 0.5093, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 762, train loss: 0.6932, test loss: 0.7037, train acc: 0.4988, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 763, train loss: 0.6931, test loss: 0.6952, train acc: 0.5075, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 764, train loss: 0.6932, test loss: 0.6935, train acc: 0.4982, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 765, train loss: 0.6932, test loss: 0.6980, train acc: 0.4959, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 766, train loss: 0.6932, test loss: 0.6961, train acc: 0.5014, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 767, train loss: 0.6933, test loss: 0.6913, train acc: 0.5000, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 768, train loss: 0.6933, test loss: 0.7010, train acc: 0.5039, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 769, train loss: 0.6933, test loss: 0.6939, train acc: 0.5024, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 770, train loss: 0.6934, test loss: 0.6873, train acc: 0.4947, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 771, train loss: 0.6931, test loss: 0.6970, train acc: 0.5041, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 772, train loss: 0.6932, test loss: 0.6879, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 773, train loss: 0.6933, test loss: 0.6878, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 774, train loss: 0.6932, test loss: 0.6960, train acc: 0.5023, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 775, train loss: 0.6932, test loss: 0.6942, train acc: 0.5016, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 776, train loss: 0.6932, test loss: 0.6906, train acc: 0.4972, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 777, train loss: 0.6931, test loss: 0.6971, train acc: 0.5038, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 778, train loss: 0.6932, test loss: 0.6891, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 779, train loss: 0.6933, test loss: 0.6913, train acc: 0.4992, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 780, train loss: 0.6930, test loss: 0.6932, train acc: 0.5056, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 781, train loss: 0.6933, test loss: 0.6947, train acc: 0.4930, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 782, train loss: 0.6932, test loss: 0.6984, train acc: 0.4977, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 783, train loss: 0.6932, test loss: 0.6899, train acc: 0.5039, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 784, train loss: 0.6933, test loss: 0.6945, train acc: 0.4935, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 785, train loss: 0.6930, test loss: 0.6958, train acc: 0.5121, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 786, train loss: 0.6932, test loss: 0.6911, train acc: 0.5041, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 787, train loss: 0.6932, test loss: 0.6894, train acc: 0.4990, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 788, train loss: 0.6927, test loss: 0.6806, train acc: 0.5106, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 789, train loss: 0.6934, test loss: 0.6885, train acc: 0.5027, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 790, train loss: 0.6932, test loss: 0.6934, train acc: 0.4969, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 791, train loss: 0.6933, test loss: 0.6915, train acc: 0.4950, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 792, train loss: 0.6931, test loss: 0.6869, train acc: 0.5024, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 793, train loss: 0.6932, test loss: 0.6901, train acc: 0.5018, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 794, train loss: 0.6933, test loss: 0.6989, train acc: 0.5037, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 795, train loss: 0.6933, test loss: 0.6923, train acc: 0.4960, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 796, train loss: 0.6932, test loss: 0.6928, train acc: 0.4937, test acc: 0.6455, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 797, train loss: 0.6932, test loss: 0.6967, train acc: 0.5015, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 798, train loss: 0.6933, test loss: 0.6934, train acc: 0.4866, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "epoch: 799, train loss: 0.6933, test loss: 0.7022, train acc: 0.4963, test acc: 0.3545, test precision: 1.0000, test recall: 0.3545, test f1: 0.5234\n",
      "Trial 1 - Fold 3 - Params: {'weightdecay': 'yes', 'batch_norm': 'no', 'dropout': 'no', 'L2lambda': 0.1}\n",
      "Additional Hyperparameters -> Weight Decay: 0.1\n",
      "FOLD 3\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\trial\\_trial.py:492: UserWarning: The reported value is ignored because this `step` 799 is already reported.\n",
      "  step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, train loss: 0.6933, test loss: 0.6954, train acc: 0.5018, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 1, train loss: 0.6932, test loss: 0.6926, train acc: 0.5003, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 2, train loss: 0.6932, test loss: 0.6937, train acc: 0.4966, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 3, train loss: 0.6933, test loss: 0.6941, train acc: 0.4972, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 4, train loss: 0.6931, test loss: 0.6978, train acc: 0.5087, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 5, train loss: 0.6933, test loss: 0.6901, train acc: 0.5011, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 6, train loss: 0.6932, test loss: 0.6977, train acc: 0.5039, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 7, train loss: 0.6931, test loss: 0.6932, train acc: 0.5070, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 8, train loss: 0.6932, test loss: 0.6897, train acc: 0.5017, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 9, train loss: 0.6932, test loss: 0.6946, train acc: 0.5009, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 10, train loss: 0.6932, test loss: 0.6982, train acc: 0.4997, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 11, train loss: 0.6934, test loss: 0.6928, train acc: 0.4928, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 12, train loss: 0.6933, test loss: 0.6938, train acc: 0.4985, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 13, train loss: 0.6932, test loss: 0.6890, train acc: 0.4964, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 14, train loss: 0.6932, test loss: 0.6968, train acc: 0.4973, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 15, train loss: 0.6932, test loss: 0.6958, train acc: 0.5008, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 16, train loss: 0.6933, test loss: 0.6903, train acc: 0.4933, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 17, train loss: 0.6932, test loss: 0.6929, train acc: 0.5010, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 18, train loss: 0.6933, test loss: 0.6921, train acc: 0.4979, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 19, train loss: 0.6932, test loss: 0.6928, train acc: 0.4970, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 20, train loss: 0.6932, test loss: 0.6941, train acc: 0.4992, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 21, train loss: 0.6934, test loss: 0.6926, train acc: 0.4950, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 22, train loss: 0.6932, test loss: 0.6974, train acc: 0.5028, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 23, train loss: 0.6932, test loss: 0.6931, train acc: 0.4996, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 24, train loss: 0.6932, test loss: 0.6925, train acc: 0.5011, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 25, train loss: 0.6932, test loss: 0.6919, train acc: 0.5016, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 26, train loss: 0.6932, test loss: 0.6889, train acc: 0.5058, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 27, train loss: 0.6934, test loss: 0.6929, train acc: 0.4956, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 28, train loss: 0.6932, test loss: 0.6926, train acc: 0.4941, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 29, train loss: 0.6933, test loss: 0.6923, train acc: 0.5008, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 30, train loss: 0.6933, test loss: 0.6985, train acc: 0.5018, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 31, train loss: 0.6932, test loss: 0.6966, train acc: 0.5008, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 32, train loss: 0.6932, test loss: 0.6955, train acc: 0.4994, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 33, train loss: 0.6932, test loss: 0.6877, train acc: 0.4987, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 34, train loss: 0.6932, test loss: 0.6933, train acc: 0.5023, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 35, train loss: 0.6932, test loss: 0.6908, train acc: 0.5004, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 36, train loss: 0.6933, test loss: 0.6913, train acc: 0.4986, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 37, train loss: 0.6933, test loss: 0.6975, train acc: 0.5028, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 38, train loss: 0.6932, test loss: 0.6944, train acc: 0.5028, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 39, train loss: 0.6932, test loss: 0.6895, train acc: 0.5038, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 40, train loss: 0.6933, test loss: 0.6956, train acc: 0.4964, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 41, train loss: 0.6932, test loss: 0.6924, train acc: 0.4990, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 42, train loss: 0.6932, test loss: 0.6918, train acc: 0.4985, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 43, train loss: 0.6932, test loss: 0.6931, train acc: 0.5017, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 44, train loss: 0.6932, test loss: 0.6952, train acc: 0.5009, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 45, train loss: 0.6932, test loss: 0.6949, train acc: 0.5020, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 46, train loss: 0.6932, test loss: 0.6962, train acc: 0.5023, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 47, train loss: 0.6932, test loss: 0.6914, train acc: 0.5013, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 48, train loss: 0.6931, test loss: 0.6944, train acc: 0.5062, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 49, train loss: 0.6933, test loss: 0.6914, train acc: 0.4935, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 50, train loss: 0.6933, test loss: 0.6881, train acc: 0.4986, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 51, train loss: 0.6934, test loss: 0.6921, train acc: 0.4961, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 52, train loss: 0.6932, test loss: 0.6969, train acc: 0.4998, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 53, train loss: 0.6933, test loss: 0.6928, train acc: 0.4883, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 54, train loss: 0.6932, test loss: 0.6971, train acc: 0.4930, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 55, train loss: 0.6933, test loss: 0.6965, train acc: 0.4973, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 56, train loss: 0.6931, test loss: 0.6962, train acc: 0.5077, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 57, train loss: 0.6933, test loss: 0.6926, train acc: 0.4952, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 58, train loss: 0.6932, test loss: 0.6990, train acc: 0.5036, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 59, train loss: 0.6932, test loss: 0.6942, train acc: 0.4961, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 60, train loss: 0.6932, test loss: 0.6898, train acc: 0.5025, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 61, train loss: 0.6933, test loss: 0.6986, train acc: 0.4964, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 62, train loss: 0.6932, test loss: 0.6913, train acc: 0.5014, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 63, train loss: 0.6932, test loss: 0.6891, train acc: 0.4981, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 64, train loss: 0.6933, test loss: 0.6926, train acc: 0.4997, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 65, train loss: 0.6933, test loss: 0.6941, train acc: 0.4975, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 66, train loss: 0.6932, test loss: 0.6987, train acc: 0.5081, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 67, train loss: 0.6933, test loss: 0.6919, train acc: 0.4949, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 68, train loss: 0.6932, test loss: 0.6908, train acc: 0.4888, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 69, train loss: 0.6933, test loss: 0.6925, train acc: 0.4901, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 70, train loss: 0.6932, test loss: 0.6971, train acc: 0.5024, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 71, train loss: 0.6932, test loss: 0.6953, train acc: 0.5026, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 72, train loss: 0.6932, test loss: 0.6881, train acc: 0.4965, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 73, train loss: 0.6933, test loss: 0.6909, train acc: 0.4940, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 74, train loss: 0.6933, test loss: 0.6928, train acc: 0.4878, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 75, train loss: 0.6932, test loss: 0.6974, train acc: 0.4986, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 76, train loss: 0.6933, test loss: 0.6948, train acc: 0.4999, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 77, train loss: 0.6933, test loss: 0.6900, train acc: 0.4891, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 78, train loss: 0.6932, test loss: 0.6921, train acc: 0.5009, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 79, train loss: 0.6932, test loss: 0.6935, train acc: 0.4969, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 80, train loss: 0.6932, test loss: 0.6886, train acc: 0.5055, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 81, train loss: 0.6932, test loss: 0.6934, train acc: 0.4999, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 82, train loss: 0.6933, test loss: 0.6957, train acc: 0.5002, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 83, train loss: 0.6932, test loss: 0.6889, train acc: 0.5037, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 84, train loss: 0.6934, test loss: 0.6922, train acc: 0.5001, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 85, train loss: 0.6932, test loss: 0.6911, train acc: 0.5052, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 86, train loss: 0.6933, test loss: 0.6996, train acc: 0.4968, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 87, train loss: 0.6933, test loss: 0.6897, train acc: 0.4963, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 88, train loss: 0.6933, test loss: 0.6953, train acc: 0.4937, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 89, train loss: 0.6930, test loss: 0.6827, train acc: 0.5062, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 90, train loss: 0.6933, test loss: 0.6909, train acc: 0.4994, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 91, train loss: 0.6932, test loss: 0.6959, train acc: 0.5026, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 92, train loss: 0.6932, test loss: 0.6977, train acc: 0.5020, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 93, train loss: 0.6932, test loss: 0.6938, train acc: 0.4993, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 94, train loss: 0.6932, test loss: 0.6923, train acc: 0.4960, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 95, train loss: 0.6934, test loss: 0.6938, train acc: 0.4999, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 96, train loss: 0.6932, test loss: 0.6888, train acc: 0.5053, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 97, train loss: 0.6931, test loss: 0.6951, train acc: 0.4998, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 98, train loss: 0.6933, test loss: 0.6952, train acc: 0.4923, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 99, train loss: 0.6932, test loss: 0.6906, train acc: 0.5018, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 100, train loss: 0.6933, test loss: 0.6926, train acc: 0.4920, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 101, train loss: 0.6931, test loss: 0.6871, train acc: 0.5054, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 102, train loss: 0.6932, test loss: 0.6969, train acc: 0.5058, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 103, train loss: 0.6933, test loss: 0.6908, train acc: 0.4946, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 104, train loss: 0.6933, test loss: 0.6899, train acc: 0.4943, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 105, train loss: 0.6933, test loss: 0.6938, train acc: 0.4938, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 106, train loss: 0.6933, test loss: 0.6906, train acc: 0.4954, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 107, train loss: 0.6931, test loss: 0.6923, train acc: 0.5077, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 108, train loss: 0.6932, test loss: 0.6937, train acc: 0.5032, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 109, train loss: 0.6932, test loss: 0.6912, train acc: 0.4971, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 110, train loss: 0.6933, test loss: 0.6896, train acc: 0.4953, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 111, train loss: 0.6932, test loss: 0.6929, train acc: 0.5050, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 112, train loss: 0.6932, test loss: 0.6859, train acc: 0.5026, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 113, train loss: 0.6934, test loss: 0.6972, train acc: 0.5018, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 114, train loss: 0.6933, test loss: 0.6967, train acc: 0.4995, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 115, train loss: 0.6932, test loss: 0.6972, train acc: 0.4970, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 116, train loss: 0.6930, test loss: 0.6952, train acc: 0.5107, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 117, train loss: 0.6932, test loss: 0.6973, train acc: 0.5082, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 118, train loss: 0.6929, test loss: 0.7001, train acc: 0.5133, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 119, train loss: 0.6933, test loss: 0.6896, train acc: 0.4917, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 120, train loss: 0.6933, test loss: 0.6945, train acc: 0.4992, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 121, train loss: 0.6932, test loss: 0.6939, train acc: 0.5052, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 122, train loss: 0.6932, test loss: 0.6908, train acc: 0.4990, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 123, train loss: 0.6933, test loss: 0.6978, train acc: 0.4916, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 124, train loss: 0.6935, test loss: 0.6882, train acc: 0.4905, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 125, train loss: 0.6930, test loss: 0.7022, train acc: 0.5099, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 126, train loss: 0.6933, test loss: 0.6977, train acc: 0.5017, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 127, train loss: 0.6932, test loss: 0.6861, train acc: 0.4956, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 128, train loss: 0.6932, test loss: 0.6977, train acc: 0.5043, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 129, train loss: 0.6932, test loss: 0.6905, train acc: 0.5055, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 130, train loss: 0.6932, test loss: 0.6916, train acc: 0.5007, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 131, train loss: 0.6931, test loss: 0.6997, train acc: 0.5063, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 132, train loss: 0.6930, test loss: 0.6897, train acc: 0.5070, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 133, train loss: 0.6932, test loss: 0.6888, train acc: 0.5011, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 134, train loss: 0.6933, test loss: 0.6948, train acc: 0.5008, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 135, train loss: 0.6933, test loss: 0.6964, train acc: 0.4933, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 136, train loss: 0.6933, test loss: 0.6940, train acc: 0.4979, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 137, train loss: 0.6933, test loss: 0.6922, train acc: 0.4955, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 138, train loss: 0.6932, test loss: 0.6911, train acc: 0.4993, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 139, train loss: 0.6933, test loss: 0.6925, train acc: 0.4895, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 140, train loss: 0.6931, test loss: 0.7003, train acc: 0.5049, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 141, train loss: 0.6933, test loss: 0.6979, train acc: 0.5009, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 142, train loss: 0.6934, test loss: 0.6900, train acc: 0.4917, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 143, train loss: 0.6932, test loss: 0.6907, train acc: 0.5036, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 144, train loss: 0.6933, test loss: 0.6950, train acc: 0.4978, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 145, train loss: 0.6931, test loss: 0.6909, train acc: 0.5063, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 146, train loss: 0.6933, test loss: 0.6897, train acc: 0.5015, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 147, train loss: 0.6932, test loss: 0.6922, train acc: 0.5001, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 148, train loss: 0.6934, test loss: 0.6951, train acc: 0.4915, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 149, train loss: 0.6932, test loss: 0.6920, train acc: 0.5058, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 150, train loss: 0.6931, test loss: 0.6990, train acc: 0.5053, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 151, train loss: 0.6932, test loss: 0.6874, train acc: 0.4963, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 152, train loss: 0.6932, test loss: 0.6967, train acc: 0.5027, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 153, train loss: 0.6932, test loss: 0.6951, train acc: 0.5002, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 154, train loss: 0.6932, test loss: 0.6904, train acc: 0.5048, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 155, train loss: 0.6933, test loss: 0.6958, train acc: 0.5015, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 156, train loss: 0.6933, test loss: 0.6969, train acc: 0.4982, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 157, train loss: 0.6931, test loss: 0.6867, train acc: 0.5009, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 158, train loss: 0.6932, test loss: 0.6879, train acc: 0.5023, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 159, train loss: 0.6932, test loss: 0.6972, train acc: 0.5015, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 160, train loss: 0.6933, test loss: 0.6974, train acc: 0.4995, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 161, train loss: 0.6933, test loss: 0.6980, train acc: 0.5010, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 162, train loss: 0.6932, test loss: 0.6930, train acc: 0.4964, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 163, train loss: 0.6932, test loss: 0.6926, train acc: 0.5040, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 164, train loss: 0.6933, test loss: 0.6904, train acc: 0.4998, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 165, train loss: 0.6932, test loss: 0.6919, train acc: 0.4992, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 166, train loss: 0.6930, test loss: 0.6898, train acc: 0.5102, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 167, train loss: 0.6932, test loss: 0.7006, train acc: 0.5001, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 168, train loss: 0.6934, test loss: 0.6870, train acc: 0.4951, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 169, train loss: 0.6931, test loss: 0.6971, train acc: 0.5057, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 170, train loss: 0.6933, test loss: 0.6921, train acc: 0.5053, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 171, train loss: 0.6932, test loss: 0.6921, train acc: 0.4942, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 172, train loss: 0.6932, test loss: 0.6834, train acc: 0.5044, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 173, train loss: 0.6932, test loss: 0.6946, train acc: 0.5063, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 174, train loss: 0.6931, test loss: 0.7022, train acc: 0.5007, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 175, train loss: 0.6934, test loss: 0.6922, train acc: 0.4923, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 176, train loss: 0.6932, test loss: 0.6937, train acc: 0.5036, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 177, train loss: 0.6932, test loss: 0.6941, train acc: 0.5016, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 178, train loss: 0.6933, test loss: 0.6927, train acc: 0.4993, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 179, train loss: 0.6933, test loss: 0.6951, train acc: 0.4960, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 180, train loss: 0.6933, test loss: 0.6966, train acc: 0.4940, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 181, train loss: 0.6933, test loss: 0.6908, train acc: 0.4880, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 182, train loss: 0.6932, test loss: 0.6942, train acc: 0.4988, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 183, train loss: 0.6932, test loss: 0.6944, train acc: 0.5038, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 184, train loss: 0.6931, test loss: 0.6929, train acc: 0.5064, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 185, train loss: 0.6933, test loss: 0.6943, train acc: 0.4929, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 186, train loss: 0.6931, test loss: 0.6889, train acc: 0.5073, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 187, train loss: 0.6933, test loss: 0.6898, train acc: 0.4927, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 188, train loss: 0.6932, test loss: 0.6921, train acc: 0.5046, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 189, train loss: 0.6933, test loss: 0.6991, train acc: 0.5039, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 190, train loss: 0.6932, test loss: 0.6972, train acc: 0.4999, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 191, train loss: 0.6933, test loss: 0.6930, train acc: 0.4950, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 192, train loss: 0.6933, test loss: 0.6903, train acc: 0.5001, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 193, train loss: 0.6931, test loss: 0.6976, train acc: 0.5086, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 194, train loss: 0.6933, test loss: 0.6975, train acc: 0.4964, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 195, train loss: 0.6933, test loss: 0.6913, train acc: 0.4946, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 196, train loss: 0.6931, test loss: 0.6978, train acc: 0.5097, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 197, train loss: 0.6931, test loss: 0.6874, train acc: 0.5016, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 198, train loss: 0.6933, test loss: 0.6939, train acc: 0.5031, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 199, train loss: 0.6934, test loss: 0.6905, train acc: 0.4951, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 200, train loss: 0.6932, test loss: 0.6891, train acc: 0.4992, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 201, train loss: 0.6932, test loss: 0.6980, train acc: 0.4962, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 202, train loss: 0.6932, test loss: 0.6937, train acc: 0.5012, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 203, train loss: 0.6931, test loss: 0.6886, train acc: 0.5007, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 204, train loss: 0.6931, test loss: 0.6967, train acc: 0.5044, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 205, train loss: 0.6934, test loss: 0.6966, train acc: 0.4998, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 206, train loss: 0.6932, test loss: 0.6874, train acc: 0.4981, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 207, train loss: 0.6933, test loss: 0.6911, train acc: 0.4975, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 208, train loss: 0.6933, test loss: 0.6942, train acc: 0.5055, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 209, train loss: 0.6932, test loss: 0.6940, train acc: 0.4999, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 210, train loss: 0.6932, test loss: 0.6943, train acc: 0.5010, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 211, train loss: 0.6933, test loss: 0.6958, train acc: 0.4922, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 212, train loss: 0.6933, test loss: 0.6909, train acc: 0.4928, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 213, train loss: 0.6932, test loss: 0.6935, train acc: 0.5036, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 214, train loss: 0.6933, test loss: 0.6913, train acc: 0.4894, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 215, train loss: 0.6933, test loss: 0.6902, train acc: 0.5020, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 216, train loss: 0.6932, test loss: 0.6915, train acc: 0.5010, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 217, train loss: 0.6932, test loss: 0.6948, train acc: 0.5031, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 218, train loss: 0.6933, test loss: 0.6938, train acc: 0.4998, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 219, train loss: 0.6933, test loss: 0.6924, train acc: 0.4942, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 220, train loss: 0.6932, test loss: 0.6930, train acc: 0.4983, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 221, train loss: 0.6931, test loss: 0.6930, train acc: 0.5022, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 222, train loss: 0.6931, test loss: 0.6985, train acc: 0.5055, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 223, train loss: 0.6934, test loss: 0.6927, train acc: 0.4950, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 224, train loss: 0.6934, test loss: 0.6908, train acc: 0.4979, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 225, train loss: 0.6933, test loss: 0.6938, train acc: 0.4931, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 226, train loss: 0.6933, test loss: 0.6996, train acc: 0.5002, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 227, train loss: 0.6931, test loss: 0.6954, train acc: 0.5040, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 228, train loss: 0.6931, test loss: 0.6868, train acc: 0.5060, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 229, train loss: 0.6932, test loss: 0.6969, train acc: 0.5046, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 230, train loss: 0.6933, test loss: 0.6935, train acc: 0.4915, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 231, train loss: 0.6932, test loss: 0.6959, train acc: 0.5024, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 232, train loss: 0.6930, test loss: 0.6878, train acc: 0.5089, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 233, train loss: 0.6932, test loss: 0.6878, train acc: 0.5012, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 234, train loss: 0.6933, test loss: 0.6968, train acc: 0.4954, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 235, train loss: 0.6932, test loss: 0.6938, train acc: 0.5002, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 236, train loss: 0.6933, test loss: 0.6929, train acc: 0.4967, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 237, train loss: 0.6933, test loss: 0.6926, train acc: 0.4899, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 238, train loss: 0.6932, test loss: 0.6966, train acc: 0.4876, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 239, train loss: 0.6933, test loss: 0.6955, train acc: 0.4974, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 240, train loss: 0.6932, test loss: 0.6980, train acc: 0.5015, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 241, train loss: 0.6932, test loss: 0.6945, train acc: 0.5055, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 242, train loss: 0.6932, test loss: 0.6959, train acc: 0.4993, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 243, train loss: 0.6930, test loss: 0.6890, train acc: 0.5094, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 244, train loss: 0.6931, test loss: 0.6940, train acc: 0.5034, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 245, train loss: 0.6933, test loss: 0.6929, train acc: 0.4915, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 246, train loss: 0.6931, test loss: 0.6982, train acc: 0.5104, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 247, train loss: 0.6934, test loss: 0.6915, train acc: 0.4946, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 248, train loss: 0.6933, test loss: 0.6919, train acc: 0.5001, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 249, train loss: 0.6931, test loss: 0.6873, train acc: 0.5018, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 250, train loss: 0.6931, test loss: 0.6876, train acc: 0.5052, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 251, train loss: 0.6932, test loss: 0.6921, train acc: 0.5026, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 252, train loss: 0.6933, test loss: 0.6940, train acc: 0.5011, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 253, train loss: 0.6931, test loss: 0.6914, train acc: 0.5068, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 254, train loss: 0.6932, test loss: 0.6892, train acc: 0.4980, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 255, train loss: 0.6931, test loss: 0.6941, train acc: 0.5052, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 256, train loss: 0.6932, test loss: 0.6940, train acc: 0.5040, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 257, train loss: 0.6932, test loss: 0.6948, train acc: 0.5031, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 258, train loss: 0.6931, test loss: 0.6872, train acc: 0.5083, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 259, train loss: 0.6933, test loss: 0.6951, train acc: 0.5000, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 260, train loss: 0.6933, test loss: 0.6958, train acc: 0.5004, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 261, train loss: 0.6933, test loss: 0.6943, train acc: 0.4985, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 262, train loss: 0.6931, test loss: 0.6908, train acc: 0.5100, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 263, train loss: 0.6935, test loss: 0.6929, train acc: 0.4962, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 264, train loss: 0.6933, test loss: 0.6947, train acc: 0.5020, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 265, train loss: 0.6934, test loss: 0.6965, train acc: 0.4971, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 266, train loss: 0.6933, test loss: 0.6925, train acc: 0.4957, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 267, train loss: 0.6932, test loss: 0.6944, train acc: 0.5026, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 268, train loss: 0.6933, test loss: 0.7003, train acc: 0.5074, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 269, train loss: 0.6934, test loss: 0.6952, train acc: 0.5004, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 270, train loss: 0.6932, test loss: 0.6954, train acc: 0.5064, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 271, train loss: 0.6932, test loss: 0.6981, train acc: 0.4974, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 272, train loss: 0.6932, test loss: 0.6881, train acc: 0.4911, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 273, train loss: 0.6932, test loss: 0.6997, train acc: 0.5052, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 274, train loss: 0.6930, test loss: 0.6975, train acc: 0.5074, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 275, train loss: 0.6933, test loss: 0.6904, train acc: 0.4960, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 276, train loss: 0.6933, test loss: 0.6896, train acc: 0.4898, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 277, train loss: 0.6932, test loss: 0.6900, train acc: 0.4985, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 278, train loss: 0.6933, test loss: 0.6923, train acc: 0.4973, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 279, train loss: 0.6932, test loss: 0.6983, train acc: 0.4986, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 280, train loss: 0.6934, test loss: 0.6963, train acc: 0.4921, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 281, train loss: 0.6932, test loss: 0.6938, train acc: 0.4988, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 282, train loss: 0.6930, test loss: 0.6892, train acc: 0.5079, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 283, train loss: 0.6931, test loss: 0.6997, train acc: 0.5064, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 284, train loss: 0.6931, test loss: 0.6898, train acc: 0.5044, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 285, train loss: 0.6932, test loss: 0.6950, train acc: 0.5018, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 286, train loss: 0.6932, test loss: 0.6919, train acc: 0.4973, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 287, train loss: 0.6932, test loss: 0.6933, train acc: 0.4995, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 288, train loss: 0.6932, test loss: 0.6978, train acc: 0.5030, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 289, train loss: 0.6932, test loss: 0.6899, train acc: 0.4984, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 290, train loss: 0.6933, test loss: 0.6901, train acc: 0.4983, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 291, train loss: 0.6933, test loss: 0.6901, train acc: 0.4937, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 292, train loss: 0.6933, test loss: 0.6971, train acc: 0.5037, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 293, train loss: 0.6932, test loss: 0.6942, train acc: 0.5026, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 294, train loss: 0.6932, test loss: 0.6946, train acc: 0.4991, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 295, train loss: 0.6932, test loss: 0.6907, train acc: 0.5011, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 296, train loss: 0.6931, test loss: 0.6906, train acc: 0.5087, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 297, train loss: 0.6933, test loss: 0.6926, train acc: 0.4903, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 298, train loss: 0.6932, test loss: 0.6921, train acc: 0.4968, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 299, train loss: 0.6933, test loss: 0.6960, train acc: 0.4954, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 300, train loss: 0.6933, test loss: 0.6910, train acc: 0.4916, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 301, train loss: 0.6932, test loss: 0.6953, train acc: 0.5036, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 302, train loss: 0.6933, test loss: 0.6905, train acc: 0.4982, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 303, train loss: 0.6932, test loss: 0.6939, train acc: 0.4933, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 304, train loss: 0.6932, test loss: 0.6965, train acc: 0.4993, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 305, train loss: 0.6934, test loss: 0.6889, train acc: 0.4967, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 306, train loss: 0.6934, test loss: 0.6903, train acc: 0.5000, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 307, train loss: 0.6933, test loss: 0.6949, train acc: 0.4938, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 308, train loss: 0.6932, test loss: 0.6994, train acc: 0.5005, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 309, train loss: 0.6934, test loss: 0.6935, train acc: 0.4912, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 310, train loss: 0.6932, test loss: 0.6923, train acc: 0.5025, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 311, train loss: 0.6932, test loss: 0.6924, train acc: 0.5045, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 312, train loss: 0.6931, test loss: 0.7013, train acc: 0.5062, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 313, train loss: 0.6934, test loss: 0.6944, train acc: 0.4958, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 314, train loss: 0.6932, test loss: 0.6967, train acc: 0.5042, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 315, train loss: 0.6931, test loss: 0.6972, train acc: 0.5094, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 316, train loss: 0.6933, test loss: 0.6929, train acc: 0.4985, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 317, train loss: 0.6932, test loss: 0.6987, train acc: 0.5009, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 318, train loss: 0.6932, test loss: 0.6907, train acc: 0.4960, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 319, train loss: 0.6933, test loss: 0.6934, train acc: 0.4983, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 320, train loss: 0.6931, test loss: 0.6963, train acc: 0.5068, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 321, train loss: 0.6932, test loss: 0.6915, train acc: 0.5015, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 322, train loss: 0.6933, test loss: 0.6930, train acc: 0.4901, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 323, train loss: 0.6933, test loss: 0.6907, train acc: 0.4903, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 324, train loss: 0.6933, test loss: 0.6953, train acc: 0.4954, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 325, train loss: 0.6932, test loss: 0.6959, train acc: 0.5010, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 326, train loss: 0.6932, test loss: 0.6888, train acc: 0.4994, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 327, train loss: 0.6932, test loss: 0.6971, train acc: 0.5063, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 328, train loss: 0.6931, test loss: 0.6899, train acc: 0.5092, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 329, train loss: 0.6931, test loss: 0.6890, train acc: 0.5025, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 330, train loss: 0.6934, test loss: 0.6952, train acc: 0.4920, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 331, train loss: 0.6932, test loss: 0.6944, train acc: 0.4991, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 332, train loss: 0.6932, test loss: 0.6898, train acc: 0.4953, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 333, train loss: 0.6932, test loss: 0.6909, train acc: 0.4960, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 334, train loss: 0.6934, test loss: 0.6917, train acc: 0.4875, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 335, train loss: 0.6933, test loss: 0.6924, train acc: 0.4951, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 336, train loss: 0.6933, test loss: 0.6953, train acc: 0.5016, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 337, train loss: 0.6932, test loss: 0.6954, train acc: 0.5061, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 338, train loss: 0.6930, test loss: 0.6899, train acc: 0.5097, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 339, train loss: 0.6931, test loss: 0.6970, train acc: 0.5059, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 340, train loss: 0.6933, test loss: 0.6943, train acc: 0.4915, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 341, train loss: 0.6932, test loss: 0.6926, train acc: 0.4993, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 342, train loss: 0.6932, test loss: 0.6918, train acc: 0.4963, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 343, train loss: 0.6931, test loss: 0.6897, train acc: 0.5057, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 344, train loss: 0.6933, test loss: 0.6923, train acc: 0.4952, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 345, train loss: 0.6933, test loss: 0.6906, train acc: 0.4949, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 346, train loss: 0.6932, test loss: 0.6992, train acc: 0.4962, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 347, train loss: 0.6932, test loss: 0.6991, train acc: 0.5053, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 348, train loss: 0.6933, test loss: 0.6918, train acc: 0.5019, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 349, train loss: 0.6933, test loss: 0.6930, train acc: 0.4957, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 350, train loss: 0.6932, test loss: 0.6888, train acc: 0.4964, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 351, train loss: 0.6931, test loss: 0.6986, train acc: 0.5063, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 352, train loss: 0.6933, test loss: 0.6981, train acc: 0.4965, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 353, train loss: 0.6931, test loss: 0.6904, train acc: 0.5065, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 354, train loss: 0.6932, test loss: 0.6966, train acc: 0.5023, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 355, train loss: 0.6932, test loss: 0.6904, train acc: 0.5015, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 356, train loss: 0.6932, test loss: 0.6914, train acc: 0.4998, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 357, train loss: 0.6933, test loss: 0.6909, train acc: 0.4921, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 358, train loss: 0.6930, test loss: 0.6944, train acc: 0.5094, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 359, train loss: 0.6932, test loss: 0.6955, train acc: 0.5009, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 360, train loss: 0.6932, test loss: 0.6886, train acc: 0.4969, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 361, train loss: 0.6932, test loss: 0.6964, train acc: 0.4956, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 362, train loss: 0.6933, test loss: 0.6932, train acc: 0.4969, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 363, train loss: 0.6932, test loss: 0.6960, train acc: 0.4981, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 364, train loss: 0.6932, test loss: 0.6881, train acc: 0.5044, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 365, train loss: 0.6932, test loss: 0.6963, train acc: 0.5043, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 366, train loss: 0.6931, test loss: 0.6922, train acc: 0.5073, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 367, train loss: 0.6933, test loss: 0.6926, train acc: 0.4934, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 368, train loss: 0.6932, test loss: 0.6954, train acc: 0.5004, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 369, train loss: 0.6933, test loss: 0.6976, train acc: 0.5027, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 370, train loss: 0.6932, test loss: 0.6897, train acc: 0.5056, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 371, train loss: 0.6932, test loss: 0.6945, train acc: 0.5029, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 372, train loss: 0.6931, test loss: 0.6885, train acc: 0.5073, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 373, train loss: 0.6932, test loss: 0.6882, train acc: 0.4976, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 374, train loss: 0.6933, test loss: 0.6939, train acc: 0.4955, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 375, train loss: 0.6933, test loss: 0.6918, train acc: 0.4993, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 376, train loss: 0.6932, test loss: 0.6902, train acc: 0.4995, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 377, train loss: 0.6932, test loss: 0.6917, train acc: 0.4985, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 378, train loss: 0.6932, test loss: 0.6916, train acc: 0.4957, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 379, train loss: 0.6933, test loss: 0.6968, train acc: 0.4960, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 380, train loss: 0.6933, test loss: 0.6908, train acc: 0.4975, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 381, train loss: 0.6930, test loss: 0.6952, train acc: 0.5074, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 382, train loss: 0.6934, test loss: 0.6975, train acc: 0.4893, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 383, train loss: 0.6932, test loss: 0.6901, train acc: 0.4977, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 384, train loss: 0.6932, test loss: 0.6939, train acc: 0.5010, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 385, train loss: 0.6932, test loss: 0.6928, train acc: 0.5050, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 386, train loss: 0.6932, test loss: 0.6903, train acc: 0.4931, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 387, train loss: 0.6932, test loss: 0.6840, train acc: 0.5009, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 388, train loss: 0.6933, test loss: 0.6931, train acc: 0.4983, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 389, train loss: 0.6932, test loss: 0.6950, train acc: 0.4991, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 390, train loss: 0.6931, test loss: 0.6978, train acc: 0.5036, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 391, train loss: 0.6933, test loss: 0.6961, train acc: 0.4991, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 392, train loss: 0.6932, test loss: 0.7009, train acc: 0.5022, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 393, train loss: 0.6932, test loss: 0.6878, train acc: 0.5040, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 394, train loss: 0.6934, test loss: 0.6940, train acc: 0.4970, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 395, train loss: 0.6932, test loss: 0.6970, train acc: 0.4954, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 396, train loss: 0.6932, test loss: 0.6971, train acc: 0.5007, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 397, train loss: 0.6932, test loss: 0.6916, train acc: 0.4976, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n",
      "epoch: 398, train loss: 0.6932, test loss: 0.6954, train acc: 0.4982, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 399, train loss: 0.6932, test loss: 0.6974, train acc: 0.4991, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 400, train loss: 0.6932, test loss: 0.6965, train acc: 0.4979, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n",
      "epoch: 401, train loss: 0.6932, test loss: 0.6920, train acc: 0.4968, test acc: 0.6454, test precision: 0.0000, test recall: 0.0000, test f1: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-04-20 12:25:06,523]\u001b[0m Trial 1 failed with parameters: {'weightdecay': 'yes', 'batch_norm': 'no', 'dropout': 'no', 'L2lambda': 0.1} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\harit\\AppData\\Local\\Temp\\ipykernel_26196\\134380466.py\", line 142, in objective\n",
      "    train_loss, train_acc = train(train_loader, model, loss_fn, optimizer)\n",
      "  File \"C:\\Users\\harit\\AppData\\Local\\Temp\\ipykernel_26196\\1077543546.py\", line 14, in train\n",
      "    for batch_idx, (data, target) in enumerate(dataloader):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 61, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 163, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-20 12:25:06,538]\u001b[0m Trial 1 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 402, train loss: 0.6932, test loss: 0.6949, train acc: 0.4989, test acc: 0.3546, test precision: 1.0000, test recall: 0.3546, test f1: 0.5236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26196\\134380466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHyperbandPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"maximize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqlite:///optuna.sqlite3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_if_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mpruned_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[0mcomplete_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         )\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26196\\134380466.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_precision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# test_auc_score, test_maxF1, test_bestthershold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"epoch: {t}, train loss: {train_loss:.4f}, test loss: {test_loss:.4f}, train acc: {train_acc:.4f}, test acc: {test_acc:.4f}, test precision: {test_precision:.4f}, test recall: {test_recall:.4f}, test f1: {test_f1:.4f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# test auc: {test_auc_score:.4f}, test maxF1: {test_maxF1:.4f}, test best threshold: {test_bestthershold:.4f}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26196\\1077543546.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Loop through dataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Move data to device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Handle `CustomType` automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def define_model(trial):\n",
    "    #global epochs\n",
    "    #epochs = trial.suggest_int(\"epochs\", 100, 1000, step = 100)\n",
    "    #epochs=1\n",
    "    # Optimize Hyperparameters\n",
    "    YorN_batchnorm = trial.suggest_categorical(\"batch_norm\",['yes','no'])\n",
    "    global YorN_dropout\n",
    "    global dropout\n",
    "    YorN_dropout = trial.suggest_categorical(\"dropout\",['yes','no'])\n",
    "    #if YorN_dropout == 'yes':\n",
    "    #    dropout = trial.suggest_float(\"dropout_l\", 0.1, 0.4, step = 0.1) \n",
    "    #n_layers = trial.suggest_int(\"n_layers\", 1,5)\n",
    "    #n_first_units = trial.suggest_categorical(\"n_first_units\", [128,256,512,1024])\n",
    "\n",
    "\n",
    "    # Define Model\n",
    "    layers = []\n",
    "\n",
    "    # Input Layer\n",
    "    in_features = np_input.shape[1]\n",
    "    out_features = n_first_units\n",
    "    layers.append(nn.Linear(in_features, out_features))\n",
    "    layers.append(nn.ReLU())\n",
    "    if YorN_dropout == 'yes':\n",
    "        layers.append(nn.Dropout(dropout))\n",
    "    in_features = out_features\n",
    "\n",
    "    # Hidden Layers\n",
    "    for i in range(n_layers): #i หมายถึงเลขชั้น hidden+1\n",
    "        #out_features = trial.suggest_int(\"n_units_l{}\".format(i), 5, 4096) \n",
    "        #out_features = trial.suggest_int(\"n_units_l{}\".format(i), 256, 2048, 256) \n",
    "        if YorN_batchnorm == 'yes':\n",
    "            layers.append(nn.BatchNorm1d(in_features))\n",
    "        out_features = int(in_features/2)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        if YorN_dropout == 'yes':\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "        in_features = out_features\n",
    "\n",
    "    # Output Layer\n",
    "    if YorN_batchnorm == 'yes':\n",
    "        layers.append(nn.BatchNorm1d(in_features))                          \n",
    "    layers.append(nn.Linear(out_features, 1)) \n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    # Return model\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    # Optimize Hyperparameters\n",
    "    #batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256, 512, 1024, 2048])\n",
    "    YorN_weightdecay = trial.suggest_categorical(\"weightdecay\",['yes','no'])\n",
    "    \n",
    "    # Create model\n",
    "    model = define_model(trial).to(device)\n",
    "    #print(model)\n",
    "\n",
    "    # Assign Optimizer\n",
    "    #learning_rate = trial.suggest_categorical(\"learning_rate\", [1e-6, 1e-5, 1e-4, 1e-3, 1e-2])\n",
    "    #learning_rate = 1e-3\n",
    "    optimizer_name = \"Adam\"\n",
    "    if YorN_weightdecay == 'yes':\n",
    "        L2lambda = trial.suggest_categorical(\"L2lambda\", [1e-4, 1e-3, 1e-2, 1e-1, 1])\n",
    "        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=learning_rate, weight_decay=L2lambda) #เพิ่ม weight decay เพื่อให้ model ไม่ overfit\n",
    "    else:\n",
    "        optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Assign Run Name\n",
    "    name = f\"trial-{trial.number}\"\n",
    "    dir = os.path.join(dirname, name)\n",
    "\n",
    "    # Create K-Fold and lock Random Seed\n",
    "    kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=123)\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "    total_train_loss = []\n",
    "    total_test_loss = []\n",
    "    total_train_acc = []\n",
    "    total_test_acc = []\n",
    "    total_test_f1 = []\n",
    "    total_test_precision = []\n",
    "    total_test_recall = []\n",
    "    total_test_auc = []\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(np_input,np_output)):\n",
    "        \n",
    "        # Reset model   \n",
    "        model.apply(reset_weights)\n",
    "\n",
    "        fold_train_loss = []\n",
    "        fold_test_loss = []\n",
    "        fold_train_acc = []\n",
    "        fold_test_acc = []\n",
    "        fold_test_f1 = []\n",
    "        fold_test_precision = []\n",
    "        fold_test_recall = []\n",
    "        #fold_test_auc = []\n",
    "\n",
    "        # Check disjoint for each fold จ้า\n",
    "        for x in train_ids: \n",
    "            if x in test_ids:\n",
    "                raise Exception(\"WARNING: Train and Test IDs are not disjoint!\")\n",
    "            \n",
    "        print(f\"Trial {trial.number} - Fold {fold} - Params: {trial.params}\")\n",
    "        if YorN_weightdecay == 'yes':\n",
    "            print(f\"Additional Hyperparameters -> Weight Decay: {L2lambda}\")\n",
    "        if YorN_dropout == 'yes':\n",
    "            print(f\"Additional Hyperparameters -> Dropout: {dropout}\")\n",
    "        # Print Fold\n",
    "        print(f'FOLD {fold}')   \n",
    "        print(f'--------')   \n",
    "\n",
    "        # Create data for each fold with the index provided by kfold.split\n",
    "        np_fold_train_input = np_input[train_ids]\n",
    "        np_fold_train_output = np_output[train_ids]\n",
    "        np_fold_test_input = np_input[test_ids]\n",
    "        np_fold_test_output = np_output[test_ids]\n",
    "\n",
    "        # Create Weight for Sampler\n",
    "        weight = (1/pd.DataFrame(np_fold_train_output).value_counts()).tolist()\n",
    "        sample_weights = np.array([weight[int(t)] for t in np_fold_train_output])\n",
    "\n",
    "        # Create Sampler\n",
    "        sampler = WeightedRandomSampler(weights=sample_weights,num_samples=len(sample_weights), replacement=True)\n",
    "        #train_sampler = RandomSampler(np_fold_train_output) #RandomSampler จะทำให้เห็นว่า class มัน imbalance ยังไง\n",
    "\n",
    "        # Create Dataset and Dataloader\n",
    "        train_dataset = TensorDataset(torch.from_numpy(np_fold_train_input).float(), torch.from_numpy(np_fold_train_output).float())\n",
    "        test_dataset = TensorDataset(torch.from_numpy(np_fold_test_input).float(), torch.from_numpy(np_fold_test_output).float())\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=len(test_ids))\n",
    "        #get_dataloader_distribution(train_loader,test_loader,label=f'Fold {fold}') #ใช้เช็ค Distribution ของแต่ละ Fold\n",
    "\n",
    "\n",
    "        # Train / Test Loops\n",
    "        for t in range(epochs):\n",
    "            \n",
    "            train_loss, train_acc = train(train_loader, model, loss_fn, optimizer)\n",
    "            test_loss, test_acc, test_precision, test_recall, test_f1 = test(test_loader, model, loss_fn) # test_auc_score, test_maxF1, test_bestthershold \n",
    "            print(f\"epoch: {t}, train loss: {train_loss:.4f}, test loss: {test_loss:.4f}, train acc: {train_acc:.4f}, test acc: {test_acc:.4f}, test precision: {test_precision:.4f}, test recall: {test_recall:.4f}, test f1: {test_f1:.4f}\")# test auc: {test_auc_score:.4f}, test maxF1: {test_maxF1:.4f}, test best threshold: {test_bestthershold:.4f}\")\n",
    "            fold_train_loss.append(train_loss)\n",
    "            fold_test_loss.append(test_loss)\n",
    "            fold_train_acc.append(train_acc)\n",
    "            fold_test_acc.append(test_acc)\n",
    "            fold_test_f1.append(test_f1)\n",
    "            fold_test_precision.append(test_precision)\n",
    "            fold_test_recall.append(test_recall)\n",
    "            # fold_test_auc.append(test_auc_score)\n",
    "            with tf.summary.create_file_writer(f\"{dir}_train_fold{fold}\").as_default():\n",
    "                tf.summary.scalar(\"loss\", train_loss, step=t)\n",
    "                tf.summary.scalar(\"acc\", train_acc, step=t)\n",
    "            with tf.summary.create_file_writer(f\"{dir}_test_fold{fold}\").as_default():    \n",
    "                tf.summary.scalar(\"loss\", test_loss, step=t) \n",
    "                tf.summary.scalar(\"acc\", test_acc, step=t)\n",
    "                tf.summary.scalar(\"precision\", test_precision, step=t)\n",
    "                tf.summary.scalar(\"f1_score\", test_f1, step=t)\n",
    "                tf.summary.scalar(\"recall_score\", test_recall, step=t)\n",
    "                # tf.summary.scalar(\"auc_score\", test_auc_score, step=t)\n",
    "                # tf.summary.scalar(\"auc_score\", test_maxF1, step=t)\n",
    "\n",
    "        # Added last value of each fold to total list\n",
    "        total_train_loss.append(train_loss)\n",
    "        total_test_loss.append(test_loss)\n",
    "        total_train_acc.append(train_acc)\n",
    "        total_test_acc.append(test_acc)\n",
    "        total_test_f1.append(test_f1)\n",
    "        total_test_precision.append(test_precision)\n",
    "        total_test_recall.append(test_recall)\n",
    "        # total_test_auc.append(test_auc_score)\n",
    "\n",
    "        trial.set_user_attr(f\"{fold} Train_loss: \", train_loss)\n",
    "        trial.set_user_attr(f\"{fold} Test_loss: \", test_loss)\n",
    "        trial.set_user_attr(f\"{fold} Train_acc: \", train_acc)\n",
    "        trial.set_user_attr(f\"{fold} Test_acc: \", test_acc)\n",
    "        trial.set_user_attr(f\"{fold} Test_precision: \", test_precision)\n",
    "        trial.set_user_attr(f\"{fold} Test_recall: \", test_recall)\n",
    "        trial.set_user_attr(f\"{fold} Test_f1: \", test_f1)\n",
    "        # trial.set_user_attr(f\"{fold} Test_auc: \", test_auc_score)\n",
    "        # trial.set_user_attr(f\"{fold} Test_maxF1: \", test_maxF1)\n",
    "        # trial.set_user_attr(f\"{fold} Test_bestthreshold: \", test_bestthershold)\n",
    "\n",
    "        trial.report(test_f1, t)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    print(\"Training Done\")\n",
    "    print(f\"K-FOLD CROSS VALIDATION FOR {k_folds} FOLDS, IN {epochs} EPOCHS\")\n",
    "    print(f\"Total Train Loss: {np.mean(total_train_loss):.5f}\")\n",
    "    print(f\"Total Test Loss: {np.mean(total_test_loss):.5f}\")\n",
    "    print(f\"Total Train Acc: {np.mean(total_train_acc):.5f}\")\n",
    "    print(f\"Total Test Acc: {np.mean(total_test_acc):.5f}\")\n",
    "    print(f\"Total Test Precision: {np.mean(total_test_precision):.5f}\")\n",
    "    print(f\"Total Test Recall: {np.mean(total_test_recall):.5f}\")\n",
    "    print(f\"Total Test F1: {np.mean(total_test_f1):.5f}\")\n",
    "    print(f\"Total Test AUC: {np.mean(total_test_auc):.5f}\")\n",
    "\n",
    "    trial.set_user_attr(f\"Total Train_loss\", np.mean(total_train_loss))\n",
    "    trial.set_user_attr(f\"Total Test_loss\", np.mean(total_test_loss))\n",
    "    trial.set_user_attr(f\"Total Train_acc\",np.mean(total_train_acc))\n",
    "    trial.set_user_attr(f\"Total Test_acc\", np.mean(total_test_acc))\n",
    "    trial.set_user_attr(f\"Total Test_precision\" , np.mean(total_test_precision))\n",
    "    trial.set_user_attr(f\"Total Test_recall\" , np.mean(total_test_recall))\n",
    "    trial.set_user_attr(f\"Total Test_f1\" , np.mean(total_test_f1))\n",
    "    trial.set_user_attr(f\"Total Test_auc\" , np.mean(total_test_auc))\n",
    "\n",
    "    try:\n",
    "        fig,ax = plt.subplots()\n",
    "        X_axis = np.arange(1,k_folds+1,1)\n",
    "        ax.bar(X_axis,total_test_f1, color='green',label = \"F1 Score\",width=1/4)\n",
    "        ax.bar(X_axis-(1/4),total_test_precision, color='blue',label = \"Precision\",width=1/4)\n",
    "        ax.bar(X_axis-(2/4),total_test_recall, color='red',label = \"Recall\",width=1/4)\n",
    "        ax.bar(X_axis-(3/4),total_test_acc, color='yellow',label = \"Accuracy\",width=1/4)\n",
    "        ax.set_xlabel(\"Fold\")\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(\"F1 Score\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../4 - Training & Testing/{dirname}/{name}_metrics.png\")\n",
    "    except:\n",
    "        print(\"Cannot save metrics plot, passed to continue\")\n",
    "        pass\n",
    "\n",
    "    return np.mean(total_test_f1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    tensorboard_callback = TensorBoardCallback(dirname = dirname, metric_name=\"target\")\n",
    "    #pruner = optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=3)\n",
    "    pruner = optuna.pruners.HyperbandPruner(min_resource=1, max_resource=1000, reduction_factor=3)\n",
    "    study = optuna.create_study(study_name = dirname, directions=[\"maximize\"],sampler=TPESampler(),storage='sqlite:///optuna.sqlite3',pruner=pruner, load_if_exists=True)\n",
    "    study.optimize(objective, n_trials=1, timeout=None)\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
