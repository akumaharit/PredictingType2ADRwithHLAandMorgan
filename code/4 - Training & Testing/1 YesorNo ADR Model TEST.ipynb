{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 9,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries ต่าง ๆ ที่จะใช้\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split # ใช้ในการแบ่งข้อมูล\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib import pyplot\n",
    "from torchmetrics.classification import MulticlassPrecisionRecallCurve\n",
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 10,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADR</th>\n",
       "      <th>Cohort ethnicity_Black</th>\n",
       "      <th>Cohort ethnicity_Caucasian</th>\n",
       "      <th>Cohort ethnicity_Diverse</th>\n",
       "      <th>Cohort ethnicity_Mongol</th>\n",
       "      <th>Allele_A*01</th>\n",
       "      <th>Allele_A*01:01</th>\n",
       "      <th>Allele_A*02</th>\n",
       "      <th>Allele_A*02:01</th>\n",
       "      <th>Allele_A*02:03</th>\n",
       "      <th>...</th>\n",
       "      <th>Drug_methazolamide</th>\n",
       "      <th>Drug_nevirapine</th>\n",
       "      <th>Drug_oxcarbazepine</th>\n",
       "      <th>Drug_oxicam NSAIDs</th>\n",
       "      <th>Drug_paracetamol</th>\n",
       "      <th>Drug_phenobarbital</th>\n",
       "      <th>Drug_phenytoin</th>\n",
       "      <th>Drug_sulfamethoxazole</th>\n",
       "      <th>Drug_trichloroethylene</th>\n",
       "      <th>Drug_valproic acid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17855</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17856</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17858</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17860 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ADR  Cohort ethnicity_Black  Cohort ethnicity_Caucasian  \\\n",
       "0        1                       0                           0   \n",
       "1        1                       0                           0   \n",
       "2        1                       0                           0   \n",
       "3        1                       0                           0   \n",
       "4        1                       0                           0   \n",
       "...    ...                     ...                         ...   \n",
       "17855    0                       0                           0   \n",
       "17856    0                       0                           0   \n",
       "17857    0                       0                           0   \n",
       "17858    0                       0                           0   \n",
       "17859    0                       0                           0   \n",
       "\n",
       "       Cohort ethnicity_Diverse  Cohort ethnicity_Mongol  Allele_A*01  \\\n",
       "0                             1                        0            0   \n",
       "1                             1                        0            0   \n",
       "2                             1                        0            0   \n",
       "3                             0                        1            0   \n",
       "4                             0                        1            0   \n",
       "...                         ...                      ...          ...   \n",
       "17855                         1                        0            0   \n",
       "17856                         1                        0            0   \n",
       "17857                         1                        0            0   \n",
       "17858                         1                        0            0   \n",
       "17859                         1                        0            0   \n",
       "\n",
       "       Allele_A*01:01  Allele_A*02  Allele_A*02:01  Allele_A*02:03  ...  \\\n",
       "0                   0            0               0               0  ...   \n",
       "1                   0            0               0               0  ...   \n",
       "2                   0            0               0               0  ...   \n",
       "3                   0            0               0               0  ...   \n",
       "4                   0            0               0               0  ...   \n",
       "...               ...          ...             ...             ...  ...   \n",
       "17855               0            0               0               0  ...   \n",
       "17856               0            0               0               0  ...   \n",
       "17857               0            0               0               0  ...   \n",
       "17858               0            0               0               0  ...   \n",
       "17859               0            0               0               0  ...   \n",
       "\n",
       "       Drug_methazolamide  Drug_nevirapine  Drug_oxcarbazepine  \\\n",
       "0                       0                0                   0   \n",
       "1                       0                0                   0   \n",
       "2                       0                0                   0   \n",
       "3                       0                0                   0   \n",
       "4                       0                0                   0   \n",
       "...                   ...              ...                 ...   \n",
       "17855                   0                0                   0   \n",
       "17856                   0                0                   0   \n",
       "17857                   0                0                   0   \n",
       "17858                   0                0                   0   \n",
       "17859                   0                0                   0   \n",
       "\n",
       "       Drug_oxicam NSAIDs  Drug_paracetamol  Drug_phenobarbital  \\\n",
       "0                       0                 0                   0   \n",
       "1                       0                 0                   0   \n",
       "2                       0                 0                   0   \n",
       "3                       0                 0                   0   \n",
       "4                       0                 0                   0   \n",
       "...                   ...               ...                 ...   \n",
       "17855                   0                 0                   0   \n",
       "17856                   0                 0                   0   \n",
       "17857                   0                 0                   0   \n",
       "17858                   0                 0                   0   \n",
       "17859                   0                 0                   0   \n",
       "\n",
       "       Drug_phenytoin  Drug_sulfamethoxazole  Drug_trichloroethylene  \\\n",
       "0                   0                      0                       0   \n",
       "1                   0                      0                       0   \n",
       "2                   0                      0                       0   \n",
       "3                   0                      0                       0   \n",
       "4                   0                      0                       0   \n",
       "...               ...                    ...                     ...   \n",
       "17855               0                      0                       1   \n",
       "17856               0                      0                       1   \n",
       "17857               0                      0                       1   \n",
       "17858               0                      0                       1   \n",
       "17859               0                      0                       1   \n",
       "\n",
       "       Drug_valproic acid  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "...                   ...  \n",
       "17855                   0  \n",
       "17856                   0  \n",
       "17857                   0  \n",
       "17858                   0  \n",
       "17859                   0  \n",
       "\n",
       "[17860 rows x 241 columns]"
      ]
     },
<<<<<<< HEAD
     "execution_count": 2,
=======
     "execution_count": 10,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(\"../3 - Cleaning & Transforming Data/EDA/complete_dataset, 1 adr columns no drug desc no prot seq.csv\",index_col = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 11,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [],
   "source": [
    "# define get_dataset()\n",
    "def get_dataset(df, BATCHSIZE):\n",
    "    #from torchsampler import ImbalancedDatasetSampler\n",
    "    df_labels = df.iloc[:, 0]\n",
    "    df_input = df.iloc[:, 1:]\n",
    "\n",
    "    np_input = df_input.to_numpy()\n",
    "    np_labels = df_labels.to_numpy()\n",
    "\n",
    "    #train test split\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(np_input, np_labels, test_size=0.2, random_state=128, stratify=np_labels, shuffle = True)\n",
    "    \n",
    "    print('train_label data distribution 0/1: {}/{}'.format(\n",
    "    len(np.where(train_labels == 0)[0]), len(np.where(train_labels == 1)[0])))\n",
    "    \n",
    "    print('test_labels data distribution 0/1: {}/{}'.format(\n",
    "    len(np.where(test_labels == 0)[0]), len(np.where(test_labels == 1)[0])))\n",
    "\n",
    "    #calculate weight for each class in train_labels\n",
    "    weight = (1/pd.DataFrame(train_labels).value_counts()).tolist()\n",
    "    \n",
    "    #create weight array for train_labels\n",
    "    sample_weights = np.array([weight[int(t)] for t in train_labels])\n",
    "    \n",
    "    #assign weight to Weighted Random Sampler\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights,num_samples=len(sample_weights), replacement=True)\n",
    "    \n",
    "    #แปลง numpy เข้า TensorDataSet และ DataLoader\n",
    "    train_dataset = TensorDataset(torch.from_numpy(train_data).float(), torch.from_numpy(train_labels).float())\n",
    "    test_dataset = TensorDataset(torch.from_numpy(test_data).float(), torch.from_numpy(test_labels).float())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCHSIZE, sampler=sampler)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=test_labels.shape[0])\n",
    "\n",
    "    #loop ดูภาพรวมของ train_loader\n",
    "    for i, (data, target) in enumerate(train_loader):\n",
    "        print(\"batch index {}, 0/1: {}/{}\".format(\n",
    "            i,\n",
    "            len(np.where(target.numpy() == 0)[0]),\n",
    "            len(np.where(target.numpy() == 1)[0])))\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 12,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label data distribution 0/1: 8940/5348\n",
      "test_labels data distribution 0/1: 2235/1337\n",
<<<<<<< HEAD
      "batch index 0, 0/1: 261/251\n",
      "batch index 1, 0/1: 252/260\n",
      "batch index 2, 0/1: 242/270\n",
      "batch index 3, 0/1: 254/258\n",
      "batch index 4, 0/1: 258/254\n",
      "batch index 5, 0/1: 248/264\n",
      "batch index 6, 0/1: 263/249\n",
      "batch index 7, 0/1: 226/286\n",
      "batch index 8, 0/1: 262/250\n",
      "batch index 9, 0/1: 255/257\n",
      "batch index 10, 0/1: 242/270\n",
      "batch index 11, 0/1: 244/268\n",
      "batch index 12, 0/1: 252/260\n",
      "batch index 13, 0/1: 271/241\n",
      "batch index 14, 0/1: 253/259\n",
      "batch index 15, 0/1: 294/218\n",
      "batch index 16, 0/1: 266/246\n",
      "batch index 17, 0/1: 246/266\n",
      "batch index 18, 0/1: 238/274\n",
      "batch index 19, 0/1: 254/258\n",
      "batch index 20, 0/1: 245/267\n",
      "batch index 21, 0/1: 277/235\n",
      "batch index 22, 0/1: 275/237\n",
      "batch index 23, 0/1: 263/249\n",
      "batch index 24, 0/1: 267/245\n",
      "batch index 25, 0/1: 273/239\n",
      "batch index 26, 0/1: 271/241\n",
      "batch index 27, 0/1: 236/228\n"
=======
      "batch index 0, 0/1: 122/134\n",
      "batch index 1, 0/1: 124/132\n",
      "batch index 2, 0/1: 136/120\n",
      "batch index 3, 0/1: 119/137\n",
      "batch index 4, 0/1: 108/148\n",
      "batch index 5, 0/1: 122/134\n",
      "batch index 6, 0/1: 131/125\n",
      "batch index 7, 0/1: 141/115\n",
      "batch index 8, 0/1: 132/124\n",
      "batch index 9, 0/1: 134/122\n",
      "batch index 10, 0/1: 118/138\n",
      "batch index 11, 0/1: 133/123\n",
      "batch index 12, 0/1: 132/124\n",
      "batch index 13, 0/1: 140/116\n",
      "batch index 14, 0/1: 132/124\n",
      "batch index 15, 0/1: 124/132\n",
      "batch index 16, 0/1: 132/124\n",
      "batch index 17, 0/1: 111/145\n",
      "batch index 18, 0/1: 126/130\n",
      "batch index 19, 0/1: 134/122\n",
      "batch index 20, 0/1: 150/106\n",
      "batch index 21, 0/1: 152/104\n",
      "batch index 22, 0/1: 127/129\n",
      "batch index 23, 0/1: 119/137\n",
      "batch index 24, 0/1: 132/124\n",
      "batch index 25, 0/1: 144/112\n",
      "batch index 26, 0/1: 126/130\n",
      "batch index 27, 0/1: 126/130\n",
      "batch index 28, 0/1: 130/126\n",
      "batch index 29, 0/1: 133/123\n",
      "batch index 30, 0/1: 111/145\n",
      "batch index 31, 0/1: 120/136\n",
      "batch index 32, 0/1: 114/142\n",
      "batch index 33, 0/1: 129/127\n",
      "batch index 34, 0/1: 119/137\n",
      "batch index 35, 0/1: 107/149\n",
      "batch index 36, 0/1: 122/134\n",
      "batch index 37, 0/1: 126/130\n",
      "batch index 38, 0/1: 121/135\n",
      "batch index 39, 0/1: 114/142\n",
      "batch index 40, 0/1: 128/128\n",
      "batch index 41, 0/1: 124/132\n",
      "batch index 42, 0/1: 124/132\n",
      "batch index 43, 0/1: 122/134\n",
      "batch index 44, 0/1: 116/140\n",
      "batch index 45, 0/1: 126/130\n",
      "batch index 46, 0/1: 125/131\n",
      "batch index 47, 0/1: 126/130\n",
      "batch index 48, 0/1: 113/143\n",
      "batch index 49, 0/1: 112/144\n",
      "batch index 50, 0/1: 131/125\n",
      "batch index 51, 0/1: 138/118\n",
      "batch index 52, 0/1: 124/132\n",
      "batch index 53, 0/1: 138/118\n",
      "batch index 54, 0/1: 124/132\n",
      "batch index 55, 0/1: 106/102\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    }
   ],
   "source": [
    "# Define the model hyperparameters\n",
    "CLASSES = 1\n",
    "BATCHSIZE = 512  # เดิมใช้ 1024\n",
    "LEARNING_RATE = 2e-6\n",
    "DROPOUT_RATE = 0    \n",
    "EPOCHS = 1000  # เดิมใช้ 500\n",
    "DIR = os.getcwd()\n",
    "# แก้ตรงนี้ทุกครั้งเวลาเปลี่ยน hyperparameters ต่าง ๆ จะได้แยกเก็บ study !\n",
    "dirname = \"logs_test22_retry_yesno_noseq_nodesc\"\n",
    "train_loader, test_loader = get_dataset(df, BATCHSIZE)\n",
    "loss_fn = nn.BCELoss()  # ไม่ได้แถม sigmoid มาด้วย!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 13,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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",
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check class distribution\n",
    "def get_distribution_graph(dataloader):\n",
    "\n",
    "    batch_no = [x+1 for x in range(len(dataloader))]\n",
    "    class_0_count = []\n",
    "    class_1_count = []\n",
    "    batch_count = []\n",
    "\n",
    "    for i, (data,target) in enumerate(dataloader):\n",
    "        tocount = pd.DataFrame(target.numpy()).value_counts()\n",
    "        batch_count.append(i+1)\n",
    "        class_0_count.append(tocount[0.0])\n",
    "        class_1_count.append(tocount[1.0])\n",
    "\n",
    "    X_axis = np.arange(len(batch_count))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_figwidth(15)\n",
    "    fig.set_figheight(10)\n",
    "    ax.set_xlabel=\"Batch Number\"\n",
    "    ax.set_ylabel=\"No. Datapoints\"\n",
    "    ax.bar(X_axis,class_0_count,width=(1/3) ,label = \"NoADR\",color='green',alpha=0.5)\n",
    "    ax.bar(X_axis+(1/3),class_1_count,width=(1/3), label = 'ADR',color='red',alpha=0.5)\n",
    "    #ax.set_xticks(X_axis+width)\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_title(\"Data Distribution\")\n",
    "    fig.show()\n",
    "\n",
    "get_distribution_graph(train_loader)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 14,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMsAAANECAYAAACuLKghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDzklEQVR4nO3de5hVdd3//9dwGCBxBk1g5BYVM0HNU1rKnWdRULMs70rSDCUtU8vsoHYbjvq9w8zMNLMwFCuPdXcwTZBQ9BviiSQViZ8aasbBPDAjmpxm//7ow/46ispwGoHH47r2VXvtz177vXBdXlxP1167plKpVAIAAAAApEN7DwAAAAAA7xRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAMBaZtiwYdlyyy3XyGdtueWWGTZsWPX5mDFjUlNTkwceeGCNfP6+++6bfffdd418FgBAIpYBAOuQpSFn6aNr167p06dPBg8enEsuuSQvvfTSCu/77rvvTmNjY+bNm7fqBk7S2NjYauZ3vetd2XzzzXPYYYflqquuyoIFC1bJ5zz66KNpbGzMk08+uUr2tyq9k2cDANY/ndp7AACAVe3cc89Nv379smjRosyZMycTJ07Mqaeemosuuig33XRTdtxxxzbv8+67784555yTYcOGpUePHqt85ssvvzzdu3fPggUL8o9//CPjxo3Lcccdl4svvjg333xz+vbtW117xRVXpKWlpU37f/TRR3POOedk3333bdNVaTNmzEiHDqv3v6++1Wy33Xbbav1sAIDXE8sAgHXOwQcfnN122636/Mwzz8ztt9+eD3/4w/nIRz6S6dOnp1u3bu044Rv913/9VzbZZJPq8xEjRuSaa67JMccck0984hO55557qq917tx5tc5SqVTy6quvplu3bunSpctq/ay3U1tb266fDwCsf3wNEwBYL+y///751re+laeeeiq/+MUvqtsfeuihDBs2LFtttVW6du2ahoaGHHfccXn++eeraxobG/P1r389SdKvX7/qVyaXfm3wqquuyv77759evXqlS5cu2W677XL55Zev9MxHHXVUPve5z+Xee+/N+PHjq9uXdc+y66+/Prvuums23HDD1NXVZYcddsgPfvCDJP/+euonPvGJJMl+++1XnX/ixIlJ/n1fsg9/+MMZN25cdtttt3Tr1i0/+clPqq+99p5lS73yyiv5/Oc/n3e/+92pq6vLMccckxdffLHVmpqamjQ2Nr7hva/d59vNtqx7lj377LMZPnx4evfuna5du2annXbK1Vdf3WrNk08+mZqamlx44YUZNWpU3vOe96RLly75wAc+kPvvv3+Zf94AAIkrywCA9chnPvOZfPOb38xtt92W448/Pkkyfvz4/O1vf8uxxx6bhoaGTJs2LaNGjcq0adNyzz33pKamJh//+Mfz//1//1+uu+66fP/7369eAdazZ88k//4K5fbbb5+PfOQj6dSpU37/+9/ni1/8YlpaWnLSSSet9MyjRo3KbbfdlgMPPHCZa8aPH5+hQ4fmgAMOyHe+850kyfTp0zNp0qR8+ctfzt57750vfelLueSSS/LNb34z2267bZJU/zf599cthw4dms9//vM5/vjj079//7ec6+STT06PHj3S2NiYGTNm5PLLL89TTz2ViRMnpqamZrmPb3lme61//etf2XffffP444/n5JNPTr9+/fLLX/4yw4YNy7x58/LlL3+51fprr702L730Uj7/+c+npqYmF1xwQT7+8Y/nb3/722q/Qg8AWDuJZQDAemOzzTZLfX19nnjiieq2L37xi/nqV7/aat0ee+yRoUOH5k9/+lP22muv7Ljjjnn/+9+f6667Locffvgbruq68847W32t8+STT86QIUNy0UUXrXQse9/73pckrWZ+vVtuuSV1dXUZN25cOnbs+IbXt9pqq+y111655JJLcuCBBy7z1yUff/zxjB07NoMHD16uuWprazNhwoRqcNpiiy3yjW98I7///e/zkY98ZLn2sbyzvdaoUaMyffr0/OIXv8hRRx2VJPnCF76QffbZJ2eddVaOO+64bLjhhtX1Tz/9dB577LFstNFGSZL+/fvnox/9aMaNG5cPf/jDyz0nALD+8DVMAGC90r1791a/ivnayPXqq6/mueeeyx577JEk+fOf/7xc+3ztPpqamvLcc89ln332yd/+9rc0NTWt9LxJ3vKXPHv06JGXX3651Vc126pfv37LHcqS5IQTTmh1ZdaJJ56YTp065Q9/+MMKz7A8/vCHP6ShoSFDhw6tbuvcuXO+9KUvZf78+bnzzjtbrf/Upz5VDWVJstdeeyVJ/va3v63WOQGAtZdYBgCsV+bPn9/qyqMXXnghX/7yl9O7d+9069YtPXv2TL9+/ZJkuUPXpEmTMmjQoGywwQbp0aNHevbsmW9+85tt2sdbzZuk1cyv98UvfjHbbLNNDj744Gy22WY57rjjMnbs2DZ9ztJjXl7vfe97Wz3v3r17Nt100+p93FaXp556Ku9973vf8AudS7+2+dRTT7Xavvnmm7d6vjScvf7+agAAS/kaJgCw3njmmWfS1NSUrbfeurrtk5/8ZO6+++58/etfz84775zu3bunpaUlQ4YMSUtLy9vu84knnsgBBxyQAQMG5KKLLkrfvn1TW1ubP/zhD/n+97+/XPt4K4888kiStJr59Xr16pWpU6dm3LhxufXWW3PrrbfmqquuyjHHHPOGG9+/mTX566BLlixZY5+1rK+lJv/+xU8AgGURywCA9cbPf/7zJKl+3fDFF1/MhAkTcs4552TEiBHVdY899tgb3vtmN63//e9/nwULFuSmm25qdRXTHXfcsVpmfjO1tbU57LDDcthhh6WlpSVf/OIX85Of/CTf+ta3svXWW7fppvvL47HHHst+++1XfT5//vzMnj07hxxySHXbRhttlHnz5rV638KFCzN79uxW29oy2xZbbJGHHnooLS0tra4u++tf/1p9HQBgZfgaJgCwXrj99ttz3nnnpV+/ftUbwy+96uj1VxldfPHFb3j/BhtskCRviD/L2kdTU1OuuuqqlZ752muvzU9/+tMMHDgwBxxwwJuue/7551s979ChQ3bcccckyYIFC95y/hU1atSoLFq0qPr88ssvz+LFi3PwwQdXt73nPe/JXXfd9Yb3vf7KsrbMdsghh2TOnDm54YYbqtsWL16cSy+9NN27d88+++yzIocDAFDlyjIAYJ1z66235q9//WsWL16cuXPn5vbbb8/48eOzxRZb5KabbkrXrl2TJHV1ddl7771zwQUXZNGiRfmP//iP3HbbbZk5c+Yb9rnrrrsmSf77v/87Rx55ZDp37pzDDjssBx10UPWqrs9//vOZP39+rrjiivTq1esNV1C9lV/96lfp3r17Fi5cmH/84x8ZN25cJk2alJ122im//OUv3/K9n/vc5/LCCy9k//33z2abbZannnoql156aXbeeefqvbx23nnndOzYMd/5znfS1NSULl26ZP/990+vXr2We8bXWrhwYQ444IB88pOfzIwZM/KjH/0oe+65Z6tfwvzc5z6XL3zhCzniiCNy4IEH5i9/+UvGjRuXTTbZpNW+2jLbCSeckJ/85CcZNmxYpkyZki233DK/+tWvMmnSpFx88cVveW83AIDlIZYBAOucpV+prK2tzcYbb5wddtghF198cY499tg3xJRrr702p5xySi677LJUKpUcdNBBufXWW9OnT59W6z7wgQ/kvPPOy49//OOMHTs2LS0tmTlzZvr3759f/epXOeuss/K1r30tDQ0NOfHEE9OzZ88cd9xxyz3ziSeemCTp2rVrNtlkk+y888658sor8+lPfzpdunR5y/ceffTRGTVqVH70ox9l3rx5aWhoyKc+9ak0NjZWv6rY0NCQH//4xxk5cmSGDx+eJUuW5I477ljhWPbDH/4w11xzTUaMGJFFixZl6NChueSSS1p9pfL444/PzJkzM3r06IwdOzZ77bVXxo8f/4ar5NoyW7du3TJx4sScccYZufrqq9Pc3Jz+/fvnqquuyrBhw1boWAAAXqum4u6mAAAAAJDEPcsAAAAAoEosAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAolN7D7C6tLS0ZNasWdlwww1TU1PT3uMAAAAA0E4qlUpeeuml9OnTJx06vPW1Y+tsLJs1a1b69u3b3mMAAAAA8A7x97//PZttttlbrllnY9mGG26Y5N9/CHV1de08DQAAAADtpbm5OX379q32oreyzsaypV+9rKurE8sAAAAAWK5bdbnBPwAAAAAUYhkAAAAAFGIZAAAAABTr7D3LAAAAANaklpaWLFy4sL3HWG/V1tamQ4eVvy5MLAMAAABYSQsXLszMmTPT0tLS3qOstzp06JB+/fqltrZ2pfYjlgEAAACshEqlktmzZ6djx47p27fvKrm6ibZpaWnJrFmzMnv27Gy++ebL9auXb0YsAwAAAFgJixcvziuvvJI+ffrkXe96V3uPs97q2bNnZs2alcWLF6dz584rvB+pEwAAAGAlLFmyJElW+ut/rJylf/5L/3msKLEMAAAAYBVYma/+sfJW1Z+/WAYAAAAAhVgGAAAAAIUb/AMAAACsBo0TG9fs5+3bts8bNmxYrr766owcOTJnnHFGdftvf/vbfOxjH0ulUmnT/q677rocffTR+cIXvpDLLrus1WsTJ07Mfvvtl+TfX5fccMMNs9VWW+XAAw/MV77ylWy66ab/7zgaG3POOeckSTp06JA+ffrk4IMPzvnnn5+NN964TTOtCFeWAQAAAKynunbtmu985zt58cUXV3pfo0ePzje+8Y1cd911efXVV5e5ZsaMGZk1a1buv//+nH766fnjH/+Y973vfXn44Ydbrdt+++0ze/bsPP3007nqqqsyduzYnHjiiSs94/IQywAAAADWU4MGDUpDQ0NGjhz5pmv+93//N9tvv326dOmSLbfcMt/73vfesGbmzJm5++67c8YZZ2SbbbbJr3/962Xuq1evXmloaMg222yTI488MpMmTUrPnj3fEMI6deqUhoaG/Md//EcGDRqUT3ziExk/fvzKHexyEssAAAAA1lMdO3bMt7/97Vx66aV55pln3vD6lClT8slPfjJHHnlkHn744TQ2NuZb3/pWxowZ02rdVVddlUMPPTT19fU5+uijM3r06OX6/G7duuULX/hCJk2alGeffXaZa5588smMGzcutbW1bT6+FSGWAQAAAKzHPvaxj2XnnXfO2Wef/YbXLrroohxwwAH51re+lW222SbDhg3LySefnO9+97vVNS0tLRkzZkyOPvroJMmRRx6ZP/3pT5k5c+Zyff6AAQOS/DuKLfXwww+ne/fu6datW/r165dp06bl9NNPX4mjXH5iGQAAAMB67jvf+U6uvvrqTJ8+vdX26dOn50Mf+lCrbR/60Ify2GOPZcmSJUmS8ePH5+WXX84hhxySJNlkk01y4IEH5sorr1yuz176QwI1NTXVbf3798/UqVOr9zYbPHhwTjnllBU+vrYQywAAAADWc3vvvXcGDx6cM888s83vHT16dF544YV069YtnTp1SqdOnfKHP/whV199dVpaWt72/UsD3ZZbblndVltbm6233jrve9/7cv7556djx47VX8hc3TqtkU8BAAAA4B3t/PPPz84775z+/ftXt2277baZNGlSq3WTJk3KNttsk44dO+b555/P7373u1x//fXZfvvtq2uWLFmSPffcM7fddluGDBnypp/5r3/9K6NGjcree++dnj17vum6s846K/vvv39OPPHE9OnTZyWO8u2JZQAAAABkhx12yFFHHZVLLrmkuu2rX/1qPvCBD+S8887Lpz71qUyePDk//OEP86Mf/ShJ8vOf/zzvfve788lPfrLV1yiT5JBDDsno0aNbxbJnn302r776al566aVMmTIlF1xwQZ577rk3/fXMpQYOHJgdd9wx3/72t/PDH/5wFR71G/kaJgAAAABJknPPPbfVVyff//7358Ybb8z111+f973vfRkxYkTOPffcDBs2LEly5ZVX5mMf+9gbQlmSHHHEEbnpppvy3HPPVbf1798/ffr0ya677przzz8/gwYNyiOPPJLtttvubWf7yle+kp/+9Kf5+9//vvIH+hZqKkvvoraOaW5uTn19fZqamlJXV9fe4wAAAADrqFdffTUzZ85Mv3790rVr1/YeZ731Vv8c2tKJXFkGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAEWn9h4AAAAAYJ3U2LhWfN7kyZOz5557ZsiQIbnllluq25988sn069ev+rx79+7ZfPPNs+++++bUU0/Ne9/73uprY8aMybHHHpskqampSe/evbP33nvnu9/9bjbffPMVO5524soyAAAAgPXY6NGjc8opp+Suu+7KrFmz3vD6H//4x8yePTt/+ctf8u1vfzvTp0/PTjvtlAkTJrRaV1dXl9mzZ+cf//hH/vd//zczZszIJz7xiTV1GKuMK8vWMo0TG9t7BABgLdO4b2N7jwAAvEPNnz8/N9xwQx544IHMmTMnY8aMyTe/+c1Wa9797nenoaEhSbLVVlvlsMMOywEHHJDhw4fniSeeSMeOHZP8+4qypes23XTTDB8+PF/60pfS3Nycurq6NXtgK8GVZQAAAADrqRtvvDEDBgxI//79c/TRR+fKK69MpVJ5y/d06NAhX/7yl/PUU09lypQpy1zz7LPP5je/+U06duxYjWlrC7EMAAAAYD01evToHH300UmSIUOGpKmpKXfeeefbvm/AgAFJ/n1fs6WamprSvXv3bLDBBundu3fuuOOOnHTSSdlggw1Wy+yri1gGAAAAsB6aMWNG7rvvvgwdOjRJ0qlTp3zqU5/K6NGj3/a9S68+q6mpqW7bcMMNM3Xq1DzwwAP53ve+l/e///35n//5n9Uz/GrknmUAAAAA66HRo0dn8eLF6dOnT3VbpVJJly5d8sMf/vAt3zt9+vQkafVrmR06dMjWW2+dJNl2223zxBNP5MQTT8zPf/7z1TD96uPKMgAAAID1zOLFi/Ozn/0s3/ve9zJ16tTq4y9/+Uv69OmT66677k3f29LSkksuuST9+vXLLrvs8qbrzjjjjNxwww3585//vDoOYbVxZRkAAADAeubmm2/Oiy++mOHDh6e+vr7Va0cccURGjx6dIUOGJEmef/75zJkzJ6+88koeeeSRXHzxxbnvvvtyyy23vOXN+/v27ZuPfexjGTFiRG6++ebVejyrkivLAAAAANYzo0ePzqBBg94QypJ/x7IHHnggzc3NSZJBgwZl0003zQ477JAzzjgj2267bR566KHst99+b/s5X/nKV3LLLbfkvvvuW+XHsLq4sgwAAABgdWhsbO8J3tTvf//7N33tgx/8YPUG/kv/9+0MGzYsw4YNe8P2PfbYY7n38U7hyjIAAAAAKMQyAAAAACjEMgAAAAAoxDIAAAAAKMQyAAAAACjEMgAAAIBVYG371cd1zar68++0SvYCAAAAsJ7q3Llzampq8s9//jM9e/ZMTU1Ne4+03qlUKvnnP/+ZmpqadO7ceaX2JZYBAAAArISOHTtms802yzPPPJMnn3yyvcdZb9XU1GSzzTZLx44dV2o/YhkAAADASurevXve+973ZtGiRe09ynqrc+fOKx3KErEMAAAAYJXo2LHjKok1tC83+AcAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAIBCLAMAAACAQiwDAAAAgEIsAwAAAICiTbFs5MiR+cAHPpANN9wwvXr1yuGHH54ZM2a0WvPqq6/mpJNOyrvf/e507949RxxxRObOndtqzdNPP51DDz0073rXu9KrV698/etfz+LFi1utmThxYt7//venS5cu2XrrrTNmzJgVO0IAAAAAWE5timV33nlnTjrppNxzzz0ZP358Fi1alIMOOigvv/xydc1XvvKV/P73v88vf/nL3HnnnZk1a1Y+/vGPV19fsmRJDj300CxcuDB33313rr766owZMyYjRoyorpk5c2YOPfTQ7Lfffpk6dWpOPfXUfO5zn8u4ceNWwSEDAAAAwLLVVCqVyoq++Z///Gd69eqVO++8M3vvvXeamprSs2fPXHvttfmv//qvJMlf//rXbLvttpk8eXL22GOP3Hrrrfnwhz+cWbNmpXfv3kmSH//4xzn99NPzz3/+M7W1tTn99NNzyy235JFHHql+1pFHHpl58+Zl7NixyzVbc3Nz6uvr09TUlLq6uhU9xHecxomN7T0CALCWady3sb1HAABoV23pRCt1z7KmpqYkycYbb5wkmTJlShYtWpRBgwZV1wwYMCCbb755Jk+enCSZPHlydthhh2ooS5LBgwenubk506ZNq6557T6Wrlm6j2VZsGBBmpubWz0AAAAAoC1WOJa1tLTk1FNPzYc+9KG8733vS5LMmTMntbW16dGjR6u1vXv3zpw5c6prXhvKlr6+9LW3WtPc3Jx//etfy5xn5MiRqa+vrz769u27oocGAAAAwHpqhWPZSSedlEceeSTXX3/9qpxnhZ155plpamqqPv7+97+390gAAAAArGU6rcibTj755Nx888256667stlmm1W3NzQ0ZOHChZk3b16rq8vmzp2bhoaG6pr77ruv1f6W/lrma9e8/hc0586dm7q6unTr1m2ZM3Xp0iVdunRZkcMBAAAAgCRtvLKsUqnk5JNPzm9+85vcfvvt6devX6vXd91113Tu3DkTJkyobpsxY0aefvrpDBw4MEkycODAPPzww3n22Wera8aPH5+6urpst9121TWv3cfSNUv3AQAAAACrQ5uuLDvppJNy7bXX5ne/+1023HDD6j3G6uvr061bt9TX12f48OE57bTTsvHGG6euri6nnHJKBg4cmD322CNJctBBB2W77bbLZz7zmVxwwQWZM2dOzjrrrJx00knVK8O+8IUv5Ic//GG+8Y1v5Ljjjsvtt9+eG2+8MbfccssqPnwAAAAA+H/adGXZ5Zdfnqampuy7777ZdNNNq48bbrihuub73/9+PvzhD+eII47I3nvvnYaGhvz617+uvt6xY8fcfPPN6dixYwYOHJijjz46xxxzTM4999zqmn79+uWWW27J+PHjs9NOO+V73/tefvrTn2bw4MGr4JABAAAAYNlqKpVKpb2HWB2am5tTX1+fpqam1NXVtfc4q0zjxMb2HgEAWMs07tvY3iMAALSrtnSiFf41TAAAAABY14hlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQtDmW3XXXXTnssMPSp0+f1NTU5Le//W2r14cNG5aamppWjyFDhrRa88ILL+Soo45KXV1devTokeHDh2f+/Pmt1jz00EPZa6+90rVr1/Tt2zcXXHBB248OAAAAANqgzbHs5Zdfzk477ZTLLrvsTdcMGTIks2fPrj6uu+66Vq8fddRRmTZtWsaPH5+bb745d911V0444YTq683NzTnooIOyxRZbZMqUKfnud7+bxsbGjBo1qq3jAgAAAMBy69TWNxx88ME5+OCD33JNly5d0tDQsMzXpk+fnrFjx+b+++/PbrvtliS59NJLc8ghh+TCCy9Mnz59cs0112ThwoW58sorU1tbm+233z5Tp07NRRdd1CqqAQAAAMCqtFruWTZx4sT06tUr/fv3z4knnpjnn3+++trkyZPTo0ePaihLkkGDBqVDhw659957q2v23nvv1NbWVtcMHjw4M2bMyIsvvrjMz1ywYEGam5tbPQAAAACgLVZ5LBsyZEh+9rOfZcKECfnOd76TO++8MwcffHCWLFmSJJkzZ0569erV6j2dOnXKxhtvnDlz5lTX9O7du9Wapc+Xrnm9kSNHpr6+vvro27fvqj40AAAAANZxbf4a5ts58sgjq/9/hx12yI477pj3vOc9mThxYg444IBV/XFVZ555Zk477bTq8+bmZsEMAAAAgDZZLV/DfK2tttoqm2yySR5//PEkSUNDQ5599tlWaxYvXpwXXnihep+zhoaGzJ07t9Wapc/f7F5oXbp0SV1dXasHAAAAALTFao9lzzzzTJ5//vlsuummSZKBAwdm3rx5mTJlSnXN7bffnpaWluy+++7VNXfddVcWLVpUXTN+/Pj0798/G2200eoeGQAAAID1VJtj2fz58zN16tRMnTo1STJz5sxMnTo1Tz/9dObPn5+vf/3rueeee/Lkk09mwoQJ+ehHP5qtt946gwcPTpJsu+22GTJkSI4//vjcd999mTRpUk4++eQceeSR6dOnT5Lk05/+dGprazN8+PBMmzYtN9xwQ37wgx+0+polAAAAAKxqbY5lDzzwQHbZZZfssssuSZLTTjstu+yyS0aMGJGOHTvmoYceykc+8pFss802GT58eHbdddf83//7f9OlS5fqPq655poMGDAgBxxwQA455JDsueeeGTVqVPX1+vr63HbbbZk5c2Z23XXXfPWrX82IESNywgknrIJDBgAAAIBlq6lUKpX2HmJ1aG5uTn19fZqamtap+5c1Tmxs7xEAgLVM476N7T0CAEC7aksnWu33LAMAAACAtYVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAABFp/YeAACA1ayxsb0nAADWRuvp3yFcWQYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAACFWAYAAAAAhVgGAAAAAIVYBgAAAABFm2PZXXfdlcMOOyx9+vRJTU1Nfvvb37Z6vVKpZMSIEdl0003TrVu3DBo0KI899lirNS+88EKOOuqo1NXVpUePHhk+fHjmz5/fas1DDz2UvfbaK127dk3fvn1zwQUXtP3oAAAAAKAN2hzLXn755ey000657LLLlvn6BRdckEsuuSQ//vGPc++992aDDTbI4MGD8+qrr1bXHHXUUZk2bVrGjx+fm2++OXfddVdOOOGE6uvNzc056KCDssUWW2TKlCn57ne/m8bGxowaNWoFDhEAAAAAlk+ntr7h4IMPzsEHH7zM1yqVSi6++OKcddZZ+ehHP5ok+dnPfpbevXvnt7/9bY488shMnz49Y8eOzf3335/ddtstSXLppZfmkEMOyYUXXpg+ffrkmmuuycKFC3PllVemtrY222+/faZOnZqLLrqoVVQDAAAAgFVpld6zbObMmZkzZ04GDRpU3VZfX5/dd989kydPTpJMnjw5PXr0qIayJBk0aFA6dOiQe++9t7pm7733Tm1tbXXN4MGDM2PGjLz44ovL/OwFCxakubm51QMAAAAA2mKVxrI5c+YkSXr37t1qe+/evauvzZkzJ7169Wr1eqdOnbLxxhu3WrOsfbz2M15v5MiRqa+vrz769u278gcEAAAAwHplnfk1zDPPPDNNTU3Vx9///vf2HgkAAACAtcwqjWUNDQ1Jkrlz57baPnfu3OprDQ0NefbZZ1u9vnjx4rzwwgut1ixrH6/9jNfr0qVL6urqWj0AAAAAoC1WaSzr169fGhoaMmHChOq25ubm3HvvvRk4cGCSZODAgZk3b16mTJlSXXP77benpaUlu+++e3XNXXfdlUWLFlXXjB8/Pv37989GG220KkcGAAAAgKo2x7L58+dn6tSpmTp1apJ/39R/6tSpefrpp1NTU5NTTz01/+f//J/cdNNNefjhh3PMMcekT58+Ofzww5Mk2267bYYMGZLjjz8+9913XyZNmpSTTz45Rx55ZPr06ZMk+fSnP53a2toMHz4806ZNyw033JAf/OAHOe2001bZgQMAAADA63Vq6xseeOCB7LffftXnSwPWZz/72YwZMybf+MY38vLLL+eEE07IvHnzsueee2bs2LHp2rVr9T3XXHNNTj755BxwwAHp0KFDjjjiiFxyySXV1+vr63PbbbflpJNOyq677ppNNtkkI0aMyAknnLAyxwoAAAAAb6mmUqlU2nuI1aG5uTn19fVpampap+5f1jixsb1HAADWMo0T23sCAGCt1NjY3hOsMm3pROvMr2ECAAAAwMoSywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoBDLAAAAAKAQywAAAACgEMsAAAAAoFjlsayxsTE1NTWtHgMGDKi+/uqrr+akk07Ku9/97nTv3j1HHHFE5s6d22ofTz/9dA499NC8613vSq9evfL1r389ixcvXtWjAgAAAEArnVbHTrfffvv88Y9//H8f0un/fcxXvvKV3HLLLfnlL3+Z+vr6nHzyyfn4xz+eSZMmJUmWLFmSQw89NA0NDbn77rsze/bsHHPMMencuXO+/e1vr45xAQAAACDJaoplnTp1SkNDwxu2NzU1ZfTo0bn22muz//77J0muuuqqbLvttrnnnnuyxx575Lbbbsujjz6aP/7xj+ndu3d23nnnnHfeeTn99NPT2NiY2tra1TEyAAAAAKyee5Y99thj6dOnT7baaqscddRRefrpp5MkU6ZMyaJFizJo0KDq2gEDBmTzzTfP5MmTkySTJ0/ODjvskN69e1fXDB48OM3NzZk2bdqbfuaCBQvS3Nzc6gEAAAAAbbHKY9nuu++eMWPGZOzYsbn88sszc+bM7LXXXnnppZcyZ86c1NbWpkePHq3e07t378yZMydJMmfOnFahbOnrS197MyNHjkx9fX310bdv31V7YAAAAACs81b51zAPPvjg6v/fcccds/vuu2eLLbbIjTfemG7duq3qj6s688wzc9ppp1WfNzc3C2YAAAAAtMlq+Rrma/Xo0SPbbLNNHn/88TQ0NGThwoWZN29eqzVz586t3uOsoaHhDb+OufT5su6DtlSXLl1SV1fX6gEAAAAAbbHaY9n8+fPzxBNPZNNNN82uu+6azp07Z8KECdXXZ8yYkaeffjoDBw5MkgwcODAPP/xwnn322eqa8ePHp66uLtttt93qHhcAAACA9dgq/xrm1772tRx22GHZYostMmvWrJx99tnp2LFjhg4dmvr6+gwfPjynnXZaNt5449TV1eWUU07JwIEDs8ceeyRJDjrooGy33Xb5zGc+kwsuuCBz5szJWWedlZNOOildunRZ1eMCAAAAQNUqj2XPPPNMhg4dmueffz49e/bMnnvumXvuuSc9e/ZMknz/+99Phw4dcsQRR2TBggUZPHhwfvSjH1Xf37Fjx9x888058cQTM3DgwGywwQb57Gc/m3PPPXdVjwoAAAAArdRUKpVKew+xOjQ3N6e+vj5NTU3r1P3LGic2tvcIAMBapnFie08AAKyVGhvbe4JVpi2daLXfswwAAAAA1hZiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFGIZAAAAABRiGQAAAAAUYhkAAAAAFO/oWHbZZZdlyy23TNeuXbP77rvnvvvua++RAAAAAFiHvWNj2Q033JDTTjstZ599dv785z9np512yuDBg/Pss8+292gAAAAArKPesbHsoosuyvHHH59jjz022223XX784x/nXe96V6688sr2Hg0AAACAdVSn9h5gWRYuXJgpU6bkzDPPrG7r0KFDBg0alMmTJy/zPQsWLMiCBQuqz5uampIkzc3Nq3fYNWzBywvefhEAwGs0++sDALAi1qGmsrQPVSqVt137joxlzz33XJYsWZLevXu32t67d+/89a9/XeZ7Ro4cmXPOOecN2/v27btaZgQAWFuc394DAABrp/PXvb9FvPTSS6mvr3/LNe/IWLYizjzzzJx22mnV5/PmzcsWW2yRp59++m3/EGBVaW5uTt++ffP3v/89dXV17T0O6xHnHu3BeUd7ce7RHpx3tBfnHu1lXTv3KpVKXnrppfTp0+dt174jY9kmm2ySjh07Zu7cua22z507Nw0NDct8T5cuXdKlS5c3bK+vr18n/qGydqmrq3Pe0S6ce7QH5x3txblHe3De0V6ce7SXdencW96Lqd6RN/ivra3NrrvumgkTJlS3tbS0ZMKECRk4cGA7TgYAAADAuuwdeWVZkpx22mn57Gc/m9122y0f/OAHc/HFF+fll1/Oscce296jAQAAALCOesfGsk996lP55z//mREjRmTOnDnZeeedM3bs2Dfc9P/NdOnSJWefffYyv5oJq4vzjvbi3KM9OO9oL8492oPzjvbi3KO9rM/nXk1leX4zEwAAAADWA+/Ie5YBAAAAQHsQywAAAACgEMsAAAAAoBDLAAAAAKBYp2LZCy+8kKOOOip1dXXp0aNHhg8fnvnz57/l+lNOOSX9+/dPt27dsvnmm+dLX/pSmpqa1uDUrO3aet4lyahRo7Lvvvumrq4uNTU1mTdv3poZlrXaZZddli233DJdu3bN7rvvnvvuu+8t1//yl7/MgAED0rVr1+ywww75wx/+sIYmZV3SlvNu2rRpOeKII7LlllumpqYmF1988ZoblHVOW869K664InvttVc22mijbLTRRhk0aNDb/jsSlqUt592vf/3r7LbbbunRo0c22GCD7Lzzzvn5z3++BqdlXdLWv+ctdf3116empiaHH3746h2QdVJbzrsxY8akpqam1aNr165rcNo1a52KZUcddVSmTZuW8ePH5+abb85dd92VE0444U3Xz5o1K7NmzcqFF16YRx55JGPGjMnYsWMzfPjwNTg1a7u2nndJ8sorr2TIkCH55je/uYamZG13ww035LTTTsvZZ5+dP//5z9lpp50yePDgPPvss8tcf/fdd2fo0KEZPnx4HnzwwRx++OE5/PDD88gjj6zhyVmbtfW8e+WVV7LVVlvl/PPPT0NDwxqelnVJW8+9iRMnZujQobnjjjsyefLk9O3bNwcddFD+8Y9/rOHJWZu19bzbeOON89///d+ZPHlyHnrooRx77LE59thjM27cuDU8OWu7tp57Sz355JP52te+lr322msNTcq6ZEXOu7q6usyePbv6eOqpp9bgxGtYZR3x6KOPVpJU7r///uq2W2+9tVJTU1P5xz/+sdz7ufHGGyu1tbWVRYsWrY4xWces7Hl3xx13VJJUXnzxxdU4JeuCD37wg5WTTjqp+nzJkiWVPn36VEaOHLnM9Z/85Ccrhx56aKttu+++e+Xzn//8ap2TdUtbz7vX2mKLLSrf//73V+N0rMtW5tyrVCqVxYsXVzbccMPK1VdfvbpGZB20suddpVKp7LLLLpWzzjprdYzHOmxFzr3FixdX/vM//7Py05/+tPLZz3628tGPfnQNTMq6pK3n3VVXXVWpr69fQ9O1v3XmyrLJkyenR48e2W233arbBg0alA4dOuTee+9d7v00NTWlrq4unTp1Wh1jso5ZVecdvJWFCxdmypQpGTRoUHVbhw4dMmjQoEyePHmZ75k8eXKr9UkyePDgN10Pr7ci5x2sCqvi3HvllVeyaNGibLzxxqtrTNYxK3veVSqVTJgwITNmzMjee++9OkdlHbOi5965556bXr16+VYUK2RFz7v58+dniy22SN++ffPRj34006ZNWxPjtot1JpbNmTMnvXr1arWtU6dO2XjjjTNnzpzl2sdzzz2X8847722/QgdLrYrzDt7Oc889lyVLlqR3796ttvfu3ftNz7M5c+a0aT283oqcd7AqrIpz7/TTT0+fPn3e8B8N4M2s6HnX1NSU7t27p7a2NoceemguvfTSHHjggat7XNYhK3Lu/elPf8ro0aNzxRVXrIkRWQetyHnXv3//XHnllfnd736XX/ziF2lpacl//ud/5plnnlkTI69x7/hYdsYZZ7zhJnKvf/z1r39d6c9pbm7OoYcemu222y6NjY0rPzhrtTV13gEAq9b555+f66+/Pr/5zW/W6RsP886w4YYbZurUqbn//vvzP//zPznttNMyceLE9h6LddhLL72Uz3zmM7niiiuyySabtPc4rEcGDhyYY445JjvvvHP22Wef/PrXv07Pnj3zk5/8pL1HWy3e8d81/OpXv5phw4a95ZqtttoqDQ0Nb7gR3eLFi/PCCy+87U2GX3rppQwZMiQbbrhhfvOb36Rz584rOzZruTVx3sHy2mSTTdKxY8fMnTu31fa5c+e+6XnW0NDQpvXweity3sGqsDLn3oUXXpjzzz8/f/zjH7PjjjuuzjFZx6zoedehQ4dsvfXWSZKdd94506dPz8iRI7PvvvuuznFZh7T13HviiSfy5JNP5rDDDqtua2lpSfLvb7jMmDEj73nPe1bv0Kz1VsXf8zp37pxddtkljz/++OoYsd29468s69mzZwYMGPCWj9ra2gwcODDz5s3LlClTqu+9/fbb09LSkt133/1N99/c3JyDDjootbW1uemmm/wXSJKs/vMO2qK2tja77rprJkyYUN3W0tKSCRMmZODAgct8z8CBA1utT5Lx48e/6Xp4vRU572BVWNFz74ILLsh5552XsWPHtrqXKCyPVfXvvJaWlixYsGB1jMg6qq3n3oABA/Lwww9n6tSp1cdHPvKR7Lfffpk6dWr69u27JsdnLbUq/p23ZMmSPPzww9l0001X15jtq71/YWBVGjJkSGWXXXap3HvvvZU//elPlfe+972VoUOHVl9/5plnKv3796/ce++9lUqlUmlqaqrsvvvulR122KHy+OOPV2bPnl19LF68uL0Og7VMW8+7SqVSmT17duXBBx+sXHHFFZUklbvuuqvy4IMPVp5//vn2OATWAtdff32lS5culTFjxlQeffTRygknnFDp0aNHZc6cOZVKpVL5zGc+UznjjDOq6ydNmlTp1KlT5cILL6xMnz69cvbZZ1c6d+5cefjhh9vrEFgLtfW8W7BgQeXBBx+sPPjgg5VNN9208rWvfa3y4IMPVh577LH2OgTWUm09984///xKbW1t5Ve/+lWrv8+99NJL7XUIrIXaet59+9vfrtx2222VJ554ovLoo49WLrzwwkqnTp0qV1xxRXsdAmuptp57r+fXMFkRbT3vzjnnnMq4ceMqTzzxRGXKlCmVI488stK1a9fKtGnT2usQVqt1KpY9//zzlaFDh1a6d+9eqaurqxx77LGt/pI0c+bMSpLKHXfcUalUKpU77rijkmSZj5kzZ7bPQbDWaet5V6lUKmefffYyz7urrrpqzR8Aa41LL720svnmm1dqa2srH/zgByv33HNP9bV99tmn8tnPfrbV+htvvLGyzTbbVGprayvbb7995ZZbblnDE7MuaMt5t/Tfd69/7LPPPmt+cNZ6bTn3tthii2Wee2efffaaH5y1WlvOu//+7/+ubL311pWuXbtWNtpoo8rAgQMr119/fTtMzbqgrX/Pey2xjBXVlvPu1FNPra7t3bt35ZBDDqn8+c9/boep14yaSqVSWXPXsQEAAADAO9c7/p5lAAAAALCmiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFCIZQAAAABQiGUAAAAAUIhlAAAAAFD8/11XRVs73CbSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_distribution_graph(test_loader)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 16,
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:157: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "\u001b[32m[I 2023-04-03 12:14:25,122]\u001b[0m Using an existing study with name 'logs_test22_retry_yesno_noseq_nodesc' instead of creating a new one.\u001b[0m\n"
=======
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:156: ExperimentalWarning: TensorBoardCallback is experimental (supported from v2.0.0). The interface can change in the future.\n",
      "\u001b[32m[I 2023-04-03 00:35:03,196]\u001b[0m A new study created in RDB with name: logs_test22_retry_yesno_noseq_nodesc\u001b[0m\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train accuracy: 0.5092292371428572, test accuracy:0.6248600223964166 train loss:0.69311399, test loss:0.69203055, test precision: 0.01720269259536275,test recall: 0.46938775510204084,test f1: 0.033189033189033185\n",
      "train accuracy: 0.5084523164285714, test accuracy:0.6245800671892497 train loss:0.69296175, test loss:0.6918329, test precision: 0.01720269259536275,test recall: 0.46,test f1: 0.03316510454217736\n",
      "train accuracy: 0.5060686378571428, test accuracy:0.6270996640537514 train loss:0.69282412, test loss:0.69169599, test precision: 0.02916978309648467,test recall: 0.5342465753424658,test f1: 0.055319148936170216\n",
      "train accuracy: 0.5053951467857143, test accuracy:0.6256998880179171 train loss:0.6927001, test loss:0.69164109, test precision: 0.030665669409124907,test recall: 0.5,test f1: 0.05778717406624383\n",
      "train accuracy: 0.5291549614285714, test accuracy:0.6640537513997761 train loss:0.69253797, test loss:0.69154489, test precision: 0.1944652206432311,test recall: 0.6788511749347258,test f1: 0.3023255813953488\n",
      "train accuracy: 0.5913302414285714, test accuracy:0.6654535274356103 train loss:0.69228474, test loss:0.69136226, test precision: 0.24831712789827973,test recall: 0.6360153256704981,test f1: 0.35718128025820334\n",
      "train accuracy: 0.5987891596428571, test accuracy:0.6648936170212766 train loss:0.69215475, test loss:0.69112688, test precision: 0.24682124158563948,test recall: 0.6346153846153846,test f1: 0.3554119547657512\n",
      "train accuracy: 0.5941300410714285, test accuracy:0.6592945128779395 train loss:0.69199301, test loss:0.69093925, test precision: 0.2513089005235602,test recall: 0.6086956521739131,test f1: 0.3557437797776601\n",
      "train accuracy: 0.5906182653571428, test accuracy:0.666013437849944 train loss:0.69191609, test loss:0.69082898, test precision: 0.2774869109947644,test recall: 0.6204013377926422,test f1: 0.38346253229974164\n",
      "train accuracy: 0.5951763578571428, test accuracy:0.6676931690929452 train loss:0.69168659, test loss:0.69065195, test precision: 0.29020194465220644,test recall: 0.6198083067092651,test f1: 0.39531329597554765\n",
      "train accuracy: 0.6078500225000001, test accuracy:0.6688129899216125 train loss:0.6914574, test loss:0.69041407, test precision: 0.2961854899027674,test recall: 0.6206896551724138,test f1: 0.4010126582278481\n",
      "train accuracy: 0.6076672185714286, test accuracy:0.6702127659574468 train loss:0.6912428, test loss:0.69010532, test precision: 0.29094988780852654,test recall: 0.6284329563812601,test f1: 0.39775051124744376\n",
      "train accuracy: 0.6028758089285715, test accuracy:0.6710526315789473 train loss:0.69122826, test loss:0.68991756, test precision: 0.3051608077786088,test recall: 0.6238532110091743,test f1: 0.4098442993470618\n",
      "train accuracy: 0.6198044953571429, test accuracy:0.6721724524076148 train loss:0.69089021, test loss:0.68965608, test precision: 0.31114435302916976,test recall: 0.6246246246246246,test f1: 0.4153769345981029\n",
      "train accuracy: 0.6157226564285713, test accuracy:0.6730123180291153 train loss:0.69070138, test loss:0.68937105, test precision: 0.3118922961854899,test recall: 0.6270676691729323,test f1: 0.41658341658341663\n",
      "train accuracy: 0.6221184192857143, test accuracy:0.6741321388577828 train loss:0.69042048, test loss:0.68907893, test precision: 0.31488406881077036,test recall: 0.6292974588938715,test f1: 0.41974077766699897\n",
      "train accuracy: 0.6133846792857144, test accuracy:0.6794512877939529 train loss:0.6904704, test loss:0.688905, test precision: 0.33283470456245323,test recall: 0.6375358166189111,test f1: 0.4373464373464373\n",
      "train accuracy: 0.6206391428571428, test accuracy:0.6836506159014558 train loss:0.69024451, test loss:0.68874669, test precision: 0.3545250560957367,test recall: 0.6396761133603239,test f1: 0.45620789220404234\n",
      "train accuracy: 0.6299838364285714, test accuracy:0.6836506159014558 train loss:0.69000197, test loss:0.68861753, test precision: 0.37845923709798057,test recall: 0.6285714285714286,test f1: 0.47245564892623715\n",
      "train accuracy: 0.6367740728571428, test accuracy:0.6839305711086227 train loss:0.68950766, test loss:0.68833423, test precision: 0.37845923709798057,test recall: 0.6293532338308457,test f1: 0.47267631947688\n",
      "train accuracy: 0.6275135657142857, test accuracy:0.6844904815229563 train loss:0.68961855, test loss:0.6880874, test precision: 0.3949139865370232,test recall: 0.624113475177305,test f1: 0.48373797526339896\n",
      "train accuracy: 0.6323266232142857, test accuracy:0.6842105263157895 train loss:0.6893141, test loss:0.6878615, test precision: 0.3949139865370232,test recall: 0.6233766233766234,test f1: 0.48351648351648346\n",
      "train accuracy: 0.6376760703571429, test accuracy:0.6847704367301232 train loss:0.68893194, test loss:0.68747765, test precision: 0.39416604338070305,test recall: 0.6251482799525504,test f1: 0.48348623853211004\n",
      "train accuracy: 0.6316411064285715, test accuracy:0.6878499440089586 train loss:0.68884228, test loss:0.68720996, test precision: 0.406133133881825,test recall: 0.6284722222222222,test f1: 0.4934120854157202\n",
      "train accuracy: 0.6363483292857143, test accuracy:0.6878499440089586 train loss:0.68865206, test loss:0.68698585, test precision: 0.42109199700822736,test recall: 0.6227876106194691,test f1: 0.5024542614904062\n",
      "train accuracy: 0.6405648664285716, test accuracy:0.6872900335946248 train loss:0.68813483, test loss:0.68665689, test precision: 0.42109199700822736,test recall: 0.6214128035320088,test f1: 0.5020062416406598\n",
      "train accuracy: 0.6400669642857143, test accuracy:0.6847704367301232 train loss:0.68777647, test loss:0.68633592, test precision: 0.4263275991024682,test recall: 0.6135629709364908,test f1: 0.5030891438658429\n",
      "train accuracy: 0.6432925064285714, test accuracy:0.6828107502799552 train loss:0.68751432, test loss:0.68596512, test precision: 0.4263275991024682,test recall: 0.6089743589743589,test f1: 0.5015398152221733\n",
      "train accuracy: 0.6423664564285714, test accuracy:0.6867301231802911 train loss:0.68732493, test loss:0.68552804, test precision: 0.42109199700822736,test recall: 0.6200440528634361,test f1: 0.5015590200445433\n",
      "train accuracy: 0.6500274210714286, test accuracy:0.6856103023516238 train loss:0.6866787, test loss:0.68513501, test precision: 0.42333582647718776,test recall: 0.616557734204793,test f1: 0.5019955654101995\n",
      "train accuracy: 0.6468042821428571, test accuracy:0.6836506159014558 train loss:0.68653512, test loss:0.68471736, test precision: 0.4263275991024682,test recall: 0.6109324758842444,test f1: 0.5022026431718061\n",
      "train accuracy: 0.6484904167857143, test accuracy:0.6822508398656215 train loss:0.68609006, test loss:0.68428463, test precision: 0.42782348541510845,test recall: 0.6072186836518046,test f1: 0.501974550241334\n",
      "train accuracy: 0.6427464978571429, test accuracy:0.6861702127659575 train loss:0.68599976, test loss:0.68379402, test precision: 0.42408376963350786,test recall: 0.6176470588235294,test f1: 0.5028824833702883\n",
      "train accuracy: 0.6477928725000001, test accuracy:0.6861702127659575 train loss:0.68553052, test loss:0.68331438, test precision: 0.42408376963350786,test recall: 0.6176470588235294,test f1: 0.5028824833702883\n",
      "train accuracy: 0.6447381092857142, test accuracy:0.6836506159014558 train loss:0.68529458, test loss:0.68290251, test precision: 0.42483171278982795,test recall: 0.6114101184068891,test f1: 0.501323918799647\n",
      "train accuracy: 0.6451806874999999, test accuracy:0.6828107502799552 train loss:0.68482477, test loss:0.6825043, test precision: 0.43156320119670905,test recall: 0.6073684210526316,test f1: 0.5045911674682991\n",
      "train accuracy: 0.6362689535714285, test accuracy:0.6861702127659575 train loss:0.68477824, test loss:0.68199128, test precision: 0.45400149588631267,test recall: 0.6082164328657315,test f1: 0.5199143468950749\n",
      "train accuracy: 0.6456184575, test accuracy:0.6836506159014558 train loss:0.68407823, test loss:0.6813938, test precision: 0.42483171278982795,test recall: 0.6114101184068891,test f1: 0.501323918799647\n",
      "train accuracy: 0.6456497257142858, test accuracy:0.6836506159014558 train loss:0.68371939, test loss:0.68084472, test precision: 0.42408376963350786,test recall: 0.6116504854368932,test f1: 0.5008833922261484\n",
      "train accuracy: 0.6455871871428572, test accuracy:0.688969764837626 train loss:0.68352163, test loss:0.68040192, test precision: 0.4532535527299925,test recall: 0.6146044624746451,test f1: 0.5217391304347826\n",
      "train accuracy: 0.6463713249999999, test accuracy:0.6858902575587906 train loss:0.68299975, test loss:0.67998689, test precision: 0.45923709798055345,test recall: 0.6061204343534057,test f1: 0.5225531914893616\n",
      "train accuracy: 0.6513575657142857, test accuracy:0.6833706606942889 train loss:0.68203507, test loss:0.67950433, test precision: 0.46297681376215405,test recall: 0.5998062015503876,test f1: 0.5225833685099198\n",
      "train accuracy: 0.6548933957142857, test accuracy:0.681131019036954 train loss:0.68180512, test loss:0.67896795, test precision: 0.49289454001495886,test recall: 0.5883928571428572,test f1: 0.5364265364265364\n",
      "train accuracy: 0.6601995453571429, test accuracy:0.6825307950727884 train loss:0.68145927, test loss:0.67836237, test precision: 0.4913986537023186,test recall: 0.5913591359135913,test f1: 0.536764705882353\n",
      "train accuracy: 0.654573487142857, test accuracy:0.681131019036954 train loss:0.68098945, test loss:0.67792553, test precision: 0.4988780852655198,test recall: 0.5871478873239436,test f1: 0.5394257986251516\n",
      "train accuracy: 0.6572289682142858, test accuracy:0.6794512877939529 train loss:0.68048098, test loss:0.67738217, test precision: 0.5056095736724009,test recall: 0.5827586206896552,test f1: 0.5414497396876251\n",
      "train accuracy: 0.6611833242857142, test accuracy:0.6791713325867861 train loss:0.67923999, test loss:0.67672032, test precision: 0.506357516828721,test recall: 0.5821152192605331,test f1: 0.5416\n",
      "train accuracy: 0.6592614682142858, test accuracy:0.6791713325867861 train loss:0.67882444, test loss:0.6760686, test precision: 0.506357516828721,test recall: 0.5821152192605331,test f1: 0.5416\n",
      "train accuracy: 0.65959581, test accuracy:0.6791713325867861 train loss:0.67856767, test loss:0.67538965, test precision: 0.506357516828721,test recall: 0.5821152192605331,test f1: 0.5416\n",
      "train accuracy: 0.6601129535714285, test accuracy:0.6783314669652856 train loss:0.67810419, test loss:0.67484832, test precision: 0.5138369483919222,test recall: 0.5792580101180439,test f1: 0.544589774078478\n",
      "train accuracy: 0.6638917210714287, test accuracy:0.6780515117581187 train loss:0.67707145, test loss:0.67438716, test precision: 0.5213163799551234,test recall: 0.5774647887323944,test f1: 0.5479559748427673\n",
      "train accuracy: 0.6533660142857143, test accuracy:0.6766517357222844 train loss:0.67748855, test loss:0.6739707, test precision: 0.525056095736724,test recall: 0.574468085106383,test f1: 0.548651817116061\n",
      "train accuracy: 0.6622031821428571, test accuracy:0.6766517357222844 train loss:0.67645109, test loss:0.6732794, test precision: 0.5258040388930442,test recall: 0.5743464052287581,test f1: 0.5490042951971886\n",
      "train accuracy: 0.6594418682142857, test accuracy:0.6763717805151176 train loss:0.67572974, test loss:0.67265564, test precision: 0.5265519820493643,test recall: 0.5737571312143439,test f1: 0.5491419656786272\n",
      "train accuracy: 0.6592879289285715, test accuracy:0.6763717805151176 train loss:0.67530303, test loss:0.67209595, test precision: 0.543754674644727,test recall: 0.5710919088766693,test f1: 0.557088122605364\n",
      "train accuracy: 0.6629897257142858, test accuracy:0.6744120940649496 train loss:0.67440446, test loss:0.67147088, test precision: 0.5467464472700074,test recall: 0.5675465838509317,test f1: 0.5569523809523809\n",
      "train accuracy: 0.6658352260714286, test accuracy:0.6730123180291153 train loss:0.67309743, test loss:0.67076689, test precision: 0.5467464472700074,test recall: 0.5653518948182521,test f1: 0.5558935361216729\n",
      "train accuracy: 0.6665520117857143, test accuracy:0.6721724524076148 train loss:0.67179154, test loss:0.67002618, test precision: 0.5467464472700074,test recall: 0.5640432098765432,test f1: 0.5552601595138625\n",
      "train accuracy: 0.6680793953571429, test accuracy:0.673572228443449 train loss:0.67148417, test loss:0.66897339, test precision: 0.543754674644727,test recall: 0.5666406858924395,test f1: 0.5549618320610687\n",
      "train accuracy: 0.6705737185714286, test accuracy:0.673572228443449 train loss:0.67021582, test loss:0.66803008, test precision: 0.5430067314884068,test recall: 0.5667447306791569,test f1: 0.5546218487394958\n",
      "train accuracy: 0.6555981560714285, test accuracy:0.6730123180291153 train loss:0.67167944, test loss:0.66756338, test precision: 0.5467464472700074,test recall: 0.5653518948182521,test f1: 0.5558935361216729\n",
      "train accuracy: 0.6585951932142857, test accuracy:0.6730123180291153 train loss:0.67030615, test loss:0.66678417, test precision: 0.5467464472700074,test recall: 0.5653518948182521,test f1: 0.5558935361216729\n",
      "train accuracy: 0.6586793789285715, test accuracy:0.673572228443449 train loss:0.66957068, test loss:0.66584367, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6675718714285714, test accuracy:0.673572228443449 train loss:0.66724333, test loss:0.66501695, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6640600939285715, test accuracy:0.6732922732362822 train loss:0.66727901, test loss:0.66425371, test precision: 0.5467464472700074,test recall: 0.5657894736842105,test f1: 0.5561049828832255\n",
      "train accuracy: 0.6602668953571429, test accuracy:0.673572228443449 train loss:0.66604702, test loss:0.66318482, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6627131114285714, test accuracy:0.673572228443449 train loss:0.66585644, test loss:0.66236204, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6644617828571429, test accuracy:0.673572228443449 train loss:0.66479085, test loss:0.66144699, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6637281589285714, test accuracy:0.673572228443449 train loss:0.66443257, test loss:0.66069388, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6661743757142856, test accuracy:0.673572228443449 train loss:0.66271801, test loss:0.65972638, test precision: 0.5459985041136873,test recall: 0.5663304887509697,test f1: 0.5559786747905561\n",
      "train accuracy: 0.6614310728571429, test accuracy:0.66993281075028 train loss:0.66335258, test loss:0.65909648, test precision: 0.5602094240837696,test recall: 0.558955223880597,test f1: 0.5595816212177811\n",
      "train accuracy: 0.6613805614285715, test accuracy:0.6671332586786114 train loss:0.66209893, test loss:0.65867668, test precision: 0.5632011967090501,test recall: 0.5544918998527246,test f1: 0.5588126159554732\n",
      "train accuracy: 0.6704654796428572, test accuracy:0.6654535274356103 train loss:0.66055, test loss:0.65798104, test precision: 0.5632011967090501,test recall: 0.5520527859237536,test f1: 0.557571269900037\n",
      "train accuracy: 0.6733422496428573, test accuracy:0.6654535274356103 train loss:0.65847465, test loss:0.65705186, test precision: 0.5632011967090501,test recall: 0.5520527859237536,test f1: 0.557571269900037\n",
      "train accuracy: 0.6608345510714285, test accuracy:0.6643337066069429 train loss:0.66005606, test loss:0.65648246, test precision: 0.5632011967090501,test recall: 0.5504385964912281,test f1: 0.5567467652495379\n",
      "train accuracy: 0.6644040560714287, test accuracy:0.6640537513997761 train loss:0.65871742, test loss:0.6556735, test precision: 0.5632011967090501,test recall: 0.550036523009496,test f1: 0.5565410199556541\n",
      "train accuracy: 0.660103332142857, test accuracy:0.6637737961926092 train loss:0.65917239, test loss:0.65503299, test precision: 0.5632011967090501,test recall: 0.5496350364963504,test f1: 0.5563354266715922\n",
      "train accuracy: 0.6668262196428572, test accuracy:0.6634938409854423 train loss:0.65710006, test loss:0.65422648, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6613613189285715, test accuracy:0.6634938409854423 train loss:0.65569528, test loss:0.65334046, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6680409103571429, test accuracy:0.6634938409854423 train loss:0.65452261, test loss:0.65215689, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6605411014285714, test accuracy:0.6634938409854423 train loss:0.65505418, test loss:0.65156978, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6635068700000001, test accuracy:0.6634938409854423 train loss:0.65276457, test loss:0.65067154, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6770440464285714, test accuracy:0.6634938409854423 train loss:0.64981837, test loss:0.64981407, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.664060095, test accuracy:0.6634938409854423 train loss:0.6515774, test loss:0.64869261, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6591652560714286, test accuracy:0.6634938409854423 train loss:0.65088286, test loss:0.64794666, test precision: 0.5639491398653702,test recall: 0.5491624180626365,test f1: 0.5564575645756457\n",
      "train accuracy: 0.6681010432142858, test accuracy:0.6626539753639418 train loss:0.64802306, test loss:0.64758754, test precision: 0.5661929693343306,test recall: 0.5477568740955138,test f1: 0.556822361162192\n",
      "train accuracy: 0.6687023735714285, test accuracy:0.6626539753639418 train loss:0.64844465, test loss:0.64682347, test precision: 0.5661929693343306,test recall: 0.5477568740955138,test f1: 0.556822361162192\n",
      "train accuracy: 0.6588020514285714, test accuracy:0.6629339305711086 train loss:0.6485414, test loss:0.64581388, test precision: 0.5669409124906507,test recall: 0.5480838756326826,test f1: 0.5573529411764705\n",
      "train accuracy: 0.6619145435714285, test accuracy:0.6629339305711086 train loss:0.64854783, test loss:0.64496189, test precision: 0.5669409124906507,test recall: 0.5480838756326826,test f1: 0.5573529411764705\n",
      "train accuracy: 0.6603077857142857, test accuracy:0.6629339305711086 train loss:0.64883953, test loss:0.64456505, test precision: 0.5669409124906507,test recall: 0.5480838756326826,test f1: 0.5573529411764705\n",
      "train accuracy: 0.6682261196428572, test accuracy:0.6629339305711086 train loss:0.64523699, test loss:0.6437223, test precision: 0.5669409124906507,test recall: 0.5480838756326826,test f1: 0.5573529411764705\n",
      "train accuracy: 0.6699339021428571, test accuracy:0.6629339305711086 train loss:0.64326099, test loss:0.64271933, test precision: 0.5661929693343306,test recall: 0.5481535119478639,test f1: 0.5570272259013982\n",
      "train accuracy: 0.6699796028571429, test accuracy:0.6629339305711086 train loss:0.64338236, test loss:0.64200115, test precision: 0.5661929693343306,test recall: 0.5481535119478639,test f1: 0.5570272259013982\n",
      "train accuracy: 0.6574719064285713, test accuracy:0.6629339305711086 train loss:0.64481594, test loss:0.64127403, test precision: 0.5661929693343306,test recall: 0.5481535119478639,test f1: 0.5570272259013982\n",
      "train accuracy: 0.6657005267857145, test accuracy:0.6629339305711086 train loss:0.64240071, test loss:0.64089322, test precision: 0.5676888556469708,test recall: 0.548014440433213,test f1: 0.5576781778104335\n",
      "train accuracy: 0.6706915792857142, test accuracy:0.6623740201567749 train loss:0.64101372, test loss:0.64029497, test precision: 0.5676888556469708,test recall: 0.5472242249459265,test f1: 0.5572687224669604\n",
      "train accuracy: 0.66888037, test accuracy:0.6629339305711086 train loss:0.63862651, test loss:0.63969564, test precision: 0.5691847419596111,test recall: 0.5478761699064075,test f1: 0.558327219369039\n",
      "train accuracy: 0.6672663939285715, test accuracy:0.6626539753639418 train loss:0.63949906, test loss:0.63943058, test precision: 0.5699326851159312,test recall: 0.5474137931034483,test f1: 0.5584463173323562\n",
      "train accuracy: 0.6652387042857143, test accuracy:0.6626539753639418 train loss:0.63983692, test loss:0.63880455, test precision: 0.5699326851159312,test recall: 0.5474137931034483,test f1: 0.5584463173323562\n",
      "train accuracy: 0.6695370225, test accuracy:0.6626539753639418 train loss:0.63660787, test loss:0.63798416, test precision: 0.5699326851159312,test recall: 0.5474137931034483,test f1: 0.5584463173323562\n",
      "train accuracy: 0.6692748425, test accuracy:0.6618141097424413 train loss:0.63676078, test loss:0.63740903, test precision: 0.5714285714285714,test recall: 0.5461043602573267,test f1: 0.5584795321637427\n",
      "train accuracy: 0.6750620575, test accuracy:0.6618141097424413 train loss:0.63562874, test loss:0.63706899, test precision: 0.5714285714285714,test recall: 0.5461043602573267,test f1: 0.5584795321637427\n",
      "train accuracy: 0.6738617985714287, test accuracy:0.6615341545352743 train loss:0.63423905, test loss:0.63637239, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6743861610714286, test accuracy:0.6615341545352743 train loss:0.63180532, test loss:0.63555026, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6682453632142857, test accuracy:0.6618141097424413 train loss:0.63383436, test loss:0.63461417, test precision: 0.5714285714285714,test recall: 0.5461043602573267,test f1: 0.5584795321637427\n",
      "train accuracy: 0.6681299071428571, test accuracy:0.6615341545352743 train loss:0.63358225, test loss:0.63430905, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6654118875, test accuracy:0.6615341545352743 train loss:0.63317621, test loss:0.63380957, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6701864614285714, test accuracy:0.6615341545352743 train loss:0.63152087, test loss:0.63314193, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6648225835714285, test accuracy:0.6615341545352743 train loss:0.63302816, test loss:0.63220489, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6634659789285714, test accuracy:0.6615341545352743 train loss:0.63403793, test loss:0.63203537, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6659939767857143, test accuracy:0.6615341545352743 train loss:0.63087353, test loss:0.63138324, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6756778214285715, test accuracy:0.6618141097424413 train loss:0.62650603, test loss:0.63045835, test precision: 0.5729244577412117,test recall: 0.5459729151817534,test f1: 0.5591240875912409\n",
      "train accuracy: 0.6703861028571428, test accuracy:0.6618141097424413 train loss:0.6299161, test loss:0.62993401, test precision: 0.5729244577412117,test recall: 0.5459729151817534,test f1: 0.5591240875912409\n",
      "train accuracy: 0.6663595867857143, test accuracy:0.6615341545352743 train loss:0.62758836, test loss:0.62933362, test precision: 0.5721765145848915,test recall: 0.5456490727532097,test f1: 0.5585980284775467\n",
      "train accuracy: 0.6687240228571429, test accuracy:0.6618141097424413 train loss:0.62843775, test loss:0.62941796, test precision: 0.5729244577412117,test recall: 0.5459729151817534,test f1: 0.5591240875912409\n",
      "train accuracy: 0.6680024250000001, test accuracy:0.6615341545352743 train loss:0.62880423, test loss:0.62935042, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6697535035714285, test accuracy:0.6612541993281075 train loss:0.6267779, test loss:0.62870961, test precision: 0.5721765145848915,test recall: 0.5452601568068425,test f1: 0.5583941605839416\n",
      "train accuracy: 0.6656572314285712, test accuracy:0.6615341545352743 train loss:0.62633512, test loss:0.62799478, test precision: 0.5721765145848915,test recall: 0.5456490727532097,test f1: 0.5585980284775467\n",
      "train accuracy: 0.6731714714285715, test accuracy:0.6615341545352743 train loss:0.62287335, test loss:0.6276952, test precision: 0.5729244577412117,test recall: 0.5455840455840456,test f1: 0.5589201021524991\n",
      "train accuracy: 0.6719327267857144, test accuracy:0.6606942889137738 train loss:0.62400989, test loss:0.62772888, test precision: 0.575168287210172,test recall: 0.5442321302193913,test f1: 0.5592727272727273\n",
      "train accuracy: 0.6681395282142857, test accuracy:0.6609742441209406 train loss:0.62519728, test loss:0.62787408, test precision: 0.5766641735228123,test recall: 0.5444915254237288,test f1: 0.5601162368325464\n",
      "train accuracy: 0.6716609257142857, test accuracy:0.6601343784994401 train loss:0.62356877, test loss:0.627711, test precision: 0.5826477187733732,test recall: 0.5428571428571428,test f1: 0.562049062049062\n",
      "train accuracy: 0.6671485335714286, test accuracy:0.6609742441209406 train loss:0.62343214, test loss:0.62692052, test precision: 0.5766641735228123,test recall: 0.5444915254237288,test f1: 0.5601162368325464\n",
      "train accuracy: 0.6758221407142857, test accuracy:0.6601343784994401 train loss:0.62031379, test loss:0.62679893, test precision: 0.5826477187733732,test recall: 0.5428571428571428,test f1: 0.562049062049062\n",
      "train accuracy: 0.6732243882142858, test accuracy:0.6606942889137738 train loss:0.61971104, test loss:0.62681168, test precision: 0.5841436050860135,test recall: 0.5434933890048712,test f1: 0.5630857966834896\n",
      "train accuracy: 0.6704823157142857, test accuracy:0.6598544232922733 train loss:0.62210229, test loss:0.62566918, test precision: 0.5818997756170531,test recall: 0.5425383542538355,test f1: 0.5615301335258029\n",
      "train accuracy: 0.6647985296428571, test accuracy:0.6606942889137738 train loss:0.62008301, test loss:0.62540489, test precision: 0.5804038893044129,test recall: 0.5437981779957953,test f1: 0.5615050651230101\n",
      "train accuracy: 0.6694287821428572, test accuracy:0.6612541993281075 train loss:0.62002889, test loss:0.62500972, test precision: 0.5818997756170531,test recall: 0.5444366689993002,test f1: 0.5625451916124368\n",
      "train accuracy: 0.6671653710714286, test accuracy:0.6612541993281075 train loss:0.62197424, test loss:0.62471205, test precision: 0.5818997756170531,test recall: 0.5444366689993002,test f1: 0.5625451916124368\n",
      "train accuracy: 0.6695971557142857, test accuracy:0.6623740201567749 train loss:0.62106568, test loss:0.62412858, test precision: 0.5774121166791324,test recall: 0.5463552724699221,test f1: 0.5614545454545454\n",
      "train accuracy: 0.6773687639285715, test accuracy:0.6629339305711086 train loss:0.61565267, test loss:0.62426364, test precision: 0.5789080029917726,test recall: 0.5469964664310955,test f1: 0.5625\n",
      "train accuracy: 0.6631268275, test accuracy:0.6626539753639418 train loss:0.62186645, test loss:0.62431359, test precision: 0.5789080029917726,test recall: 0.5466101694915254,test f1: 0.5622956774427897\n",
      "train accuracy: 0.6719110785714285, test accuracy:0.6629339305711086 train loss:0.61689399, test loss:0.62377459, test precision: 0.5789080029917726,test recall: 0.5469964664310955,test f1: 0.5625\n",
      "train accuracy: 0.6766880578571428, test accuracy:0.6629339305711086 train loss:0.61465233, test loss:0.6231705, test precision: 0.5789080029917726,test recall: 0.5469964664310955,test f1: 0.5625\n",
      "train accuracy: 0.6698280678571428, test accuracy:0.6629339305711086 train loss:0.6187914, test loss:0.62217778, test precision: 0.5789080029917726,test recall: 0.5469964664310955,test f1: 0.5625\n",
      "train accuracy: 0.6661070260714286, test accuracy:0.6587346024636058 train loss:0.6187993, test loss:0.6226908, test precision: 0.5901271503365744,test recall: 0.5404109589041096,test f1: 0.5641759027529495\n",
      "train accuracy: 0.6660180296428573, test accuracy:0.660414333706607 train loss:0.62050838, test loss:0.62327135, test precision: 0.6118175018698578,test recall: 0.541005291005291,test f1: 0.5742365742365741\n",
      "train accuracy: 0.6712520210714287, test accuracy:0.6606942889137738 train loss:0.61665877, test loss:0.62266004, test precision: 0.6118175018698578,test recall: 0.5413633355393779,test f1: 0.574438202247191\n",
      "train accuracy: 0.6687192117857144, test accuracy:0.6606942889137738 train loss:0.61796531, test loss:0.62227154, test precision: 0.6118175018698578,test recall: 0.5413633355393779,test f1: 0.574438202247191\n",
      "train accuracy: 0.6693566239285715, test accuracy:0.6606942889137738 train loss:0.61721888, test loss:0.62182134, test precision: 0.6103216155572176,test recall: 0.5414731254147312,test f1: 0.5738396624472574\n",
      "train accuracy: 0.6751582703571428, test accuracy:0.6606942889137738 train loss:0.61472613, test loss:0.62170064, test precision: 0.6103216155572176,test recall: 0.5414731254147312,test f1: 0.5738396624472574\n",
      "train accuracy: 0.6793291049999999, test accuracy:0.6615341545352743 train loss:0.61088492, test loss:0.62116432, test precision: 0.6088257292445775,test recall: 0.5426666666666666,test f1: 0.5738456115615087\n",
      "train accuracy: 0.6756585785714285, test accuracy:0.6615341545352743 train loss:0.61437985, test loss:0.6214143, test precision: 0.6088257292445775,test recall: 0.5426666666666666,test f1: 0.5738456115615087\n",
      "train accuracy: 0.672187692857143, test accuracy:0.6618141097424413 train loss:0.61651268, test loss:0.62121022, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6695418339285715, test accuracy:0.6618141097424413 train loss:0.6160424, test loss:0.62093502, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6683079000000001, test accuracy:0.6618141097424413 train loss:0.61710748, test loss:0.62133884, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6762550989285715, test accuracy:0.6618141097424413 train loss:0.61048018, test loss:0.62087601, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6764932260714286, test accuracy:0.6618141097424413 train loss:0.61002693, test loss:0.62076759, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.678645995, test accuracy:0.6618141097424413 train loss:0.61019795, test loss:0.62022626, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6736765896428573, test accuracy:0.6618141097424413 train loss:0.61288806, test loss:0.62000936, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6664918785714287, test accuracy:0.6618141097424413 train loss:0.61576102, test loss:0.62029922, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6718196764285713, test accuracy:0.6623740201567749 train loss:0.61294271, test loss:0.6193831, test precision: 0.6088257292445775,test recall: 0.5437541750167001,test f1: 0.5744530698659139\n",
      "train accuracy: 0.6687673178571428, test accuracy:0.6618141097424413 train loss:0.61429786, test loss:0.62032431, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6805462014285714, test accuracy:0.6618141097424413 train loss:0.6112185, test loss:0.62049657, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6805462021428571, test accuracy:0.6601343784994401 train loss:0.60689306, test loss:0.62056309, test precision: 0.6095736724008975,test recall: 0.5408095554080955,test f1: 0.5731364275668072\n",
      "train accuracy: 0.6775178957142857, test accuracy:0.6618141097424413 train loss:0.60920271, test loss:0.61988121, test precision: 0.6088257292445775,test recall: 0.543028685790527,test f1: 0.5740479548660085\n",
      "train accuracy: 0.6690559567857142, test accuracy:0.6626539753639418 train loss:0.61507363, test loss:0.61867255, test precision: 0.6088257292445775,test recall: 0.5441176470588235,test f1: 0.5746558418637487\n",
      "train accuracy: 0.6703115367857143, test accuracy:0.6654535274356103 train loss:0.61396158, test loss:0.61790216, test precision: 0.6020942408376964,test recall: 0.5483651226158038,test f1: 0.5739750445632797\n",
      "train accuracy: 0.6698545257142857, test accuracy:0.6643337066069429 train loss:0.6145791, test loss:0.61859798, test precision: 0.6080777860882572,test recall: 0.5463709677419355,test f1: 0.575575221238938\n",
      "train accuracy: 0.6894290717857142, test accuracy:0.6654535274356103 train loss:0.60269799, test loss:0.61823559, test precision: 0.6020942408376964,test recall: 0.5483651226158038,test f1: 0.5739750445632797\n",
      "train accuracy: 0.6783525442857143, test accuracy:0.6662933930571109 train loss:0.60789073, test loss:0.61798918, test precision: 0.6050860134629769,test recall: 0.5492192803801765,test f1: 0.5758007117437723\n",
      "train accuracy: 0.6782659517857142, test accuracy:0.6662933930571109 train loss:0.60860936, test loss:0.61795229, test precision: 0.6050860134629769,test recall: 0.5492192803801765,test f1: 0.5758007117437723\n",
      "train accuracy: 0.674037387142857, test accuracy:0.6662933930571109 train loss:0.6102975, test loss:0.61741459, test precision: 0.6050860134629769,test recall: 0.5492192803801765,test f1: 0.5758007117437723\n",
      "train accuracy: 0.6744318617857142, test accuracy:0.6662933930571109 train loss:0.61116103, test loss:0.61798859, test precision: 0.6050860134629769,test recall: 0.5492192803801765,test f1: 0.5758007117437723\n",
      "train accuracy: 0.6782298721428572, test accuracy:0.666013437849944 train loss:0.60957007, test loss:0.61651635, test precision: 0.6013462976813763,test recall: 0.5491803278688525,test f1: 0.5740806854694753\n",
      "train accuracy: 0.6797356064285713, test accuracy:0.666013437849944 train loss:0.60312987, test loss:0.61662227, test precision: 0.6013462976813763,test recall: 0.5491803278688525,test f1: 0.5740806854694753\n",
      "train accuracy: 0.6785810496428571, test accuracy:0.6685330347144457 train loss:0.60690645, test loss:0.61622262, test precision: 0.6043380703066566,test recall: 0.5522898154477102,test f1: 0.5771428571428572\n",
      "train accuracy: 0.6750981360714284, test accuracy:0.6685330347144457 train loss:0.60863881, test loss:0.61618233, test precision: 0.6043380703066566,test recall: 0.5522898154477102,test f1: 0.5771428571428572\n",
      "train accuracy: 0.6759327857142855, test accuracy:0.6690929451287794 train loss:0.60801187, test loss:0.61653751, test precision: 0.6043380703066566,test recall: 0.5530458590006845,test f1: 0.577555396711937\n",
      "train accuracy: 0.677647782857143, test accuracy:0.6674132138857782 train loss:0.60650214, test loss:0.61698425, test precision: 0.6043380703066566,test recall: 0.5507839127471029,test f1: 0.5763195435092725\n",
      "train accuracy: 0.6810657521428573, test accuracy:0.6671332586786114 train loss:0.60573745, test loss:0.61721885, test precision: 0.6050860134629769,test recall: 0.5503401360544218,test f1: 0.5764161026006412\n",
      "train accuracy: 0.6756249032142857, test accuracy:0.6690929451287794 train loss:0.60930019, test loss:0.61633259, test precision: 0.6043380703066566,test recall: 0.5530458590006845,test f1: 0.577555396711937\n",
      "train accuracy: 0.6850585939285715, test accuracy:0.6690929451287794 train loss:0.60207757, test loss:0.61670625, test precision: 0.6043380703066566,test recall: 0.5530458590006845,test f1: 0.577555396711937\n",
      "train accuracy: 0.6747830392857143, test accuracy:0.6690929451287794 train loss:0.6090734, test loss:0.61693615, test precision: 0.6043380703066566,test recall: 0.5530458590006845,test f1: 0.577555396711937\n",
      "train accuracy: 0.6789851428571428, test accuracy:0.6690929451287794 train loss:0.60584742, test loss:0.6164394, test precision: 0.6013462976813763,test recall: 0.553337921541638,test f1: 0.5763440860215053\n",
      "train accuracy: 0.6757235225, test accuracy:0.6690929451287794 train loss:0.60912243, test loss:0.61604953, test precision: 0.6013462976813763,test recall: 0.553337921541638,test f1: 0.5763440860215053\n",
      "train accuracy: 0.68182343, test accuracy:0.6693729003359462 train loss:0.60372885, test loss:0.61500543, test precision: 0.5983545250560958,test recall: 0.554016620498615,test f1: 0.5753326141675656\n",
      "train accuracy: 0.6811210742857143, test accuracy:0.6693729003359462 train loss:0.60534476, test loss:0.61560512, test precision: 0.5983545250560958,test recall: 0.554016620498615,test f1: 0.5753326141675656\n",
      "train accuracy: 0.6743813489285715, test accuracy:0.6662933930571109 train loss:0.60698108, test loss:0.61574942, test precision: 0.599850411368736,test recall: 0.5496915695681974,test f1: 0.5736766809728183\n",
      "train accuracy: 0.6765124700000001, test accuracy:0.6643337066069429 train loss:0.60570475, test loss:0.61717069, test precision: 0.6035901271503366,test recall: 0.5467479674796748,test f1: 0.5737646640597227\n",
      "train accuracy: 0.6756008517857143, test accuracy:0.666013437849944 train loss:0.60868282, test loss:0.61627573, test precision: 0.6020942408376964,test recall: 0.5491132332878581,test f1: 0.5743845879414913\n",
      "train accuracy: 0.6746290992857144, test accuracy:0.666013437849944 train loss:0.60728199, test loss:0.61572981, test precision: 0.6020942408376964,test recall: 0.5491132332878581,test f1: 0.5743845879414913\n",
      "train accuracy: 0.6790981953571429, test accuracy:0.666013437849944 train loss:0.6038121, test loss:0.6153574, test precision: 0.6020942408376964,test recall: 0.5491132332878581,test f1: 0.5743845879414913\n",
      "train accuracy: 0.6765822235714286, test accuracy:0.666013437849944 train loss:0.60699535, test loss:0.61500329, test precision: 0.6020942408376964,test recall: 0.5491132332878581,test f1: 0.5743845879414913\n",
      "train accuracy: 0.6800218400000001, test accuracy:0.6676931690929452 train loss:0.6041861, test loss:0.6135124, test precision: 0.5991024682124159,test recall: 0.5516528925619835,test f1: 0.5743994263176765\n",
      "train accuracy: 0.6733350324999999, test accuracy:0.6676931690929452 train loss:0.60458913, test loss:0.61343354, test precision: 0.5991024682124159,test recall: 0.5516528925619835,test f1: 0.5743994263176765\n",
      "train accuracy: 0.6817512689285713, test accuracy:0.6668533034714446 train loss:0.60130166, test loss:0.61431181, test precision: 0.5991024682124159,test recall: 0.5505154639175258,test f1: 0.57378223495702\n",
      "train accuracy: 0.6734023821428572, test accuracy:0.6665733482642777 train loss:0.60574669, test loss:0.61465508, test precision: 0.6013462976813763,test recall: 0.5499316005471956,test f1: 0.5744908896034299\n",
      "train accuracy: 0.6789683067857143, test accuracy:0.6665733482642777 train loss:0.60272865, test loss:0.61514837, test precision: 0.6013462976813763,test recall: 0.5499316005471956,test f1: 0.5744908896034299\n",
      "train accuracy: 0.6822203089285714, test accuracy:0.6690929451287794 train loss:0.60151054, test loss:0.61563224, test precision: 0.6185489902767389,test recall: 0.5517011340893929,test f1: 0.5832157968970381\n",
      "train accuracy: 0.6775395428571428, test accuracy:0.6696528555431132 train loss:0.60612704, test loss:0.61511469, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6812172875, test accuracy:0.6696528555431132 train loss:0.60163454, test loss:0.61469036, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6772533107142856, test accuracy:0.6665733482642777 train loss:0.60168036, test loss:0.61376888, test precision: 0.6013462976813763,test recall: 0.5499316005471956,test f1: 0.5744908896034299\n",
      "train accuracy: 0.6844692896428572, test accuracy:0.6688129899216125 train loss:0.59929532, test loss:0.61379963, test precision: 0.6155572176514585,test recall: 0.5516085790884718,test f1: 0.5818310357016615\n",
      "train accuracy: 0.6765052528571428, test accuracy:0.6696528555431132 train loss:0.60770154, test loss:0.61473274, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6800843789285714, test accuracy:0.6696528555431132 train loss:0.60450353, test loss:0.61426795, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6835913442857142, test accuracy:0.6696528555431132 train loss:0.60071613, test loss:0.61439741, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6867471325, test accuracy:0.6696528555431132 train loss:0.60384787, test loss:0.61375034, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6778329932142857, test accuracy:0.6696528555431132 train loss:0.60290977, test loss:0.61419725, test precision: 0.6178010471204188,test recall: 0.5525083612040134,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6787879071428572, test accuracy:0.66993281075028 train loss:0.6013557, test loss:0.61420751, test precision: 0.6185489902767389,test recall: 0.5528074866310161,test f1: 0.583833392163784\n",
      "train accuracy: 0.6835600749999999, test accuracy:0.6707726763717805 train loss:0.60084271, test loss:0.61330217, test precision: 0.6178010471204188,test recall: 0.5539906103286385,test f1: 0.5841584158415842\n",
      "train accuracy: 0.6835239957142857, test accuracy:0.6707726763717805 train loss:0.60126658, test loss:0.61311489, test precision: 0.6178010471204188,test recall: 0.5539906103286385,test f1: 0.5841584158415842\n",
      "train accuracy: 0.6818041878571429, test accuracy:0.6707726763717805 train loss:0.60285921, test loss:0.61359453, test precision: 0.6178010471204188,test recall: 0.5539906103286385,test f1: 0.5841584158415842\n",
      "train accuracy: 0.6772797689285713, test accuracy:0.6710526315789473 train loss:0.60526107, test loss:0.61401498, test precision: 0.6185489902767389,test recall: 0.5542895442359249,test f1: 0.5846588900671615\n",
      "train accuracy: 0.6849623810714286, test accuracy:0.6710526315789473 train loss:0.59707062, test loss:0.6137833, test precision: 0.6185489902767389,test recall: 0.5542895442359249,test f1: 0.5846588900671615\n",
      "train accuracy: 0.6825065417857142, test accuracy:0.6710526315789473 train loss:0.59743849, test loss:0.6140061, test precision: 0.6185489902767389,test recall: 0.5542895442359249,test f1: 0.5846588900671615\n",
      "train accuracy: 0.6843899146428571, test accuracy:0.6710526315789473 train loss:0.59869381, test loss:0.61360735, test precision: 0.6185489902767389,test recall: 0.5542895442359249,test f1: 0.5846588900671615\n",
      "train accuracy: 0.6841830546428571, test accuracy:0.6710526315789473 train loss:0.59654363, test loss:0.61280048, test precision: 0.6155572176514585,test recall: 0.5545822102425876,test f1: 0.5834810350939383\n",
      "train accuracy: 0.6867735914285714, test accuracy:0.6710526315789473 train loss:0.60056479, test loss:0.61124647, test precision: 0.6140613313388182,test recall: 0.5547297297297298,test f1: 0.5828895988640397\n",
      "train accuracy: 0.676575007142857, test accuracy:0.6707726763717805 train loss:0.60427131, test loss:0.61197704, test precision: 0.6148092744951383,test recall: 0.5542818610923803,test f1: 0.5829787234042554\n",
      "train accuracy: 0.6877309128571428, test accuracy:0.6710526315789473 train loss:0.59600931, test loss:0.61246455, test precision: 0.6163051608077786,test recall: 0.5545087483176312,test f1: 0.583776124690046\n",
      "train accuracy: 0.6838607410714286, test accuracy:0.6707726763717805 train loss:0.59875342, test loss:0.61272871, test precision: 0.6185489902767389,test recall: 0.5539182853315472,test f1: 0.5844522968197879\n",
      "train accuracy: 0.687127175357143, test accuracy:0.6707726763717805 train loss:0.59551088, test loss:0.61241096, test precision: 0.6185489902767389,test recall: 0.5539182853315472,test f1: 0.5844522968197879\n",
      "train accuracy: 0.6742129767857142, test accuracy:0.6710526315789473 train loss:0.6065143, test loss:0.61212575, test precision: 0.6192969334330591,test recall: 0.5542168674698795,test f1: 0.5849523136700813\n",
      "train accuracy: 0.6862829039285714, test accuracy:0.6710526315789473 train loss:0.59872819, test loss:0.6124838, test precision: 0.6192969334330591,test recall: 0.5542168674698795,test f1: 0.5849523136700813\n",
      "train accuracy: 0.6814241464285714, test accuracy:0.6713325867861142 train loss:0.60111671, test loss:0.61052573, test precision: 0.6148092744951383,test recall: 0.5550303848750844,test f1: 0.5833924769339957\n",
      "train accuracy: 0.6792280821428571, test accuracy:0.671612541993281 train loss:0.60250248, test loss:0.61090147, test precision: 0.6163051608077786,test recall: 0.555256064690027,test f1: 0.5841900035448423\n",
      "train accuracy: 0.6823357639285713, test accuracy:0.6713325867861142 train loss:0.60110169, test loss:0.61117607, test precision: 0.6170531039640987,test recall: 0.554808338937458,test f1: 0.5842776203966006\n",
      "train accuracy: 0.6833267589285714, test accuracy:0.6713325867861142 train loss:0.59753167, test loss:0.61120796, test precision: 0.6170531039640987,test recall: 0.554808338937458,test f1: 0.5842776203966006\n",
      "train accuracy: 0.6821890396428572, test accuracy:0.6707726763717805 train loss:0.60071551, test loss:0.6118201, test precision: 0.6200448765893792,test recall: 0.5537742150968604,test f1: 0.5850388143966126\n",
      "train accuracy: 0.6833315682142855, test accuracy:0.6710526315789473 train loss:0.59740917, test loss:0.61158872, test precision: 0.6178010471204188,test recall: 0.5543624161073826,test f1: 0.5843650512911214\n",
      "train accuracy: 0.6804018814285714, test accuracy:0.6713325867861142 train loss:0.60254809, test loss:0.61131728, test precision: 0.6178010471204188,test recall: 0.554734721289456,test f1: 0.5845718329794763\n",
      "train accuracy: 0.6889888967857143, test accuracy:0.6676931690929452 train loss:0.59746593, test loss:0.61194247, test precision: 0.6207928197456993,test recall: 0.5496688741721855,test f1: 0.5830698981383913\n",
      "train accuracy: 0.6784006510714287, test accuracy:0.6713325867861142 train loss:0.60268713, test loss:0.61144537, test precision: 0.6178010471204188,test recall: 0.554734721289456,test f1: 0.5845718329794763\n",
      "train accuracy: 0.6830573632142858, test accuracy:0.6713325867861142 train loss:0.60128742, test loss:0.61119336, test precision: 0.6178010471204188,test recall: 0.554734721289456,test f1: 0.5845718329794763\n",
      "train accuracy: 0.6907279478571429, test accuracy:0.6713325867861142 train loss:0.5932134, test loss:0.61085826, test precision: 0.6178010471204188,test recall: 0.554734721289456,test f1: 0.5845718329794763\n",
      "train accuracy: 0.6809575110714287, test accuracy:0.6713325867861142 train loss:0.59984828, test loss:0.61071771, test precision: 0.6178010471204188,test recall: 0.554734721289456,test f1: 0.5845718329794763\n",
      "train accuracy: 0.6759207585714285, test accuracy:0.667973124300112 train loss:0.60444047, test loss:0.61151707, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6844957471428571, test accuracy:0.667973124300112 train loss:0.59832368, test loss:0.61109322, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6791487074999999, test accuracy:0.667973124300112 train loss:0.60238889, test loss:0.6113559, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6773374953571427, test accuracy:0.667973124300112 train loss:0.60592301, test loss:0.61218607, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6909059421428572, test accuracy:0.667973124300112 train loss:0.59500744, test loss:0.61215776, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6832161139285714, test accuracy:0.667973124300112 train loss:0.59814225, test loss:0.61207724, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6790885739285715, test accuracy:0.667973124300112 train loss:0.59969029, test loss:0.61146325, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.68595097, test accuracy:0.667973124300112 train loss:0.59856119, test loss:0.61087275, test precision: 0.6207928197456993,test recall: 0.5500331345261763,test f1: 0.5832747716092762\n",
      "train accuracy: 0.6766856524999998, test accuracy:0.6682530795072789 train loss:0.60364228, test loss:0.61068767, test precision: 0.6185489902767389,test recall: 0.5505992010652463,test f1: 0.5825995068686156\n",
      "train accuracy: 0.680659252142857, test accuracy:0.6693729003359462 train loss:0.59876266, test loss:0.6098271, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6864825478571428, test accuracy:0.6724524076147816 train loss:0.59539099, test loss:0.60813701, test precision: 0.6110695587135377,test recall: 0.5569188820722563,test f1: 0.5827389443651926\n",
      "train accuracy: 0.6857393010714287, test accuracy:0.6724524076147816 train loss:0.59532031, test loss:0.60869277, test precision: 0.6110695587135377,test recall: 0.5569188820722563,test f1: 0.5827389443651926\n",
      "train accuracy: 0.6828384778571428, test accuracy:0.6693729003359462 train loss:0.60003154, test loss:0.60966611, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6772941996428571, test accuracy:0.6693729003359462 train loss:0.60114363, test loss:0.61003119, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6872979521428572, test accuracy:0.6693729003359462 train loss:0.59199416, test loss:0.61072803, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6823285467857143, test accuracy:0.6693729003359462 train loss:0.60069577, test loss:0.60992539, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6847867917857143, test accuracy:0.6693729003359462 train loss:0.59437694, test loss:0.60897028, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6851524007142856, test accuracy:0.6730123180291153 train loss:0.59294026, test loss:0.60777462, test precision: 0.6110695587135377,test recall: 0.557679180887372,test f1: 0.5831548893647395\n",
      "train accuracy: 0.683812635, test accuracy:0.6693729003359462 train loss:0.59551607, test loss:0.60840952, test precision: 0.6118175018698578,test recall: 0.5527027027027027,test f1: 0.5807596734114305\n",
      "train accuracy: 0.6855252275000001, test accuracy:0.6690929451287794 train loss:0.59659939, test loss:0.60916865, test precision: 0.6118175018698578,test recall: 0.5523295070898042,test f1: 0.5805535841022001\n",
      "train accuracy: 0.6817175953571427, test accuracy:0.6690929451287794 train loss:0.59719192, test loss:0.60909098, test precision: 0.6118175018698578,test recall: 0.5523295070898042,test f1: 0.5805535841022001\n",
      "train accuracy: 0.6752280242857144, test accuracy:0.66993281075028 train loss:0.59996981, test loss:0.60839111, test precision: 0.6118175018698578,test recall: 0.5534506089309879,test f1: 0.5811722912966253\n",
      "train accuracy: 0.6761805353571428, test accuracy:0.6696528555431132 train loss:0.59750547, test loss:0.60877419, test precision: 0.6118175018698578,test recall: 0.5530764029749831,test f1: 0.580965909090909\n",
      "train accuracy: 0.6901194007142858, test accuracy:0.6696528555431132 train loss:0.59245355, test loss:0.60857099, test precision: 0.6118175018698578,test recall: 0.5530764029749831,test f1: 0.580965909090909\n",
      "train accuracy: 0.6874951903571428, test accuracy:0.6696528555431132 train loss:0.58890573, test loss:0.60902685, test precision: 0.6118175018698578,test recall: 0.5530764029749831,test f1: 0.580965909090909\n",
      "train accuracy: 0.6836490717857142, test accuracy:0.6710526315789473 train loss:0.59674952, test loss:0.60790849, test precision: 0.6103216155572176,test recall: 0.5551020408163265,test f1: 0.5814036337727112\n",
      "train accuracy: 0.6905932489285714, test accuracy:0.6702127659574468 train loss:0.59257046, test loss:0.6089372, test precision: 0.6118175018698578,test recall: 0.5538253215978335,test f1: 0.5813788201847903\n",
      "train accuracy: 0.6863815239285714, test accuracy:0.6702127659574468 train loss:0.59415559, test loss:0.60838574, test precision: 0.6118175018698578,test recall: 0.5538253215978335,test f1: 0.5813788201847903\n",
      "train accuracy: 0.6883731335714286, test accuracy:0.6702127659574468 train loss:0.59164562, test loss:0.60863745, test precision: 0.6118175018698578,test recall: 0.5538253215978335,test f1: 0.5813788201847903\n",
      "train accuracy: 0.680688115357143, test accuracy:0.6702127659574468 train loss:0.5962306, test loss:0.60800791, test precision: 0.6118175018698578,test recall: 0.5538253215978335,test f1: 0.5813788201847903\n",
      "train accuracy: 0.6874182189285715, test accuracy:0.6741321388577828 train loss:0.59228551, test loss:0.6072278, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6955001160714287, test accuracy:0.6741321388577828 train loss:0.59035415, test loss:0.60627705, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6905403335714285, test accuracy:0.6772116461366181 train loss:0.5924837, test loss:0.6059249, test precision: 0.6073298429319371,test recall: 0.5638888888888889,test f1: 0.5848037450486135\n",
      "train accuracy: 0.6888229292857143, test accuracy:0.6772116461366181 train loss:0.59241375, test loss:0.60574394, test precision: 0.6073298429319371,test recall: 0.5638888888888889,test f1: 0.5848037450486135\n",
      "train accuracy: 0.6895782032142858, test accuracy:0.6741321388577828 train loss:0.59423631, test loss:0.60663235, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6847627385714287, test accuracy:0.6713325867861142 train loss:0.59396225, test loss:0.60720283, test precision: 0.6103216155572176,test recall: 0.5554799183117767,test f1: 0.5816108339272985\n",
      "train accuracy: 0.6889648439285715, test accuracy:0.6741321388577828 train loss:0.59459474, test loss:0.60606205, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6863743067857142, test accuracy:0.6741321388577828 train loss:0.5929335, test loss:0.60600924, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6843658596428571, test accuracy:0.6741321388577828 train loss:0.59626468, test loss:0.60616976, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6826364303571429, test accuracy:0.6738521836506159 train loss:0.59896839, test loss:0.60718185, test precision: 0.6080777860882572,test recall: 0.5591471801925723,test f1: 0.5825868864206377\n",
      "train accuracy: 0.6854217982142857, test accuracy:0.6724524076147816 train loss:0.59264298, test loss:0.6078347, test precision: 0.6140613313388182,test recall: 0.5566101694915254,test f1: 0.5839260312944523\n",
      "train accuracy: 0.6845630967857144, test accuracy:0.6738521836506159 train loss:0.59688717, test loss:0.60715282, test precision: 0.6080777860882572,test recall: 0.5591471801925723,test f1: 0.5825868864206377\n",
      "train accuracy: 0.6891211892857142, test accuracy:0.6741321388577828 train loss:0.59012018, test loss:0.60671234, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6927652578571429, test accuracy:0.6741321388577828 train loss:0.58973742, test loss:0.60573173, test precision: 0.6080777860882572,test recall: 0.559532002752925,test f1: 0.5827956989247312\n",
      "train accuracy: 0.6783765975, test accuracy:0.6752519596864501 train loss:0.59795381, test loss:0.60652363, test precision: 0.6118175018698578,test recall: 0.5606579849211789,test f1: 0.5851216022889842\n",
      "train accuracy: 0.6855348478571429, test accuracy:0.6752519596864501 train loss:0.59348406, test loss:0.60699934, test precision: 0.6118175018698578,test recall: 0.5606579849211789,test f1: 0.5851216022889842\n",
      "train accuracy: 0.6938380353571428, test accuracy:0.6749720044792833 train loss:0.5884299, test loss:0.6073783, test precision: 0.6140613313388182,test recall: 0.5600272851296043,test f1: 0.5858009275775954\n",
      "train accuracy: 0.6903214464285713, test accuracy:0.6749720044792833 train loss:0.59017722, test loss:0.6070959, test precision: 0.6140613313388182,test recall: 0.5600272851296043,test f1: 0.5858009275775954\n",
      "train accuracy: 0.6986414721428572, test accuracy:0.6760918253079508 train loss:0.58387437, test loss:0.60654414, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6878752317857143, test accuracy:0.6760918253079508 train loss:0.59377754, test loss:0.60626924, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6860399671428572, test accuracy:0.6760918253079508 train loss:0.59380599, test loss:0.60602444, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6907495957142855, test accuracy:0.6760918253079508 train loss:0.58990829, test loss:0.6058448, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6926570192857142, test accuracy:0.6760918253079508 train loss:0.58747994, test loss:0.60643601, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6793098642857143, test accuracy:0.6758118701007839 train loss:0.59913393, test loss:0.60660911, test precision: 0.6110695587135377,test recall: 0.5615120274914089,test f1: 0.585243553008596\n",
      "train accuracy: 0.6844380185714284, test accuracy:0.6760918253079508 train loss:0.59480784, test loss:0.60629576, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.690910752142857, test accuracy:0.6760918253079508 train loss:0.58889956, test loss:0.60586154, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.682857719642857, test accuracy:0.6763717805151176 train loss:0.59589069, test loss:0.60505641, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6870141235714285, test accuracy:0.6758118701007839 train loss:0.59170124, test loss:0.60566694, test precision: 0.6110695587135377,test recall: 0.5615120274914089,test f1: 0.585243553008596\n",
      "train accuracy: 0.6836610992857143, test accuracy:0.6760918253079508 train loss:0.59760908, test loss:0.60540169, test precision: 0.6103216155572176,test recall: 0.5619834710743802,test f1: 0.5851559698816781\n",
      "train accuracy: 0.6851932928571428, test accuracy:0.6758118701007839 train loss:0.58970675, test loss:0.60531664, test precision: 0.6103216155572176,test recall: 0.5615966964900206,test f1: 0.5849462365591398\n",
      "train accuracy: 0.6893857760714287, test accuracy:0.6758118701007839 train loss:0.5902198, test loss:0.60575968, test precision: 0.6103216155572176,test recall: 0.5615966964900206,test f1: 0.5849462365591398\n",
      "train accuracy: 0.6840363296428571, test accuracy:0.6774916013437849 train loss:0.59506065, test loss:0.60498142, test precision: 0.6080777860882572,test recall: 0.5641915336571826,test f1: 0.5853131749460042\n",
      "train accuracy: 0.6916227303571427, test accuracy:0.6774916013437849 train loss:0.58745576, test loss:0.60592306, test precision: 0.6080777860882572,test recall: 0.5641915336571826,test f1: 0.5853131749460042\n",
      "train accuracy: 0.6837645285714286, test accuracy:0.6774916013437849 train loss:0.59449559, test loss:0.60601896, test precision: 0.6088257292445775,test recall: 0.5641025641025641,test f1: 0.585611510791367\n",
      "train accuracy: 0.680512527857143, test accuracy:0.6774916013437849 train loss:0.59746318, test loss:0.60541445, test precision: 0.6080777860882572,test recall: 0.5641915336571826,test f1: 0.5853131749460042\n",
      "train accuracy: 0.6850922689285716, test accuracy:0.6777715565509519 train loss:0.59194034, test loss:0.60512155, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6818498875, test accuracy:0.6777715565509519 train loss:0.59538308, test loss:0.60441059, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6853328014285713, test accuracy:0.6777715565509519 train loss:0.59571016, test loss:0.60390377, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6861915010714285, test accuracy:0.6777715565509519 train loss:0.5938541, test loss:0.60399383, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6899750814285716, test accuracy:0.6777715565509519 train loss:0.58823543, test loss:0.60405833, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6851187271428572, test accuracy:0.6777715565509519 train loss:0.59201808, test loss:0.60479861, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6870429864285714, test accuracy:0.6777715565509519 train loss:0.59227967, test loss:0.60336405, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6921398739285713, test accuracy:0.6777715565509519 train loss:0.58509325, test loss:0.6037786, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6882191928571428, test accuracy:0.6777715565509519 train loss:0.58949638, test loss:0.60365212, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.694937270357143, test accuracy:0.6777715565509519 train loss:0.5849265, test loss:0.60389417, test precision: 0.6088257292445775,test recall: 0.5644937586685159,test f1: 0.5858222382151853\n",
      "train accuracy: 0.6889239532142858, test accuracy:0.6777715565509519 train loss:0.58681212, test loss:0.60289812, test precision: 0.6080777860882572,test recall: 0.5645833333333333,test f1: 0.5855239467050773\n",
      "train accuracy: 0.6858186764285714, test accuracy:0.6777715565509519 train loss:0.58944077, test loss:0.6041882, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6893280475, test accuracy:0.6777715565509519 train loss:0.59153516, test loss:0.60429358, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6865090049999999, test accuracy:0.6777715565509519 train loss:0.59118018, test loss:0.60416031, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6825330017857143, test accuracy:0.6777715565509519 train loss:0.59557516, test loss:0.60355943, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6853929335714285, test accuracy:0.6777715565509519 train loss:0.59107871, test loss:0.60405326, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6855228221428572, test accuracy:0.6777715565509519 train loss:0.59234259, test loss:0.60369009, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6834686732142857, test accuracy:0.6777715565509519 train loss:0.59261753, test loss:0.60334408, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6825522442857143, test accuracy:0.6777715565509519 train loss:0.59538141, test loss:0.60304976, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6858956464285714, test accuracy:0.6777715565509519 train loss:0.58998193, test loss:0.60288143, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6878319353571429, test accuracy:0.6777715565509519 train loss:0.591168, test loss:0.6031161, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6867808071428572, test accuracy:0.6774916013437849 train loss:0.58998222, test loss:0.60376412, test precision: 0.6103216155572176,test recall: 0.5639253628196268,test f1: 0.5862068965517241\n",
      "train accuracy: 0.6839064425, test accuracy:0.6774916013437849 train loss:0.59460224, test loss:0.603055, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6813495807142858, test accuracy:0.6774916013437849 train loss:0.59374307, test loss:0.602687, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6835769132142858, test accuracy:0.6777715565509519 train loss:0.59246509, test loss:0.60250217, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6917141307142858, test accuracy:0.6777715565509519 train loss:0.58762916, test loss:0.60191697, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6910165871428572, test accuracy:0.6777715565509519 train loss:0.58544963, test loss:0.60188496, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6850513771428572, test accuracy:0.6777715565509519 train loss:0.59027924, test loss:0.60197562, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6810537253571428, test accuracy:0.6774916013437849 train loss:0.59216, test loss:0.60269564, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6882672992857143, test accuracy:0.6774916013437849 train loss:0.58534521, test loss:0.60228765, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6839545489285713, test accuracy:0.6774916013437849 train loss:0.59206266, test loss:0.60213923, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6897730342857142, test accuracy:0.6774916013437849 train loss:0.58634091, test loss:0.60198289, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6879594175, test accuracy:0.6794512877939529 train loss:0.58852782, test loss:0.60100341, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6854314192857142, test accuracy:0.6797312430011199 train loss:0.59123915, test loss:0.60040098, test precision: 0.6073298429319371,test recall: 0.56743535988819,test f1: 0.5867052023121387\n",
      "train accuracy: 0.686311769642857, test accuracy:0.6791713325867861 train loss:0.58978209, test loss:0.6011557, test precision: 0.6088257292445775,test recall: 0.5664578983994433,test f1: 0.5868781542898343\n",
      "train accuracy: 0.6912138242857143, test accuracy:0.6794512877939529 train loss:0.58486548, test loss:0.60042953, test precision: 0.6073298429319371,test recall: 0.5670391061452514,test f1: 0.586493318887685\n",
      "train accuracy: 0.6901795335714286, test accuracy:0.6794512877939529 train loss:0.58624404, test loss:0.60043329, test precision: 0.6073298429319371,test recall: 0.5670391061452514,test f1: 0.586493318887685\n",
      "train accuracy: 0.68806044, test accuracy:0.6794512877939529 train loss:0.5868025, test loss:0.60057741, test precision: 0.6073298429319371,test recall: 0.5670391061452514,test f1: 0.586493318887685\n",
      "train accuracy: 0.690889105, test accuracy:0.6788913773796192 train loss:0.58733775, test loss:0.60177797, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6921903860714285, test accuracy:0.6788913773796192 train loss:0.5858561, test loss:0.60141307, test precision: 0.6110695587135377,test recall: 0.5657894736842105,test f1: 0.5875584322186264\n",
      "train accuracy: 0.6896287128571428, test accuracy:0.6788913773796192 train loss:0.5871594, test loss:0.60239762, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6871656592857143, test accuracy:0.6788913773796192 train loss:0.58790598, test loss:0.60172546, test precision: 0.6110695587135377,test recall: 0.5657894736842105,test f1: 0.5875584322186264\n",
      "train accuracy: 0.693951085, test accuracy:0.6791713325867861 train loss:0.58265534, test loss:0.60063177, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6902637203571429, test accuracy:0.6791713325867861 train loss:0.5852149, test loss:0.60117668, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6916660257142856, test accuracy:0.6791713325867861 train loss:0.58323254, test loss:0.6006375, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6883755389285715, test accuracy:0.6791713325867861 train loss:0.58649466, test loss:0.60021996, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6867447278571427, test accuracy:0.6774916013437849 train loss:0.58736437, test loss:0.60196167, test precision: 0.6118175018698578,test recall: 0.5637491385251551,test f1: 0.5868005738880918\n",
      "train accuracy: 0.6891741082142858, test accuracy:0.6774916013437849 train loss:0.58763173, test loss:0.60171723, test precision: 0.6118175018698578,test recall: 0.5637491385251551,test f1: 0.5868005738880918\n",
      "train accuracy: 0.6891380264285714, test accuracy:0.6791713325867861 train loss:0.58843473, test loss:0.60059512, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6864248196428572, test accuracy:0.6791713325867861 train loss:0.58836493, test loss:0.59942305, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6855661182142858, test accuracy:0.6791713325867861 train loss:0.5883418, test loss:0.59995353, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6889504121428571, test accuracy:0.6791713325867861 train loss:0.58753363, test loss:0.59860349, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6848565457142856, test accuracy:0.6791713325867861 train loss:0.59024151, test loss:0.59992194, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6900015385714285, test accuracy:0.6777715565509519 train loss:0.58472836, test loss:0.59994382, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6835264003571428, test accuracy:0.6777715565509519 train loss:0.5918331, test loss:0.60036898, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6847795764285715, test accuracy:0.6777715565509519 train loss:0.58631255, test loss:0.60052186, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6873941660714287, test accuracy:0.6777715565509519 train loss:0.58872568, test loss:0.599868, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6826508628571428, test accuracy:0.6794512877939529 train loss:0.5949767, test loss:0.59855473, test precision: 0.6080777860882572,test recall: 0.5669456066945606,test f1: 0.5867917719234933\n",
      "train accuracy: 0.6933665914285714, test accuracy:0.6794512877939529 train loss:0.58065732, test loss:0.59822375, test precision: 0.6073298429319371,test recall: 0.5670391061452514,test f1: 0.586493318887685\n",
      "train accuracy: 0.6888205239285714, test accuracy:0.6777715565509519 train loss:0.58533744, test loss:0.59943354, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6820543414285715, test accuracy:0.6777715565509519 train loss:0.58945981, test loss:0.59933424, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6909540492857144, test accuracy:0.6791713325867861 train loss:0.58291164, test loss:0.59865052, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6894988267857143, test accuracy:0.6791713325867861 train loss:0.58490275, test loss:0.5988481, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6934676153571429, test accuracy:0.6791713325867861 train loss:0.58311387, test loss:0.59873396, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6901073753571427, test accuracy:0.6774916013437849 train loss:0.58693781, test loss:0.59982014, test precision: 0.6103216155572176,test recall: 0.5639253628196268,test f1: 0.5862068965517241\n",
      "train accuracy: 0.6837765546428571, test accuracy:0.6774916013437849 train loss:0.58567491, test loss:0.59941375, test precision: 0.6103216155572176,test recall: 0.5639253628196268,test f1: 0.5862068965517241\n",
      "train accuracy: 0.693599907142857, test accuracy:0.6774916013437849 train loss:0.58271982, test loss:0.59873205, test precision: 0.6103216155572176,test recall: 0.5639253628196268,test f1: 0.5862068965517241\n",
      "train accuracy: 0.692137470357143, test accuracy:0.6780515117581187 train loss:0.58081139, test loss:0.59831524, test precision: 0.6103216155572176,test recall: 0.5647058823529412,test f1: 0.5866283249460819\n",
      "train accuracy: 0.6906798407142857, test accuracy:0.6777715565509519 train loss:0.58316172, test loss:0.59822834, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.678742207142857, test accuracy:0.6788913773796192 train loss:0.59091865, test loss:0.59775275, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.6894531253571429, test accuracy:0.6777715565509519 train loss:0.58672071, test loss:0.59829867, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6905042528571429, test accuracy:0.6777715565509519 train loss:0.58438539, test loss:0.59865171, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6898524089285714, test accuracy:0.6777715565509519 train loss:0.58197252, test loss:0.59816831, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6852462092857143, test accuracy:0.6788913773796192 train loss:0.58482561, test loss:0.59889609, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.689164485, test accuracy:0.6788913773796192 train loss:0.58497133, test loss:0.59798002, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.6879858760714285, test accuracy:0.6788913773796192 train loss:0.58342112, test loss:0.59811378, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.693674472142857, test accuracy:0.6788913773796192 train loss:0.57926953, test loss:0.59810525, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.6946005242857144, test accuracy:0.6819708846584547 train loss:0.58170798, test loss:0.59744, test precision: 0.5991024682124159,test recall: 0.5717344753747323,test f1: 0.5850986121256392\n",
      "train accuracy: 0.6821240960714287, test accuracy:0.6788913773796192 train loss:0.58870999, test loss:0.5976181, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.691990745, test accuracy:0.6819708846584547 train loss:0.58021683, test loss:0.59732038, test precision: 0.5991024682124159,test recall: 0.5717344753747323,test f1: 0.5850986121256392\n",
      "train accuracy: 0.68241995, test accuracy:0.6788913773796192 train loss:0.5875713, test loss:0.59796637, test precision: 0.599850411368736,test recall: 0.5671852899575672,test f1: 0.5830607051981098\n",
      "train accuracy: 0.6934171039285716, test accuracy:0.6777715565509519 train loss:0.58034804, test loss:0.59806979, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6890851110714287, test accuracy:0.6777715565509519 train loss:0.58034503, test loss:0.59764385, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6948145971428571, test accuracy:0.6819708846584547 train loss:0.57982439, test loss:0.59724742, test precision: 0.5991024682124159,test recall: 0.5717344753747323,test f1: 0.5850986121256392\n",
      "train accuracy: 0.6906269239285715, test accuracy:0.6777715565509519 train loss:0.58172423, test loss:0.5970847, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6901025635714285, test accuracy:0.6777715565509519 train loss:0.5787097, test loss:0.59744823, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6866557303571429, test accuracy:0.6777715565509519 train loss:0.58546153, test loss:0.59785026, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6893160214285715, test accuracy:0.6777715565509519 train loss:0.58241084, test loss:0.59875804, test precision: 0.6103216155572176,test recall: 0.5643153526970954,test f1: 0.5864175350341357\n",
      "train accuracy: 0.6836153985714285, test accuracy:0.6805711086226204 train loss:0.58802895, test loss:0.59768724, test precision: 0.6088257292445775,test recall: 0.5684357541899442,test f1: 0.5879378837125316\n",
      "train accuracy: 0.6844115607142857, test accuracy:0.6805711086226204 train loss:0.58626441, test loss:0.59831512, test precision: 0.6088257292445775,test recall: 0.5684357541899442,test f1: 0.5879378837125316\n",
      "train accuracy: 0.6889624378571428, test accuracy:0.6769316909294513 train loss:0.58148013, test loss:0.59848493, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6848974367857144, test accuracy:0.6800111982082867 train loss:0.5829083, test loss:0.59752482, test precision: 0.6118175018698578,test recall: 0.5672676837725381,test f1: 0.5887009715725081\n",
      "train accuracy: 0.6917742653571428, test accuracy:0.6769316909294513 train loss:0.57797766, test loss:0.59800583, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6943599914285714, test accuracy:0.681131019036954 train loss:0.58125255, test loss:0.59760708, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6987040110714285, test accuracy:0.681131019036954 train loss:0.5784362, test loss:0.59718519, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.689138027857143, test accuracy:0.681131019036954 train loss:0.58621963, test loss:0.59662366, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6865931907142856, test accuracy:0.681131019036954 train loss:0.58621598, test loss:0.5964309, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6873099789285714, test accuracy:0.681131019036954 train loss:0.58376953, test loss:0.59639567, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6866773774999999, test accuracy:0.681131019036954 train loss:0.58154636, test loss:0.59689462, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6801084321428572, test accuracy:0.681131019036954 train loss:0.58957181, test loss:0.59691375, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6878126921428572, test accuracy:0.681131019036954 train loss:0.58368673, test loss:0.59609902, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6928253917857143, test accuracy:0.6816909294512878 train loss:0.5772363, test loss:0.59411728, test precision: 0.5976065818997757,test recall: 0.5715307582260372,test f1: 0.5842778793418647\n",
      "train accuracy: 0.6839160628571428, test accuracy:0.683090705487122 train loss:0.58930604, test loss:0.59364682, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6965704864285714, test accuracy:0.6816909294512878 train loss:0.57683438, test loss:0.59415257, test precision: 0.5976065818997757,test recall: 0.5715307582260372,test f1: 0.5842778793418647\n",
      "train accuracy: 0.6852991264285714, test accuracy:0.6816909294512878 train loss:0.5840012, test loss:0.59449381, test precision: 0.5976065818997757,test recall: 0.5715307582260372,test f1: 0.5842778793418647\n",
      "train accuracy: 0.6935349635714285, test accuracy:0.681131019036954 train loss:0.58142825, test loss:0.59506506, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6927580449999999, test accuracy:0.681131019036954 train loss:0.57827502, test loss:0.59494764, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6880171453571429, test accuracy:0.681131019036954 train loss:0.58118755, test loss:0.59522152, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6915241114285715, test accuracy:0.6800111982082867 train loss:0.57964545, test loss:0.59558493, test precision: 0.6013462976813763,test recall: 0.5685997171145686,test f1: 0.5845147219193021\n",
      "train accuracy: 0.6932030267857144, test accuracy:0.6800111982082867 train loss:0.57909717, test loss:0.59565032, test precision: 0.6013462976813763,test recall: 0.5685997171145686,test f1: 0.5845147219193021\n",
      "train accuracy: 0.6926498039285715, test accuracy:0.6797312430011199 train loss:0.58041746, test loss:0.59544861, test precision: 0.6013462976813763,test recall: 0.5681978798586572,test f1: 0.5843023255813953\n",
      "train accuracy: 0.6871223642857143, test accuracy:0.681131019036954 train loss:0.58329783, test loss:0.59472519, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6993221789285714, test accuracy:0.681131019036954 train loss:0.57667038, test loss:0.59447467, test precision: 0.6013462976813763,test recall: 0.5702127659574469,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6863719014285715, test accuracy:0.6797312430011199 train loss:0.58363592, test loss:0.59551811, test precision: 0.6013462976813763,test recall: 0.5681978798586572,test f1: 0.5843023255813953\n",
      "train accuracy: 0.6873027624999999, test accuracy:0.6797312430011199 train loss:0.57989834, test loss:0.59648913, test precision: 0.6013462976813763,test recall: 0.5681978798586572,test f1: 0.5843023255813953\n",
      "train accuracy: 0.6922312764285714, test accuracy:0.6797312430011199 train loss:0.58156361, test loss:0.59481269, test precision: 0.6013462976813763,test recall: 0.5681978798586572,test f1: 0.5843023255813953\n",
      "train accuracy: 0.6785545921428573, test accuracy:0.6808510638297872 train loss:0.58793202, test loss:0.59427184, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6934219128571427, test accuracy:0.6808510638297872 train loss:0.58033414, test loss:0.59341395, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6941242692857142, test accuracy:0.6808510638297872 train loss:0.57917076, test loss:0.59333378, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6860543982142857, test accuracy:0.6808510638297872 train loss:0.58490299, test loss:0.59420305, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6901699132142857, test accuracy:0.6808510638297872 train loss:0.58027312, test loss:0.59302896, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6845630975000001, test accuracy:0.6808510638297872 train loss:0.58454394, test loss:0.59241092, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6851187267857143, test accuracy:0.6808510638297872 train loss:0.58551866, test loss:0.59193403, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6853279907142857, test accuracy:0.6808510638297872 train loss:0.58117753, test loss:0.59325886, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6899414067857144, test accuracy:0.6808510638297872 train loss:0.58012293, test loss:0.59412694, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6909324, test accuracy:0.6808510638297872 train loss:0.57871334, test loss:0.5947848, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6921254421428571, test accuracy:0.6808510638297872 train loss:0.58308491, test loss:0.59444308, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6939486803571429, test accuracy:0.6797312430011199 train loss:0.5735324, test loss:0.59596479, test precision: 0.6013462976813763,test recall: 0.5681978798586572,test f1: 0.5843023255813953\n",
      "train accuracy: 0.6908818892857143, test accuracy:0.6808510638297872 train loss:0.57936294, test loss:0.59565675, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6883779428571428, test accuracy:0.6808510638297872 train loss:0.58113307, test loss:0.59576315, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6926281560714285, test accuracy:0.6808510638297872 train loss:0.57856025, test loss:0.59452152, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6905547642857143, test accuracy:0.6808510638297872 train loss:0.57806637, test loss:0.59409082, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6899943228571429, test accuracy:0.6808510638297872 train loss:0.57598106, test loss:0.59448868, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6852173453571428, test accuracy:0.6808510638297872 train loss:0.58325926, test loss:0.59426379, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6931188432142859, test accuracy:0.6808510638297872 train loss:0.57651752, test loss:0.59315991, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6856551150000001, test accuracy:0.6808510638297872 train loss:0.58077445, test loss:0.59362352, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6871704696428571, test accuracy:0.6808510638297872 train loss:0.58079213, test loss:0.59404337, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6836105874999998, test accuracy:0.6808510638297872 train loss:0.58329958, test loss:0.59430468, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6916780521428573, test accuracy:0.6808510638297872 train loss:0.57592298, test loss:0.59438694, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6907423796428571, test accuracy:0.6808510638297872 train loss:0.58224931, test loss:0.59420305, test precision: 0.6013462976813763,test recall: 0.5698086463501063,test f1: 0.5851528384279476\n",
      "train accuracy: 0.6854506614285715, test accuracy:0.6814109742441209 train loss:0.58166222, test loss:0.59461898, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6881277903571429, test accuracy:0.6814109742441209 train loss:0.5797457, test loss:0.59415442, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6906317335714286, test accuracy:0.6805711086226204 train loss:0.57776132, test loss:0.59284079, test precision: 0.600598354525056,test recall: 0.5695035460992908,test f1: 0.5846377866763741\n",
      "train accuracy: 0.6883731335714286, test accuracy:0.6814109742441209 train loss:0.58306774, test loss:0.59211671, test precision: 0.600598354525056,test recall: 0.5707178393745558,test f1: 0.5852769679300291\n",
      "train accuracy: 0.6809094060714286, test accuracy:0.6814109742441209 train loss:0.58301888, test loss:0.59446961, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6847651446428571, test accuracy:0.6814109742441209 train loss:0.57913054, test loss:0.59401435, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6830477399999999, test accuracy:0.6822508398656215 train loss:0.58355585, test loss:0.59332764, test precision: 0.6035901271503366,test recall: 0.5715297450424929,test f1: 0.5871225900327391\n",
      "train accuracy: 0.6883899710714286, test accuracy:0.6814109742441209 train loss:0.57899126, test loss:0.59391963, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6864344389285714, test accuracy:0.681131019036954 train loss:0.58180496, test loss:0.59398752, test precision: 0.6028421839940165,test recall: 0.57001414427157,test f1: 0.5859687386404943\n",
      "train accuracy: 0.6886521517857142, test accuracy:0.6816909294512878 train loss:0.57968839, test loss:0.59403574, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6898163296428571, test accuracy:0.6822508398656215 train loss:0.57766805, test loss:0.59263617, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6901819392857143, test accuracy:0.681131019036954 train loss:0.57637529, test loss:0.59322321, test precision: 0.6133133881824981,test recall: 0.5686546463245492,test f1: 0.5901403382511695\n",
      "train accuracy: 0.6931404885714285, test accuracy:0.6822508398656215 train loss:0.5774042, test loss:0.59186774, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6912450928571429, test accuracy:0.6816909294512878 train loss:0.5779541, test loss:0.59175617, test precision: 0.600598354525056,test recall: 0.5711237553342816,test f1: 0.5854903390448415\n",
      "train accuracy: 0.6883033796428571, test accuracy:0.6808510638297872 train loss:0.57725324, test loss:0.59323221, test precision: 0.6133133881824981,test recall: 0.5682605682605683,test f1: 0.5899280575539568\n",
      "train accuracy: 0.6882817307142857, test accuracy:0.6819708846584547 train loss:0.58013577, test loss:0.59265822, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6868433457142856, test accuracy:0.6819708846584547 train loss:0.58333427, test loss:0.59251934, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6844476403571428, test accuracy:0.6819708846584547 train loss:0.57998989, test loss:0.59308839, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6868337246428571, test accuracy:0.6788913773796192 train loss:0.58023389, test loss:0.59352654, test precision: 0.6035901271503366,test recall: 0.5667134831460674,test f1: 0.5845708076783774\n",
      "train accuracy: 0.6889528174999999, test accuracy:0.6786114221724524 train loss:0.57598473, test loss:0.59363586, test precision: 0.6035901271503366,test recall: 0.5663157894736842,test f1: 0.5843591600289646\n",
      "train accuracy: 0.6837019892857142, test accuracy:0.6816909294512878 train loss:0.5828444, test loss:0.59340358, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6945572267857143, test accuracy:0.6822508398656215 train loss:0.57876922, test loss:0.59301239, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6867254857142857, test accuracy:0.6819708846584547 train loss:0.58140008, test loss:0.5923683, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6873292210714287, test accuracy:0.6822508398656215 train loss:0.57968936, test loss:0.59200066, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6873003585714287, test accuracy:0.6819708846584547 train loss:0.58036066, test loss:0.59169441, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6874085989285714, test accuracy:0.6816909294512878 train loss:0.57945721, test loss:0.59343624, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6904008235714285, test accuracy:0.6816909294512878 train loss:0.57869283, test loss:0.59279561, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6823429785714286, test accuracy:0.6816909294512878 train loss:0.58569995, test loss:0.59305334, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.7007966446428572, test accuracy:0.6819708846584547 train loss:0.56900992, test loss:0.59230965, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6823910867857144, test accuracy:0.6816909294512878 train loss:0.58135267, test loss:0.59298509, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6911633125, test accuracy:0.6816909294512878 train loss:0.57647154, test loss:0.59243429, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6862323921428571, test accuracy:0.6819708846584547 train loss:0.58062179, test loss:0.59140116, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6927147485714287, test accuracy:0.6822508398656215 train loss:0.5765578, test loss:0.5907163, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6870165285714285, test accuracy:0.6822508398656215 train loss:0.57914333, test loss:0.59112066, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6925968867857142, test accuracy:0.6816909294512878 train loss:0.57310636, test loss:0.59242326, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6870886896428571, test accuracy:0.6816909294512878 train loss:0.57945287, test loss:0.5923453, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6882119767857143, test accuracy:0.6816909294512878 train loss:0.57656982, test loss:0.59192294, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6847074175, test accuracy:0.6816909294512878 train loss:0.58059155, test loss:0.59201336, test precision: 0.6028421839940165,test recall: 0.5708215297450425,test f1: 0.5863950527464533\n",
      "train accuracy: 0.6883178103571429, test accuracy:0.6822508398656215 train loss:0.58047796, test loss:0.59118956, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6908963207142857, test accuracy:0.6822508398656215 train loss:0.57455139, test loss:0.59127742, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.683709205357143, test accuracy:0.6822508398656215 train loss:0.58214159, test loss:0.59079695, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6887796328571428, test accuracy:0.6819708846584547 train loss:0.57941849, test loss:0.59136826, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6845149885714285, test accuracy:0.6819708846584547 train loss:0.58197935, test loss:0.59154552, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6920364464285714, test accuracy:0.6819708846584547 train loss:0.57401974, test loss:0.59112555, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6904152557142857, test accuracy:0.6819708846584547 train loss:0.57636007, test loss:0.59155071, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6933834289285714, test accuracy:0.6819708846584547 train loss:0.57179664, test loss:0.59170163, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6909107524999999, test accuracy:0.6819708846584547 train loss:0.57505494, test loss:0.59176326, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6912835785714284, test accuracy:0.6786114221724524 train loss:0.5774982, test loss:0.5928455, test precision: 0.6035901271503366,test recall: 0.5663157894736842,test f1: 0.5843591600289646\n",
      "train accuracy: 0.6946582503571428, test accuracy:0.6819708846584547 train loss:0.57456558, test loss:0.59135401, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6877309110714285, test accuracy:0.6819708846584547 train loss:0.58037137, test loss:0.59039915, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6769983442857141, test accuracy:0.6819708846584547 train loss:0.58483829, test loss:0.59012216, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6927724749999999, test accuracy:0.6822508398656215 train loss:0.57321817, test loss:0.58902264, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6844596667857142, test accuracy:0.6822508398656215 train loss:0.57890189, test loss:0.58958173, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6812822314285715, test accuracy:0.6819708846584547 train loss:0.58198919, test loss:0.59126937, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6904922264285714, test accuracy:0.6819708846584547 train loss:0.57772179, test loss:0.59089273, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6962794414285715, test accuracy:0.6819708846584547 train loss:0.57412658, test loss:0.59126127, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6859245099999999, test accuracy:0.6819708846584547 train loss:0.57984329, test loss:0.59128201, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6857032210714286, test accuracy:0.6819708846584547 train loss:0.58022446, test loss:0.59092087, test precision: 0.6028421839940165,test recall: 0.5712260807937632,test f1: 0.586608442503639\n",
      "train accuracy: 0.6975542650000001, test accuracy:0.6886898096304591 train loss:0.57182668, test loss:0.59059227, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6878319357142858, test accuracy:0.6886898096304591 train loss:0.57755724, test loss:0.5906561, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6989036532142858, test accuracy:0.6886898096304591 train loss:0.57389397, test loss:0.58961266, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6970876310714286, test accuracy:0.6886898096304591 train loss:0.57273992, test loss:0.59086734, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6898331664285714, test accuracy:0.6886898096304591 train loss:0.57849074, test loss:0.58972448, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.7021003307142857, test accuracy:0.688969764837626 train loss:0.57020771, test loss:0.58891004, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.69247181, test accuracy:0.688969764837626 train loss:0.57718526, test loss:0.58854145, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.6909107521428572, test accuracy:0.688969764837626 train loss:0.57663744, test loss:0.5887804, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.6963636282142857, test accuracy:0.6886898096304591 train loss:0.57469648, test loss:0.58927786, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.69056198, test accuracy:0.688969764837626 train loss:0.57999284, test loss:0.58787143, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.6955337903571427, test accuracy:0.688969764837626 train loss:0.57211483, test loss:0.58893359, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.696305899642857, test accuracy:0.6886898096304591 train loss:0.57428593, test loss:0.58954757, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.690756812857143, test accuracy:0.688969764837626 train loss:0.58113984, test loss:0.58887899, test precision: 0.6020942408376964,test recall: 0.5816473988439307,test f1: 0.591694230062477\n",
      "train accuracy: 0.6951176689285715, test accuracy:0.6886898096304591 train loss:0.57486824, test loss:0.58949524, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6956300042857143, test accuracy:0.6886898096304591 train loss:0.57461037, test loss:0.58976847, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6913340917857143, test accuracy:0.6886898096304591 train loss:0.57933323, test loss:0.58955324, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6972776524999998, test accuracy:0.6886898096304591 train loss:0.57142283, test loss:0.58962369, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6940593250000001, test accuracy:0.687010078387458 train loss:0.578315, test loss:0.59121388, test precision: 0.6028421839940165,test recall: 0.5786073223259153,test f1: 0.5904761904761905\n",
      "train accuracy: 0.6923900285714285, test accuracy:0.6886898096304591 train loss:0.57812814, test loss:0.59064919, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6926882882142857, test accuracy:0.6886898096304591 train loss:0.57617521, test loss:0.59001178, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6899077303571428, test accuracy:0.6886898096304591 train loss:0.58068664, test loss:0.58903551, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6969745792857144, test accuracy:0.6886898096304591 train loss:0.57102118, test loss:0.58889008, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6874783514285714, test accuracy:0.6886898096304591 train loss:0.5759992, test loss:0.58910751, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6940905946428572, test accuracy:0.6886898096304591 train loss:0.57492707, test loss:0.5891003, test precision: 0.6020942408376964,test recall: 0.5812274368231047,test f1: 0.59147685525349\n",
      "train accuracy: 0.6954977103571428, test accuracy:0.6886898096304591 train loss:0.57195451, test loss:0.58946425, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6931501114285714, test accuracy:0.6886898096304591 train loss:0.57444119, test loss:0.58973664, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6975254014285713, test accuracy:0.687010078387458 train loss:0.57495976, test loss:0.58964962, test precision: 0.6028421839940165,test recall: 0.5786073223259153,test f1: 0.5904761904761905\n",
      "train accuracy: 0.6950142403571429, test accuracy:0.687010078387458 train loss:0.57490736, test loss:0.59030688, test precision: 0.6028421839940165,test recall: 0.5786073223259153,test f1: 0.5904761904761905\n",
      "train accuracy: 0.6945427964285714, test accuracy:0.687010078387458 train loss:0.5728683, test loss:0.58956695, test precision: 0.6028421839940165,test recall: 0.5786073223259153,test f1: 0.5904761904761905\n",
      "train accuracy: 0.6905138739285714, test accuracy:0.687010078387458 train loss:0.57784174, test loss:0.59023631, test precision: 0.6028421839940165,test recall: 0.5786073223259153,test f1: 0.5904761904761905\n",
      "train accuracy: 0.6895661750000001, test accuracy:0.6886898096304591 train loss:0.58115606, test loss:0.590011, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6984442342857144, test accuracy:0.688969764837626 train loss:0.57194915, test loss:0.5878197, test precision: 0.6028421839940165,test recall: 0.5815295815295816,test f1: 0.5919941241278003\n",
      "train accuracy: 0.6900953471428571, test accuracy:0.6886898096304591 train loss:0.57667361, test loss:0.58834952, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6898043021428572, test accuracy:0.6886898096304591 train loss:0.57685461, test loss:0.58847076, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6860856692857144, test accuracy:0.6886898096304591 train loss:0.58513985, test loss:0.58925349, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.7036421460714287, test accuracy:0.6886898096304591 train loss:0.56955332, test loss:0.58846354, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6908337832142858, test accuracy:0.6886898096304591 train loss:0.58135224, test loss:0.58907664, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6941146475000001, test accuracy:0.6884098544232923 train loss:0.57586074, test loss:0.58980483, test precision: 0.6028421839940165,test recall: 0.5806916426512968,test f1: 0.5915596330275229\n",
      "train accuracy: 0.7012320089285715, test accuracy:0.6886898096304591 train loss:0.56725802, test loss:0.58900678, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6891765139285715, test accuracy:0.6886898096304591 train loss:0.57556638, test loss:0.58745515, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6937273889285714, test accuracy:0.6886898096304591 train loss:0.57339533, test loss:0.58877933, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6932511339285714, test accuracy:0.6886898096304591 train loss:0.57653607, test loss:0.58901072, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6962024717857143, test accuracy:0.6886898096304591 train loss:0.5707337, test loss:0.58908153, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6970852260714286, test accuracy:0.6886898096304591 train loss:0.57372897, test loss:0.58874404, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6948891628571429, test accuracy:0.6886898096304591 train loss:0.57205901, test loss:0.58853918, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6963058992857142, test accuracy:0.6886898096304591 train loss:0.57368399, test loss:0.58882868, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6931044096428572, test accuracy:0.6886898096304591 train loss:0.57607109, test loss:0.58941686, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6958416714285715, test accuracy:0.6886898096304591 train loss:0.57075297, test loss:0.58840519, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.7008447517857144, test accuracy:0.6886898096304591 train loss:0.56812028, test loss:0.5881806, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.69061971, test accuracy:0.6886898096304591 train loss:0.57753581, test loss:0.58883649, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6934700192857142, test accuracy:0.6884098544232923 train loss:0.57658816, test loss:0.58996475, test precision: 0.6028421839940165,test recall: 0.5806916426512968,test f1: 0.5915596330275229\n",
      "train accuracy: 0.6971453589285714, test accuracy:0.6886898096304591 train loss:0.57180453, test loss:0.58838999, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6923515428571428, test accuracy:0.6886898096304591 train loss:0.57612809, test loss:0.58777171, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6886786096428571, test accuracy:0.6892497200447928 train loss:0.57749495, test loss:0.58719623, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6901314282142856, test accuracy:0.6912094064949608 train loss:0.57596215, test loss:0.58720416, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6948939725, test accuracy:0.6886898096304591 train loss:0.5709462, test loss:0.58797574, test precision: 0.6028421839940165,test recall: 0.5811103100216294,test f1: 0.5917767988252569\n",
      "train accuracy: 0.6931861910714285, test accuracy:0.6892497200447928 train loss:0.57687913, test loss:0.58767295, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6944586096428572, test accuracy:0.6892497200447928 train loss:0.57582567, test loss:0.58754414, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6874807575, test accuracy:0.6912094064949608 train loss:0.58037443, test loss:0.58757305, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6980064664285714, test accuracy:0.6912094064949608 train loss:0.56943667, test loss:0.58598316, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6893761546428571, test accuracy:0.6912094064949608 train loss:0.57743481, test loss:0.58653885, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6928855253571429, test accuracy:0.6912094064949608 train loss:0.57619925, test loss:0.58722496, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6996925989285714, test accuracy:0.6912094064949608 train loss:0.56983712, test loss:0.58712006, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6938813325000001, test accuracy:0.6912094064949608 train loss:0.57521714, test loss:0.58651638, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6930130071428572, test accuracy:0.6912094064949608 train loss:0.57223985, test loss:0.58595055, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6964381932142858, test accuracy:0.6912094064949608 train loss:0.57469076, test loss:0.58613038, test precision: 0.5923709798055348,test recall: 0.5866666666666667,test f1: 0.5895050241905471\n",
      "train accuracy: 0.6950815878571429, test accuracy:0.6948488241881299 train loss:0.57419907, test loss:0.58707672, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6992307767857142, test accuracy:0.6948488241881299 train loss:0.56893677, test loss:0.58680034, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6996853828571429, test accuracy:0.6914893617021277 train loss:0.56927354, test loss:0.58616906, test precision: 0.5931189229618549,test recall: 0.5869726128793487,test f1: 0.590029761904762\n",
      "train accuracy: 0.6972968932142857, test accuracy:0.6948488241881299 train loss:0.5686178, test loss:0.5869894, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6865907864285713, test accuracy:0.6948488241881299 train loss:0.57944706, test loss:0.58702892, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6946173603571429, test accuracy:0.6914893617021277 train loss:0.57443935, test loss:0.58662426, test precision: 0.5931189229618549,test recall: 0.5869726128793487,test f1: 0.590029761904762\n",
      "train accuracy: 0.6949517003571428, test accuracy:0.6914893617021277 train loss:0.57555029, test loss:0.58568954, test precision: 0.5931189229618549,test recall: 0.5869726128793487,test f1: 0.590029761904762\n",
      "train accuracy: 0.6890201664285714, test accuracy:0.6914893617021277 train loss:0.58040272, test loss:0.58578467, test precision: 0.5931189229618549,test recall: 0.5869726128793487,test f1: 0.590029761904762\n",
      "train accuracy: 0.7021436271428572, test accuracy:0.6942889137737962 train loss:0.56892143, test loss:0.58748937, test precision: 0.6095736724008975,test recall: 0.5884476534296029,test f1: 0.5988243938280675\n",
      "train accuracy: 0.6977972021428572, test accuracy:0.6917693169092946 train loss:0.57079373, test loss:0.58931255, test precision: 0.6222887060583395,test recall: 0.5826330532212886,test f1: 0.6018083182640144\n",
      "train accuracy: 0.6969577425000001, test accuracy:0.6923292273236282 train loss:0.56895288, test loss:0.58939165, test precision: 0.612565445026178,test recall: 0.585,test f1: 0.5984654731457799\n",
      "train accuracy: 0.7018453671428572, test accuracy:0.6940089585666294 train loss:0.57087985, test loss:0.58781314, test precision: 0.6110695587135377,test recall: 0.5877697841726619,test f1: 0.5991932526585992\n",
      "train accuracy: 0.6940737575, test accuracy:0.6973684210526315 train loss:0.57399232, test loss:0.58606672, test precision: 0.605833956619297,test recall: 0.593841642228739,test f1: 0.5997778600518325\n",
      "train accuracy: 0.7002025271428572, test accuracy:0.6970884658454647 train loss:0.56957642, test loss:0.58634084, test precision: 0.606581899775617,test recall: 0.5932699341623994,test f1: 0.5998520710059171\n",
      "train accuracy: 0.6848421139285714, test accuracy:0.6942889137737962 train loss:0.58158746, test loss:0.58664453, test precision: 0.6095736724008975,test recall: 0.5884476534296029,test f1: 0.5988243938280675\n",
      "train accuracy: 0.6994400399999999, test accuracy:0.6942889137737962 train loss:0.56869423, test loss:0.58699644, test precision: 0.6095736724008975,test recall: 0.5884476534296029,test f1: 0.5988243938280675\n",
      "train accuracy: 0.6997719732142856, test accuracy:0.6923292273236282 train loss:0.57190066, test loss:0.5870676, test precision: 0.6103216155572176,test recall: 0.5853658536585366,test f1: 0.59758330281948\n",
      "train accuracy: 0.70135468, test accuracy:0.6926091825307951 train loss:0.57074032, test loss:0.58646655, test precision: 0.6095736724008975,test recall: 0.5859094176851186,test f1: 0.597507331378299\n",
      "train accuracy: 0.6999235110714286, test accuracy:0.6973684210526315 train loss:0.57059138, test loss:0.58534545, test precision: 0.605833956619297,test recall: 0.593841642228739,test f1: 0.5997778600518325\n",
      "train accuracy: 0.6997912164285714, test accuracy:0.6973684210526315 train loss:0.56827069, test loss:0.58562291, test precision: 0.605833956619297,test recall: 0.593841642228739,test f1: 0.5997778600518325\n",
      "train accuracy: 0.6959883978571428, test accuracy:0.6954087346024636 train loss:0.57249632, test loss:0.58632201, test precision: 0.606581899775617,test recall: 0.5906773488710853,test f1: 0.5985239852398525\n",
      "train accuracy: 0.6988098428571429, test accuracy:0.6926091825307951 train loss:0.57348226, test loss:0.58711696, test precision: 0.6118175018698578,test recall: 0.5855404438081604,test f1: 0.5983906364301389\n",
      "train accuracy: 0.6979800075, test accuracy:0.6956886898096305 train loss:0.57023302, test loss:0.58645272, test precision: 0.6080777860882572,test recall: 0.590843023255814,test f1: 0.5993365278289717\n",
      "train accuracy: 0.6955313857142856, test accuracy:0.6951287793952967 train loss:0.57314495, test loss:0.58698142, test precision: 0.6095736724008975,test recall: 0.58972503617945,test f1: 0.5994851048179478\n",
      "train accuracy: 0.6986919835714286, test accuracy:0.6948488241881299 train loss:0.57125202, test loss:0.58639073, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6953245264285713, test accuracy:0.6951287793952967 train loss:0.57450645, test loss:0.5861606, test precision: 0.6073298429319371,test recall: 0.5901162790697675,test f1: 0.598599336527829\n",
      "train accuracy: 0.6921422792857143, test accuracy:0.6951287793952967 train loss:0.57240282, test loss:0.58623093, test precision: 0.6073298429319371,test recall: 0.5901162790697675,test f1: 0.598599336527829\n",
      "train accuracy: 0.6961279064285714, test accuracy:0.6954087346024636 train loss:0.57262321, test loss:0.58643919, test precision: 0.6088257292445775,test recall: 0.5902828136330674,test f1: 0.5994108983799705\n",
      "train accuracy: 0.7022133807142856, test accuracy:0.6951287793952967 train loss:0.56872992, test loss:0.58602065, test precision: 0.6073298429319371,test recall: 0.5901162790697675,test f1: 0.598599336527829\n",
      "train accuracy: 0.6975783167857144, test accuracy:0.6951287793952967 train loss:0.57436641, test loss:0.58568871, test precision: 0.6073298429319371,test recall: 0.5901162790697675,test f1: 0.598599336527829\n",
      "train accuracy: 0.7016072382142857, test accuracy:0.6959686450167973 train loss:0.56957106, test loss:0.58529961, test precision: 0.605833956619297,test recall: 0.591672753834916,test f1: 0.5986696230598669\n",
      "train accuracy: 0.6976095867857143, test accuracy:0.6979283314669653 train loss:0.56796121, test loss:0.58511955, test precision: 0.6050860134629769,test recall: 0.5948529411764706,test f1: 0.599925843529848\n",
      "train accuracy: 0.6940088132142856, test accuracy:0.6959686450167973 train loss:0.57466703, test loss:0.58613658, test precision: 0.6080777860882572,test recall: 0.5912727272727273,test f1: 0.5995575221238938\n",
      "train accuracy: 0.7051791475, test accuracy:0.6959686450167973 train loss:0.5682325, test loss:0.58562738, test precision: 0.605833956619297,test recall: 0.591672753834916,test f1: 0.5986696230598669\n",
      "train accuracy: 0.6960870153571427, test accuracy:0.6979283314669653 train loss:0.57476188, test loss:0.58524299, test precision: 0.6050860134629769,test recall: 0.5948529411764706,test f1: 0.599925843529848\n",
      "train accuracy: 0.6957021621428572, test accuracy:0.6948488241881299 train loss:0.5697991, test loss:0.58616847, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.6973642425000001, test accuracy:0.694568868980963 train loss:0.56916, test loss:0.58676606, test precision: 0.6110695587135377,test recall: 0.5886167146974063,test f1: 0.5996330275229358\n",
      "train accuracy: 0.6993221800000001, test accuracy:0.694568868980963 train loss:0.57110412, test loss:0.5867188, test precision: 0.6110695587135377,test recall: 0.5886167146974063,test f1: 0.5996330275229358\n",
      "train accuracy: 0.6979270900000001, test accuracy:0.6959686450167973 train loss:0.57142402, test loss:0.58571267, test precision: 0.6073298429319371,test recall: 0.5914056809905317,test f1: 0.5992619926199262\n",
      "train accuracy: 0.6925896714285714, test accuracy:0.694568868980963 train loss:0.57468981, test loss:0.58627284, test precision: 0.6110695587135377,test recall: 0.5886167146974063,test f1: 0.5996330275229358\n",
      "train accuracy: 0.6915553803571429, test accuracy:0.6954087346024636 train loss:0.57751029, test loss:0.58671319, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.7026054492857144, test accuracy:0.6959686450167973 train loss:0.56793309, test loss:0.5851562, test precision: 0.6080777860882572,test recall: 0.5912727272727273,test f1: 0.5995575221238938\n",
      "train accuracy: 0.6996517092857143, test accuracy:0.6956886898096305 train loss:0.56708228, test loss:0.58580792, test precision: 0.6080777860882572,test recall: 0.590843023255814,test f1: 0.5993365278289717\n",
      "train accuracy: 0.7029157360714285, test accuracy:0.6959686450167973 train loss:0.56974182, test loss:0.58567125, test precision: 0.6080777860882572,test recall: 0.5912727272727273,test f1: 0.5995575221238938\n",
      "train accuracy: 0.6916299453571428, test accuracy:0.6956886898096305 train loss:0.57390155, test loss:0.58648288, test precision: 0.6080777860882572,test recall: 0.590843023255814,test f1: 0.5993365278289717\n",
      "train accuracy: 0.7003660903571428, test accuracy:0.6954087346024636 train loss:0.56882553, test loss:0.58691281, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.691235470357143, test accuracy:0.6956886898096305 train loss:0.57730575, test loss:0.58612972, test precision: 0.6080777860882572,test recall: 0.590843023255814,test f1: 0.5993365278289717\n",
      "train accuracy: 0.7022085710714284, test accuracy:0.6956886898096305 train loss:0.56674271, test loss:0.58539337, test precision: 0.6080777860882572,test recall: 0.590843023255814,test f1: 0.5993365278289717\n",
      "train accuracy: 0.695120075, test accuracy:0.6973684210526315 train loss:0.57433715, test loss:0.58488375, test precision: 0.6073298429319371,test recall: 0.5935672514619883,test f1: 0.6003696857670979\n",
      "train accuracy: 0.6979246842857142, test accuracy:0.6982082866741322 train loss:0.57316185, test loss:0.58569336, test precision: 0.606581899775617,test recall: 0.59501100513573,test f1: 0.6007407407407408\n",
      "train accuracy: 0.6980882467857142, test accuracy:0.6982082866741322 train loss:0.572492, test loss:0.58572108, test precision: 0.606581899775617,test recall: 0.59501100513573,test f1: 0.6007407407407408\n",
      "train accuracy: 0.7026607721428572, test accuracy:0.6951287793952967 train loss:0.56835072, test loss:0.58657557, test precision: 0.6095736724008975,test recall: 0.58972503617945,test f1: 0.5994851048179478\n",
      "train accuracy: 0.6934074821428572, test accuracy:0.6982082866741322 train loss:0.57529637, test loss:0.58569521, test precision: 0.606581899775617,test recall: 0.59501100513573,test f1: 0.6007407407407408\n",
      "train accuracy: 0.6985524742857142, test accuracy:0.6956886898096305 train loss:0.57384972, test loss:0.58576292, test precision: 0.6095736724008975,test recall: 0.5905797101449275,test f1: 0.5999263894000736\n",
      "train accuracy: 0.6996517078571428, test accuracy:0.698488241881299 train loss:0.56956187, test loss:0.58532375, test precision: 0.606581899775617,test recall: 0.5954478707782672,test f1: 0.6009633197480548\n",
      "train accuracy: 0.6949925910714286, test accuracy:0.6982082866741322 train loss:0.57408713, test loss:0.58455652, test precision: 0.6050860134629769,test recall: 0.5952906548933039,test f1: 0.6001483679525222\n",
      "train accuracy: 0.6949517, test accuracy:0.698488241881299 train loss:0.5727078, test loss:0.58412361, test precision: 0.6043380703066566,test recall: 0.5958702064896755,test f1: 0.6000742666171557\n",
      "train accuracy: 0.6987665482142857, test accuracy:0.698488241881299 train loss:0.57378837, test loss:0.5839023, test precision: 0.6043380703066566,test recall: 0.5958702064896755,test f1: 0.6000742666171557\n",
      "train accuracy: 0.6902973946428571, test accuracy:0.698488241881299 train loss:0.57446857, test loss:0.58514994, test precision: 0.6073298429319371,test recall: 0.5953079178885631,test f1: 0.601258793039615\n",
      "train accuracy: 0.6956516507142857, test accuracy:0.6954087346024636 train loss:0.57326968, test loss:0.58647555, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.7075965010714285, test accuracy:0.6962486002239642 train loss:0.56946719, test loss:0.58618397, test precision: 0.6200448765893792,test recall: 0.5896159317211949,test f1: 0.6044476850164054\n",
      "train accuracy: 0.7004887621428572, test accuracy:0.6954087346024636 train loss:0.5703383, test loss:0.58637971, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.7015567267857142, test accuracy:0.6954087346024636 train loss:0.56948375, test loss:0.58580148, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.702040197142857, test accuracy:0.6956886898096305 train loss:0.56933388, test loss:0.58549184, test precision: 0.6088257292445775,test recall: 0.590711175616836,test f1: 0.5996316758747697\n",
      "train accuracy: 0.6965344042857142, test accuracy:0.6973684210526315 train loss:0.57065775, test loss:0.58485681, test precision: 0.6088257292445775,test recall: 0.5932944606413995,test f1: 0.6009597637504615\n",
      "train accuracy: 0.7033943953571428, test accuracy:0.7001679731243001 train loss:0.56657089, test loss:0.58432585, test precision: 0.606581899775617,test recall: 0.5980825958702065,test f1: 0.6023022651318232\n",
      "train accuracy: 0.7073728057142856, test accuracy:0.7001679731243001 train loss:0.56275171, test loss:0.58382064, test precision: 0.606581899775617,test recall: 0.5980825958702065,test f1: 0.6023022651318232\n",
      "train accuracy: 0.7005970028571429, test accuracy:0.6976483762597985 train loss:0.57165399, test loss:0.58467865, test precision: 0.6088257292445775,test recall: 0.5937272064186725,test f1: 0.601181683899557\n",
      "train accuracy: 0.696976985, test accuracy:0.696528555431131 train loss:0.57199283, test loss:0.58558404, test precision: 0.6103216155572176,test recall: 0.5917331399564902,test f1: 0.6008836524300442\n",
      "train accuracy: 0.6955843014285714, test accuracy:0.6956886898096305 train loss:0.57217123, test loss:0.58513987, test precision: 0.6095736724008975,test recall: 0.5905797101449275,test f1: 0.5999263894000736\n",
      "train accuracy: 0.7051502842857144, test accuracy:0.6956886898096305 train loss:0.56688438, test loss:0.58540714, test precision: 0.6095736724008975,test recall: 0.5905797101449275,test f1: 0.5999263894000736\n",
      "train accuracy: 0.6987449010714286, test accuracy:0.6954087346024636 train loss:0.56838289, test loss:0.58591467, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.6938957621428571, test accuracy:0.6951287793952967 train loss:0.57543783, test loss:0.58625829, test precision: 0.6095736724008975,test recall: 0.58972503617945,test f1: 0.5994851048179478\n",
      "train accuracy: 0.6994857410714286, test accuracy:0.6954087346024636 train loss:0.57006809, test loss:0.58538789, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.7009553957142857, test accuracy:0.6954087346024636 train loss:0.5700396, test loss:0.58549905, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.6992764771428572, test accuracy:0.6954087346024636 train loss:0.56902584, test loss:0.58517087, test precision: 0.6095736724008975,test recall: 0.5901520637219406,test f1: 0.5997056659308315\n",
      "train accuracy: 0.7037744382142855, test accuracy:0.6948488241881299 train loss:0.57010974, test loss:0.58497953, test precision: 0.6110695587135377,test recall: 0.589041095890411,test f1: 0.5998531571218795\n",
      "train accuracy: 0.7051334478571428, test accuracy:0.6982082866741322 train loss:0.56736132, test loss:0.5839445, test precision: 0.6080777860882572,test recall: 0.5947329919531822,test f1: 0.6013313609467456\n",
      "train accuracy: 0.6993582578571428, test accuracy:0.6982082866741322 train loss:0.5645419, test loss:0.58366495, test precision: 0.6073298429319371,test recall: 0.5948717948717949,test f1: 0.6010362694300517\n",
      "train accuracy: 0.6991441846428572, test accuracy:0.6982082866741322 train loss:0.56875676, test loss:0.5838967, test precision: 0.6080777860882572,test recall: 0.5947329919531822,test f1: 0.6013313609467456\n",
      "train accuracy: 0.6988555457142859, test accuracy:0.7035274356103024 train loss:0.56585261, test loss:0.58207673, test precision: 0.5983545250560958,test recall: 0.6051437216338881,test f1: 0.6017299736743137\n",
      "train accuracy: 0.7009241246428571, test accuracy:0.6982082866741322 train loss:0.5710853, test loss:0.58438849, test precision: 0.6080777860882572,test recall: 0.5947329919531822,test f1: 0.6013313609467456\n",
      "train accuracy: 0.6974772939285715, test accuracy:0.6959686450167973 train loss:0.56947285, test loss:0.58586222, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.7058213717857144, test accuracy:0.6993281075027995 train loss:0.5668027, test loss:0.58429825, test precision: 0.6080777860882572,test recall: 0.5964783565663977,test f1: 0.6022222222222222\n",
      "train accuracy: 0.6991971014285714, test accuracy:0.6959686450167973 train loss:0.57234491, test loss:0.58547443, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.6987545199999999, test accuracy:0.6973684210526315 train loss:0.57112834, test loss:0.58522028, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.7057756689285714, test accuracy:0.6973684210526315 train loss:0.56547594, test loss:0.58509636, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.7071803796428571, test accuracy:0.6979283314669653 train loss:0.56514507, test loss:0.58443087, test precision: 0.6200448765893792,test recall: 0.5921428571428572,test f1: 0.6057727438801608\n",
      "train accuracy: 0.705479814642857, test accuracy:0.6996080627099664 train loss:0.56479487, test loss:0.58311653, test precision: 0.6073298429319371,test recall: 0.5970588235294118,test f1: 0.6021505376344085\n",
      "train accuracy: 0.7004550871428571, test accuracy:0.7012877939529675 train loss:0.57333763, test loss:0.58257675, test precision: 0.6073298429319371,test recall: 0.5997045790251108,test f1: 0.6034931252322556\n",
      "train accuracy: 0.6935662325, test accuracy:0.7001679731243001 train loss:0.57633967, test loss:0.58407336, test precision: 0.6185489902767389,test recall: 0.595821325648415,test f1: 0.6069724770642202\n",
      "train accuracy: 0.7017106692857144, test accuracy:0.700447928331467 train loss:0.56699835, test loss:0.58332783, test precision: 0.6178010471204188,test recall: 0.5963898916967509,test f1: 0.6069066862601029\n",
      "train accuracy: 0.696895205, test accuracy:0.7012877939529675 train loss:0.57265431, test loss:0.5826304, test precision: 0.6073298429319371,test recall: 0.5997045790251108,test f1: 0.6034931252322556\n",
      "train accuracy: 0.7027762271428571, test accuracy:0.7021276595744681 train loss:0.56901532, test loss:0.5830518, test precision: 0.6178010471204188,test recall: 0.5989847715736041,test f1: 0.6082474226804123\n",
      "train accuracy: 0.7019223360714285, test accuracy:0.6976483762597985 train loss:0.56774428, test loss:0.58437276, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.6911825539285715, test accuracy:0.6973684210526315 train loss:0.57917137, test loss:0.58512336, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.7019680392857144, test accuracy:0.6973684210526315 train loss:0.57103573, test loss:0.58507317, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.6999908596428571, test accuracy:0.6959686450167973 train loss:0.56906485, test loss:0.58530354, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.6987352800000001, test accuracy:0.6959686450167973 train loss:0.57061199, test loss:0.5855794, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.7047630275000001, test accuracy:0.6959686450167973 train loss:0.56519132, test loss:0.5854491, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.6928686889285712, test accuracy:0.6959686450167973 train loss:0.57388195, test loss:0.58526403, test precision: 0.6200448765893792,test recall: 0.5891968727789624,test f1: 0.6042274052478135\n",
      "train accuracy: 0.7073150778571428, test accuracy:0.6973684210526315 train loss:0.5632189, test loss:0.58518147, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.7011382003571428, test accuracy:0.6976483762597985 train loss:0.57013423, test loss:0.58439195, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7075724482142858, test accuracy:0.6976483762597985 train loss:0.56103216, test loss:0.58454746, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7034809878571429, test accuracy:0.6976483762597985 train loss:0.56606637, test loss:0.58407843, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7022013553571428, test accuracy:0.6993281075027995 train loss:0.5711028, test loss:0.58406818, test precision: 0.6200448765893792,test recall: 0.5942652329749104,test f1: 0.6068814055636896\n",
      "train accuracy: 0.7033799635714286, test accuracy:0.6996080627099664 train loss:0.56662201, test loss:0.58296418, test precision: 0.6200448765893792,test recall: 0.5946915351506457,test f1: 0.6071036250457708\n",
      "train accuracy: 0.6992740728571428, test accuracy:0.6993281075027995 train loss:0.56983992, test loss:0.584252, test precision: 0.6200448765893792,test recall: 0.5942652329749104,test f1: 0.6068814055636896\n",
      "train accuracy: 0.7006378925, test accuracy:0.6993281075027995 train loss:0.5712245, test loss:0.58341503, test precision: 0.6200448765893792,test recall: 0.5942652329749104,test f1: 0.6068814055636896\n",
      "train accuracy: 0.7065670221428573, test accuracy:0.6976483762597985 train loss:0.56425467, test loss:0.58346522, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.6990142975, test accuracy:0.6976483762597985 train loss:0.57033142, test loss:0.58374834, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7073415375, test accuracy:0.6976483762597985 train loss:0.56113073, test loss:0.58449972, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.6951248846428572, test accuracy:0.6976483762597985 train loss:0.57469203, test loss:0.58371371, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7051719321428572, test accuracy:0.6976483762597985 train loss:0.56682037, test loss:0.58303106, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7033053992857142, test accuracy:0.7001679731243001 train loss:0.56809509, test loss:0.58311707, test precision: 0.6185489902767389,test recall: 0.595821325648415,test f1: 0.6069724770642202\n",
      "train accuracy: 0.7080871878571429, test accuracy:0.6976483762597985 train loss:0.56334255, test loss:0.5842765, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7001688528571428, test accuracy:0.6976483762597985 train loss:0.56918279, test loss:0.58489966, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7039620525, test accuracy:0.6973684210526315 train loss:0.56430795, test loss:0.58525592, test precision: 0.6200448765893792,test recall: 0.5912981455064193,test f1: 0.6053304125593282\n",
      "train accuracy: 0.7073920478571428, test accuracy:0.7001679731243001 train loss:0.56451175, test loss:0.58347046, test precision: 0.6185489902767389,test recall: 0.595821325648415,test f1: 0.6069724770642202\n",
      "train accuracy: 0.698995055, test accuracy:0.6976483762597985 train loss:0.5706688, test loss:0.5843026, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7033968021428573, test accuracy:0.6998880179171333 train loss:0.56595298, test loss:0.58416522, test precision: 0.6110695587135377,test recall: 0.5967859751643535,test f1: 0.6038433111603844\n",
      "train accuracy: 0.6998417296428572, test accuracy:0.6976483762597985 train loss:0.57231589, test loss:0.5840528, test precision: 0.6200448765893792,test recall: 0.5917201998572448,test f1: 0.6055514974433894\n",
      "train accuracy: 0.7087967585714285, test accuracy:0.7001679731243001 train loss:0.56393919, test loss:0.58316475, test precision: 0.6185489902767389,test recall: 0.595821325648415,test f1: 0.6069724770642202\n",
      "train accuracy: 0.7030696775, test accuracy:0.7040873460246361 train loss:0.56690612, test loss:0.58290976, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7056722414285714, test accuracy:0.6973684210526315 train loss:0.56574641, test loss:0.58460855, test precision: 0.6207928197456993,test recall: 0.5911680911680912,test f1: 0.6056183874498359\n",
      "train accuracy: 0.7025044260714287, test accuracy:0.6973684210526315 train loss:0.56580537, test loss:0.5851438, test precision: 0.6207928197456993,test recall: 0.5911680911680912,test f1: 0.6056183874498359\n",
      "train accuracy: 0.6970900357142858, test accuracy:0.6973684210526315 train loss:0.57009312, test loss:0.58469576, test precision: 0.6207928197456993,test recall: 0.5911680911680912,test f1: 0.6056183874498359\n",
      "train accuracy: 0.7053571417857143, test accuracy:0.7049272116461366 train loss:0.56884897, test loss:0.58199763, test precision: 0.6095736724008975,test recall: 0.6050482553823311,test f1: 0.6073025335320418\n",
      "train accuracy: 0.7054750046428573, test accuracy:0.7021276595744681 train loss:0.56677813, test loss:0.58333129, test precision: 0.6118175018698578,test recall: 0.6001467351430667,test f1: 0.605925925925926\n",
      "train accuracy: 0.7033414792857143, test accuracy:0.6996080627099664 train loss:0.56996853, test loss:0.58456278, test precision: 0.6118175018698578,test recall: 0.5962099125364432,test f1: 0.6039128829826503\n",
      "train accuracy: 0.7117505003571428, test accuracy:0.7024076147816349 train loss:0.56288421, test loss:0.58264697, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7091359099999999, test accuracy:0.7049272116461366 train loss:0.56285987, test loss:0.5812574, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7078201978571429, test accuracy:0.7040873460246361 train loss:0.56579049, test loss:0.58230489, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7045417374999999, test accuracy:0.7040873460246361 train loss:0.56639568, test loss:0.5827238, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7046427610714286, test accuracy:0.7043673012318029 train loss:0.56747355, test loss:0.58305299, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7056433767857142, test accuracy:0.7049272116461366 train loss:0.56786807, test loss:0.58264899, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7008904517857142, test accuracy:0.7049272116461366 train loss:0.57172386, test loss:0.58207601, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7021243828571428, test accuracy:0.7024076147816349 train loss:0.56919997, test loss:0.58246827, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.6992115346428572, test accuracy:0.7024076147816349 train loss:0.57150574, test loss:0.58341384, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7033631271428572, test accuracy:0.6998880179171333 train loss:0.5646052, test loss:0.58480209, test precision: 0.6192969334330591,test recall: 0.595255212077642,test f1: 0.6070381231671554\n",
      "train accuracy: 0.7031538646428572, test accuracy:0.7049272116461366 train loss:0.57133915, test loss:0.58278787, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.705944042857143, test accuracy:0.7049272116461366 train loss:0.5647042, test loss:0.5826968, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7011189575, test accuracy:0.7049272116461366 train loss:0.5704725, test loss:0.58310682, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7049362107142857, test accuracy:0.7024076147816349 train loss:0.56899688, test loss:0.58371526, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7046259239285714, test accuracy:0.7024076147816349 train loss:0.56673281, test loss:0.58314073, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7026872292857143, test accuracy:0.7024076147816349 train loss:0.56615735, test loss:0.58232284, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7020498192857143, test accuracy:0.7024076147816349 train loss:0.56635302, test loss:0.58321369, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.700358875, test accuracy:0.7032474804031354 train loss:0.56713514, test loss:0.58252442, test precision: 0.6095736724008975,test recall: 0.6023651145602366,test f1: 0.6059479553903346\n",
      "train accuracy: 0.7063288942857142, test accuracy:0.7032474804031354 train loss:0.56261057, test loss:0.58288515, test precision: 0.6095736724008975,test recall: 0.6023651145602366,test f1: 0.6059479553903346\n",
      "train accuracy: 0.7121738371428571, test accuracy:0.7032474804031354 train loss:0.55877644, test loss:0.58260983, test precision: 0.6095736724008975,test recall: 0.6023651145602366,test f1: 0.6059479553903346\n",
      "train accuracy: 0.6982975107142858, test accuracy:0.7024076147816349 train loss:0.56950503, test loss:0.5830453, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.6982951046428572, test accuracy:0.7057670772676372 train loss:0.57012705, test loss:0.5815143, test precision: 0.6095736724008975,test recall: 0.6063988095238095,test f1: 0.607982096232749\n",
      "train accuracy: 0.7090348864285714, test accuracy:0.7049272116461366 train loss:0.56231029, test loss:0.58255166, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7025934228571428, test accuracy:0.7049272116461366 train loss:0.56949654, test loss:0.58219892, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7031658892857143, test accuracy:0.7046472564389697 train loss:0.56614999, test loss:0.58235836, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7002362028571429, test accuracy:0.7043673012318029 train loss:0.56978929, test loss:0.58372921, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7005440842857144, test accuracy:0.7043673012318029 train loss:0.57050895, test loss:0.58342516, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7091407214285714, test accuracy:0.7043673012318029 train loss:0.56654962, test loss:0.58332157, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7062952192857141, test accuracy:0.7046472564389697 train loss:0.56571775, test loss:0.58333743, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7020233600000001, test accuracy:0.7046472564389697 train loss:0.57048396, test loss:0.58287245, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.6979006314285715, test accuracy:0.7046472564389697 train loss:0.57155718, test loss:0.58329314, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.6986414721428572, test accuracy:0.7046472564389697 train loss:0.57348299, test loss:0.5827052, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7097059732142857, test accuracy:0.7057670772676372 train loss:0.56441003, test loss:0.58147496, test precision: 0.6095736724008975,test recall: 0.6063988095238095,test f1: 0.607982096232749\n",
      "train accuracy: 0.69766972, test accuracy:0.706047032474804 train loss:0.5749864, test loss:0.58104402, test precision: 0.6073298429319371,test recall: 0.6073298429319371,test f1: 0.6073298429319371\n",
      "train accuracy: 0.7059993635714285, test accuracy:0.7057670772676372 train loss:0.56648655, test loss:0.5821389, test precision: 0.6095736724008975,test recall: 0.6063988095238095,test f1: 0.607982096232749\n",
      "train accuracy: 0.7042338564285716, test accuracy:0.7057670772676372 train loss:0.56782211, test loss:0.58126426, test precision: 0.6095736724008975,test recall: 0.6063988095238095,test f1: 0.607982096232749\n",
      "train accuracy: 0.7102904667857143, test accuracy:0.7046472564389697 train loss:0.56433333, test loss:0.58217245, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7009698275, test accuracy:0.7043673012318029 train loss:0.56986791, test loss:0.58273602, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7005994078571428, test accuracy:0.7046472564389697 train loss:0.5690384, test loss:0.58229709, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7070528982142857, test accuracy:0.7026875699888018 train loss:0.56257847, test loss:0.58318138, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7047822692857144, test accuracy:0.7043673012318029 train loss:0.56586986, test loss:0.58247691, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7030095442857143, test accuracy:0.7046472564389697 train loss:0.56641842, test loss:0.58255535, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7040414285714286, test accuracy:0.7046472564389697 train loss:0.5673245, test loss:0.58182657, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7075171260714285, test accuracy:0.7026875699888018 train loss:0.56644865, test loss:0.58330202, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7021243839285713, test accuracy:0.7043673012318029 train loss:0.57132638, test loss:0.58252156, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7017226942857143, test accuracy:0.7043673012318029 train loss:0.56469903, test loss:0.58074361, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7036108757142856, test accuracy:0.7043673012318029 train loss:0.56560194, test loss:0.58173418, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7053114414285714, test accuracy:0.7026875699888018 train loss:0.56602719, test loss:0.58197439, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.6987713589285713, test accuracy:0.7043673012318029 train loss:0.5646473, test loss:0.58246762, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7025260735714286, test accuracy:0.7043673012318029 train loss:0.56832241, test loss:0.58228928, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7088785410714287, test accuracy:0.7043673012318029 train loss:0.56070942, test loss:0.58110029, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7020041185714286, test accuracy:0.7026875699888018 train loss:0.56600535, test loss:0.58186543, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7035868214285713, test accuracy:0.7026875699888018 train loss:0.56612241, test loss:0.58118194, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.6985115832142856, test accuracy:0.7026875699888018 train loss:0.57298152, test loss:0.58133382, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.6991610228571429, test accuracy:0.7018477043673013 train loss:0.5746147, test loss:0.58304161, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7052633357142858, test accuracy:0.7026875699888018 train loss:0.56737941, test loss:0.58173954, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7066391828571428, test accuracy:0.7043673012318029 train loss:0.56579842, test loss:0.58106124, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.705792507142857, test accuracy:0.7043673012318029 train loss:0.56392582, test loss:0.58127987, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7070985989285713, test accuracy:0.7038073908174692 train loss:0.56664131, test loss:0.58058816, test precision: 0.6088257292445775,test recall: 0.603409933283914,test f1: 0.6061057334326136\n",
      "train accuracy: 0.7047870800000001, test accuracy:0.7043673012318029 train loss:0.5649464, test loss:0.58054608, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7041785325000001, test accuracy:0.7026875699888018 train loss:0.56673438, test loss:0.58215058, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7118683607142857, test accuracy:0.7026875699888018 train loss:0.56068295, test loss:0.58265543, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7000389667857144, test accuracy:0.7018477043673013 train loss:0.56798459, test loss:0.58355486, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7017154778571429, test accuracy:0.7026875699888018 train loss:0.56957198, test loss:0.58240604, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7034521250000001, test accuracy:0.7026875699888018 train loss:0.56499425, test loss:0.58235502, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7035603642857142, test accuracy:0.7018477043673013 train loss:0.56637516, test loss:0.58353031, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.6999475632142856, test accuracy:0.7024076147816349 train loss:0.56613625, test loss:0.58278048, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7068724974999999, test accuracy:0.7026875699888018 train loss:0.56162718, test loss:0.58242238, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7013065739285714, test accuracy:0.7026875699888018 train loss:0.57034222, test loss:0.58148789, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7036156857142857, test accuracy:0.7026875699888018 train loss:0.56905764, test loss:0.58261853, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7049843171428571, test accuracy:0.7026875699888018 train loss:0.56539334, test loss:0.58293623, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7001760692857142, test accuracy:0.7026875699888018 train loss:0.56712349, test loss:0.58258462, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7008688042857143, test accuracy:0.7026875699888018 train loss:0.56769387, test loss:0.58246076, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7022975671428572, test accuracy:0.7043673012318029 train loss:0.5672794, test loss:0.58113509, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7009890689285714, test accuracy:0.7026875699888018 train loss:0.56326003, test loss:0.58201462, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.70113339, test accuracy:0.7043673012318029 train loss:0.56916188, test loss:0.58225477, test precision: 0.6103216155572176,test recall: 0.6039970392301999,test f1: 0.6071428571428571\n",
      "train accuracy: 0.7008447496428571, test accuracy:0.7026875699888018 train loss:0.5698437, test loss:0.58281809, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7007292960714285, test accuracy:0.7026875699888018 train loss:0.56370986, test loss:0.58232701, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7039981332142856, test accuracy:0.7026875699888018 train loss:0.56388221, test loss:0.58270419, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7028772510714285, test accuracy:0.7026875699888018 train loss:0.5664075, test loss:0.58344489, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.6973450010714286, test accuracy:0.7024076147816349 train loss:0.57187292, test loss:0.58312076, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7007076457142858, test accuracy:0.7026875699888018 train loss:0.56883224, test loss:0.58271307, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7086043325, test accuracy:0.7021276595744681 train loss:0.56215549, test loss:0.5826456, test precision: 0.6133133881824981,test recall: 0.5998536942209217,test f1: 0.606508875739645\n",
      "train accuracy: 0.7063553546428573, test accuracy:0.7038073908174692 train loss:0.56518738, test loss:0.58102834, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7084696353571429, test accuracy:0.7054871220604704 train loss:0.55988517, test loss:0.58176565, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.6994352289285715, test accuracy:0.7054871220604704 train loss:0.56850722, test loss:0.58195025, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7042555032142858, test accuracy:0.7054871220604704 train loss:0.56528306, test loss:0.58079213, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7042506932142858, test accuracy:0.7054871220604704 train loss:0.56499958, test loss:0.58140481, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7087197892857143, test accuracy:0.7054871220604704 train loss:0.56121632, test loss:0.58085376, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7005128160714287, test accuracy:0.7054871220604704 train loss:0.56689843, test loss:0.58035481, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7041761285714286, test accuracy:0.7054871220604704 train loss:0.56590116, test loss:0.58017737, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7020065228571427, test accuracy:0.7054871220604704 train loss:0.56610901, test loss:0.58154768, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7031827278571429, test accuracy:0.7038073908174692 train loss:0.56077831, test loss:0.58172655, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.6996252499999999, test accuracy:0.7032474804031354 train loss:0.56768945, test loss:0.58026248, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7076758764285713, test accuracy:0.7038073908174692 train loss:0.56344501, test loss:0.58067793, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7031947542857143, test accuracy:0.7026875699888018 train loss:0.57102291, test loss:0.58123225, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7080318642857143, test accuracy:0.7032474804031354 train loss:0.56293046, test loss:0.58047253, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.6999788332142857, test accuracy:0.7032474804031354 train loss:0.56783771, test loss:0.58025986, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7088977835714285, test accuracy:0.7021276595744681 train loss:0.56247369, test loss:0.58081979, test precision: 0.6088257292445775,test recall: 0.6007380073800738,test f1: 0.6047548291233283\n",
      "train accuracy: 0.7000654246428571, test accuracy:0.7018477043673013 train loss:0.56804483, test loss:0.58276999, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7014581085714285, test accuracy:0.7018477043673013 train loss:0.56829656, test loss:0.58327574, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7043036107142857, test accuracy:0.7018477043673013 train loss:0.56576776, test loss:0.58138508, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.6993991485714285, test accuracy:0.7018477043673013 train loss:0.56903546, test loss:0.58136952, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7020377932142858, test accuracy:0.7018477043673013 train loss:0.5693069, test loss:0.58173227, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7046403567857144, test accuracy:0.7018477043673013 train loss:0.56919562, test loss:0.58136582, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7023721321428571, test accuracy:0.7026875699888018 train loss:0.56843334, test loss:0.58203429, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7049915325000001, test accuracy:0.7026875699888018 train loss:0.56638331, test loss:0.58271956, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7016216714285715, test accuracy:0.7026875699888018 train loss:0.56673396, test loss:0.58283573, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7063120578571429, test accuracy:0.7026875699888018 train loss:0.5632568, test loss:0.58255446, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7027593907142856, test accuracy:0.7038073908174692 train loss:0.56268707, test loss:0.58114076, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7010059071428572, test accuracy:0.7018477043673013 train loss:0.56732732, test loss:0.58295357, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7032909675, test accuracy:0.7018477043673013 train loss:0.56548552, test loss:0.58266115, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7109687682142857, test accuracy:0.7038073908174692 train loss:0.55780409, test loss:0.58132166, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7036637924999999, test accuracy:0.7049272116461366 train loss:0.56411913, test loss:0.58035052, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7102471728571429, test accuracy:0.7038073908174692 train loss:0.56140308, test loss:0.58119166, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7060907660714285, test accuracy:0.7029675251959686 train loss:0.56519302, test loss:0.58221376, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.6980569775000001, test accuracy:0.7038073908174692 train loss:0.56713362, test loss:0.58179176, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7035002310714286, test accuracy:0.7029675251959686 train loss:0.56742863, test loss:0.58199984, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7101317139285713, test accuracy:0.7029675251959686 train loss:0.56031896, test loss:0.58149028, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.6958176189285714, test accuracy:0.7038073908174692 train loss:0.56992634, test loss:0.58065099, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7047510010714285, test accuracy:0.7038073908174692 train loss:0.56733026, test loss:0.5806585, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7090950207142857, test accuracy:0.7038073908174692 train loss:0.56164854, test loss:0.58128369, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7005729492857142, test accuracy:0.7029675251959686 train loss:0.56850527, test loss:0.58130473, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7022398403571428, test accuracy:0.7032474804031354 train loss:0.56862616, test loss:0.57981622, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7105406214285714, test accuracy:0.7032474804031354 train loss:0.56044994, test loss:0.57977086, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7006932150000001, test accuracy:0.7038073908174692 train loss:0.56653531, test loss:0.58101588, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7086019285714285, test accuracy:0.7038073908174692 train loss:0.56002821, test loss:0.58078092, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7059921499999999, test accuracy:0.7032474804031354 train loss:0.56552296, test loss:0.57957447, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.6998080542857142, test accuracy:0.7038073908174692 train loss:0.56990417, test loss:0.58116311, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7039428110714285, test accuracy:0.7038073908174692 train loss:0.56244685, test loss:0.58117336, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7023528885714285, test accuracy:0.7032474804031354 train loss:0.56667502, test loss:0.58081573, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7013161942857142, test accuracy:0.7032474804031354 train loss:0.56608161, test loss:0.5805046, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.6964141392857143, test accuracy:0.7038073908174692 train loss:0.57002401, test loss:0.58159834, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7070408714285714, test accuracy:0.7038073908174692 train loss:0.56623345, test loss:0.58111227, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.6913773864285713, test accuracy:0.7038073908174692 train loss:0.57947102, test loss:0.58092493, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7049650739285714, test accuracy:0.7049272116461366 train loss:0.56470691, test loss:0.57982332, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7053162521428573, test accuracy:0.7032474804031354 train loss:0.5631933, test loss:0.58016503, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7063337057142858, test accuracy:0.7032474804031354 train loss:0.5631629, test loss:0.58035791, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7075075042857143, test accuracy:0.7032474804031354 train loss:0.56207006, test loss:0.57981461, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7072645657142858, test accuracy:0.7032474804031354 train loss:0.55995687, test loss:0.57987845, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7108773664285714, test accuracy:0.7049272116461366 train loss:0.5593699, test loss:0.57919014, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7016601553571429, test accuracy:0.7049272116461366 train loss:0.57043887, test loss:0.57928842, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7030408146428572, test accuracy:0.7049272116461366 train loss:0.56777041, test loss:0.57990128, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7048448085714286, test accuracy:0.7054871220604704 train loss:0.56310677, test loss:0.58063567, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7044527389285715, test accuracy:0.7054871220604704 train loss:0.56691151, test loss:0.58053774, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7056578089285714, test accuracy:0.7040873460246361 train loss:0.56317679, test loss:0.57841235, test precision: 0.605833956619297,test recall: 0.6044776119402985,test f1: 0.6051550242809115\n",
      "train accuracy: 0.707408885357143, test accuracy:0.7052071668533034 train loss:0.55992137, test loss:0.5783931, test precision: 0.6088257292445775,test recall: 0.6056547619047619,test f1: 0.6072361059306228\n",
      "train accuracy: 0.7005994071428571, test accuracy:0.7049272116461366 train loss:0.56649055, test loss:0.57885814, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.6986607139285714, test accuracy:0.7052071668533034 train loss:0.56889554, test loss:0.57845473, test precision: 0.6088257292445775,test recall: 0.6056547619047619,test f1: 0.6072361059306228\n",
      "train accuracy: 0.69703712, test accuracy:0.7054871220604704 train loss:0.56848241, test loss:0.5806464, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7072236760714287, test accuracy:0.7038073908174692 train loss:0.56212053, test loss:0.58197057, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.6996950046428572, test accuracy:0.7038073908174692 train loss:0.57040812, test loss:0.58235383, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7041953710714287, test accuracy:0.7038073908174692 train loss:0.56190728, test loss:0.58168209, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7055351371428572, test accuracy:0.7049272116461366 train loss:0.56429112, test loss:0.57967782, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7043877953571427, test accuracy:0.7049272116461366 train loss:0.56229909, test loss:0.57948625, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.70946063, test accuracy:0.7049272116461366 train loss:0.56202529, test loss:0.57975179, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7040702935714286, test accuracy:0.7032474804031354 train loss:0.5645418, test loss:0.58137679, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.7011694707142857, test accuracy:0.7049272116461366 train loss:0.57148754, test loss:0.58074117, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.6972776525000001, test accuracy:0.7049272116461366 train loss:0.56927386, test loss:0.58065152, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7072116492857142, test accuracy:0.7049272116461366 train loss:0.56159812, test loss:0.57920378, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7004093875, test accuracy:0.7040873460246361 train loss:0.56681893, test loss:0.58072418, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.700289120357143, test accuracy:0.7029675251959686 train loss:0.56707702, test loss:0.58197409, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7078562771428573, test accuracy:0.7040873460246361 train loss:0.56266528, test loss:0.58074147, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7068869299999999, test accuracy:0.7049272116461366 train loss:0.56407865, test loss:0.58083421, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7035098514285715, test accuracy:0.7054871220604704 train loss:0.56326932, test loss:0.58053195, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.7002386078571429, test accuracy:0.7054871220604704 train loss:0.56669615, test loss:0.58049423, test precision: 0.6103216155572176,test recall: 0.6057906458797327,test f1: 0.6080476900149031\n",
      "train accuracy: 0.71067532, test accuracy:0.7052071668533034 train loss:0.55865062, test loss:0.57807839, test precision: 0.606581899775617,test recall: 0.6061285500747384,test f1: 0.6063551401869158\n",
      "train accuracy: 0.6971621953571427, test accuracy:0.7049272116461366 train loss:0.57047457, test loss:0.57821935, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7025284799999999, test accuracy:0.7049272116461366 train loss:0.56624259, test loss:0.58040637, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7002650667857144, test accuracy:0.7040873460246361 train loss:0.56673477, test loss:0.58072346, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7093668221428572, test accuracy:0.7049272116461366 train loss:0.56034917, test loss:0.57937896, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.6999042682142858, test accuracy:0.7040873460246361 train loss:0.56373238, test loss:0.58005816, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7033005889285714, test accuracy:0.7040873460246361 train loss:0.56047986, test loss:0.57971537, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7003083635714286, test accuracy:0.7040873460246361 train loss:0.56560888, test loss:0.58009988, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7018213121428571, test accuracy:0.7046472564389697 train loss:0.56601286, test loss:0.5810253, test precision: 0.6110695587135377,test recall: 0.6042899408284024,test f1: 0.607660840461138\n",
      "train accuracy: 0.6965945382142857, test accuracy:0.7040873460246361 train loss:0.5689629, test loss:0.58044481, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.7073198885714286, test accuracy:0.7040873460246361 train loss:0.55941706, test loss:0.57948351, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.6947568692857143, test accuracy:0.7040873460246361 train loss:0.57391567, test loss:0.5799703, test precision: 0.6095736724008975,test recall: 0.6037037037037037,test f1: 0.6066244882768888\n",
      "train accuracy: 0.6978020132142858, test accuracy:0.7029675251959686 train loss:0.57067151, test loss:0.58135027, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7097468642857142, test accuracy:0.7029675251959686 train loss:0.55770158, test loss:0.58217245, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7021917321428571, test accuracy:0.6998880179171333 train loss:0.56852993, test loss:0.58243728, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7108605303571428, test accuracy:0.7029675251959686 train loss:0.55561415, test loss:0.58184993, test precision: 0.6110695587135377,test recall: 0.601620029455081,test f1: 0.6063079777365491\n",
      "train accuracy: 0.7066439925, test accuracy:0.7063269876819709 train loss:0.56158814, test loss:0.57875699, test precision: 0.6073298429319371,test recall: 0.6077844311377245,test f1: 0.6075570520014963\n",
      "train accuracy: 0.7007653757142857, test accuracy:0.7071668533034714 train loss:0.565763, test loss:0.5777483, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.7034857982142857, test accuracy:0.7071668533034714 train loss:0.56842427, test loss:0.57762009, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.7073198903571428, test accuracy:0.7077267637178052 train loss:0.56497562, test loss:0.57956088, test precision: 0.6088257292445775,test recall: 0.6097378277153558,test f1: 0.6092814371257484\n",
      "train accuracy: 0.7047269478571427, test accuracy:0.7063269876819709 train loss:0.56295427, test loss:0.58035725, test precision: 0.6103216155572176,test recall: 0.6071428571428571,test f1: 0.608728086534875\n",
      "train accuracy: 0.7028892782142858, test accuracy:0.7071668533034714 train loss:0.56378722, test loss:0.57869083, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.7076638517857143, test accuracy:0.7071668533034714 train loss:0.56297205, test loss:0.5779205, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.6982133235714285, test accuracy:0.7071668533034714 train loss:0.56679985, test loss:0.57871801, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.7107138039285715, test accuracy:0.7054871220604704 train loss:0.55746299, test loss:0.57996249, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7077744953571429, test accuracy:0.7071668533034714 train loss:0.56038384, test loss:0.57841754, test precision: 0.6073298429319371,test recall: 0.609152288072018,test f1: 0.6082397003745318\n",
      "train accuracy: 0.7016192646428572, test accuracy:0.7054871220604704 train loss:0.56560498, test loss:0.57926631, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.6989998646428572, test accuracy:0.7038073908174692 train loss:0.56931351, test loss:0.58163589, test precision: 0.6110695587135377,test recall: 0.6029520295202953,test f1: 0.6069836552748885\n",
      "train accuracy: 0.70127771, test accuracy:0.7046472564389697 train loss:0.5639707, test loss:0.58088011, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7016072389285714, test accuracy:0.706047032474804 train loss:0.56949183, test loss:0.58048457, test precision: 0.6088257292445775,test recall: 0.6070096942580164,test f1: 0.6079163554891711\n",
      "train accuracy: 0.7090541289285713, test accuracy:0.7054871220604704 train loss:0.55862789, test loss:0.57944453, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7044479299999999, test accuracy:0.7054871220604704 train loss:0.56360637, test loss:0.57933056, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7061845753571429, test accuracy:0.7054871220604704 train loss:0.56407126, test loss:0.57953382, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7059656910714285, test accuracy:0.7054871220604704 train loss:0.56500967, test loss:0.57938427, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.701741937142857, test accuracy:0.706047032474804 train loss:0.56491571, test loss:0.57968324, test precision: 0.6088257292445775,test recall: 0.6070096942580164,test f1: 0.6079163554891711\n",
      "train accuracy: 0.7069278214285715, test accuracy:0.7054871220604704 train loss:0.56272668, test loss:0.57894051, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7058309928571429, test accuracy:0.7054871220604704 train loss:0.56473445, test loss:0.57976997, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7018982828571428, test accuracy:0.7054871220604704 train loss:0.56486401, test loss:0.57953095, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7014460821428571, test accuracy:0.7054871220604704 train loss:0.56641381, test loss:0.5791344, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7041376417857144, test accuracy:0.7054871220604704 train loss:0.5646381, test loss:0.57845771, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7089001882142857, test accuracy:0.7054871220604704 train loss:0.56184039, test loss:0.58020663, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7093066896428571, test accuracy:0.7054871220604704 train loss:0.55899056, test loss:0.5793516, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7024515092857143, test accuracy:0.7024076147816349 train loss:0.56657117, test loss:0.57995224, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7028628192857143, test accuracy:0.7024076147816349 train loss:0.56562458, test loss:0.57895249, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7031971596428572, test accuracy:0.7054871220604704 train loss:0.564356, test loss:0.57811201, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7009842582142858, test accuracy:0.7024076147816349 train loss:0.56308049, test loss:0.57947367, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7094486028571428, test accuracy:0.7024076147816349 train loss:0.55955037, test loss:0.57946873, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7065574007142857, test accuracy:0.7024076147816349 train loss:0.56108874, test loss:0.57914972, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7044912253571428, test accuracy:0.7024076147816349 train loss:0.56486917, test loss:0.57885551, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7049578592857143, test accuracy:0.7054871220604704 train loss:0.55977022, test loss:0.57874131, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7055255160714287, test accuracy:0.7024076147816349 train loss:0.5660704, test loss:0.57927662, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7054052482142857, test accuracy:0.7010078387458006 train loss:0.56338514, test loss:0.57980376, test precision: 0.6095736724008975,test recall: 0.5988243938280676,test f1: 0.6041512231282431\n",
      "train accuracy: 0.7015879960714286, test accuracy:0.7024076147816349 train loss:0.56900302, test loss:0.57896435, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7024827778571429, test accuracy:0.7024076147816349 train loss:0.56443583, test loss:0.57864285, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7076277717857142, test accuracy:0.7024076147816349 train loss:0.55797591, test loss:0.57909507, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7051166110714286, test accuracy:0.7024076147816349 train loss:0.56128943, test loss:0.57991147, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.704563385, test accuracy:0.7024076147816349 train loss:0.564419, test loss:0.58013725, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7040943467857144, test accuracy:0.7054871220604704 train loss:0.56192828, test loss:0.57846415, test precision: 0.6073298429319371,test recall: 0.6064227035100822,test f1: 0.6068759342301943\n",
      "train accuracy: 0.7038922978571428, test accuracy:0.7057670772676372 train loss:0.56655482, test loss:0.57805926, test precision: 0.605833956619297,test recall: 0.6071964017991005,test f1: 0.6065144140771247\n",
      "train accuracy: 0.6981459728571427, test accuracy:0.7057670772676372 train loss:0.56768232, test loss:0.57846636, test precision: 0.605833956619297,test recall: 0.6071964017991005,test f1: 0.6065144140771247\n",
      "train accuracy: 0.6992091289285715, test accuracy:0.7026875699888018 train loss:0.56951284, test loss:0.5791862, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7045657903571428, test accuracy:0.7024076147816349 train loss:0.56366962, test loss:0.58041763, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.706037850357143, test accuracy:0.7026875699888018 train loss:0.56556916, test loss:0.57991928, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7100066392857142, test accuracy:0.7024076147816349 train loss:0.55766258, test loss:0.58045924, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7015855907142857, test accuracy:0.7024076147816349 train loss:0.56337421, test loss:0.58039302, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.6998056492857144, test accuracy:0.7024076147816349 train loss:0.56759838, test loss:0.58055335, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7161570589285715, test accuracy:0.7074468085106383 train loss:0.55601273, test loss:0.57803977, test precision: 0.605833956619297,test recall: 0.6099397590361446,test f1: 0.6078799249530957\n",
      "train accuracy: 0.7061605207142857, test accuracy:0.7074468085106383 train loss:0.56395688, test loss:0.57825482, test precision: 0.605833956619297,test recall: 0.6099397590361446,test f1: 0.6078799249530957\n",
      "train accuracy: 0.7068316085714287, test accuracy:0.7043673012318029 train loss:0.56250798, test loss:0.57925153, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7124360182142858, test accuracy:0.7040873460246361 train loss:0.55397176, test loss:0.57992572, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.6994881464285715, test accuracy:0.7040873460246361 train loss:0.56870122, test loss:0.58089739, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7074329396428573, test accuracy:0.7024076147816349 train loss:0.56070095, test loss:0.58051449, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7049554532142857, test accuracy:0.7040873460246361 train loss:0.55855118, test loss:0.58008528, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7088641078571428, test accuracy:0.7040873460246361 train loss:0.55993106, test loss:0.57955354, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7058646664285714, test accuracy:0.7043673012318029 train loss:0.56365228, test loss:0.57766974, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7087751121428572, test accuracy:0.7043673012318029 train loss:0.56047123, test loss:0.57807326, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7093932803571429, test accuracy:0.7043673012318029 train loss:0.56313068, test loss:0.57856369, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.6983816957142858, test accuracy:0.7043673012318029 train loss:0.56946158, test loss:0.5786646, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7018405567857142, test accuracy:0.7040873460246361 train loss:0.56740355, test loss:0.57961786, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7039428103571428, test accuracy:0.7040873460246361 train loss:0.5660411, test loss:0.57949787, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7069831435714286, test accuracy:0.7043673012318029 train loss:0.56072617, test loss:0.57881671, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7083950696428571, test accuracy:0.7040873460246361 train loss:0.5600236, test loss:0.57903022, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7013691121428571, test accuracy:0.7040873460246361 train loss:0.56220866, test loss:0.57960713, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7064804317857144, test accuracy:0.7040873460246361 train loss:0.5610025, test loss:0.57932127, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7150337710714286, test accuracy:0.7040873460246361 train loss:0.55925155, test loss:0.5790171, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7065598064285714, test accuracy:0.7043673012318029 train loss:0.56459231, test loss:0.57807046, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7083181007142858, test accuracy:0.7043673012318029 train loss:0.56396173, test loss:0.57747638, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7037912767857144, test accuracy:0.7043673012318029 train loss:0.56296155, test loss:0.5781067, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7122315664285715, test accuracy:0.7043673012318029 train loss:0.55640772, test loss:0.5782851, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.70500356, test accuracy:0.7026875699888018 train loss:0.56230887, test loss:0.5787549, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7029085214285714, test accuracy:0.7043673012318029 train loss:0.56420414, test loss:0.57829022, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7050059653571428, test accuracy:0.7043673012318029 train loss:0.56000564, test loss:0.57737845, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7018814464285714, test accuracy:0.7085666293393057 train loss:0.57110621, test loss:0.5761013, test precision: 0.6028421839940165,test recall: 0.6124620060790273,test f1: 0.607614021862043\n",
      "train accuracy: 0.7065261307142857, test accuracy:0.7043673012318029 train loss:0.56001626, test loss:0.57817602, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7083373439285715, test accuracy:0.7043673012318029 train loss:0.56229605, test loss:0.5779416, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7011382007142857, test accuracy:0.7043673012318029 train loss:0.56533805, test loss:0.57842314, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7014484896428571, test accuracy:0.7043673012318029 train loss:0.56462996, test loss:0.57935995, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7148822357142858, test accuracy:0.7026875699888018 train loss:0.5542865, test loss:0.57896787, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7040245921428571, test accuracy:0.7054871220604704 train loss:0.56372537, test loss:0.57772511, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7059175839285715, test accuracy:0.7054871220604704 train loss:0.56623405, test loss:0.57806039, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7083373428571429, test accuracy:0.7043673012318029 train loss:0.56205236, test loss:0.57904404, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7032452660714287, test accuracy:0.7026875699888018 train loss:0.56823418, test loss:0.58039558, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7038008964285715, test accuracy:0.7040873460246361 train loss:0.56412, test loss:0.5798552, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.6976432607142857, test accuracy:0.7024076147816349 train loss:0.56954994, test loss:0.5809831, test precision: 0.6080777860882572,test recall: 0.6013313609467456,test f1: 0.6046857567869096\n",
      "train accuracy: 0.7010540135714285, test accuracy:0.7015677491601344 train loss:0.56693163, test loss:0.58171785, test precision: 0.6110695587135377,test recall: 0.5994130594277329,test f1: 0.6051851851851852\n",
      "train accuracy: 0.7028964939285715, test accuracy:0.7026875699888018 train loss:0.57092225, test loss:0.57979286, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7064539707142856, test accuracy:0.7054871220604704 train loss:0.55844979, test loss:0.57948118, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7080198385714285, test accuracy:0.7043673012318029 train loss:0.55879834, test loss:0.57965744, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7033053992857142, test accuracy:0.7043673012318029 train loss:0.56164791, test loss:0.57926834, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7042122067857143, test accuracy:0.7054871220604704 train loss:0.56344057, test loss:0.57826322, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7067089364285714, test accuracy:0.7040873460246361 train loss:0.56108468, test loss:0.57979053, test precision: 0.6080777860882572,test recall: 0.6040118870728083,test f1: 0.606038017144987\n",
      "train accuracy: 0.7012849239285713, test accuracy:0.6998880179171333 train loss:0.56177675, test loss:0.58128488, test precision: 0.6095736724008975,test recall: 0.5970695970695971,test f1: 0.6032568467801629\n",
      "train accuracy: 0.7007485382142857, test accuracy:0.7043673012318029 train loss:0.56663007, test loss:0.57998306, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7060282303571428, test accuracy:0.7043673012318029 train loss:0.56331504, test loss:0.57854468, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.6984682882142856, test accuracy:0.7026875699888018 train loss:0.56695073, test loss:0.5797388, test precision: 0.606581899775617,test recall: 0.6020786933927246,test f1: 0.6043219076005961\n",
      "train accuracy: 0.7074810460714286, test accuracy:0.7054871220604704 train loss:0.55906996, test loss:0.57755607, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7098382657142857, test accuracy:0.7043673012318029 train loss:0.55832848, test loss:0.57860947, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7078923575000001, test accuracy:0.7043673012318029 train loss:0.56196935, test loss:0.57906991, test precision: 0.606581899775617,test recall: 0.604772557792692,test f1: 0.6056758775205378\n",
      "train accuracy: 0.7127318732142857, test accuracy:0.7057670772676372 train loss:0.55551306, test loss:0.57758081, test precision: 0.6035901271503366,test recall: 0.6076807228915663,test f1: 0.6056285178236397\n",
      "train accuracy: 0.7114618599999999, test accuracy:0.7054871220604704 train loss:0.55685596, test loss:0.57765102, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7017804232142858, test accuracy:0.7054871220604704 train loss:0.563766, test loss:0.57749116, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7037576000000001, test accuracy:0.7054871220604704 train loss:0.56209702, test loss:0.57770449, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7018068814285715, test accuracy:0.7054871220604704 train loss:0.56521527, test loss:0.57879484, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.6983624553571428, test accuracy:0.7054871220604704 train loss:0.56709793, test loss:0.57966757, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7097901603571428, test accuracy:0.7054871220604704 train loss:0.55827536, test loss:0.57827038, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.6971237107142857, test accuracy:0.7054871220604704 train loss:0.56989375, test loss:0.57873815, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7002049339285714, test accuracy:0.7054871220604704 train loss:0.5681682, test loss:0.57828003, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7067426114285713, test accuracy:0.7054871220604704 train loss:0.5610301, test loss:0.57757086, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7060210128571428, test accuracy:0.7054871220604704 train loss:0.55881383, test loss:0.57681948, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7088568921428571, test accuracy:0.7054871220604704 train loss:0.56196262, test loss:0.57643694, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.6993197732142856, test accuracy:0.7054871220604704 train loss:0.56658323, test loss:0.57817817, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7093547953571429, test accuracy:0.7054871220604704 train loss:0.56405611, test loss:0.57928085, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7079019785714287, test accuracy:0.7038073908174692 train loss:0.56239698, test loss:0.58029222, test precision: 0.6035901271503366,test recall: 0.604494382022472,test f1: 0.6040419161676647\n",
      "train accuracy: 0.7098069960714286, test accuracy:0.7054871220604704 train loss:0.56130347, test loss:0.57894355, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7167992803571429, test accuracy:0.7038073908174692 train loss:0.55460551, test loss:0.57973105, test precision: 0.6035901271503366,test recall: 0.604494382022472,test f1: 0.6040419161676647\n",
      "train accuracy: 0.7081930242857143, test accuracy:0.7038073908174692 train loss:0.56057346, test loss:0.57925618, test precision: 0.6035901271503366,test recall: 0.604494382022472,test f1: 0.6040419161676647\n",
      "train accuracy: 0.7088063803571428, test accuracy:0.7038073908174692 train loss:0.55912845, test loss:0.57934165, test precision: 0.6035901271503366,test recall: 0.604494382022472,test f1: 0.6040419161676647\n",
      "train accuracy: 0.7010997157142856, test accuracy:0.7029675251959686 train loss:0.56653809, test loss:0.57965714, test precision: 0.6043380703066566,test recall: 0.6029850746268657,test f1: 0.6036608143444154\n",
      "train accuracy: 0.7164505078571429, test accuracy:0.7054871220604704 train loss:0.5553374, test loss:0.57735944, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7069398478571429, test accuracy:0.7054871220604704 train loss:0.56340817, test loss:0.57710069, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7067690699999999, test accuracy:0.7038073908174692 train loss:0.56017397, test loss:0.57808125, test precision: 0.6035901271503366,test recall: 0.604494382022472,test f1: 0.6040419161676647\n",
      "train accuracy: 0.7077143614285715, test accuracy:0.7054871220604704 train loss:0.56012332, test loss:0.57823056, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.7075965010714285, test accuracy:0.7043673012318029 train loss:0.55922715, test loss:0.57914203, test precision: 0.6140613313388182,test recall: 0.6032329169728141,test f1: 0.6085989621942179\n",
      "train accuracy: 0.7033799646428571, test accuracy:0.7043673012318029 train loss:0.56522403, test loss:0.57928902, test precision: 0.6140613313388182,test recall: 0.6032329169728141,test f1: 0.6085989621942179\n",
      "train accuracy: 0.6997407057142857, test accuracy:0.7043673012318029 train loss:0.56614349, test loss:0.58017355, test precision: 0.6140613313388182,test recall: 0.6032329169728141,test f1: 0.6085989621942179\n",
      "train accuracy: 0.7097444578571428, test accuracy:0.7054871220604704 train loss:0.55763706, test loss:0.58047509, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.6970515510714286, test accuracy:0.7054871220604704 train loss:0.57021272, test loss:0.57917023, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n"
=======
      "train accuracy: 0.51064023875, test accuracy:0.49720044792833146 train loss:0.69340575, test loss:50.27995682, test precision: 0.6387434554973822,test recall: 0.3940932164282418,test f1: 0.48744292237442916\n",
      "train accuracy: 0.5391376201785715, test accuracy:0.5223964165733482 train loss:0.69272773, test loss:47.76036072, test precision: 0.6275243081525804,test recall: 0.40986809965803617,test f1: 0.4958628841607566\n",
      "train accuracy: 0.5478140023214285, test accuracy:0.5506718924972005 train loss:0.69245542, test loss:44.93281174, test precision: 0.5736724008975318,test recall: 0.42563817980022195,test f1: 0.48869066581713916\n",
      "train accuracy: 0.5625268285714285, test accuracy:0.5571108622620381 train loss:0.69181504, test loss:44.28891373, test precision: 0.5587135377711294,test recall: 0.42955721679125936,test f1: 0.4856957087126138\n",
      "train accuracy: 0.5714339371428572, test accuracy:0.5638297872340425 train loss:0.69130567, test loss:43.61702347, test precision: 0.5714285714285714,test recall: 0.4368210405946255,test f1: 0.4951393389500972\n",
      "train accuracy: 0.5827073317857143, test accuracy:0.5792273236282195 train loss:0.69077593, test loss:42.07727051, test precision: 0.5654450261780105,test recall: 0.4505363528009535,test f1: 0.5014925373134329\n",
      "train accuracy: 0.5865813873214286, test accuracy:0.583986562150056 train loss:0.69044103, test loss:41.60134506, test precision: 0.5721765145848915,test recall: 0.45562835020845743,test f1: 0.5072944297082229\n",
      "train accuracy: 0.5911368905357143, test accuracy:0.591545352743561 train loss:0.69001858, test loss:40.84546661, test precision: 0.5676888556469708,test recall: 0.4628048780487805,test f1: 0.50990930466913\n",
      "train accuracy: 0.6084681919642857, test accuracy:0.6125419932810751 train loss:0.68948689, test loss:38.74580383, test precision: 0.5594614809274495,test recall: 0.4847699287103046,test f1: 0.5194444444444445\n",
      "train accuracy: 0.6167367789285715, test accuracy:0.6153415453527435 train loss:0.68881053, test loss:38.46584702, test precision: 0.550486163051608,test recall: 0.487740225314778,test f1: 0.5172171468728038\n",
      "train accuracy: 0.6098203553571429, test accuracy:0.6167413213885778 train loss:0.68857248, test loss:38.32587051, test precision: 0.5497382198952879,test recall: 0.48934753661784286,test f1: 0.5177879535047551\n",
      "train accuracy: 0.6231756525, test accuracy:0.618421052631579 train loss:0.68786862, test loss:38.15789413, test precision: 0.556469708302169,test recall: 0.4914134742404227,test f1: 0.5219221325850578\n",
      "train accuracy: 0.6203801082142857, test accuracy:0.6273796192609182 train loss:0.68768251, test loss:37.26203918, test precision: 0.5512341062079282,test recall: 0.5020435967302452,test f1: 0.5254901960784314\n",
      "train accuracy: 0.6301081730357143, test accuracy:0.6279395296752519 train loss:0.68670938, test loss:37.20604706, test precision: 0.5519820493642483,test recall: 0.502724795640327,test f1: 0.5262032085561498\n",
      "train accuracy: 0.6243185525, test accuracy:0.6265397536394177 train loss:0.68676588, test loss:37.34602737, test precision: 0.5796559461480928,test recall: 0.5009696186166774,test f1: 0.5374479889042997\n",
      "train accuracy: 0.62607851125, test accuracy:0.6290593505039194 train loss:0.68606608, test loss:37.09406662, test precision: 0.5804038893044129,test recall: 0.5038961038961038,test f1: 0.5394508168230796\n",
      "train accuracy: 0.6344812414285714, test accuracy:0.6290593505039194 train loss:0.68543122, test loss:37.09406662, test precision: 0.5796559461480928,test recall: 0.5039011703511054,test f1: 0.5391304347826088\n",
      "train accuracy: 0.6354041466071428, test accuracy:0.643057110862262 train loss:0.68500864, test loss:35.69429016, test precision: 0.5736724008975318,test recall: 0.5210597826086957,test f1: 0.5461018155927376\n",
      "train accuracy: 0.6424117875, test accuracy:0.6433370660694289 train loss:0.68442454, test loss:35.6662941, test precision: 0.5736724008975318,test recall: 0.521414004078858,test f1: 0.5462962962962963\n",
      "train accuracy: 0.6367992358928571, test accuracy:0.6424972004479284 train loss:0.683995, test loss:35.75028229, test precision: 0.5781600598354525,test recall: 0.5201884253028264,test f1: 0.5476443499822883\n",
      "train accuracy: 0.63984160375, test accuracy:0.6436170212765957 train loss:0.68354978, test loss:35.63829803, test precision: 0.5766641735228123,test recall: 0.5216508795669824,test f1: 0.5477797513321492\n",
      "train accuracy: 0.6423098385714285, test accuracy:0.6433370660694289 train loss:0.68299865, test loss:35.6662941, test precision: 0.6043380703066566,test recall: 0.5202833226014166,test f1: 0.5591695501730103\n",
      "train accuracy: 0.6459585335714285, test accuracy:0.6517357222844344 train loss:0.68244603, test loss:34.82642746, test precision: 0.5968586387434555,test recall: 0.530938123752495,test f1: 0.5619718309859155\n",
      "train accuracy: 0.6515174278571428, test accuracy:0.6528555431131019 train loss:0.68172306, test loss:34.71444702, test precision: 0.600598354525056,test recall: 0.5321404903909874,test f1: 0.5643007730147575\n",
      "train accuracy: 0.6470531421428571, test accuracy:0.6553751399776035 train loss:0.68204534, test loss:34.46248627, test precision: 0.5968586387434555,test recall: 0.5355704697986577,test f1: 0.5645560665015918\n",
      "train accuracy: 0.6562446342857143, test accuracy:0.6542553191489362 train loss:0.68021357, test loss:34.57447052, test precision: 0.6028421839940165,test recall: 0.5337748344370861,test f1: 0.5662100456621004\n",
      "train accuracy: 0.6555846496428571, test accuracy:0.6620940649496081 train loss:0.68034225, test loss:33.79059601, test precision: 0.600598354525056,test recall: 0.5440379403794038,test f1: 0.5709207252044082\n",
      "train accuracy: 0.6562553657142857, test accuracy:0.6590145576707727 train loss:0.68013235, test loss:34.09854507, test precision: 0.6050860134629769,test recall: 0.5396931287525016,test f1: 0.5705218617771509\n",
      "train accuracy: 0.6668795071428572, test accuracy:0.6606942889137738 train loss:0.67854288, test loss:33.93057251, test precision: 0.5841436050860135,test recall: 0.5434933890048712,test f1: 0.5630857966834896\n",
      "train accuracy: 0.6516998626785714, test accuracy:0.6609742441209406 train loss:0.67881505, test loss:33.90257645, test precision: 0.5833956619296934,test recall: 0.5439330543933054,test f1: 0.5629736557199567\n",
      "train accuracy: 0.6616532880357143, test accuracy:0.6620940649496081 train loss:0.67767712, test loss:33.79059601, test precision: 0.5766641735228123,test recall: 0.5460339943342776,test f1: 0.560931247726446\n",
      "train accuracy: 0.6654951494642857, test accuracy:0.666013437849944 train loss:0.67635803, test loss:33.39865875, test precision: 0.575168287210172,test recall: 0.5516499282639885,test f1: 0.5631636763090444\n",
      "train accuracy: 0.6602957589285714, test accuracy:0.6662933930571109 train loss:0.6769193, test loss:33.37066269, test precision: 0.575168287210172,test recall: 0.552045944005743,test f1: 0.5633699633699634\n",
      "train accuracy: 0.6599577180357142, test accuracy:0.6662933930571109 train loss:0.6759048, test loss:33.37066269, test precision: 0.575168287210172,test recall: 0.552045944005743,test f1: 0.5633699633699634\n",
      "train accuracy: 0.6675555889285715, test accuracy:0.6651735722284434 train loss:0.67504819, test loss:33.48264313, test precision: 0.5766641735228123,test recall: 0.550321199143469,test f1: 0.5631848064280497\n",
      "train accuracy: 0.6683443508928572, test accuracy:0.6629339305711086 train loss:0.67434042, test loss:33.70660782, test precision: 0.5789080029917726,test recall: 0.5469964664310955,test f1: 0.5625\n",
      "train accuracy: 0.6603118560714286, test accuracy:0.6657334826427772 train loss:0.67384563, test loss:33.426651, test precision: 0.5587135377711294,test recall: 0.5529237601776462,test f1: 0.5558035714285714\n",
      "train accuracy: 0.6631610576785715, test accuracy:0.6657334826427772 train loss:0.67340729, test loss:33.426651, test precision: 0.5587135377711294,test recall: 0.5529237601776462,test f1: 0.5558035714285714\n",
      "train accuracy: 0.6607142857142857, test accuracy:0.6674132138857782 train loss:0.67302597, test loss:33.25867844, test precision: 0.5841436050860135,test recall: 0.5527246992215145,test f1: 0.5680000000000001\n",
      "train accuracy: 0.6660639166071428, test accuracy:0.6643337066069429 train loss:0.67104271, test loss:33.56663132, test precision: 0.5669409124906507,test recall: 0.5500725689404935,test f1: 0.5583793738489871\n",
      "train accuracy: 0.6632952008928571, test accuracy:0.6648936170212766 train loss:0.67097548, test loss:33.51063919, test precision: 0.5699326851159312,test recall: 0.5505780346820809,test f1: 0.5600882028665931\n",
      "train accuracy: 0.6635205614285714, test accuracy:0.666013437849944 train loss:0.67003946, test loss:33.39865875, test precision: 0.5706806282722513,test recall: 0.5520984081041969,test f1: 0.5612357484369254\n",
      "train accuracy: 0.66064453125, test accuracy:0.667973124300112 train loss:0.6693813, test loss:33.20269012, test precision: 0.5654450261780105,test recall: 0.5554739162380602,test f1: 0.5604151223128243\n",
      "train accuracy: 0.6632308121428572, test accuracy:0.6682530795072789 train loss:0.66850213, test loss:33.17469406, test precision: 0.5669409124906507,test recall: 0.5557184750733137,test f1: 0.5612736023694926\n",
      "train accuracy: 0.6619752317857143, test accuracy:0.6682530795072789 train loss:0.66854904, test loss:33.17469406, test precision: 0.5669409124906507,test recall: 0.5557184750733137,test f1: 0.5612736023694926\n",
      "train accuracy: 0.6605264851785714, test accuracy:0.6665733482642777 train loss:0.66763561, test loss:33.34266663, test precision: 0.5676888556469708,test recall: 0.5532069970845481,test f1: 0.5603543743078626\n",
      "train accuracy: 0.6617391398214286, test accuracy:0.6646136618141097 train loss:0.66796521, test loss:33.53863525, test precision: 0.5721765145848915,test recall: 0.5499640546369519,test f1: 0.560850439882698\n",
      "train accuracy: 0.6554934323214285, test accuracy:0.6646136618141097 train loss:0.66790617, test loss:33.53863525, test precision: 0.5721765145848915,test recall: 0.5499640546369519,test f1: 0.560850439882698\n",
      "train accuracy: 0.6635849501785714, test accuracy:0.6648936170212766 train loss:0.66529773, test loss:33.51063919, test precision: 0.5714285714285714,test recall: 0.5504322766570605,test f1: 0.5607339449541285\n",
      "train accuracy: 0.6592977335714286, test accuracy:0.6632138857782754 train loss:0.66498, test loss:33.67861176, test precision: 0.5721765145848915,test recall: 0.5479942693409742,test f1: 0.5598243688254665\n",
      "train accuracy: 0.66221132375, test accuracy:0.6643337066069429 train loss:0.66461663, test loss:33.56663132, test precision: 0.5744203440538519,test recall: 0.5493562231759657,test f1: 0.5616087751371115\n",
      "train accuracy: 0.6639283567857143, test accuracy:0.6626539753639418 train loss:0.66309265, test loss:33.73460388, test precision: 0.575168287210172,test recall: 0.5469416785206259,test f1: 0.5606999635435653\n",
      "train accuracy: 0.6562821942857143, test accuracy:0.6626539753639418 train loss:0.66356595, test loss:33.73460388, test precision: 0.575168287210172,test recall: 0.5469416785206259,test f1: 0.5606999635435653\n",
      "train accuracy: 0.66289277125, test accuracy:0.6623740201567749 train loss:0.6623936, test loss:33.76259995, test precision: 0.5759162303664922,test recall: 0.5464868701206529,test f1: 0.56081573197378\n",
      "train accuracy: 0.6626835078571428, test accuracy:0.6598544232922733 train loss:0.66101012, test loss:34.0145607, test precision: 0.5774121166791324,test recall: 0.5428973277074542,test f1: 0.5596230518303733\n",
      "train accuracy: 0.6612937842857143, test accuracy:0.6609742441209406 train loss:0.66203577, test loss:33.90257645, test precision: 0.5804038893044129,test recall: 0.544179523141655,test f1: 0.5617082880926529\n",
      "train accuracy: 0.6583211710714286, test accuracy:0.6623740201567749 train loss:0.6603643, test loss:33.76259995, test precision: 0.5759162303664922,test recall: 0.5464868701206529,test f1: 0.56081573197378\n",
      "train accuracy: 0.6607411142857142, test accuracy:0.6623740201567749 train loss:0.65904243, test loss:33.76259995, test precision: 0.5759162303664922,test recall: 0.5464868701206529,test f1: 0.56081573197378\n",
      "train accuracy: 0.6625600960714285, test accuracy:0.6623740201567749 train loss:0.6581768, test loss:33.76259995, test precision: 0.5759162303664922,test recall: 0.5464868701206529,test f1: 0.56081573197378\n",
      "train accuracy: 0.6647278503571429, test accuracy:0.6634938409854423 train loss:0.65669726, test loss:33.65061569, test precision: 0.5789080029917726,test recall: 0.5477707006369427,test f1: 0.5629090909090908\n",
      "train accuracy: 0.6635044642857143, test accuracy:0.6634938409854423 train loss:0.65794358, test loss:33.65061569, test precision: 0.5789080029917726,test recall: 0.5477707006369427,test f1: 0.5629090909090908\n",
      "train accuracy: 0.6625493646428572, test accuracy:0.6640537513997761 train loss:0.65611291, test loss:33.59462738, test precision: 0.5759162303664922,test recall: 0.5488239486813971,test f1: 0.5620437956204379\n",
      "train accuracy: 0.6698896807142857, test accuracy:0.6640537513997761 train loss:0.65433115, test loss:33.59462738, test precision: 0.5759162303664922,test recall: 0.5488239486813971,test f1: 0.5620437956204379\n",
      "train accuracy: 0.6526334992857142, test accuracy:0.6643337066069429 train loss:0.65641348, test loss:33.56663132, test precision: 0.5766641735228123,test recall: 0.5491452991452992,test f1: 0.5625684056913535\n",
      "train accuracy: 0.6642395691071429, test accuracy:0.6637737961926092 train loss:0.65397167, test loss:33.62261963, test precision: 0.5796559461480928,test recall: 0.5480905233380481,test f1: 0.5634314794620139\n",
      "train accuracy: 0.6611167153571429, test accuracy:0.6612541993281075 train loss:0.65360355, test loss:33.87458038, test precision: 0.599850411368736,test recall: 0.5429925524712255,test f1: 0.57000710732054\n",
      "train accuracy: 0.67291595125, test accuracy:0.6612541993281075 train loss:0.65158898, test loss:33.87458038, test precision: 0.599850411368736,test recall: 0.5429925524712255,test f1: 0.57000710732054\n",
      "train accuracy: 0.6647385817857143, test accuracy:0.6612541993281075 train loss:0.65249062, test loss:33.87458038, test precision: 0.599850411368736,test recall: 0.5429925524712255,test f1: 0.57000710732054\n",
      "train accuracy: 0.6632361778571428, test accuracy:0.6609742441209406 train loss:0.65165936, test loss:33.90257645, test precision: 0.6013462976813763,test recall: 0.5425101214574899,test f1: 0.570415040794608\n",
      "train accuracy: 0.6617552369642857, test accuracy:0.6609742441209406 train loss:0.6506103, test loss:33.90257645, test precision: 0.6013462976813763,test recall: 0.5425101214574899,test f1: 0.570415040794608\n",
      "train accuracy: 0.6643254207142857, test accuracy:0.6609742441209406 train loss:0.64982545, test loss:33.90257645, test precision: 0.6013462976813763,test recall: 0.5425101214574899,test f1: 0.570415040794608\n",
      "train accuracy: 0.6658814817857143, test accuracy:0.6609742441209406 train loss:0.6500218, test loss:33.90257645, test precision: 0.6013462976813763,test recall: 0.5425101214574899,test f1: 0.570415040794608\n",
      "train accuracy: 0.6684945914285715, test accuracy:0.6609742441209406 train loss:0.64696399, test loss:33.90257645, test precision: 0.6013462976813763,test recall: 0.5425101214574899,test f1: 0.570415040794608\n",
      "train accuracy: 0.6742681146428572, test accuracy:0.6576147816349384 train loss:0.64478522, test loss:34.23852158, test precision: 0.6050860134629769,test recall: 0.5378989361702128,test f1: 0.5695177754311862\n",
      "train accuracy: 0.6647439475, test accuracy:0.6576147816349384 train loss:0.64605951, test loss:34.23852158, test precision: 0.6050860134629769,test recall: 0.5378989361702128,test f1: 0.5695177754311862\n",
      "train accuracy: 0.6686877575, test accuracy:0.6576147816349384 train loss:0.64533901, test loss:34.23852158, test precision: 0.6050860134629769,test recall: 0.5378989361702128,test f1: 0.5695177754311862\n",
      "train accuracy: 0.6692618905357143, test accuracy:0.6576147816349384 train loss:0.64403707, test loss:34.23852158, test precision: 0.6050860134629769,test recall: 0.5378989361702128,test f1: 0.5695177754311862\n",
      "train accuracy: 0.6688755580357143, test accuracy:0.658454647256439 train loss:0.64307981, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6728998541071428, test accuracy:0.658454647256439 train loss:0.64184469, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6737905648214285, test accuracy:0.658454647256439 train loss:0.64181996, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6630859375, test accuracy:0.658454647256439 train loss:0.64404979, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6659619676785714, test accuracy:0.658454647256439 train loss:0.64191065, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6683443508928572, test accuracy:0.6587346024636058 train loss:0.64048998, test loss:34.12654114, test precision: 0.6043380703066566,test recall: 0.5393858477970628,test f1: 0.5700176366843034\n",
      "train accuracy: 0.6719232916071428, test accuracy:0.6587346024636058 train loss:0.63809918, test loss:34.12654114, test precision: 0.6043380703066566,test recall: 0.5393858477970628,test f1: 0.5700176366843034\n",
      "train accuracy: 0.6649907708928572, test accuracy:0.6587346024636058 train loss:0.639771, test loss:34.12654114, test precision: 0.6043380703066566,test recall: 0.5393858477970628,test f1: 0.5700176366843034\n",
      "train accuracy: 0.6669170673214285, test accuracy:0.6587346024636058 train loss:0.63947103, test loss:34.12654114, test precision: 0.6043380703066566,test recall: 0.5393858477970628,test f1: 0.5700176366843034\n",
      "train accuracy: 0.6715101305357143, test accuracy:0.6643337066069429 train loss:0.63704619, test loss:33.56663132, test precision: 0.6013462976813763,test recall: 0.5469387755102041,test f1: 0.5728535803348771\n",
      "train accuracy: 0.66930481625, test accuracy:0.6643337066069429 train loss:0.63802504, test loss:33.56663132, test precision: 0.6013462976813763,test recall: 0.5469387755102041,test f1: 0.5728535803348771\n",
      "train accuracy: 0.6737851991071429, test accuracy:0.6643337066069429 train loss:0.63433042, test loss:33.56663132, test precision: 0.6013462976813763,test recall: 0.5469387755102041,test f1: 0.5728535803348771\n",
      "train accuracy: 0.6664931748214286, test accuracy:0.6646136618141097 train loss:0.63533219, test loss:33.53863525, test precision: 0.6028421839940165,test recall: 0.5471826205023761,test f1: 0.5736654804270462\n",
      "train accuracy: 0.6643468835714286, test accuracy:0.6651735722284434 train loss:0.63571273, test loss:33.48264313, test precision: 0.599850411368736,test recall: 0.5481886534518113,test f1: 0.5728571428571427\n",
      "train accuracy: 0.672170115, test accuracy:0.6671332586786114 train loss:0.63359327, test loss:33.2866745, test precision: 0.5953627524308153,test recall: 0.5512465373961218,test f1: 0.5724559510967279\n",
      "train accuracy: 0.6736832503571428, test accuracy:0.667973124300112 train loss:0.63265401, test loss:33.20269012, test precision: 0.5983545250560958,test recall: 0.5521048999309869,test f1: 0.574300071787509\n",
      "train accuracy: 0.66832825375, test accuracy:0.667973124300112 train loss:0.63554432, test loss:33.20269012, test precision: 0.5983545250560958,test recall: 0.5521048999309869,test f1: 0.574300071787509\n",
      "train accuracy: 0.6725081558928572, test accuracy:0.667973124300112 train loss:0.63094145, test loss:33.20269012, test precision: 0.5983545250560958,test recall: 0.5521048999309869,test f1: 0.574300071787509\n",
      "train accuracy: 0.6658814817857143, test accuracy:0.6646136618141097 train loss:0.6335028, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.6690365298214286, test accuracy:0.6646136618141097 train loss:0.63271429, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.6771709735714285, test accuracy:0.6646136618141097 train loss:0.62834388, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.6608913548214286, test accuracy:0.6648936170212766 train loss:0.6351561, test loss:33.51063919, test precision: 0.5833956619296934,test recall: 0.5492957746478874,test f1: 0.5658324265505986\n",
      "train accuracy: 0.6675609546428571, test accuracy:0.6648936170212766 train loss:0.63128992, test loss:33.51063919, test precision: 0.5833956619296934,test recall: 0.5492957746478874,test f1: 0.5658324265505986\n",
      "train accuracy: 0.6707374657142857, test accuracy:0.6648936170212766 train loss:0.62829837, test loss:33.51063919, test precision: 0.5833956619296934,test recall: 0.5492957746478874,test f1: 0.5658324265505986\n",
      "train accuracy: 0.6735759357142858, test accuracy:0.6648936170212766 train loss:0.62725385, test loss:33.51063919, test precision: 0.5833956619296934,test recall: 0.5492957746478874,test f1: 0.5658324265505986\n",
      "train accuracy: 0.6729052198214286, test accuracy:0.6643337066069429 train loss:0.63027275, test loss:33.56663132, test precision: 0.5818997756170531,test recall: 0.5486600846262342,test f1: 0.5647912885662433\n",
      "train accuracy: 0.6650712567857143, test accuracy:0.6646136618141097 train loss:0.63083502, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.67402129125, test accuracy:0.6646136618141097 train loss:0.62570199, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.6736295930357142, test accuracy:0.6646136618141097 train loss:0.62618595, test loss:33.53863525, test precision: 0.5833956619296934,test recall: 0.5489092188599578,test f1: 0.5656272661348803\n",
      "train accuracy: 0.6765163548214286, test accuracy:0.6646136618141097 train loss:0.62438755, test loss:33.53863525, test precision: 0.5856394913986537,test recall: 0.5487035739313244,test f1: 0.5665701881331402\n",
      "train accuracy: 0.6732271633928572, test accuracy:0.6646136618141097 train loss:0.62426434, test loss:33.53863525, test precision: 0.5856394913986537,test recall: 0.5487035739313244,test f1: 0.5665701881331402\n",
      "train accuracy: 0.6719930460714286, test accuracy:0.6646136618141097 train loss:0.62569952, test loss:33.53863525, test precision: 0.5856394913986537,test recall: 0.5487035739313244,test f1: 0.5665701881331402\n",
      "train accuracy: 0.66852142, test accuracy:0.6651735722284434 train loss:0.62446478, test loss:33.48264313, test precision: 0.5878833208676141,test recall: 0.549266247379455,test f1: 0.5679190751445088\n",
      "train accuracy: 0.6719447544642857, test accuracy:0.6662933930571109 train loss:0.62176727, test loss:33.37066269, test precision: 0.587135377711294,test recall: 0.5508771929824562,test f1: 0.5684286748732802\n",
      "train accuracy: 0.6684194710714285, test accuracy:0.6609742441209406 train loss:0.62540154, test loss:33.90257645, test precision: 0.5991024682124159,test recall: 0.5426829268292683,test f1: 0.5694987557767507\n",
      "train accuracy: 0.6704316191071429, test accuracy:0.6609742441209406 train loss:0.6220368, test loss:33.90257645, test precision: 0.5991024682124159,test recall: 0.5426829268292683,test f1: 0.5694987557767507\n",
      "train accuracy: 0.6723257210714285, test accuracy:0.6618141097424413 train loss:0.62225584, test loss:33.81859207, test precision: 0.5983545250560958,test recall: 0.5438477226376615,test f1: 0.5698005698005698\n",
      "train accuracy: 0.6673838857142858, test accuracy:0.6620940649496081 train loss:0.62555452, test loss:33.79059601, test precision: 0.5983545250560958,test recall: 0.54421768707483,test f1: 0.5700035625222658\n",
      "train accuracy: 0.6719984117857143, test accuracy:0.6632138857782754 train loss:0.62275184, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6728086366071429, test accuracy:0.6632138857782754 train loss:0.61913195, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.66737852, test accuracy:0.6632138857782754 train loss:0.62503679, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6753734546428571, test accuracy:0.6632138857782754 train loss:0.61840359, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6737691019642857, test accuracy:0.6632138857782754 train loss:0.61944154, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6692565246428571, test accuracy:0.6632138857782754 train loss:0.62114905, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6795801853571428, test accuracy:0.6632138857782754 train loss:0.61626559, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6775358430357142, test accuracy:0.6632138857782754 train loss:0.6174529, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6768275669642857, test accuracy:0.6632138857782754 train loss:0.61929739, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6728247339285715, test accuracy:0.6632138857782754 train loss:0.62051572, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6619001116071429, test accuracy:0.6632138857782754 train loss:0.62159746, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6793601905357143, test accuracy:0.6632138857782754 train loss:0.61241393, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6735652042857143, test accuracy:0.6632138857782754 train loss:0.6188175, test loss:33.67861176, test precision: 0.5968586387434555,test recall: 0.5458276333789329,test f1: 0.570203644158628\n",
      "train accuracy: 0.6673731541071428, test accuracy:0.6626539753639418 train loss:0.62039593, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6710862380357143, test accuracy:0.6626539753639418 train loss:0.61930878, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6797465230357143, test accuracy:0.6629339305711086 train loss:0.6142699, test loss:33.70660782, test precision: 0.5976065818997757,test recall: 0.5453924914675768,test f1: 0.5703069236259816\n",
      "train accuracy: 0.67346862125, test accuracy:0.6626539753639418 train loss:0.61700794, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6664448832142857, test accuracy:0.6634938409854423 train loss:0.61819005, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.67474029875, test accuracy:0.6634938409854423 train loss:0.61457797, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6649156507142857, test accuracy:0.6634938409854423 train loss:0.61878654, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6763607485714286, test accuracy:0.6632138857782754 train loss:0.61184999, test loss:33.67861176, test precision: 0.5983545250560958,test recall: 0.5457025920873124,test f1: 0.5708169818052087\n",
      "train accuracy: 0.6727335164285714, test accuracy:0.6634938409854423 train loss:0.61444112, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6717086625, test accuracy:0.6632138857782754 train loss:0.61294959, test loss:33.67861176, test precision: 0.5983545250560958,test recall: 0.5457025920873124,test f1: 0.5708169818052087\n",
      "train accuracy: 0.67724609375, test accuracy:0.6632138857782754 train loss:0.61077789, test loss:33.67861176, test precision: 0.5983545250560958,test recall: 0.5457025920873124,test f1: 0.5708169818052087\n",
      "train accuracy: 0.6752822373214286, test accuracy:0.6634938409854423 train loss:0.61346442, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6761300223214286, test accuracy:0.6637737961926092 train loss:0.61042139, test loss:33.62261963, test precision: 0.5976065818997757,test recall: 0.5465116279069767,test f1: 0.570918185066095\n",
      "train accuracy: 0.6799665178571429, test accuracy:0.6634938409854423 train loss:0.61210834, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6785875257142857, test accuracy:0.6634938409854423 train loss:0.61076688, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6750837053571429, test accuracy:0.6634938409854423 train loss:0.61209751, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6782655821428571, test accuracy:0.6634938409854423 train loss:0.61067912, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6725618132142858, test accuracy:0.6654535274356103 train loss:0.61322578, test loss:33.45464706, test precision: 0.5976065818997757,test recall: 0.5487637362637363,test f1: 0.5721446473326173\n",
      "train accuracy: 0.6811040521428572, test accuracy:0.6654535274356103 train loss:0.60609143, test loss:33.45464706, test precision: 0.5976065818997757,test recall: 0.5487637362637363,test f1: 0.5721446473326173\n",
      "train accuracy: 0.6700077266071428, test accuracy:0.6646136618141097 train loss:0.61759652, test loss:33.53863525, test precision: 0.599850411368736,test recall: 0.5474402730375426,test f1: 0.5724482512491077\n",
      "train accuracy: 0.6800040780357143, test accuracy:0.6654535274356103 train loss:0.61076793, test loss:33.45464706, test precision: 0.5976065818997757,test recall: 0.5487637362637363,test f1: 0.5721446473326173\n",
      "train accuracy: 0.6754271119642857, test accuracy:0.6654535274356103 train loss:0.60947572, test loss:33.45464706, test precision: 0.5976065818997757,test recall: 0.5487637362637363,test f1: 0.5721446473326173\n",
      "train accuracy: 0.6744129892857142, test accuracy:0.6654535274356103 train loss:0.61153696, test loss:33.45464706, test precision: 0.5976065818997757,test recall: 0.5487637362637363,test f1: 0.5721446473326173\n",
      "train accuracy: 0.6753090658928571, test accuracy:0.6646136618141097 train loss:0.60923745, test loss:33.53863525, test precision: 0.599850411368736,test recall: 0.5474402730375426,test f1: 0.5724482512491077\n",
      "train accuracy: 0.6728891226785715, test accuracy:0.6654535274356103 train loss:0.61151611, test loss:33.45464706, test precision: 0.5953627524308153,test recall: 0.5489655172413793,test f1: 0.5712235378543237\n",
      "train accuracy: 0.66962676, test accuracy:0.6651735722284434 train loss:0.61260727, test loss:33.48264313, test precision: 0.5953627524308153,test recall: 0.5485871812543074,test f1: 0.5710186513629841\n",
      "train accuracy: 0.6731466775, test accuracy:0.666013437849944 train loss:0.61111576, test loss:33.39865875, test precision: 0.5916230366492147,test recall: 0.5500695410292072,test f1: 0.57009009009009\n",
      "train accuracy: 0.67860898875, test accuracy:0.6654535274356103 train loss:0.60986518, test loss:33.45464706, test precision: 0.5953627524308153,test recall: 0.5489655172413793,test f1: 0.5712235378543237\n",
      "train accuracy: 0.6769080528571428, test accuracy:0.6662933930571109 train loss:0.60755637, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6793118991071428, test accuracy:0.6651735722284434 train loss:0.60940796, test loss:33.48264313, test precision: 0.5983545250560958,test recall: 0.5483207676490747,test f1: 0.5722460658082976\n",
      "train accuracy: 0.6795533567857143, test accuracy:0.6651735722284434 train loss:0.60606644, test loss:33.48264313, test precision: 0.5983545250560958,test recall: 0.5483207676490747,test f1: 0.5722460658082976\n",
      "train accuracy: 0.6754056491071428, test accuracy:0.6651735722284434 train loss:0.60908534, test loss:33.48264313, test precision: 0.5983545250560958,test recall: 0.5483207676490747,test f1: 0.5722460658082976\n",
      "train accuracy: 0.6784533825, test accuracy:0.6651735722284434 train loss:0.60866453, test loss:33.48264313, test precision: 0.5983545250560958,test recall: 0.5483207676490747,test f1: 0.5722460658082976\n",
      "train accuracy: 0.6718803657142857, test accuracy:0.666013437849944 train loss:0.61307346, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6748637105357143, test accuracy:0.666013437849944 train loss:0.60967584, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6830464457142857, test accuracy:0.666013437849944 train loss:0.60314248, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6824347526785715, test accuracy:0.666013437849944 train loss:0.60470924, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6822201235714286, test accuracy:0.666013437849944 train loss:0.60322897, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6721271892857142, test accuracy:0.666013437849944 train loss:0.61030362, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6739890967857143, test accuracy:0.666013437849944 train loss:0.60721683, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6746812757142857, test accuracy:0.666013437849944 train loss:0.606194, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.6765431833928571, test accuracy:0.6662933930571109 train loss:0.60592774, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6879238925, test accuracy:0.6662933930571109 train loss:0.59879297, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6747671273214285, test accuracy:0.6662933930571109 train loss:0.6105017, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6771656078571429, test accuracy:0.6662933930571109 train loss:0.60462067, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6732593578571429, test accuracy:0.6662933930571109 train loss:0.61003305, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6797035971428571, test accuracy:0.6662933930571109 train loss:0.60503634, test loss:33.37066269, test precision: 0.5976065818997757,test recall: 0.5498967653131452,test f1: 0.5727598566308244\n",
      "train accuracy: 0.6785767942857143, test accuracy:0.666013437849944 train loss:0.60420785, test loss:33.39865875, test precision: 0.5983545250560958,test recall: 0.5494505494505495,test f1: 0.5728607232366631\n",
      "train accuracy: 0.68196256875, test accuracy:0.6634938409854423 train loss:0.60363822, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6787860576785715, test accuracy:0.6634938409854423 train loss:0.60433902, test loss:33.65061569, test precision: 0.5991024682124159,test recall: 0.5460122699386503,test f1: 0.5713266761768901\n",
      "train accuracy: 0.6834971669642858, test accuracy:0.666013437849944 train loss:0.60294296, test loss:33.39865875, test precision: 0.5968586387434555,test recall: 0.5495867768595041,test f1: 0.5722481176048763\n",
      "train accuracy: 0.6798699348214285, test accuracy:0.6657334826427772 train loss:0.60297782, test loss:33.426651, test precision: 0.5961106955871354,test recall: 0.549276361130255,test f1: 0.5717360114777619\n",
      "train accuracy: 0.6686287344642857, test accuracy:0.6637737961926092 train loss:0.60840417, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6804762619642857, test accuracy:0.6637737961926092 train loss:0.60274627, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6835722871428571, test accuracy:0.6637737961926092 train loss:0.60416219, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6794353107142858, test accuracy:0.6637737961926092 train loss:0.60312222, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6811094178571429, test accuracy:0.6637737961926092 train loss:0.60234925, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6756900326785714, test accuracy:0.6646136618141097 train loss:0.60679005, test loss:33.53863525, test precision: 0.5976065818997757,test recall: 0.5476353666895134,test f1: 0.5715307582260372\n",
      "train accuracy: 0.6739998282142857, test accuracy:0.6637737961926092 train loss:0.60834638, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6743432348214285, test accuracy:0.6646136618141097 train loss:0.60543358, test loss:33.53863525, test precision: 0.5976065818997757,test recall: 0.5476353666895134,test f1: 0.5715307582260372\n",
      "train accuracy: 0.67737487125, test accuracy:0.6637737961926092 train loss:0.60532231, test loss:33.62261963, test precision: 0.5983545250560958,test recall: 0.546448087431694,test f1: 0.5712245626561943\n",
      "train accuracy: 0.6688648266071429, test accuracy:0.6634938409854423 train loss:0.61151232, test loss:33.65061569, test precision: 0.5983545250560958,test recall: 0.5460750853242321,test f1: 0.5710206995003569\n",
      "train accuracy: 0.6701901614285715, test accuracy:0.6646136618141097 train loss:0.6097022, test loss:33.53863525, test precision: 0.5976065818997757,test recall: 0.5476353666895134,test f1: 0.5715307582260372\n",
      "train accuracy: 0.67779876375, test accuracy:0.6657334826427772 train loss:0.60606887, test loss:33.426651, test precision: 0.5953627524308153,test recall: 0.549344375431332,test f1: 0.5714285714285715\n",
      "train accuracy: 0.6823596325, test accuracy:0.6657334826427772 train loss:0.59966627, test loss:33.426651, test precision: 0.5953627524308153,test recall: 0.549344375431332,test f1: 0.5714285714285715\n",
      "train accuracy: 0.6754646719642857, test accuracy:0.6657334826427772 train loss:0.60796088, test loss:33.426651, test precision: 0.5953627524308153,test recall: 0.549344375431332,test f1: 0.5714285714285715\n",
      "train accuracy: 0.6748368817857143, test accuracy:0.6654535274356103 train loss:0.6053052, test loss:33.45464706, test precision: 0.5953627524308153,test recall: 0.5489655172413793,test f1: 0.5712235378543237\n",
      "train accuracy: 0.6768812242857143, test accuracy:0.6654535274356103 train loss:0.60517025, test loss:33.45464706, test precision: 0.5953627524308153,test recall: 0.5489655172413793,test f1: 0.5712235378543237\n",
      "train accuracy: 0.6724759616071428, test accuracy:0.6651735722284434 train loss:0.60419844, test loss:33.48264313, test precision: 0.5953627524308153,test recall: 0.5485871812543074,test f1: 0.5710186513629841\n",
      "train accuracy: 0.6740266569642858, test accuracy:0.6671332586786114 train loss:0.60606694, test loss:33.2866745, test precision: 0.6095736724008975,test recall: 0.5499325236167342,test f1: 0.5782192266761262\n",
      "train accuracy: 0.6816513564285714, test accuracy:0.6671332586786114 train loss:0.60296557, test loss:33.2866745, test precision: 0.6095736724008975,test recall: 0.5499325236167342,test f1: 0.5782192266761262\n",
      "train accuracy: 0.6808840573214285, test accuracy:0.6671332586786114 train loss:0.60479673, test loss:33.2866745, test precision: 0.6095736724008975,test recall: 0.5499325236167342,test f1: 0.5782192266761262\n",
      "train accuracy: 0.67936555625, test accuracy:0.6665733482642777 train loss:0.60481801, test loss:33.34266663, test precision: 0.5953627524308153,test recall: 0.5504840940525588,test f1: 0.5720445562342795\n",
      "train accuracy: 0.6839693508928572, test accuracy:0.6685330347144457 train loss:0.6004554, test loss:33.146698, test precision: 0.6095736724008975,test recall: 0.5517941773865944,test f1: 0.5792466240227434\n",
      "train accuracy: 0.6767363496428571, test accuracy:0.6693729003359462 train loss:0.60674437, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.68229524375, test accuracy:0.6693729003359462 train loss:0.60240999, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6803528503571429, test accuracy:0.6690929451287794 train loss:0.6012876, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6849137191071428, test accuracy:0.6693729003359462 train loss:0.5980183, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6815708705357143, test accuracy:0.6690929451287794 train loss:0.59998644, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6821718321428571, test accuracy:0.6690929451287794 train loss:0.60111406, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6846400669642857, test accuracy:0.6693729003359462 train loss:0.59940681, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6754700378571429, test accuracy:0.6693729003359462 train loss:0.60820551, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.67975188875, test accuracy:0.6690929451287794 train loss:0.60379071, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6772085335714285, test accuracy:0.6690929451287794 train loss:0.6027878, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.67991822625, test accuracy:0.6690929451287794 train loss:0.60357664, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6773051167857143, test accuracy:0.6690929451287794 train loss:0.60189938, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6781797303571429, test accuracy:0.6690929451287794 train loss:0.59868662, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6860619848214285, test accuracy:0.6690929451287794 train loss:0.60058224, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6858956473214286, test accuracy:0.6690929451287794 train loss:0.59406385, test loss:33.09070587, test precision: 0.6088257292445775,test recall: 0.5526137135098439,test f1: 0.5793594306049823\n",
      "train accuracy: 0.6825635301785714, test accuracy:0.6688129899216125 train loss:0.59910423, test loss:33.11870193, test precision: 0.6088257292445775,test recall: 0.5522388059701493,test f1: 0.5791533262184276\n",
      "train accuracy: 0.6855629721428571, test accuracy:0.6682530795072789 train loss:0.59850783, test loss:33.17469406, test precision: 0.6148092744951383,test recall: 0.5509383378016086,test f1: 0.5811240721102863\n",
      "train accuracy: 0.6856166294642857, test accuracy:0.6682530795072789 train loss:0.60027427, test loss:33.17469406, test precision: 0.6148092744951383,test recall: 0.5509383378016086,test f1: 0.5811240721102863\n",
      "train accuracy: 0.6901614010714285, test accuracy:0.6682530795072789 train loss:0.59857003, test loss:33.17469406, test precision: 0.6148092744951383,test recall: 0.5509383378016086,test f1: 0.5811240721102863\n",
      "train accuracy: 0.6826601133928571, test accuracy:0.6688129899216125 train loss:0.60230165, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6871834219642857, test accuracy:0.6688129899216125 train loss:0.59756307, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6827137705357142, test accuracy:0.6696528555431132 train loss:0.59958913, test loss:33.03471375, test precision: 0.6088257292445775,test recall: 0.5533650577838205,test f1: 0.5797720797720798\n",
      "train accuracy: 0.6867756267857142, test accuracy:0.6688129899216125 train loss:0.59445373, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6783836280357143, test accuracy:0.6688129899216125 train loss:0.60233596, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.683336195, test accuracy:0.6685330347144457 train loss:0.5976604, test loss:33.146698, test precision: 0.6148092744951383,test recall: 0.5513078470824949,test f1: 0.5813295615275813\n",
      "train accuracy: 0.6808089371428572, test accuracy:0.6688129899216125 train loss:0.60099423, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6848385989285715, test accuracy:0.6688129899216125 train loss:0.59862419, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.67988066625, test accuracy:0.6688129899216125 train loss:0.59975632, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6837117960714286, test accuracy:0.6688129899216125 train loss:0.60072092, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6758778330357142, test accuracy:0.6685330347144457 train loss:0.6022214, test loss:33.146698, test precision: 0.6148092744951383,test recall: 0.5513078470824949,test f1: 0.5813295615275813\n",
      "train accuracy: 0.6776538891071429, test accuracy:0.6685330347144457 train loss:0.6051488, test loss:33.146698, test precision: 0.6148092744951383,test recall: 0.5513078470824949,test f1: 0.5813295615275813\n",
      "train accuracy: 0.6890131353571428, test accuracy:0.6688129899216125 train loss:0.59751202, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6751373626785714, test accuracy:0.6707726763717805 train loss:0.60486655, test loss:32.92273331, test precision: 0.6140613313388182,test recall: 0.5543551654287644,test f1: 0.5826827537260468\n",
      "train accuracy: 0.6766344007142857, test accuracy:0.6707726763717805 train loss:0.60300101, test loss:32.92273331, test precision: 0.6140613313388182,test recall: 0.5543551654287644,test f1: 0.5826827537260468\n",
      "train accuracy: 0.6865180717857143, test accuracy:0.6704927211646137 train loss:0.5984692, test loss:32.95072937, test precision: 0.6133133881824981,test recall: 0.5540540540540541,test f1: 0.58217962371317\n",
      "train accuracy: 0.6862444196428571, test accuracy:0.6688129899216125 train loss:0.59728828, test loss:33.11870193, test precision: 0.6148092744951383,test recall: 0.5516778523489932,test f1: 0.5815351963211884\n",
      "train accuracy: 0.6786036228571428, test accuracy:0.6707726763717805 train loss:0.59988398, test loss:32.92273331, test precision: 0.6140613313388182,test recall: 0.5543551654287644,test f1: 0.5826827537260468\n",
      "train accuracy: 0.6747349330357143, test accuracy:0.6704927211646137 train loss:0.60308025, test loss:32.95072937, test precision: 0.6140613313388182,test recall: 0.5539811066126855,test f1: 0.5824760553387726\n",
      "train accuracy: 0.6771226819642857, test accuracy:0.6682530795072789 train loss:0.60197171, test loss:33.17469406, test precision: 0.6140613313388182,test recall: 0.5510067114093959,test f1: 0.5808277325787053\n",
      "train accuracy: 0.6825635301785714, test accuracy:0.6682530795072789 train loss:0.59615479, test loss:33.17469406, test precision: 0.6140613313388182,test recall: 0.5510067114093959,test f1: 0.5808277325787053\n",
      "train accuracy: 0.6802669985714286, test accuracy:0.6682530795072789 train loss:0.59919784, test loss:33.17469406, test precision: 0.6140613313388182,test recall: 0.5510067114093959,test f1: 0.5808277325787053\n",
      "train accuracy: 0.68255279875, test accuracy:0.6682530795072789 train loss:0.59873993, test loss:33.17469406, test precision: 0.6140613313388182,test recall: 0.5510067114093959,test f1: 0.5808277325787053\n",
      "train accuracy: 0.6784372853571429, test accuracy:0.66993281075028 train loss:0.60155831, test loss:33.0067215, test precision: 0.6133133881824981,test recall: 0.553306342780027,test f1: 0.5817665838949982\n",
      "train accuracy: 0.6832879035714285, test accuracy:0.66993281075028 train loss:0.59789479, test loss:33.0067215, test precision: 0.6133133881824981,test recall: 0.553306342780027,test f1: 0.5817665838949982\n",
      "train accuracy: 0.6809645432142857, test accuracy:0.66993281075028 train loss:0.59892408, test loss:33.0067215, test precision: 0.6133133881824981,test recall: 0.553306342780027,test f1: 0.5817665838949982\n",
      "train accuracy: 0.6842322716071428, test accuracy:0.6682530795072789 train loss:0.59688388, test loss:33.17469406, test precision: 0.6140613313388182,test recall: 0.5510067114093959,test f1: 0.5808277325787053\n",
      "train accuracy: 0.6767041551785714, test accuracy:0.66993281075028 train loss:0.59858329, test loss:33.0067215, test precision: 0.6133133881824981,test recall: 0.553306342780027,test f1: 0.5817665838949982\n",
      "train accuracy: 0.6785338683928571, test accuracy:0.6704927211646137 train loss:0.60135728, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6861746651785714, test accuracy:0.6704927211646137 train loss:0.59643831, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6819411057142857, test accuracy:0.6704927211646137 train loss:0.5992825, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6765056232142858, test accuracy:0.6704927211646137 train loss:0.6008499, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6833791208928571, test accuracy:0.6704927211646137 train loss:0.59715056, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6792314130357143, test accuracy:0.6704927211646137 train loss:0.60108649, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6846078726785715, test accuracy:0.6721724524076148 train loss:0.59632886, test loss:32.78275681, test precision: 0.6103216155572176,test recall: 0.5566166439290586,test f1: 0.5822333214413129\n",
      "train accuracy: 0.6815279446428572, test accuracy:0.6704927211646137 train loss:0.59877822, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6795426253571428, test accuracy:0.6704927211646137 train loss:0.60245122, test loss:32.95072937, test precision: 0.6103216155572176,test recall: 0.5543478260869565,test f1: 0.5809896760412958\n",
      "train accuracy: 0.6741071428571429, test accuracy:0.6721724524076148 train loss:0.60443184, test loss:32.78275681, test precision: 0.6103216155572176,test recall: 0.5566166439290586,test f1: 0.5822333214413129\n",
      "train accuracy: 0.6753197973214285, test accuracy:0.6721724524076148 train loss:0.60384559, test loss:32.78275681, test precision: 0.6103216155572176,test recall: 0.5566166439290586,test f1: 0.5822333214413129\n",
      "train accuracy: 0.67848021125, test accuracy:0.6724524076147816 train loss:0.6005495, test loss:32.75476074, test precision: 0.6103216155572176,test recall: 0.5569965870307167,test f1: 0.5824411134903641\n",
      "train accuracy: 0.6798860319642858, test accuracy:0.6724524076147816 train loss:0.6007841, test loss:32.75476074, test precision: 0.6103216155572176,test recall: 0.5569965870307167,test f1: 0.5824411134903641\n",
      "train accuracy: 0.6759368560714286, test accuracy:0.6724524076147816 train loss:0.59985175, test loss:32.75476074, test precision: 0.6103216155572176,test recall: 0.5569965870307167,test f1: 0.5824411134903641\n",
      "train accuracy: 0.6755827180357142, test accuracy:0.6721724524076148 train loss:0.6029744, test loss:32.78275681, test precision: 0.6103216155572176,test recall: 0.5566166439290586,test f1: 0.5822333214413129\n",
      "train accuracy: 0.6759475875, test accuracy:0.6721724524076148 train loss:0.59995384, test loss:32.78275681, test precision: 0.6103216155572176,test recall: 0.5566166439290586,test f1: 0.5822333214413129\n",
      "train accuracy: 0.6803957760714285, test accuracy:0.6704927211646137 train loss:0.59677439, test loss:32.95072937, test precision: 0.6110695587135377,test recall: 0.5542740841248304,test f1: 0.5812877979366773\n",
      "train accuracy: 0.6849029876785714, test accuracy:0.6730123180291153 train loss:0.59474068, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6790489783928572, test accuracy:0.6730123180291153 train loss:0.60063974, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6797465230357143, test accuracy:0.6713325867861142 train loss:0.59646885, test loss:32.86674118, test precision: 0.6043380703066566,test recall: 0.5560908465244322,test f1: 0.5792114695340502\n",
      "train accuracy: 0.6906443166071429, test accuracy:0.6710526315789473 train loss:0.59249369, test loss:32.89473724, test precision: 0.6043380703066566,test recall: 0.5557083906464925,test f1: 0.579003941239699\n",
      "train accuracy: 0.6812972183928572, test accuracy:0.6702127659574468 train loss:0.60112327, test loss:32.97872543, test precision: 0.6103216155572176,test recall: 0.5539714867617108,test f1: 0.5807829181494663\n",
      "train accuracy: 0.6865931919642857, test accuracy:0.6710526315789473 train loss:0.59522379, test loss:32.89473724, test precision: 0.6035901271503366,test recall: 0.5557851239669421,test f1: 0.5787020437432772\n",
      "train accuracy: 0.6854878519642857, test accuracy:0.6713325867861142 train loss:0.59287409, test loss:32.86674118, test precision: 0.6043380703066566,test recall: 0.5560908465244322,test f1: 0.5792114695340502\n",
      "train accuracy: 0.6872907366071429, test accuracy:0.671612541993281 train loss:0.59410699, test loss:32.83874512, test precision: 0.606581899775617,test recall: 0.556241426611797,test f1: 0.5803220035778176\n",
      "train accuracy: 0.6841356885714286, test accuracy:0.6732922732362822 train loss:0.59695792, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6776968148214285, test accuracy:0.6732922732362822 train loss:0.59947534, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6827245021428572, test accuracy:0.6732922732362822 train loss:0.59876353, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6831913203571428, test accuracy:0.6732922732362822 train loss:0.59755119, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6869044041071428, test accuracy:0.6727323628219485 train loss:0.59546403, test loss:32.72676468, test precision: 0.612565445026178,test recall: 0.5571428571428572,test f1: 0.5835411471321696\n",
      "train accuracy: 0.68369569875, test accuracy:0.6727323628219485 train loss:0.59578541, test loss:32.72676468, test precision: 0.612565445026178,test recall: 0.5571428571428572,test f1: 0.5835411471321696\n",
      "train accuracy: 0.6936115642857142, test accuracy:0.6732922732362822 train loss:0.58888042, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6876395089285714, test accuracy:0.6732922732362822 train loss:0.59372726, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6867756267857142, test accuracy:0.6732922732362822 train loss:0.59293231, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6859224758928572, test accuracy:0.6732922732362822 train loss:0.59531073, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6856649210714286, test accuracy:0.6732922732362822 train loss:0.59470181, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6853912689285714, test accuracy:0.6732922732362822 train loss:0.59423091, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6848385989285715, test accuracy:0.6732922732362822 train loss:0.59590927, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6839639851785714, test accuracy:0.6732922732362822 train loss:0.59487659, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6835508241071429, test accuracy:0.6732922732362822 train loss:0.59720074, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6816620878571429, test accuracy:0.6721724524076148 train loss:0.60250351, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6820645175, test accuracy:0.6704927211646137 train loss:0.59586805, test loss:32.95072937, test precision: 0.606581899775617,test recall: 0.554719562243502,test f1: 0.5794926759556985\n",
      "train accuracy: 0.6800791982142858, test accuracy:0.6674132138857782 train loss:0.59670664, test loss:33.25867844, test precision: 0.6073298429319371,test recall: 0.5505084745762712,test f1: 0.577524893314367\n",
      "train accuracy: 0.6845756782142857, test accuracy:0.6674132138857782 train loss:0.59778119, test loss:33.25867844, test precision: 0.6073298429319371,test recall: 0.5505084745762712,test f1: 0.577524893314367\n",
      "train accuracy: 0.6803689475, test accuracy:0.6674132138857782 train loss:0.59968614, test loss:33.25867844, test precision: 0.6073298429319371,test recall: 0.5505084745762712,test f1: 0.577524893314367\n",
      "train accuracy: 0.6864429516071429, test accuracy:0.6704927211646137 train loss:0.5923155, test loss:32.95072937, test precision: 0.606581899775617,test recall: 0.554719562243502,test f1: 0.5794926759556985\n",
      "train accuracy: 0.6859707675, test accuracy:0.6707726763717805 train loss:0.59343241, test loss:32.92273331, test precision: 0.6080777860882572,test recall: 0.5549488054607509,test f1: 0.5802997858672376\n",
      "train accuracy: 0.6872478107142858, test accuracy:0.6676931690929452 train loss:0.59659182, test loss:33.23068237, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6845381182142857, test accuracy:0.6676931690929452 train loss:0.59643157, test loss:33.23068237, test precision: 0.6095736724008975,test recall: 0.5506756756756757,test f1: 0.5786297479588215\n",
      "train accuracy: 0.6865288032142857, test accuracy:0.6676931690929452 train loss:0.59774458, test loss:33.23068237, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6860458876785714, test accuracy:0.6676931690929452 train loss:0.59554326, test loss:33.23068237, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6814689217857143, test accuracy:0.6676931690929452 train loss:0.60081121, test loss:33.23068237, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6847527473214285, test accuracy:0.6676931690929452 train loss:0.59428124, test loss:33.23068237, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6876180460714286, test accuracy:0.6685330347144457 train loss:0.59254792, test loss:33.146698, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.6915296617857143, test accuracy:0.6685330347144457 train loss:0.59179496, test loss:33.146698, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.6885516826785715, test accuracy:0.6732922732362822 train loss:0.59347209, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6816889166071428, test accuracy:0.6702127659574468 train loss:0.59551134, test loss:32.97872543, test precision: 0.6073298429319371,test recall: 0.5542662116040956,test f1: 0.5795860099928622\n",
      "train accuracy: 0.6891365469642857, test accuracy:0.6702127659574468 train loss:0.59257064, test loss:32.97872543, test precision: 0.6073298429319371,test recall: 0.5542662116040956,test f1: 0.5795860099928622\n",
      "train accuracy: 0.6831752232142857, test accuracy:0.6702127659574468 train loss:0.5934194, test loss:32.97872543, test precision: 0.6073298429319371,test recall: 0.5542662116040956,test f1: 0.5795860099928622\n",
      "train accuracy: 0.6755290607142858, test accuracy:0.6702127659574468 train loss:0.59763527, test loss:32.97872543, test precision: 0.6073298429319371,test recall: 0.5542662116040956,test f1: 0.5795860099928622\n",
      "train accuracy: 0.6847581130357143, test accuracy:0.6702127659574468 train loss:0.59390954, test loss:32.97872543, test precision: 0.6073298429319371,test recall: 0.5542662116040956,test f1: 0.5795860099928622\n",
      "train accuracy: 0.6854556576785714, test accuracy:0.6685330347144457 train loss:0.59530702, test loss:33.146698, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.69023652125, test accuracy:0.6685330347144457 train loss:0.58963609, test loss:33.146698, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.691663805, test accuracy:0.6682530795072789 train loss:0.58733509, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6859224758928572, test accuracy:0.6682530795072789 train loss:0.59605609, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6868292839285715, test accuracy:0.6682530795072789 train loss:0.59349378, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6851337139285715, test accuracy:0.6682530795072789 train loss:0.59580309, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6800684666071428, test accuracy:0.6682530795072789 train loss:0.5976853, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6917603880357143, test accuracy:0.6682530795072789 train loss:0.59409514, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6885463169642857, test accuracy:0.6682530795072789 train loss:0.59011065, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6835776528571429, test accuracy:0.6682530795072789 train loss:0.59760199, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6816620878571429, test accuracy:0.6682530795072789 train loss:0.59621443, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6882136417857143, test accuracy:0.6682530795072789 train loss:0.59408058, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6776914491071429, test accuracy:0.6682530795072789 train loss:0.59960111, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6831913203571428, test accuracy:0.6682530795072789 train loss:0.59476881, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6857990642857142, test accuracy:0.6682530795072789 train loss:0.59133642, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6891794728571429, test accuracy:0.6682530795072789 train loss:0.59141483, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.68489225625, test accuracy:0.6682530795072789 train loss:0.59462309, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.69618711375, test accuracy:0.6682530795072789 train loss:0.58586651, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6879453553571429, test accuracy:0.6682530795072789 train loss:0.59096173, test loss:33.17469406, test precision: 0.6073298429319371,test recall: 0.5516304347826086,test f1: 0.5781416874332502\n",
      "train accuracy: 0.6862444196428571, test accuracy:0.6730123180291153 train loss:0.58971987, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6848332332142857, test accuracy:0.6746920492721165 train loss:0.59223318, test loss:32.53079605, test precision: 0.6043380703066566,test recall: 0.5607217210270645,test f1: 0.5817134629229661\n",
      "train accuracy: 0.6808786916071429, test accuracy:0.6713325867861142 train loss:0.59656136, test loss:32.86674118, test precision: 0.606581899775617,test recall: 0.5558601782042495,test f1: 0.5801144492131617\n",
      "train accuracy: 0.6868561126785714, test accuracy:0.6682530795072789 train loss:0.59124463, test loss:33.17469406, test precision: 0.6080777860882572,test recall: 0.5515603799185889,test f1: 0.5784418356456776\n",
      "train accuracy: 0.6844522664285714, test accuracy:0.6713325867861142 train loss:0.59538247, test loss:32.86674118, test precision: 0.606581899775617,test recall: 0.5558601782042495,test f1: 0.5801144492131617\n",
      "train accuracy: 0.6883209564285714, test accuracy:0.6713325867861142 train loss:0.58908506, test loss:32.86674118, test precision: 0.606581899775617,test recall: 0.5558601782042495,test f1: 0.5801144492131617\n",
      "train accuracy: 0.6870975703571428, test accuracy:0.6713325867861142 train loss:0.59265152, test loss:32.86674118, test precision: 0.606581899775617,test recall: 0.5558601782042495,test f1: 0.5801144492131617\n",
      "train accuracy: 0.6881921789285714, test accuracy:0.6730123180291153 train loss:0.59519456, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6946203210714286, test accuracy:0.6730123180291153 train loss:0.58656725, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6859224758928572, test accuracy:0.6730123180291153 train loss:0.59309843, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6825206044642858, test accuracy:0.6685330347144457 train loss:0.59239722, test loss:33.146698, test precision: 0.605833956619297,test recall: 0.5521472392638037,test f1: 0.5777460770328102\n",
      "train accuracy: 0.6770100017857142, test accuracy:0.6682530795072789 train loss:0.59797113, test loss:33.17469406, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6785070398214286, test accuracy:0.6682530795072789 train loss:0.59789659, test loss:33.17469406, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6833147321428571, test accuracy:0.6730123180291153 train loss:0.59049514, test loss:32.69876862, test precision: 0.6043380703066566,test recall: 0.5583966827919834,test f1: 0.5804597701149424\n",
      "train accuracy: 0.6851390796428571, test accuracy:0.6682530795072789 train loss:0.589813, test loss:33.17469406, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6832879035714285, test accuracy:0.6682530795072789 train loss:0.59501356, test loss:33.17469406, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6919106283928571, test accuracy:0.6682530795072789 train loss:0.5868029, test loss:33.17469406, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6834435096428572, test accuracy:0.66993281075028 train loss:0.59060542, test loss:33.0067215, test precision: 0.605833956619297,test recall: 0.5540355677154583,test f1: 0.5787781350482315\n",
      "train accuracy: 0.6842269058928572, test accuracy:0.6702127659574468 train loss:0.59513294, test loss:32.97872543, test precision: 0.605833956619297,test recall: 0.5544147843942505,test f1: 0.5789849892780558\n",
      "train accuracy: 0.6845971410714285, test accuracy:0.6758118701007839 train loss:0.59271943, test loss:32.41881561, test precision: 0.6028421839940165,test recall: 0.5624563852058618,test f1: 0.5819494584837546\n",
      "train accuracy: 0.6829176682142857, test accuracy:0.6758118701007839 train loss:0.59427228, test loss:32.41881561, test precision: 0.6028421839940165,test recall: 0.5624563852058618,test f1: 0.5819494584837546\n",
      "train accuracy: 0.688347785, test accuracy:0.6738521836506159 train loss:0.59083401, test loss:32.61478424, test precision: 0.605833956619297,test recall: 0.5593922651933702,test f1: 0.5816876122082586\n",
      "train accuracy: 0.6896301941071429, test accuracy:0.6738521836506159 train loss:0.59013835, test loss:32.61478424, test precision: 0.605833956619297,test recall: 0.5593922651933702,test f1: 0.5816876122082586\n",
      "train accuracy: 0.6871136675, test accuracy:0.6766517357222844 train loss:0.59410727, test loss:32.33482742, test precision: 0.6028421839940165,test recall: 0.5636363636363636,test f1: 0.5825804119985544\n",
      "train accuracy: 0.6783621651785714, test accuracy:0.6721724524076148 train loss:0.59832582, test loss:32.78275681, test precision: 0.6073298429319371,test recall: 0.5569272976680384,test f1: 0.5810375670840787\n",
      "train accuracy: 0.6847473816071429, test accuracy:0.6749720044792833 train loss:0.59584856, test loss:32.50279999, test precision: 0.6043380703066566,test recall: 0.5611111111111111,test f1: 0.5819229384227584\n",
      "train accuracy: 0.6824079241071429, test accuracy:0.6721724524076148 train loss:0.59383404, test loss:32.78275681, test precision: 0.6073298429319371,test recall: 0.5569272976680384,test f1: 0.5810375670840787\n",
      "train accuracy: 0.6874517083928572, test accuracy:0.6724524076147816 train loss:0.59035016, test loss:32.75476074, test precision: 0.6080777860882572,test recall: 0.5572309801233721,test f1: 0.5815450643776824\n",
      "train accuracy: 0.6839425223214286, test accuracy:0.6693729003359462 train loss:0.59217061, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.68450592375, test accuracy:0.6724524076147816 train loss:0.59018518, test loss:32.75476074, test precision: 0.6080777860882572,test recall: 0.5572309801233721,test f1: 0.5815450643776824\n",
      "train accuracy: 0.6848332332142857, test accuracy:0.6724524076147816 train loss:0.58866513, test loss:32.75476074, test precision: 0.6080777860882572,test recall: 0.5572309801233721,test f1: 0.5815450643776824\n",
      "train accuracy: 0.6835454583928572, test accuracy:0.6693729003359462 train loss:0.59106547, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6929945055357143, test accuracy:0.6724524076147816 train loss:0.58742306, test loss:32.75476074, test precision: 0.6080777860882572,test recall: 0.5572309801233721,test f1: 0.5815450643776824\n",
      "train accuracy: 0.6869365985714285, test accuracy:0.6707726763717805 train loss:0.59078976, test loss:32.92273331, test precision: 0.6103216155572176,test recall: 0.5547246770904147,test f1: 0.5811965811965812\n",
      "train accuracy: 0.6823971926785715, test accuracy:0.6674132138857782 train loss:0.59188188, test loss:33.25867844, test precision: 0.6110695587135377,test recall: 0.5501683501683502,test f1: 0.5790219702338768\n",
      "train accuracy: 0.6909447973214285, test accuracy:0.6693729003359462 train loss:0.58591538, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6902311555357142, test accuracy:0.6693729003359462 train loss:0.58962114, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6883531507142857, test accuracy:0.6693729003359462 train loss:0.58845157, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6802187071428571, test accuracy:0.6693729003359462 train loss:0.59226355, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6869956216071429, test accuracy:0.6693729003359462 train loss:0.58867909, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6904135903571429, test accuracy:0.6693729003359462 train loss:0.59032328, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6823542667857143, test accuracy:0.6693729003359462 train loss:0.59384084, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6826547476785715, test accuracy:0.6693729003359462 train loss:0.59465172, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.68694733, test accuracy:0.6693729003359462 train loss:0.58827593, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6889111864285714, test accuracy:0.6721724524076148 train loss:0.58734976, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6853698058928571, test accuracy:0.6721724524076148 train loss:0.58804173, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6928871908928571, test accuracy:0.6721724524076148 train loss:0.58726382, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6874463426785714, test accuracy:0.6693729003359462 train loss:0.58850996, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6881814475, test accuracy:0.6721724524076148 train loss:0.59155243, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6840283739285714, test accuracy:0.6693729003359462 train loss:0.59009804, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6823059753571429, test accuracy:0.6693729003359462 train loss:0.59418438, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.67741243125, test accuracy:0.6721724524076148 train loss:0.5981707, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6855254121428571, test accuracy:0.6721724524076148 train loss:0.59209014, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.68284791375, test accuracy:0.6693729003359462 train loss:0.59207164, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6851229825, test accuracy:0.6693729003359462 train loss:0.59157785, test loss:33.06270981, test precision: 0.6088257292445775,test recall: 0.5529891304347826,test f1: 0.5795656817372731\n",
      "train accuracy: 0.6911969866071429, test accuracy:0.6721724524076148 train loss:0.58868603, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6816781851785715, test accuracy:0.6721724524076148 train loss:0.59352426, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6859707675, test accuracy:0.6721724524076148 train loss:0.5898181, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6863839285714286, test accuracy:0.6721724524076148 train loss:0.59034003, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6904028589285715, test accuracy:0.6721724524076148 train loss:0.58968283, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6930481628571429, test accuracy:0.6721724524076148 train loss:0.58696381, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6919428228571428, test accuracy:0.6738521836506159 train loss:0.58695081, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6871565933928572, test accuracy:0.6721724524076148 train loss:0.58842496, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6811845380357143, test accuracy:0.6738521836506159 train loss:0.5939338, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6904833448214286, test accuracy:0.6738521836506159 train loss:0.58604815, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6908428485714285, test accuracy:0.6738521836506159 train loss:0.58781328, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6840176425, test accuracy:0.6738521836506159 train loss:0.59113769, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6896999485714286, test accuracy:0.6721724524076148 train loss:0.58716259, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6890185010714286, test accuracy:0.6721724524076148 train loss:0.59210202, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6882619333928571, test accuracy:0.6721724524076148 train loss:0.58864642, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.69202330875, test accuracy:0.6721724524076148 train loss:0.58693156, test loss:32.78275681, test precision: 0.606581899775617,test recall: 0.5570054945054945,test f1: 0.5807375581811673\n",
      "train accuracy: 0.6888199691071428, test accuracy:0.6738521836506159 train loss:0.58938169, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6886750944642858, test accuracy:0.6738521836506159 train loss:0.58877404, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6861532023214286, test accuracy:0.6738521836506159 train loss:0.58970444, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6956451751785714, test accuracy:0.6738521836506159 train loss:0.58355792, test loss:32.61478424, test precision: 0.606581899775617,test recall: 0.5593103448275862,test f1: 0.5819878005023322\n",
      "train accuracy: 0.6916101476785714, test accuracy:0.6749720044792833 train loss:0.58650919, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.69026335, test accuracy:0.6749720044792833 train loss:0.58489084, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6901935955357142, test accuracy:0.6749720044792833 train loss:0.58761468, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6835025326785714, test accuracy:0.6749720044792833 train loss:0.59206654, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6928549966071429, test accuracy:0.6749720044792833 train loss:0.5863463, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6896409255357143, test accuracy:0.6732922732362822 train loss:0.58712449, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6826869419642857, test accuracy:0.6749720044792833 train loss:0.59152154, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6889326494642857, test accuracy:0.6732922732362822 train loss:0.58899521, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6886589973214285, test accuracy:0.6732922732362822 train loss:0.58617896, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6819893973214286, test accuracy:0.6732922732362822 train loss:0.58880903, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6870278158928571, test accuracy:0.6749720044792833 train loss:0.5869426, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6866629464285714, test accuracy:0.6732922732362822 train loss:0.58705255, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6885570483928571, test accuracy:0.6732922732362822 train loss:0.5873592, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6857132125, test accuracy:0.6749720044792833 train loss:0.58814678, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.68391569375, test accuracy:0.6732922732362822 train loss:0.59027255, test loss:32.67077255, test precision: 0.606581899775617,test recall: 0.5585399449035813,test f1: 0.5815704553603442\n",
      "train accuracy: 0.6820054944642857, test accuracy:0.6749720044792833 train loss:0.5941282, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.68913118125, test accuracy:0.6730123180291153 train loss:0.58776946, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6866146548214286, test accuracy:0.6746920492721165 train loss:0.58657544, test loss:32.53079605, test precision: 0.606581899775617,test recall: 0.5604699378023497,test f1: 0.5826149425287356\n",
      "train accuracy: 0.6819411057142857, test accuracy:0.6746920492721165 train loss:0.59494596, test loss:32.53079605, test precision: 0.606581899775617,test recall: 0.5604699378023497,test f1: 0.5826149425287356\n",
      "train accuracy: 0.68518737125, test accuracy:0.6730123180291153 train loss:0.58966778, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6862497853571429, test accuracy:0.6730123180291153 train loss:0.58985132, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6863249055357142, test accuracy:0.6730123180291153 train loss:0.59046927, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6937403416071428, test accuracy:0.6730123180291153 train loss:0.58255095, test loss:32.69876862, test precision: 0.606581899775617,test recall: 0.5581555402615279,test f1: 0.5813620071684588\n",
      "train accuracy: 0.6881760817857143, test accuracy:0.6749720044792833 train loss:0.5887625, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6874731714285715, test accuracy:0.6749720044792833 train loss:0.58974899, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6822147578571428, test accuracy:0.6763717805151176 train loss:0.59222268, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6915564903571428, test accuracy:0.6763717805151176 train loss:0.58766261, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6932252317857143, test accuracy:0.6763717805151176 train loss:0.58711475, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6950925051785715, test accuracy:0.6749720044792833 train loss:0.58332836, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6887341175, test accuracy:0.6763717805151176 train loss:0.58686376, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.68870728875, test accuracy:0.6763717805151176 train loss:0.58721976, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6836527730357143, test accuracy:0.6749720044792833 train loss:0.59475503, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6896999485714286, test accuracy:0.6749720044792833 train loss:0.58714361, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6871136675, test accuracy:0.6749720044792833 train loss:0.58988491, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6826279189285714, test accuracy:0.6749720044792833 train loss:0.58935881, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6884014423214285, test accuracy:0.6749720044792833 train loss:0.58881467, test loss:32.50279999, test precision: 0.606581899775617,test recall: 0.5608575380359613,test f1: 0.5828242903341717\n",
      "train accuracy: 0.6979899982142858, test accuracy:0.6763717805151176 train loss:0.58109028, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6911057692857143, test accuracy:0.6763717805151176 train loss:0.58708743, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6836420416071428, test accuracy:0.6758118701007839 train loss:0.59436076, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6880097441071429, test accuracy:0.6749720044792833 train loss:0.59001355, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6904726133928571, test accuracy:0.6741321388577828 train loss:0.58330833, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6861156421428571, test accuracy:0.6741321388577828 train loss:0.58673218, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6928174364285714, test accuracy:0.6741321388577828 train loss:0.58413834, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6886482657142857, test accuracy:0.6741321388577828 train loss:0.58717304, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6810289319642857, test accuracy:0.6741321388577828 train loss:0.59065094, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6909608946428571, test accuracy:0.6744120940649496 train loss:0.59016711, test loss:32.55879211, test precision: 0.6140613313388182,test recall: 0.5592643051771117,test f1: 0.5853832442067736\n",
      "train accuracy: 0.6905691964285714, test accuracy:0.6744120940649496 train loss:0.58383988, test loss:32.55879211, test precision: 0.6140613313388182,test recall: 0.5592643051771117,test f1: 0.5853832442067736\n",
      "train accuracy: 0.6909501630357143, test accuracy:0.6741321388577828 train loss:0.58625025, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6925437842857143, test accuracy:0.6744120940649496 train loss:0.58515258, test loss:32.55879211, test precision: 0.6140613313388182,test recall: 0.5592643051771117,test f1: 0.5853832442067736\n",
      "train accuracy: 0.6905155391071428, test accuracy:0.6749720044792833 train loss:0.58702222, test loss:32.50279999, test precision: 0.6103216155572176,test recall: 0.5604395604395604,test f1: 0.5843179377013963\n",
      "train accuracy: 0.6917442908928572, test accuracy:0.6746920492721165 train loss:0.58371882, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6892492273214286, test accuracy:0.6741321388577828 train loss:0.58921181, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.69299987125, test accuracy:0.6741321388577828 train loss:0.58463531, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6973192823214286, test accuracy:0.6741321388577828 train loss:0.58271936, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6918247767857143, test accuracy:0.6741321388577828 train loss:0.58669832, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6858205271428571, test accuracy:0.6741321388577828 train loss:0.58990655, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6868990383928572, test accuracy:0.6741321388577828 train loss:0.58749528, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.68629271125, test accuracy:0.6741321388577828 train loss:0.58963937, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.687757555, test accuracy:0.6741321388577828 train loss:0.58576911, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6920716003571429, test accuracy:0.6741321388577828 train loss:0.58537007, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.68841217375, test accuracy:0.6746920492721165 train loss:0.59011926, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6962407708928572, test accuracy:0.6741321388577828 train loss:0.58219922, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6959402901785714, test accuracy:0.6746920492721165 train loss:0.58161941, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6879775498214286, test accuracy:0.6746920492721165 train loss:0.58693274, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6882619333928571, test accuracy:0.6741321388577828 train loss:0.58947023, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6887716775, test accuracy:0.6741321388577828 train loss:0.58528855, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6885033910714285, test accuracy:0.6746920492721165 train loss:0.5887584, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6870331816071429, test accuracy:0.6746920492721165 train loss:0.5866699, test loss:32.53079605, test precision: 0.6103216155572176,test recall: 0.5600549073438572,test f1: 0.5841088045812455\n",
      "train accuracy: 0.6879936469642857, test accuracy:0.6741321388577828 train loss:0.58832973, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6791026357142858, test accuracy:0.6741321388577828 train loss:0.59559246, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6842000773214286, test accuracy:0.6741321388577828 train loss:0.58815235, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6875321942857143, test accuracy:0.6741321388577828 train loss:0.58749282, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6889272835714285, test accuracy:0.6741321388577828 train loss:0.58627157, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6879346239285714, test accuracy:0.6741321388577828 train loss:0.58681189, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6836152128571429, test accuracy:0.6741321388577828 train loss:0.59066732, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6847098214285714, test accuracy:0.6741321388577828 train loss:0.59032387, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6873873196428572, test accuracy:0.6741321388577828 train loss:0.58716184, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6908052883928572, test accuracy:0.6741321388577828 train loss:0.58454362, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6873819539285714, test accuracy:0.6749720044792833 train loss:0.58287863, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6955217633928571, test accuracy:0.6741321388577828 train loss:0.58394591, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6906067566071429, test accuracy:0.6741321388577828 train loss:0.58509302, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.68805267, test accuracy:0.6741321388577828 train loss:0.58765151, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6896516569642858, test accuracy:0.6749720044792833 train loss:0.58569835, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6857615041071429, test accuracy:0.6749720044792833 train loss:0.58852138, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6869365985714285, test accuracy:0.6749720044792833 train loss:0.58656233, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6920018458928572, test accuracy:0.6749720044792833 train loss:0.58194512, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6873282967857143, test accuracy:0.6749720044792833 train loss:0.58665501, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6806211366071429, test accuracy:0.6749720044792833 train loss:0.59104998, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6944217891071428, test accuracy:0.6749720044792833 train loss:0.57997242, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.69299987125, test accuracy:0.6749720044792833 train loss:0.58093624, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6880473042857143, test accuracy:0.6741321388577828 train loss:0.58745745, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6847473816071429, test accuracy:0.6749720044792833 train loss:0.58808461, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6938637533928571, test accuracy:0.6749720044792833 train loss:0.58354533, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6906496823214285, test accuracy:0.6741321388577828 train loss:0.58430572, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6906711451785714, test accuracy:0.6758118701007839 train loss:0.58407264, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6891472785714285, test accuracy:0.6766517357222844 train loss:0.5870302, test loss:32.33482742, test precision: 0.6170531039640987,test recall: 0.5619891008174387,test f1: 0.5882352941176471\n",
      "train accuracy: 0.6884336366071429, test accuracy:0.6749720044792833 train loss:0.58527902, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6939442392857142, test accuracy:0.6758118701007839 train loss:0.5824199, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6871512276785714, test accuracy:0.6766517357222844 train loss:0.5852503, test loss:32.33482742, test precision: 0.6170531039640987,test recall: 0.5619891008174387,test f1: 0.5882352941176471\n",
      "train accuracy: 0.6962568682142857, test accuracy:0.6758118701007839 train loss:0.58140578, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6945988582142857, test accuracy:0.6758118701007839 train loss:0.58318694, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6888789921428572, test accuracy:0.6766517357222844 train loss:0.58466778, test loss:32.33482742, test precision: 0.6170531039640987,test recall: 0.5619891008174387,test f1: 0.5882352941176471\n",
      "train accuracy: 0.6871619591071428, test accuracy:0.6758118701007839 train loss:0.58873916, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.69195892, test accuracy:0.6758118701007839 train loss:0.58364759, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6917389251785714, test accuracy:0.6758118701007839 train loss:0.58056202, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6943413032142857, test accuracy:0.6758118701007839 train loss:0.58161739, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6924418355357143, test accuracy:0.6766517357222844 train loss:0.58365209, test loss:32.33482742, test precision: 0.6170531039640987,test recall: 0.5619891008174387,test f1: 0.5882352941176471\n",
      "train accuracy: 0.6929569453571428, test accuracy:0.6766517357222844 train loss:0.58305522, test loss:32.33482742, test precision: 0.6170531039640987,test recall: 0.5619891008174387,test f1: 0.5882352941176471\n",
      "train accuracy: 0.6899199433928571, test accuracy:0.6758118701007839 train loss:0.58444231, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6963319883928571, test accuracy:0.6758118701007839 train loss:0.5819053, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6866039233928571, test accuracy:0.6758118701007839 train loss:0.58296017, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6845488496428571, test accuracy:0.6758118701007839 train loss:0.58555929, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6923720810714286, test accuracy:0.6758118701007839 train loss:0.58084599, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.69176575375, test accuracy:0.6758118701007839 train loss:0.58569436, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6888253348214286, test accuracy:0.6741321388577828 train loss:0.58640895, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6821396376785714, test accuracy:0.6749720044792833 train loss:0.59005708, test loss:32.50279999, test precision: 0.6170531039640987,test recall: 0.5597014925373134,test f1: 0.5869797225186766\n",
      "train accuracy: 0.6865502660714285, test accuracy:0.6741321388577828 train loss:0.58616248, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6930481628571429, test accuracy:0.6741321388577828 train loss:0.58181488, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6873926853571428, test accuracy:0.6741321388577828 train loss:0.58560541, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6898072630357143, test accuracy:0.6758118701007839 train loss:0.58390378, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6961334564285714, test accuracy:0.6741321388577828 train loss:0.5813596, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6886965573214285, test accuracy:0.6741321388577828 train loss:0.58494936, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6853054173214286, test accuracy:0.6741321388577828 train loss:0.58434838, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6925008585714286, test accuracy:0.6741321388577828 train loss:0.58329988, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6920018458928572, test accuracy:0.6758118701007839 train loss:0.58318357, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.68245085, test accuracy:0.6741321388577828 train loss:0.58845098, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6879292582142857, test accuracy:0.6741321388577828 train loss:0.58878219, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6925813444642858, test accuracy:0.6741321388577828 train loss:0.58322036, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6914760044642857, test accuracy:0.6741321388577828 train loss:0.58453623, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6886911916071429, test accuracy:0.6741321388577828 train loss:0.58435904, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6898287258928572, test accuracy:0.6741321388577828 train loss:0.58090197, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6953285971428571, test accuracy:0.6741321388577828 train loss:0.58021952, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6904565160714285, test accuracy:0.6741321388577828 train loss:0.58245332, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6844951923214285, test accuracy:0.6741321388577828 train loss:0.58546275, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6903760301785714, test accuracy:0.6741321388577828 train loss:0.58663086, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6891204498214286, test accuracy:0.6741321388577828 train loss:0.58655133, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.690596025, test accuracy:0.6741321388577828 train loss:0.58293084, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6926940246428571, test accuracy:0.6741321388577828 train loss:0.58173478, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6858205271428571, test accuracy:0.6741321388577828 train loss:0.58644392, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.68408203125, test accuracy:0.6741321388577828 train loss:0.58702918, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6845595810714286, test accuracy:0.6741321388577828 train loss:0.58870851, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6979148780357143, test accuracy:0.6741321388577828 train loss:0.57714205, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6917925825, test accuracy:0.6741321388577828 train loss:0.58033667, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6900755494642857, test accuracy:0.6758118701007839 train loss:0.58487339, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6929623110714286, test accuracy:0.6758118701007839 train loss:0.58204445, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6882780305357142, test accuracy:0.6741321388577828 train loss:0.58653593, test loss:32.58678818, test precision: 0.6140613313388182,test recall: 0.5588835942818243,test f1: 0.5851746258018532\n",
      "train accuracy: 0.6890614267857142, test accuracy:0.6758118701007839 train loss:0.58746072, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6900272578571428, test accuracy:0.6758118701007839 train loss:0.58261159, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6894692221428571, test accuracy:0.6758118701007839 train loss:0.58261487, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6878916982142858, test accuracy:0.6758118701007839 train loss:0.58440695, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6899360405357143, test accuracy:0.6758118701007839 train loss:0.58277806, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6906174880357143, test accuracy:0.6758118701007839 train loss:0.58169875, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6936866844642857, test accuracy:0.6758118701007839 train loss:0.5807925, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6864375858928572, test accuracy:0.6758118701007839 train loss:0.58474584, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6860029619642857, test accuracy:0.6758118701007839 train loss:0.58720334, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6905101733928571, test accuracy:0.6758118701007839 train loss:0.58363654, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6902204241071429, test accuracy:0.6758118701007839 train loss:0.58069003, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6928925566071429, test accuracy:0.6758118701007839 train loss:0.58177479, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6903384701785714, test accuracy:0.6758118701007839 train loss:0.58381291, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6844737294642858, test accuracy:0.6758118701007839 train loss:0.58726812, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6853859032142857, test accuracy:0.6758118701007839 train loss:0.58545559, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6813347785714285, test accuracy:0.6758118701007839 train loss:0.58823232, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6898287258928572, test accuracy:0.6758118701007839 train loss:0.5845957, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6921091603571429, test accuracy:0.6758118701007839 train loss:0.5832837, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.68467226125, test accuracy:0.6758118701007839 train loss:0.58483829, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6943413032142857, test accuracy:0.6758118701007839 train loss:0.58020232, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6932735233928572, test accuracy:0.6758118701007839 train loss:0.58120826, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6815172132142857, test accuracy:0.6758118701007839 train loss:0.58798067, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6894101991071429, test accuracy:0.6758118701007839 train loss:0.58101718, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6897858001785714, test accuracy:0.6758118701007839 train loss:0.5876772, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6902848128571428, test accuracy:0.6758118701007839 train loss:0.58140579, test loss:32.41881561, test precision: 0.6140613313388182,test recall: 0.5611756664388243,test f1: 0.5864285714285714\n",
      "train accuracy: 0.6924579326785715, test accuracy:0.6766517357222844 train loss:0.57920557, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.6903813958928572, test accuracy:0.6766517357222844 train loss:0.5854833, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.6911325978571429, test accuracy:0.6766517357222844 train loss:0.58159034, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.6902794471428572, test accuracy:0.6766517357222844 train loss:0.58228453, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.6910252833928572, test accuracy:0.6769316909294513 train loss:0.58065748, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6927584133928572, test accuracy:0.6766517357222844 train loss:0.57944423, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.7014723557142857, test accuracy:0.6766517357222844 train loss:0.57488329, test loss:32.33482742, test precision: 0.612565445026178,test recall: 0.5625,test f1: 0.5864661654135338\n",
      "train accuracy: 0.6873282967857143, test accuracy:0.6769316909294513 train loss:0.58019843, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6863678314285714, test accuracy:0.6769316909294513 train loss:0.58429139, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6858956473214286, test accuracy:0.6752519596864501 train loss:0.5870967, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6854717548214285, test accuracy:0.6752519596864501 train loss:0.58681644, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.69121308375, test accuracy:0.6769316909294513 train loss:0.58398849, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6850907880357143, test accuracy:0.6769316909294513 train loss:0.58643815, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6856756525, test accuracy:0.6769316909294513 train loss:0.58659443, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6941535026785715, test accuracy:0.6769316909294513 train loss:0.57772313, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6830625428571429, test accuracy:0.6769316909294513 train loss:0.58811737, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6861317392857142, test accuracy:0.6744120940649496 train loss:0.58710889, test loss:32.55879211, test precision: 0.6148092744951383,test recall: 0.5591836734693878,test f1: 0.5856786604916281\n",
      "train accuracy: 0.6921037946428571, test accuracy:0.6752519596864501 train loss:0.58152572, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6899521376785714, test accuracy:0.6752519596864501 train loss:0.58082258, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6878004807142857, test accuracy:0.6752519596864501 train loss:0.58453878, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6879131610714285, test accuracy:0.6744120940649496 train loss:0.58454796, test loss:32.55879211, test precision: 0.6148092744951383,test recall: 0.5591836734693878,test f1: 0.5856786604916281\n",
      "train accuracy: 0.6946686126785714, test accuracy:0.6752519596864501 train loss:0.57733031, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6886160714285714, test accuracy:0.6752519596864501 train loss:0.57855039, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6944271548214286, test accuracy:0.6752519596864501 train loss:0.58382737, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6903170071428572, test accuracy:0.6752519596864501 train loss:0.58110452, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6921628176785715, test accuracy:0.6752519596864501 train loss:0.58191238, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6913096669642858, test accuracy:0.6769316909294513 train loss:0.58171874, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6955593235714286, test accuracy:0.6769316909294513 train loss:0.57887514, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6918516053571429, test accuracy:0.6769316909294513 train loss:0.58016585, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.68535370875, test accuracy:0.6769316909294513 train loss:0.58728879, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6903867616071429, test accuracy:0.6769316909294513 train loss:0.58199615, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6895282451785715, test accuracy:0.6769316909294513 train loss:0.58050419, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6935686383928571, test accuracy:0.6769316909294513 train loss:0.58227183, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6908106541071428, test accuracy:0.6769316909294513 train loss:0.5802266, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6936222957142857, test accuracy:0.6769316909294513 train loss:0.57893551, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6947008069642857, test accuracy:0.6769316909294513 train loss:0.57741714, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.68675416375, test accuracy:0.6752519596864501 train loss:0.58283716, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6913525926785714, test accuracy:0.6783314669652856 train loss:0.57954629, test loss:32.16685486, test precision: 0.6133133881824981,test recall: 0.5647382920110193,test f1: 0.588024381498745\n",
      "train accuracy: 0.6849459133928572, test accuracy:0.6783314669652856 train loss:0.58640922, test loss:32.16685486, test precision: 0.6133133881824981,test recall: 0.5647382920110193,test f1: 0.588024381498745\n",
      "train accuracy: 0.6948188530357143, test accuracy:0.6783314669652856 train loss:0.57762993, test loss:32.16685486, test precision: 0.6133133881824981,test recall: 0.5647382920110193,test f1: 0.588024381498745\n",
      "train accuracy: 0.6939281421428571, test accuracy:0.6766517357222844 train loss:0.57917324, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6890828898214286, test accuracy:0.6766517357222844 train loss:0.58029331, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6917389251785714, test accuracy:0.6752519596864501 train loss:0.58128251, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6849405476785714, test accuracy:0.6752519596864501 train loss:0.58585174, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6921628176785715, test accuracy:0.6752519596864501 train loss:0.58105739, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6835883842857143, test accuracy:0.6752519596864501 train loss:0.58548577, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6923828125, test accuracy:0.6752519596864501 train loss:0.5807146, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6962836967857143, test accuracy:0.6752519596864501 train loss:0.57310962, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6951515282142857, test accuracy:0.6752519596864501 train loss:0.57742037, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6829230339285715, test accuracy:0.6752519596864501 train loss:0.58716445, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6954949348214285, test accuracy:0.6769316909294513 train loss:0.57737701, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6871887878571429, test accuracy:0.6769316909294513 train loss:0.58227874, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6888897235714285, test accuracy:0.6752519596864501 train loss:0.58434088, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6899360405357143, test accuracy:0.6766517357222844 train loss:0.5829301, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6950388478571429, test accuracy:0.6786114221724524 train loss:0.57951687, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.68964629125, test accuracy:0.6772116461366181 train loss:0.58459918, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6892545930357142, test accuracy:0.6772116461366181 train loss:0.58168452, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6880312071428571, test accuracy:0.6769316909294513 train loss:0.58300638, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6961441878571428, test accuracy:0.6769316909294513 train loss:0.57512344, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6842430030357143, test accuracy:0.6752519596864501 train loss:0.589653, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6943681317857143, test accuracy:0.6766517357222844 train loss:0.57699464, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6860673505357143, test accuracy:0.6769316909294513 train loss:0.58444714, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6811094178571429, test accuracy:0.6752519596864501 train loss:0.59036887, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6858902816071428, test accuracy:0.6752519596864501 train loss:0.57956092, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6853483430357142, test accuracy:0.6752519596864501 train loss:0.58135754, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6879614526785715, test accuracy:0.6752519596864501 train loss:0.58186051, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6933701064285714, test accuracy:0.6786114221724524 train loss:0.57899921, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.6925545157142857, test accuracy:0.6786114221724524 train loss:0.579449, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.6923881782142857, test accuracy:0.6786114221724524 train loss:0.58065721, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.6897858001785714, test accuracy:0.6772116461366181 train loss:0.58290242, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6927906078571429, test accuracy:0.6772116461366181 train loss:0.57554635, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6927262191071428, test accuracy:0.6772116461366181 train loss:0.57750661, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6869741585714285, test accuracy:0.6772116461366181 train loss:0.58262548, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6851498110714286, test accuracy:0.6772116461366181 train loss:0.58635054, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6985319367857142, test accuracy:0.6786114221724524 train loss:0.57527034, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.6884068080357143, test accuracy:0.6772116461366181 train loss:0.58036971, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6951139680357142, test accuracy:0.6772116461366181 train loss:0.58007539, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6931930375, test accuracy:0.6772116461366181 train loss:0.58066958, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6869526957142857, test accuracy:0.675531914893617 train loss:0.5838366, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6901184753571429, test accuracy:0.675531914893617 train loss:0.58140351, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6912882039285714, test accuracy:0.6772116461366181 train loss:0.57937648, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6977646376785714, test accuracy:0.675531914893617 train loss:0.5761227, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6951729910714286, test accuracy:0.6772116461366181 train loss:0.5752311, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6907945569642857, test accuracy:0.6752519596864501 train loss:0.58212318, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6865127060714286, test accuracy:0.6772116461366181 train loss:0.58412455, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6908589457142857, test accuracy:0.6772116461366181 train loss:0.57943563, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6946095896428571, test accuracy:0.6772116461366181 train loss:0.57883981, test loss:32.2788353, test precision: 0.6133133881824981,test recall: 0.5631868131868132,test f1: 0.5871822413175797\n",
      "train accuracy: 0.6958276098214285, test accuracy:0.6786114221724524 train loss:0.57896203, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.6925062242857143, test accuracy:0.6786114221724524 train loss:0.57852831, test loss:32.1388588, test precision: 0.6133133881824981,test recall: 0.5651274982770503,test f1: 0.588235294117647\n",
      "train accuracy: 0.68951751375, test accuracy:0.675531914893617 train loss:0.5760488, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6941588683928571, test accuracy:0.6769316909294513 train loss:0.57575699, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6887180201785714, test accuracy:0.6769316909294513 train loss:0.58418664, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6894584907142857, test accuracy:0.6769316909294513 train loss:0.58139736, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6911647923214286, test accuracy:0.6769316909294513 train loss:0.57782621, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6874517083928572, test accuracy:0.6769316909294513 train loss:0.57854094, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6943359375, test accuracy:0.6766517357222844 train loss:0.580085, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6866146548214286, test accuracy:0.6766517357222844 train loss:0.58261658, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6957685869642857, test accuracy:0.6766517357222844 train loss:0.57488233, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6831108344642857, test accuracy:0.6752519596864501 train loss:0.58853539, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6912291808928571, test accuracy:0.6752519596864501 train loss:0.58120264, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6905155391071428, test accuracy:0.6752519596864501 train loss:0.5785472, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6887663117857142, test accuracy:0.6752519596864501 train loss:0.58098576, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6956451751785714, test accuracy:0.675531914893617 train loss:0.57906466, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6880365728571428, test accuracy:0.675531914893617 train loss:0.58255441, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6990953382142857, test accuracy:0.675531914893617 train loss:0.57536993, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6882297389285714, test accuracy:0.675531914893617 train loss:0.58389405, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6928979223214285, test accuracy:0.675531914893617 train loss:0.57709456, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.69355254125, test accuracy:0.675531914893617 train loss:0.58034971, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.695570055, test accuracy:0.6769316909294513 train loss:0.57496883, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6860941792857143, test accuracy:0.6752519596864501 train loss:0.58145052, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6941159426785715, test accuracy:0.6769316909294513 train loss:0.57702094, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6903170071428572, test accuracy:0.6752519596864501 train loss:0.58080374, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6939335078571428, test accuracy:0.6752519596864501 train loss:0.57530729, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6911004035714285, test accuracy:0.6752519596864501 train loss:0.5779475, test loss:32.47480392, test precision: 0.6133133881824981,test recall: 0.5604921394395078,test f1: 0.5857142857142857\n",
      "train accuracy: 0.6923023266071429, test accuracy:0.675531914893617 train loss:0.58518493, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6836474073214286, test accuracy:0.675531914893617 train loss:0.58228405, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6951622596428572, test accuracy:0.675531914893617 train loss:0.57798245, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6930964542857143, test accuracy:0.6769316909294513 train loss:0.57814264, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6878648694642857, test accuracy:0.6769316909294513 train loss:0.58301525, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6918140453571429, test accuracy:0.6769316909294513 train loss:0.57805708, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6924579326785715, test accuracy:0.6769316909294513 train loss:0.5804297, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6902794471428572, test accuracy:0.6769316909294513 train loss:0.58226518, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6854771205357143, test accuracy:0.6769316909294513 train loss:0.58570986, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6928228021428572, test accuracy:0.6769316909294513 train loss:0.5789971, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6849512791071428, test accuracy:0.675531914893617 train loss:0.58021647, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6921198917857143, test accuracy:0.6769316909294513 train loss:0.57439741, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6877092633928571, test accuracy:0.675531914893617 train loss:0.58380663, test loss:32.44680786, test precision: 0.6133133881824981,test recall: 0.560875512995896,test f1: 0.585923544122901\n",
      "train accuracy: 0.6902794471428572, test accuracy:0.6769316909294513 train loss:0.57853654, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6856005323214286, test accuracy:0.6769316909294513 train loss:0.58422325, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6925598816071429, test accuracy:0.6769316909294513 train loss:0.58142789, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.69261353875, test accuracy:0.6769316909294513 train loss:0.57718176, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6974158653571428, test accuracy:0.6769316909294513 train loss:0.57382795, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6925813444642858, test accuracy:0.6769316909294513 train loss:0.57606253, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6953983516071428, test accuracy:0.6769316909294513 train loss:0.57738365, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6929247510714286, test accuracy:0.6769316909294513 train loss:0.57652574, test loss:32.30683136, test precision: 0.612565445026178,test recall: 0.5628865979381443,test f1: 0.5866762177650431\n",
      "train accuracy: 0.6932359632142857, test accuracy:0.6783314669652856 train loss:0.57574483, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6881814475, test accuracy:0.6783314669652856 train loss:0.58840992, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6938100960714285, test accuracy:0.6769316909294513 train loss:0.57534689, test loss:32.30683136, test precision: 0.612565445026178,test recall: 0.5628865979381443,test f1: 0.5866762177650431\n",
      "train accuracy: 0.6897804344642857, test accuracy:0.6766517357222844 train loss:0.58113452, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6814581901785715, test accuracy:0.6766517357222844 train loss:0.58433507, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6866629464285714, test accuracy:0.6783314669652856 train loss:0.58548669, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6894584907142857, test accuracy:0.6780515117581187 train loss:0.57808821, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6885946085714286, test accuracy:0.6780515117581187 train loss:0.58359039, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6907784598214286, test accuracy:0.6797312430011199 train loss:0.57906104, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.688347785, test accuracy:0.6797312430011199 train loss:0.58307936, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6930535285714285, test accuracy:0.6797312430011199 train loss:0.57661884, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.7000719007142857, test accuracy:0.6797312430011199 train loss:0.56971288, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6919481885714286, test accuracy:0.6797312430011199 train loss:0.58341894, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6866307521428572, test accuracy:0.6797312430011199 train loss:0.58222201, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6954305460714286, test accuracy:0.6797312430011199 train loss:0.57580204, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.7011235833928572, test accuracy:0.6797312430011199 train loss:0.57376803, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6935954669642858, test accuracy:0.6797312430011199 train loss:0.57561693, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6935471755357143, test accuracy:0.6797312430011199 train loss:0.57754468, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6912291808928571, test accuracy:0.6780515117581187 train loss:0.58078108, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6922647664285714, test accuracy:0.6780515117581187 train loss:0.57686778, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6892760558928571, test accuracy:0.6797312430011199 train loss:0.58170221, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.7002382383928571, test accuracy:0.6797312430011199 train loss:0.57025343, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6944915435714286, test accuracy:0.6797312430011199 train loss:0.57649178, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6910628433928572, test accuracy:0.6797312430011199 train loss:0.58260687, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6878273094642857, test accuracy:0.6780515117581187 train loss:0.58589891, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6985587655357143, test accuracy:0.6780515117581187 train loss:0.57528711, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6913472269642857, test accuracy:0.6780515117581187 train loss:0.58196429, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6909233344642857, test accuracy:0.6780515117581187 train loss:0.58061224, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6903867616071429, test accuracy:0.6780515117581187 train loss:0.57807332, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6912882039285714, test accuracy:0.6780515117581187 train loss:0.57679017, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6885194883928571, test accuracy:0.6780515117581187 train loss:0.58073927, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6906657794642858, test accuracy:0.6780515117581187 train loss:0.57815261, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6920394058928572, test accuracy:0.6780515117581187 train loss:0.57845155, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6977217119642857, test accuracy:0.6780515117581187 train loss:0.57461842, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6920018458928572, test accuracy:0.6780515117581187 train loss:0.57911404, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6946471496428571, test accuracy:0.6780515117581187 train loss:0.57751833, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6955378605357143, test accuracy:0.6780515117581187 train loss:0.57581182, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6990416808928571, test accuracy:0.6780515117581187 train loss:0.57394126, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6944861778571428, test accuracy:0.6780515117581187 train loss:0.57563336, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6913955185714286, test accuracy:0.6780515117581187 train loss:0.57957688, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6900648180357143, test accuracy:0.6780515117581187 train loss:0.57839628, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6952803057142857, test accuracy:0.6780515117581187 train loss:0.57443442, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6966217376785714, test accuracy:0.6780515117581187 train loss:0.57506862, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6912291808928571, test accuracy:0.6780515117581187 train loss:0.57827393, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6920286744642857, test accuracy:0.6780515117581187 train loss:0.57804938, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6990899725, test accuracy:0.6797312430011199 train loss:0.57636107, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6957202953571429, test accuracy:0.6797312430011199 train loss:0.57677102, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6961549192857143, test accuracy:0.6797312430011199 train loss:0.57212958, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6941266741071429, test accuracy:0.6780515117581187 train loss:0.57711214, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6897536057142857, test accuracy:0.6780515117581187 train loss:0.57743095, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6930427969642857, test accuracy:0.6780515117581187 train loss:0.57473826, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6901131094642857, test accuracy:0.6797312430011199 train loss:0.58170933, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6865931919642857, test accuracy:0.6797312430011199 train loss:0.5814195, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6929515796428571, test accuracy:0.6780515117581187 train loss:0.57711654, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6973997682142857, test accuracy:0.6780515117581187 train loss:0.57331581, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6896033653571428, test accuracy:0.6780515117581187 train loss:0.58171649, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6907140710714286, test accuracy:0.6780515117581187 train loss:0.58038063, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6917228280357143, test accuracy:0.6780515117581187 train loss:0.57953143, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6979417067857143, test accuracy:0.6780515117581187 train loss:0.57376913, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6953232314285714, test accuracy:0.6780515117581187 train loss:0.57785748, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6945881267857142, test accuracy:0.6780515117581187 train loss:0.57783484, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6988646119642857, test accuracy:0.6797312430011199 train loss:0.57199319, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6934398608928571, test accuracy:0.6797312430011199 train loss:0.57631021, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6965627146428571, test accuracy:0.6797312430011199 train loss:0.57309222, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6903492016071429, test accuracy:0.6797312430011199 train loss:0.57617544, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6902901785714286, test accuracy:0.6797312430011199 train loss:0.57861986, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6871458619642857, test accuracy:0.6797312430011199 train loss:0.58272864, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6882082760714285, test accuracy:0.6797312430011199 train loss:0.58295982, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6941266741071429, test accuracy:0.6797312430011199 train loss:0.57557835, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6908965058928571, test accuracy:0.6797312430011199 train loss:0.57504956, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6906657794642858, test accuracy:0.6797312430011199 train loss:0.57746375, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6902311555357142, test accuracy:0.6797312430011199 train loss:0.57741496, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6940354567857143, test accuracy:0.6797312430011199 train loss:0.57329814, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6903116414285714, test accuracy:0.6797312430011199 train loss:0.57925964, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6829820569642857, test accuracy:0.6797312430011199 train loss:0.58217077, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6870439130357143, test accuracy:0.6797312430011199 train loss:0.58069427, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6914760044642857, test accuracy:0.6797312430011199 train loss:0.57580477, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.69524811125, test accuracy:0.6797312430011199 train loss:0.57417328, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6941320398214286, test accuracy:0.6797312430011199 train loss:0.57495521, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6923398866071429, test accuracy:0.6797312430011199 train loss:0.57992444, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6900218921428571, test accuracy:0.6797312430011199 train loss:0.57754199, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6911272321428571, test accuracy:0.6797312430011199 train loss:0.57993055, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6955003005357143, test accuracy:0.6802911534154535 train loss:0.57699835, test loss:31.97088623, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6922594007142857, test accuracy:0.6797312430011199 train loss:0.57458585, test loss:32.02687836, test precision: 0.6118175018698578,test recall: 0.5668745668745668,test f1: 0.5884892086330935\n",
      "train accuracy: 0.6916852678571429, test accuracy:0.6802911534154535 train loss:0.57934653, test loss:31.97088623, test precision: 0.6118175018698578,test recall: 0.5676613462873005,test f1: 0.5889128869690424\n",
      "train accuracy: 0.6879399896428572, test accuracy:0.6814109742441209 train loss:0.57882359, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6968524639285715, test accuracy:0.6814109742441209 train loss:0.57355548, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6886160714285714, test accuracy:0.6814109742441209 train loss:0.57986748, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6882297389285714, test accuracy:0.6814109742441209 train loss:0.58244695, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6935149810714286, test accuracy:0.6814109742441209 train loss:0.57794943, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6865127060714286, test accuracy:0.6814109742441209 train loss:0.58628164, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6947437328571429, test accuracy:0.6814109742441209 train loss:0.57474734, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6888950892857143, test accuracy:0.6783314669652856 train loss:0.57672234, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6902472526785715, test accuracy:0.6814109742441209 train loss:0.57810477, test loss:31.85890388, test precision: 0.6013462976813763,test recall: 0.5706174591909156,test f1: 0.58557902403496\n",
      "train accuracy: 0.6912506439285714, test accuracy:0.6783314669652856 train loss:0.57681768, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.69745879125, test accuracy:0.6794512877939529 train loss:0.5705165, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6888092376785714, test accuracy:0.6783314669652856 train loss:0.58085379, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6941642342857143, test accuracy:0.6783314669652856 train loss:0.57560175, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6870278158928571, test accuracy:0.6783314669652856 train loss:0.58253244, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6899145776785715, test accuracy:0.6794512877939529 train loss:0.57697627, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6897321428571429, test accuracy:0.6788913773796192 train loss:0.58004185, test loss:32.11086273, test precision: 0.6163051608077786,test recall: 0.5651577503429356,test f1: 0.5896243291592129\n",
      "train accuracy: 0.68922239875, test accuracy:0.6780515117581187 train loss:0.57966745, test loss:32.19485092, test precision: 0.6170531039640987,test recall: 0.5639097744360902,test f1: 0.5892857142857143\n",
      "train accuracy: 0.6961924794642858, test accuracy:0.6788913773796192 train loss:0.57524092, test loss:32.11086273, test precision: 0.6163051608077786,test recall: 0.5651577503429356,test f1: 0.5896243291592129\n",
      "train accuracy: 0.6906282194642858, test accuracy:0.6800111982082867 train loss:0.57959838, test loss:31.99888039, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.69117552375, test accuracy:0.6800111982082867 train loss:0.57929893, test loss:31.99888039, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6943627660714285, test accuracy:0.6794512877939529 train loss:0.57232081, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.69342376375, test accuracy:0.6794512877939529 train loss:0.57819701, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6939925308928572, test accuracy:0.6786114221724524 train loss:0.57632941, test loss:32.1388588, test precision: 0.6043380703066566,test recall: 0.5662228451296426,test f1: 0.5846599131693198\n",
      "train accuracy: 0.690596025, test accuracy:0.6794512877939529 train loss:0.57996095, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.69524811125, test accuracy:0.6783314669652856 train loss:0.57581474, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6883048592857143, test accuracy:0.6783314669652856 train loss:0.58206181, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6890506953571428, test accuracy:0.6780515117581187 train loss:0.58001222, test loss:32.19485092, test precision: 0.6170531039640987,test recall: 0.5639097744360902,test f1: 0.5892857142857143\n",
      "train accuracy: 0.6926081730357143, test accuracy:0.6788913773796192 train loss:0.57654795, test loss:32.11086273, test precision: 0.6163051608077786,test recall: 0.5651577503429356,test f1: 0.5896243291592129\n",
      "train accuracy: 0.694464715, test accuracy:0.6794512877939529 train loss:0.5740604, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6913257641071429, test accuracy:0.6794512877939529 train loss:0.58060966, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6944700807142857, test accuracy:0.6788913773796192 train loss:0.57963362, test loss:32.11086273, test precision: 0.6163051608077786,test recall: 0.5651577503429356,test f1: 0.5896243291592129\n",
      "train accuracy: 0.6923667153571429, test accuracy:0.6794512877939529 train loss:0.57757058, test loss:32.05487061, test precision: 0.6035901271503366,test recall: 0.5675105485232067,test f1: 0.5849945632475533\n",
      "train accuracy: 0.6976197630357143, test accuracy:0.6783314669652856 train loss:0.57327476, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6970563616071429, test accuracy:0.6783314669652856 train loss:0.57405117, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6919750171428571, test accuracy:0.6783314669652856 train loss:0.57241444, test loss:32.16685486, test precision: 0.6140613313388182,test recall: 0.5646492434662999,test f1: 0.5883195987101397\n",
      "train accuracy: 0.6927369505357143, test accuracy:0.6802911534154535 train loss:0.57908422, test loss:31.97088623, test precision: 0.6035901271503366,test recall: 0.5687103594080338,test f1: 0.5856313497822931\n",
      "train accuracy: 0.6973085508928571, test accuracy:0.6802911534154535 train loss:0.57463335, test loss:31.97088623, test precision: 0.6035901271503366,test recall: 0.5687103594080338,test f1: 0.5856313497822931\n",
      "train accuracy: 0.6868668441071428, test accuracy:0.6802911534154535 train loss:0.58223129, test loss:31.97088623, test precision: 0.6035901271503366,test recall: 0.5687103594080338,test f1: 0.5856313497822931\n",
      "train accuracy: 0.6914277128571429, test accuracy:0.6805711086226204 train loss:0.57628927, test loss:31.94289017, test precision: 0.6163051608077786,test recall: 0.5674931129476584,test f1: 0.5908927931158121\n",
      "train accuracy: 0.6941964285714286, test accuracy:0.6808510638297872 train loss:0.57411829, test loss:31.9148941, test precision: 0.6140613313388182,test recall: 0.568166089965398,test f1: 0.5902228612508987\n",
      "train accuracy: 0.6967451494642857, test accuracy:0.6808510638297872 train loss:0.56960622, test loss:31.9148941, test precision: 0.6140613313388182,test recall: 0.568166089965398,test f1: 0.5902228612508987\n",
      "train accuracy: 0.6921252575, test accuracy:0.6808510638297872 train loss:0.57855372, test loss:31.9148941, test precision: 0.6140613313388182,test recall: 0.568166089965398,test f1: 0.5902228612508987\n",
      "train accuracy: 0.6896355598214285, test accuracy:0.6839305711086227 train loss:0.57623165, test loss:31.60694313, test precision: 0.6035901271503366,test recall: 0.5739687055476529,test f1: 0.5884068538096973\n",
      "train accuracy: 0.6869258671428572, test accuracy:0.6833706606942889 train loss:0.5806045, test loss:31.66293526, test precision: 0.6013462976813763,test recall: 0.5734664764621968,test f1: 0.5870755750273823\n",
      "train accuracy: 0.69032773875, test accuracy:0.6828107502799552 train loss:0.57859942, test loss:31.71892548, test precision: 0.6035901271503366,test recall: 0.5723404255319149,test f1: 0.5875500546050236\n",
      "train accuracy: 0.6892867875, test accuracy:0.6828107502799552 train loss:0.57667266, test loss:31.71892548, test precision: 0.6035901271503366,test recall: 0.5723404255319149,test f1: 0.5875500546050236\n",
      "train accuracy: 0.6983816964285714, test accuracy:0.6839305711086227 train loss:0.57123585, test loss:31.60694313, test precision: 0.6035901271503366,test recall: 0.5739687055476529,test f1: 0.5884068538096973\n",
      "train accuracy: 0.6967988066071429, test accuracy:0.6822508398656215 train loss:0.57271792, test loss:31.7749176, test precision: 0.6013462976813763,test recall: 0.5718349928876245,test f1: 0.5862194677360554\n",
      "train accuracy: 0.6895819025, test accuracy:0.6833706606942889 train loss:0.57536269, test loss:31.66293526, test precision: 0.6013462976813763,test recall: 0.5734664764621968,test f1: 0.5870755750273823\n",
      "train accuracy: 0.7023898951785714, test accuracy:0.6833706606942889 train loss:0.57102344, test loss:31.66293526, test precision: 0.6013462976813763,test recall: 0.5734664764621968,test f1: 0.5870755750273823\n",
      "train accuracy: 0.6982099932142857, test accuracy:0.6833706606942889 train loss:0.57121112, test loss:31.66293526, test precision: 0.6013462976813763,test recall: 0.5734664764621968,test f1: 0.5870755750273823\n",
      "train accuracy: 0.6897536057142857, test accuracy:0.6833706606942889 train loss:0.57755369, test loss:31.66293526, test precision: 0.6013462976813763,test recall: 0.5734664764621968,test f1: 0.5870755750273823\n",
      "train accuracy: 0.6942822801785714, test accuracy:0.6839305711086227 train loss:0.57331475, test loss:31.60694313, test precision: 0.5721765145848915,test recall: 0.5786686838124054,test f1: 0.5754042873260624\n",
      "train accuracy: 0.6986768114285714, test accuracy:0.6842105263157895 train loss:0.5696421, test loss:31.57894897, test precision: 0.5931189229618549,test recall: 0.5758896151053013,test f1: 0.5843773028739867\n",
      "train accuracy: 0.6952427455357143, test accuracy:0.6842105263157895 train loss:0.57470213, test loss:31.57894897, test precision: 0.5931189229618549,test recall: 0.5758896151053013,test f1: 0.5843773028739867\n",
      "train accuracy: 0.69580078125, test accuracy:0.6802911534154535 train loss:0.57353128, test loss:31.97088623, test precision: 0.6035901271503366,test recall: 0.5687103594080338,test f1: 0.5856313497822931\n",
      "train accuracy: 0.6939549708928572, test accuracy:0.6814109742441209 train loss:0.57586771, test loss:31.85890388, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.69303743125, test accuracy:0.683090705487122 train loss:0.57297106, test loss:31.69093132, test precision: 0.6035901271503366,test recall: 0.5727466288147622,test f1: 0.5877640203932993\n",
      "train accuracy: 0.69228086375, test accuracy:0.6819708846584547 train loss:0.57860333, test loss:31.80291176, test precision: 0.605833956619297,test recall: 0.5708245243128964,test f1: 0.5878084179970973\n",
      "train accuracy: 0.7007426167857143, test accuracy:0.6819708846584547 train loss:0.56895953, test loss:31.80291176, test precision: 0.605833956619297,test recall: 0.5708245243128964,test f1: 0.5878084179970973\n",
      "train accuracy: 0.7011021205357143, test accuracy:0.6819708846584547 train loss:0.56944801, test loss:31.80291176, test precision: 0.605833956619297,test recall: 0.5708245243128964,test f1: 0.5878084179970973\n",
      "train accuracy: 0.7012899210714286, test accuracy:0.6825307950727884 train loss:0.5721218, test loss:31.74692154, test precision: 0.5931189229618549,test recall: 0.5733911785972523,test f1: 0.5830882352941177\n",
      "train accuracy: 0.6926510989285715, test accuracy:0.6822508398656215 train loss:0.57396802, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6909287001785714, test accuracy:0.6822508398656215 train loss:0.57708806, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6835508241071429, test accuracy:0.6822508398656215 train loss:0.58108652, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6972066019642857, test accuracy:0.6822508398656215 train loss:0.57249633, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6999431232142858, test accuracy:0.6822508398656215 train loss:0.56945826, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6908428485714285, test accuracy:0.6822508398656215 train loss:0.57699583, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6858849158928572, test accuracy:0.6822508398656215 train loss:0.58280794, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.69537688875, test accuracy:0.6822508398656215 train loss:0.57605726, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6999484889285714, test accuracy:0.6847704367301232 train loss:0.569283, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6989343664285714, test accuracy:0.6847704367301232 train loss:0.57371844, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6964607657142857, test accuracy:0.6847704367301232 train loss:0.57525877, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6999001975, test accuracy:0.6844904815229563 train loss:0.57107783, test loss:31.55095291, test precision: 0.5908750934928946,test recall: 0.5766423357664233,test f1: 0.583671961581086\n",
      "train accuracy: 0.6903921273214285, test accuracy:0.6847704367301232 train loss:0.57692343, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6873443939285714, test accuracy:0.6847704367301232 train loss:0.57987206, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6935686383928571, test accuracy:0.6847704367301232 train loss:0.57764149, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6946525155357143, test accuracy:0.683090705487122 train loss:0.57081325, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.7011665092857143, test accuracy:0.683090705487122 train loss:0.57059459, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6907462655357143, test accuracy:0.683090705487122 train loss:0.57591743, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6904726133928571, test accuracy:0.683090705487122 train loss:0.578214, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6976626889285714, test accuracy:0.683090705487122 train loss:0.57078808, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6962890625, test accuracy:0.6847704367301232 train loss:0.57218151, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6893833705357143, test accuracy:0.6822508398656215 train loss:0.57961162, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.68971068, test accuracy:0.681131019036954 train loss:0.57719919, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6916852678571429, test accuracy:0.681131019036954 train loss:0.57844146, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6931930375, test accuracy:0.681131019036954 train loss:0.57377046, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6963588169642857, test accuracy:0.681131019036954 train loss:0.57150892, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6929462139285715, test accuracy:0.6836506159014558 train loss:0.57806673, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6919267255357143, test accuracy:0.681131019036954 train loss:0.57751624, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6921198917857143, test accuracy:0.681131019036954 train loss:0.57641526, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6915296617857143, test accuracy:0.6836506159014558 train loss:0.57689137, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6976036658928572, test accuracy:0.6836506159014558 train loss:0.57248762, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6932252317857143, test accuracy:0.681131019036954 train loss:0.5760459, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6951837225, test accuracy:0.681131019036954 train loss:0.57465407, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.7004635989285715, test accuracy:0.681131019036954 train loss:0.56863911, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6909877232142857, test accuracy:0.6800111982082867 train loss:0.57906548, test loss:31.99888039, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6986768114285714, test accuracy:0.681131019036954 train loss:0.57092472, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6943305717857143, test accuracy:0.681131019036954 train loss:0.57239575, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6865663633928571, test accuracy:0.6800111982082867 train loss:0.58094936, test loss:31.99888039, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6900970123214286, test accuracy:0.6800111982082867 train loss:0.57878651, test loss:31.99888039, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6953393285714285, test accuracy:0.681131019036954 train loss:0.57547117, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6953393285714285, test accuracy:0.681131019036954 train loss:0.57624946, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6900970123214286, test accuracy:0.681131019036954 train loss:0.57488164, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6915725875, test accuracy:0.681131019036954 train loss:0.57574999, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6926725617857142, test accuracy:0.681131019036954 train loss:0.57726104, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.69554322625, test accuracy:0.681131019036954 train loss:0.57082703, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6924793955357142, test accuracy:0.6836506159014558 train loss:0.57488116, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6947490985714285, test accuracy:0.6836506159014558 train loss:0.57566354, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6879024296428572, test accuracy:0.6836506159014558 train loss:0.57952907, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6910682091071428, test accuracy:0.6836506159014558 train loss:0.57826496, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6906711451785714, test accuracy:0.6836506159014558 train loss:0.57979959, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6916799021428571, test accuracy:0.6836506159014558 train loss:0.57691537, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6962729653571429, test accuracy:0.6836506159014558 train loss:0.57219281, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6912667410714286, test accuracy:0.6836506159014558 train loss:0.5764696, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6977968321428571, test accuracy:0.6836506159014558 train loss:0.57140523, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6894477592857143, test accuracy:0.6836506159014558 train loss:0.57837892, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.69365449, test accuracy:0.6836506159014558 train loss:0.57405195, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.697818295, test accuracy:0.6836506159014558 train loss:0.57242397, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6950334821428571, test accuracy:0.6836506159014558 train loss:0.57549284, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.69397643375, test accuracy:0.6819708846584547 train loss:0.57079962, test loss:31.80291176, test precision: 0.605833956619297,test recall: 0.5708245243128964,test f1: 0.5878084179970973\n",
      "train accuracy: 0.6947490985714285, test accuracy:0.6836506159014558 train loss:0.57000767, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6958598042857143, test accuracy:0.6836506159014558 train loss:0.5727305, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6968095380357143, test accuracy:0.6819708846584547 train loss:0.57118386, test loss:31.80291176, test precision: 0.605833956619297,test recall: 0.5708245243128964,test f1: 0.5878084179970973\n",
      "train accuracy: 0.6939174107142857, test accuracy:0.6836506159014558 train loss:0.57389926, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6879399896428572, test accuracy:0.681131019036954 train loss:0.57786248, test loss:31.88689995, test precision: 0.606581899775617,test recall: 0.5695224719101124,test f1: 0.5874683085838465\n",
      "train accuracy: 0.6866790435714286, test accuracy:0.6836506159014558 train loss:0.58379847, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6987090058928571, test accuracy:0.6836506159014558 train loss:0.57044595, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6948510473214285, test accuracy:0.6856103023516238 train loss:0.57119452, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6899253091071429, test accuracy:0.6847704367301232 train loss:0.5759305, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.69550566625, test accuracy:0.6847704367301232 train loss:0.57312481, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6858902816071428, test accuracy:0.6847704367301232 train loss:0.57942968, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6977968321428571, test accuracy:0.6836506159014558 train loss:0.57119762, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6995084992857142, test accuracy:0.6836506159014558 train loss:0.57035061, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.7012791896428572, test accuracy:0.6836506159014558 train loss:0.56788723, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.7000987294642858, test accuracy:0.6847704367301232 train loss:0.5691631, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6978290264285715, test accuracy:0.6836506159014558 train loss:0.5692838, test loss:31.63493919, test precision: 0.605833956619297,test recall: 0.5732484076433121,test f1: 0.5890909090909091\n",
      "train accuracy: 0.6838566707142857, test accuracy:0.6847704367301232 train loss:0.57954332, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6869848901785715, test accuracy:0.6847704367301232 train loss:0.57686645, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6899199433928571, test accuracy:0.6847704367301232 train loss:0.57586591, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6978343921428571, test accuracy:0.6856103023516238 train loss:0.57175374, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6938583876785714, test accuracy:0.6847704367301232 train loss:0.57733056, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6890775241071428, test accuracy:0.6856103023516238 train loss:0.57760958, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6936705871428571, test accuracy:0.6856103023516238 train loss:0.57738967, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6943627660714285, test accuracy:0.683090705487122 train loss:0.57076896, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6997231283928571, test accuracy:0.6847704367301232 train loss:0.56823662, test loss:31.52295685, test precision: 0.5953627524308153,test recall: 0.5763939174511223,test f1: 0.5857247976453274\n",
      "train accuracy: 0.6912828382142857, test accuracy:0.683090705487122 train loss:0.57423691, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.686689775, test accuracy:0.683090705487122 train loss:0.57588203, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6932896205357143, test accuracy:0.683090705487122 train loss:0.57399748, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.69440032625, test accuracy:0.6822508398656215 train loss:0.56831655, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6926242701785714, test accuracy:0.6822508398656215 train loss:0.57520442, test loss:31.7749176, test precision: 0.5961106955871354,test recall: 0.5725574712643678,test f1: 0.5840967387321364\n",
      "train accuracy: 0.6926671960714286, test accuracy:0.683090705487122 train loss:0.57469554, test loss:31.69093132, test precision: 0.5953627524308153,test recall: 0.5739005046863734,test f1: 0.5844346549192363\n",
      "train accuracy: 0.6929247510714286, test accuracy:0.6856103023516238 train loss:0.5728147, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6937457075, test accuracy:0.6839305711086227 train loss:0.57586497, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6904082246428571, test accuracy:0.6839305711086227 train loss:0.57705941, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6930535285714285, test accuracy:0.6839305711086227 train loss:0.57494231, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6928281678571429, test accuracy:0.6839305711086227 train loss:0.57197102, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6886965573214285, test accuracy:0.6839305711086227 train loss:0.57806941, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6916745364285715, test accuracy:0.6839305711086227 train loss:0.57326148, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6929730425, test accuracy:0.6839305711086227 train loss:0.57451934, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6882726648214286, test accuracy:0.683090705487122 train loss:0.58084055, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.69622467375, test accuracy:0.6839305711086227 train loss:0.57269958, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6991436298214285, test accuracy:0.6839305711086227 train loss:0.56875285, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6933003519642857, test accuracy:0.6839305711086227 train loss:0.57946899, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6912291808928571, test accuracy:0.6839305711086227 train loss:0.57416889, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6938100960714285, test accuracy:0.6839305711086227 train loss:0.5715171, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6985694969642857, test accuracy:0.6839305711086227 train loss:0.5689849, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6894477592857143, test accuracy:0.683090705487122 train loss:0.5727031, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.69325742625, test accuracy:0.683090705487122 train loss:0.57268236, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6957685869642857, test accuracy:0.683090705487122 train loss:0.56926372, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6993689903571428, test accuracy:0.683090705487122 train loss:0.56582928, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6923023266071429, test accuracy:0.683090705487122 train loss:0.57269414, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6940515539285714, test accuracy:0.683090705487122 train loss:0.57299172, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6971046532142857, test accuracy:0.683090705487122 train loss:0.56674495, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.69469544125, test accuracy:0.683090705487122 train loss:0.57414723, test loss:31.69093132, test precision: 0.5961106955871354,test recall: 0.5737940964722822,test f1: 0.5847395451210565\n",
      "train accuracy: 0.6975285457142857, test accuracy:0.6839305711086227 train loss:0.5711122, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6925867101785714, test accuracy:0.6839305711086227 train loss:0.57287156, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6898018973214286, test accuracy:0.6839305711086227 train loss:0.57851357, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6879238925, test accuracy:0.6836506159014558 train loss:0.58022799, test loss:31.63493919, test precision: 0.5961106955871354,test recall: 0.5746214852198991,test f1: 0.5851688693098386\n",
      "train accuracy: 0.6864000257142857, test accuracy:0.6836506159014558 train loss:0.57930538, test loss:31.63493919, test precision: 0.5961106955871354,test recall: 0.5746214852198991,test f1: 0.5851688693098386\n",
      "train accuracy: 0.6906443166071429, test accuracy:0.6836506159014558 train loss:0.5757303, test loss:31.63493919, test precision: 0.5961106955871354,test recall: 0.5746214852198991,test f1: 0.5851688693098386\n",
      "train accuracy: 0.6992133842857143, test accuracy:0.6839305711086227 train loss:0.57036295, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6915242960714286, test accuracy:0.6836506159014558 train loss:0.57567917, test loss:31.63493919, test precision: 0.5961106955871354,test recall: 0.5746214852198991,test f1: 0.5851688693098386\n",
      "train accuracy: 0.6957149296428572, test accuracy:0.6839305711086227 train loss:0.57263209, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.6949690933928572, test accuracy:0.6856103023516238 train loss:0.57128114, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.693359375, test accuracy:0.6839305711086227 train loss:0.57375891, test loss:31.60694313, test precision: 0.5953627524308153,test recall: 0.5751445086705202,test f1: 0.5850790150679898\n",
      "train accuracy: 0.68798828125, test accuracy:0.6836506159014558 train loss:0.57751419, test loss:31.63493919, test precision: 0.5961106955871354,test recall: 0.5746214852198991,test f1: 0.5851688693098386\n",
      "train accuracy: 0.6910789405357143, test accuracy:0.6856103023516238 train loss:0.577272, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6896570226785714, test accuracy:0.6856103023516238 train loss:0.57291919, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6893028846428572, test accuracy:0.6856103023516238 train loss:0.57953826, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.7028459821428571, test accuracy:0.6856103023516238 train loss:0.56858157, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6913579583928572, test accuracy:0.6856103023516238 train loss:0.57725228, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6952266483928572, test accuracy:0.6856103023516238 train loss:0.57211406, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6919159941071429, test accuracy:0.6856103023516238 train loss:0.57510758, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6976948832142857, test accuracy:0.6856103023516238 train loss:0.57098619, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6942769144642857, test accuracy:0.6856103023516238 train loss:0.57133702, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6964446685714286, test accuracy:0.6853303471444568 train loss:0.57278484, test loss:31.46696663, test precision: 0.5961106955871354,test recall: 0.5771180304127443,test f1: 0.5864606328182487\n",
      "train accuracy: 0.6918247767857143, test accuracy:0.6856103023516238 train loss:0.57383657, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6938369248214286, test accuracy:0.68505039193729 train loss:0.57255484, test loss:31.49496269, test precision: 0.5766641735228123,test recall: 0.5796992481203007,test f1: 0.578177727784027\n",
      "train accuracy: 0.6963695483928571, test accuracy:0.6853303471444568 train loss:0.57517989, test loss:31.46696663, test precision: 0.5961106955871354,test recall: 0.5771180304127443,test f1: 0.5864606328182487\n",
      "train accuracy: 0.6924525669642857, test accuracy:0.6856103023516238 train loss:0.57112834, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6985212053571429, test accuracy:0.6856103023516238 train loss:0.57120899, test loss:31.43897057, test precision: 0.5953627524308153,test recall: 0.5776487663280117,test f1: 0.5863720073664827\n",
      "train accuracy: 0.6870975703571428, test accuracy:0.68505039193729 train loss:0.57868607, test loss:31.49496269, test precision: 0.5766641735228123,test recall: 0.5796992481203007,test f1: 0.578177727784027\n",
      "train accuracy: 0.6881438873214286, test accuracy:0.6853303471444568 train loss:0.57529641, test loss:31.46696663, test precision: 0.5961106955871354,test recall: 0.5771180304127443,test f1: 0.5864606328182487\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[32m[I 2023-04-03 12:20:03,078]\u001b[0m Trial 6 finished with value: 0.5595905206033162 and parameters: {'n_layers': 2, 'n_units_l0': 304, 'n_units_l1': 539, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5502296771321978.\u001b[0m\n"
=======
      "\u001b[32m[I 2023-04-03 00:45:58,353]\u001b[0m Trial 0 finished with value: 0.5731068764414106 and parameters: {'n_layers': 1, 'n_units_l0': 350, 'optimizer': 'Adam'}. Best is trial 0 with value: 0.5731068764414106.\u001b[0m\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train accuracy: 0.712830492857143, test accuracy:0.7054871220604704 train loss:0.55959052, test loss:0.57774639, test precision: 0.6035901271503366,test recall: 0.6072234762979684,test f1: 0.6054013503375844\n",
      "train accuracy: 0.5229492196428571, test accuracy:0.5772676371780515 train loss:0.69293506, test loss:0.6913662, test precision: 0.27973074046372476,test recall: 0.40608034744842564,test f1: 0.33126660761736054\n",
      "train accuracy: 0.5167122067857143, test accuracy:0.576427771556551 train loss:0.69289314, test loss:0.69117254, test precision: 0.27973074046372476,test recall: 0.40476190476190477,test f1: 0.33082706766917297\n",
      "train accuracy: 0.5402747828571428, test accuracy:0.6310190369540873 train loss:0.69257701, test loss:0.69099158, test precision: 0.21914734480179507,test recall: 0.5167548500881834,test f1: 0.3077731092436975\n",
      "train accuracy: 0.5566983535714286, test accuracy:0.6329787234042553 train loss:0.6923814, test loss:0.69090503, test precision: 0.23335826477187735,test recall: 0.5217391304347826,test f1: 0.32248062015503876\n",
      "train accuracy: 0.5550795685714286, test accuracy:0.6290593505039194 train loss:0.6922744, test loss:0.69074398, test precision: 0.23635003739715782,test recall: 0.5096774193548387,test f1: 0.3229432805314257\n",
      "train accuracy: 0.5634308610714286, test accuracy:0.6343784994400896 train loss:0.69201971, test loss:0.69060791, test precision: 0.2543006731488407,test recall: 0.5238828967642527,test f1: 0.3423967774420947\n",
      "train accuracy: 0.5626707789285714, test accuracy:0.6371780515117581 train loss:0.69188294, test loss:0.690467, test precision: 0.25355272999252054,test recall: 0.5321821036106751,test f1: 0.34346504559270513\n",
      "train accuracy: 0.5681597335714286, test accuracy:0.6382978723404256 train loss:0.6916173, test loss:0.69027442, test precision: 0.25654450261780104,test recall: 0.5351014040561622,test f1: 0.3468149646107179\n",
      "train accuracy: 0.5627814221428571, test accuracy:0.6436170212765957 train loss:0.6916285, test loss:0.69016874, test precision: 0.27225130890052357,test recall: 0.5481927710843374,test f1: 0.3638180909545228\n",
      "train accuracy: 0.5779662482142857, test accuracy:0.6466965285554311 train loss:0.6913705, test loss:0.6901108, test precision: 0.2916978309648467,test recall: 0.5531914893617021,test f1: 0.38197845249755147\n",
      "train accuracy: 0.5848358607142856, test accuracy:0.6497760358342665 train loss:0.69103823, test loss:0.68996745, test precision: 0.30142109199700823,test recall: 0.5597222222222222,test f1: 0.391832766164317\n",
      "train accuracy: 0.5892977425, test accuracy:0.6497760358342665 train loss:0.69090032, test loss:0.6897797, test precision: 0.3044128646222887,test recall: 0.5590659340659341,test f1: 0.39418886198547215\n",
      "train accuracy: 0.5869934385714285, test accuracy:0.6494960806270996 train loss:0.69077186, test loss:0.6896143, test precision: 0.30740463724756917,test recall: 0.5576662143826323,test f1: 0.39633558341369335\n",
      "train accuracy: 0.5900457975, test accuracy:0.6528555431131019 train loss:0.6905979, test loss:0.68948817, test precision: 0.31712789827973076,test recall: 0.5645805592543276,test f1: 0.40613026819923376\n",
      "train accuracy: 0.5967927378571429, test accuracy:0.6528555431131019 train loss:0.69018018, test loss:0.6893099, test precision: 0.31712789827973076,test recall: 0.5645805592543276,test f1: 0.40613026819923376\n",
      "train accuracy: 0.5975359839285714, test accuracy:0.658454647256439 train loss:0.69009289, test loss:0.68918729, test precision: 0.3537771129394166,test recall: 0.5705669481302774,test f1: 0.43674976915974145\n",
      "train accuracy: 0.6029888585714286, test accuracy:0.6559350503919373 train loss:0.69002007, test loss:0.6890704, test precision: 0.40089753178758414,test recall: 0.5560165975103735,test f1: 0.4658843980877879\n",
      "train accuracy: 0.6076888664285715, test accuracy:0.6559350503919373 train loss:0.68976739, test loss:0.6889047, test precision: 0.4023934181002244,test recall: 0.5557851239669421,test f1: 0.46681127982646425\n",
      "train accuracy: 0.5985534374999999, test accuracy:0.6542553191489362 train loss:0.68977088, test loss:0.68874121, test precision: 0.4113687359760658,test recall: 0.5511022044088176,test f1: 0.47109207708779444\n",
      "train accuracy: 0.6183468671428571, test accuracy:0.6528555431131019 train loss:0.68922363, test loss:0.68863428, test precision: 0.41660433807030667,test recall: 0.5476892822025565,test f1: 0.4732370433305013\n",
      "train accuracy: 0.6047495575, test accuracy:0.6528555431131019 train loss:0.68926296, test loss:0.68845856, test precision: 0.418848167539267,test recall: 0.5474095796676441,test f1: 0.4745762711864407\n",
      "train accuracy: 0.6116841117857142, test accuracy:0.6520156774916014 train loss:0.68926004, test loss:0.68831605, test precision: 0.4495138369483919,test recall: 0.5424187725631769,test f1: 0.4916155419222904\n",
      "train accuracy: 0.6193378621428572, test accuracy:0.6520156774916014 train loss:0.68892231, test loss:0.68822998, test precision: 0.506357516828721,test recall: 0.5373015873015873,test f1: 0.5213708124759338\n",
      "train accuracy: 0.6342749389285715, test accuracy:0.6528555431131019 train loss:0.68865613, test loss:0.68805063, test precision: 0.5086013462976814,test recall: 0.5384006334125099,test f1: 0.5230769230769231\n",
      "train accuracy: 0.6416039667857144, test accuracy:0.6536954087346024 train loss:0.68819184, test loss:0.68790352, test precision: 0.5153328347045625,test recall: 0.5391236306729265,test f1: 0.5269598470363289\n",
      "train accuracy: 0.6439804314285714, test accuracy:0.654535274356103 train loss:0.68794317, test loss:0.68769461, test precision: 0.5205684367988033,test recall: 0.5399534522885958,test f1: 0.5300837776085301\n",
      "train accuracy: 0.6454476800000001, test accuracy:0.6550951847704367 train loss:0.68806934, test loss:0.68748766, test precision: 0.5205684367988033,test recall: 0.5407925407925408,test f1: 0.5304878048780488\n"
=======
      "train accuracy: 0.6951139680357142, test accuracy:0.6853303471444568 train loss:0.57310688, test loss:31.46696663, test precision: 0.5961106955871354,test recall: 0.5771180304127443,test f1: 0.5864606328182487\n",
      "train accuracy: 0.5022428742857142, test accuracy:0.6256998880179171 train loss:0.6926879, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5255086710714286, test accuracy:0.6612541993281075 train loss:0.69245539, test loss:33.87458038, test precision: 0.15033657442034407,test recall: 0.730909090909091,test f1: 0.24937965260545905\n",
      "train accuracy: 0.5624409769642857, test accuracy:0.660414333706607 train loss:0.69204328, test loss:33.95856857, test precision: 0.156320119670905,test recall: 0.7108843537414966,test f1: 0.2562844880441447\n",
      "train accuracy: 0.5673774467857143, test accuracy:0.6601343784994401 train loss:0.69158348, test loss:33.98656464, test precision: 0.15706806282722513,test recall: 0.7070707070707071,test f1: 0.25703794369645044\n",
      "train accuracy: 0.5696525155357143, test accuracy:0.6671332586786114 train loss:0.69130708, test loss:33.2866745, test precision: 0.2281226626776365,test recall: 0.6601731601731602,test f1: 0.3390772651473041\n",
      "train accuracy: 0.5901495964285715, test accuracy:0.675531914893617 train loss:0.69096067, test loss:32.44680786, test precision: 0.2513089005235602,test recall: 0.680161943319838,test f1: 0.36701256144183503\n",
      "train accuracy: 0.6102818080357143, test accuracy:0.6858902575587906 train loss:0.69060612, test loss:31.4109745, test precision: 0.31338818249813016,test recall: 0.6725521669341894,test f1: 0.4275510204081633\n",
      "train accuracy: 0.6302315848214286, test accuracy:0.6861702127659575 train loss:0.68998787, test loss:31.38298035, test precision: 0.3395661929693343,test recall: 0.6560693641618497,test f1: 0.4475110892065057\n",
      "train accuracy: 0.6268941019642857, test accuracy:0.6951287793952967 train loss:0.68983946, test loss:30.48712349, test precision: 0.37471952131638,test recall: 0.6644562334217506,test f1: 0.47919655667144906\n",
      "train accuracy: 0.6431522578571428, test accuracy:0.696528555431131 train loss:0.68908607, test loss:30.34714508, test precision: 0.4031413612565445,test recall: 0.6533333333333333,test f1: 0.4986123959296947\n",
      "train accuracy: 0.6436298076785715, test accuracy:0.7001679731243001 train loss:0.68873043, test loss:29.98320389, test precision: 0.4397905759162304,test recall: 0.6461538461538462,test f1: 0.5233644859813084\n",
      "train accuracy: 0.6487809066071428, test accuracy:0.700447928331467 train loss:0.68827396, test loss:29.95520782, test precision: 0.4532535527299925,test recall: 0.6412698412698413,test f1: 0.5311130587204207\n",
      "train accuracy: 0.6460765796428571, test accuracy:0.6900895856662934 train loss:0.68791961, test loss:30.99104309, test precision: 0.47643979057591623,test recall: 0.6101532567049809,test f1: 0.5350692986140277\n",
      "train accuracy: 0.65979674625, test accuracy:0.687010078387458 train loss:0.68693733, test loss:31.29899406, test precision: 0.5287958115183246,test recall: 0.5916317991631799,test f1: 0.5584518167456557\n",
      "train accuracy: 0.6670029189285714, test accuracy:0.6822508398656215 train loss:0.68625795, test loss:31.7749176, test precision: 0.5347793567688855,test recall: 0.5822475570032574,test f1: 0.557504873294347\n",
      "train accuracy: 0.6665521978571428, test accuracy:0.6833706606942889 train loss:0.68570434, test loss:31.66293526, test precision: 0.5452505609573672,test recall: 0.5822683706070287,test f1: 0.5631517960602549\n",
      "train accuracy: 0.6671263307142857, test accuracy:0.6822508398656215 train loss:0.68500749, test loss:31.7749176, test precision: 0.5579655946148093,test recall: 0.5782945736434109,test f1: 0.5679482299200609\n",
      "train accuracy: 0.6651463771428572, test accuracy:0.6825307950727884 train loss:0.6844544, test loss:31.74692154, test precision: 0.5594614809274495,test recall: 0.5784996133023975,test f1: 0.5688212927756654\n",
      "train accuracy: 0.6634990985714285, test accuracy:0.6794512877939529 train loss:0.68336316, test loss:32.05487061, test precision: 0.5602094240837696,test recall: 0.5735068912710567,test f1: 0.5667801740446462\n",
      "train accuracy: 0.6583909255357143, test accuracy:0.6766517357222844 train loss:0.68311196, test loss:32.33482742, test precision: 0.5632011967090501,test recall: 0.5687311178247734,test f1: 0.5659526493799324\n",
      "train accuracy: 0.6615674364285714, test accuracy:0.6763717805151176 train loss:0.68184337, test loss:32.36282349, test precision: 0.5691847419596111,test recall: 0.5674869500372856,test f1: 0.5683345780433159\n",
      "train accuracy: 0.6646205357142857, test accuracy:0.6707726763717805 train loss:0.68106212, test loss:32.92273331, test precision: 0.5729244577412117,test recall: 0.5587162654996353,test f1: 0.5657311669128507\n",
      "train accuracy: 0.6651141826785715, test accuracy:0.6707726763717805 train loss:0.67983208, test loss:32.92273331, test precision: 0.5744203440538519,test recall: 0.5585454545454546,test f1: 0.5663716814159292\n",
      "train accuracy: 0.6649478451785714, test accuracy:0.6710526315789473 train loss:0.67879369, test loss:32.89473724, test precision: 0.5744203440538519,test recall: 0.5589519650655022,test f1: 0.566580597565474\n",
      "train accuracy: 0.6605425825, test accuracy:0.671612541993281 train loss:0.67796239, test loss:32.83874512, test precision: 0.5661929693343306,test recall: 0.5607407407407408,test f1: 0.5634536657982882\n",
      "train accuracy: 0.6657151442857143, test accuracy:0.6668533034714446 train loss:0.6766542, test loss:33.31467056, test precision: 0.5766641735228123,test recall: 0.5526881720430108,test f1: 0.5644216691068815\n",
      "train accuracy: 0.6652912517857142, test accuracy:0.6620940649496081 train loss:0.67548459, test loss:33.79059601, test precision: 0.5848915482423336,test recall: 0.5453277545327755,test f1: 0.5644171779141104\n",
      "train accuracy: 0.6545705271428571, test accuracy:0.6587346024636058 train loss:0.67511596, test loss:34.12654114, test precision: 0.5916230366492147,test recall: 0.5403005464480874,test f1: 0.564798286326312\n",
      "train accuracy: 0.6626191191071429, test accuracy:0.6590145576707727 train loss:0.67341896, test loss:34.09854507, test precision: 0.5916230366492147,test recall: 0.5406698564593302,test f1: 0.565\n",
      "train accuracy: 0.6659619676785714, test accuracy:0.6590145576707727 train loss:0.67123414, test loss:34.09854507, test precision: 0.5916230366492147,test recall: 0.5406698564593302,test f1: 0.565\n",
      "train accuracy: 0.662109375, test accuracy:0.6592945128779395 train loss:0.67025818, test loss:34.07054901, test precision: 0.5916230366492147,test recall: 0.5410396716826266,test f1: 0.5652018578063595\n",
      "train accuracy: 0.6626405821428571, test accuracy:0.6592945128779395 train loss:0.66875856, test loss:34.07054901, test precision: 0.5916230366492147,test recall: 0.5410396716826266,test f1: 0.5652018578063595\n",
      "train accuracy: 0.6646366328571428, test accuracy:0.6590145576707727 train loss:0.66712368, test loss:34.09854507, test precision: 0.5931189229618549,test recall: 0.5405589638718473,test f1: 0.5656205420827389\n",
      "train accuracy: 0.6615030476785714, test accuracy:0.6592945128779395 train loss:0.66630165, test loss:34.07054901, test precision: 0.5931189229618549,test recall: 0.5409276944065484,test f1: 0.5658223332144131\n",
      "train accuracy: 0.6664448832142857, test accuracy:0.6587346024636058 train loss:0.66415061, test loss:34.12654114, test precision: 0.5931189229618549,test recall: 0.5401907356948229,test f1: 0.5654188948306595\n",
      "train accuracy: 0.65686705875, test accuracy:0.658454647256439 train loss:0.66383578, test loss:34.1545372, test precision: 0.5946148092744952,test recall: 0.539714867617108,test f1: 0.5658362989323844\n",
      "train accuracy: 0.66578489875, test accuracy:0.658454647256439 train loss:0.65992004, test loss:34.1545372, test precision: 0.5946148092744952,test recall: 0.539714867617108,test f1: 0.5658362989323844\n",
      "train accuracy: 0.6653717376785714, test accuracy:0.6587346024636058 train loss:0.66003483, test loss:34.12654114, test precision: 0.5961106955871354,test recall: 0.5399728997289973,test f1: 0.5666548169214363\n",
      "train accuracy: 0.6637942135714285, test accuracy:0.6587346024636058 train loss:0.65673253, test loss:34.12654114, test precision: 0.5961106955871354,test recall: 0.5399728997289973,test f1: 0.5666548169214363\n",
      "train accuracy: 0.6605533139285714, test accuracy:0.6587346024636058 train loss:0.65720877, test loss:34.12654114, test precision: 0.5968586387434555,test recall: 0.5399188092016238,test f1: 0.5669626998223801\n",
      "train accuracy: 0.6609074519642857, test accuracy:0.6587346024636058 train loss:0.65561713, test loss:34.12654114, test precision: 0.5961106955871354,test recall: 0.5399728997289973,test f1: 0.5666548169214363\n",
      "train accuracy: 0.6707160026785715, test accuracy:0.6587346024636058 train loss:0.65130064, test loss:34.12654114, test precision: 0.5968586387434555,test recall: 0.5399188092016238,test f1: 0.5669626998223801\n",
      "train accuracy: 0.6654683207142857, test accuracy:0.6587346024636058 train loss:0.65027574, test loss:34.12654114, test precision: 0.5968586387434555,test recall: 0.5399188092016238,test f1: 0.5669626998223801\n",
      "train accuracy: 0.6602367358928571, test accuracy:0.6587346024636058 train loss:0.65100489, test loss:34.12654114, test precision: 0.5968586387434555,test recall: 0.5399188092016238,test f1: 0.5669626998223801\n",
      "train accuracy: 0.6659780648214285, test accuracy:0.6592945128779395 train loss:0.6464774, test loss:34.07054901, test precision: 0.5968586387434555,test recall: 0.540650406504065,test f1: 0.5673658016352648\n",
      "train accuracy: 0.6585465316071428, test accuracy:0.6618141097424413 train loss:0.64678716, test loss:33.81859207, test precision: 0.5953627524308153,test recall: 0.5440874914559125,test f1: 0.5685714285714285\n",
      "train accuracy: 0.67353301, test accuracy:0.6615341545352743 train loss:0.6414065, test loss:33.84658432, test precision: 0.5953627524308153,test recall: 0.5437158469945356,test f1: 0.5683684398429133\n",
      "train accuracy: 0.6633112980357143, test accuracy:0.6615341545352743 train loss:0.64369635, test loss:33.84658432, test precision: 0.5953627524308153,test recall: 0.5437158469945356,test f1: 0.5683684398429133\n",
      "train accuracy: 0.6652590573214285, test accuracy:0.6578947368421053 train loss:0.64094641, test loss:34.21052933, test precision: 0.5968586387434555,test recall: 0.5388251181634031,test f1: 0.5663591199432222\n",
      "train accuracy: 0.6682745964285715, test accuracy:0.6609742441209406 train loss:0.63680979, test loss:33.90257645, test precision: 0.5953627524308153,test recall: 0.5429740791268759,test f1: 0.5679628968961827\n",
      "train accuracy: 0.6670512105357143, test accuracy:0.6612541993281075 train loss:0.63509909, test loss:33.87458038, test precision: 0.5946148092744952,test recall: 0.543403964456596,test f1: 0.5678571428571428\n",
      "train accuracy: 0.6619376717857143, test accuracy:0.6612541993281075 train loss:0.63703724, test loss:33.87458038, test precision: 0.5946148092744952,test recall: 0.543403964456596,test f1: 0.5678571428571428\n",
      "train accuracy: 0.6615620707142857, test accuracy:0.6612541993281075 train loss:0.63443368, test loss:33.87458038, test precision: 0.5946148092744952,test recall: 0.543403964456596,test f1: 0.5678571428571428\n",
      "train accuracy: 0.663804945, test accuracy:0.6620940649496081 train loss:0.63371597, test loss:33.79059601, test precision: 0.5931189229618549,test recall: 0.5446428571428571,test f1: 0.5678481919083422\n",
      "train accuracy: 0.6612830528571428, test accuracy:0.6620940649496081 train loss:0.6336019, test loss:33.79059601, test precision: 0.5931189229618549,test recall: 0.5446428571428571,test f1: 0.5678481919083422\n",
      "train accuracy: 0.6650390625, test accuracy:0.6620940649496081 train loss:0.62862695, test loss:33.79059601, test precision: 0.5931189229618549,test recall: 0.5446428571428571,test f1: 0.5678481919083422\n",
      "train accuracy: 0.6614386589285715, test accuracy:0.658454647256439 train loss:0.63214087, test loss:34.1545372, test precision: 0.606581899775617,test recall: 0.5388704318936877,test f1: 0.5707248416608023\n",
      "train accuracy: 0.6618357228571429, test accuracy:0.6632138857782754 train loss:0.62893715, test loss:33.67861176, test precision: 0.5931189229618549,test recall: 0.5461432506887053,test f1: 0.5686626030835424\n",
      "train accuracy: 0.6625279017857143, test accuracy:0.6595744680851063 train loss:0.62819011, test loss:34.04255295, test precision: 0.6020942408376964,test recall: 0.5406312961719275,test f1: 0.5697098372257609\n",
      "train accuracy: 0.6642288375, test accuracy:0.6587346024636058 train loss:0.62484563, test loss:34.12654114, test precision: 0.6028421839940165,test recall: 0.5394912985274432,test f1: 0.5694101024373014\n",
      "train accuracy: 0.663252275, test accuracy:0.6587346024636058 train loss:0.62668649, test loss:34.12654114, test precision: 0.6028421839940165,test recall: 0.5394912985274432,test f1: 0.5694101024373014\n",
      "train accuracy: 0.66243131875, test accuracy:0.660414333706607 train loss:0.62462322, test loss:33.95856857, test precision: 0.5991024682124159,test recall: 0.5419485791610285,test f1: 0.5690941385435169\n",
      "train accuracy: 0.66047819375, test accuracy:0.6618141097424413 train loss:0.62578415, test loss:33.81859207, test precision: 0.5983545250560958,test recall: 0.5438477226376615,test f1: 0.5698005698005698\n",
      "train accuracy: 0.6735169128571429, test accuracy:0.6618141097424413 train loss:0.61939508, test loss:33.81859207, test precision: 0.5983545250560958,test recall: 0.5438477226376615,test f1: 0.5698005698005698\n",
      "train accuracy: 0.6676950978571429, test accuracy:0.6618141097424413 train loss:0.62115346, test loss:33.81859207, test precision: 0.5983545250560958,test recall: 0.5438477226376615,test f1: 0.5698005698005698\n",
      "train accuracy: 0.6673033996428571, test accuracy:0.6618141097424413 train loss:0.61924658, test loss:33.81859207, test precision: 0.5983545250560958,test recall: 0.5438477226376615,test f1: 0.5698005698005698\n",
      "train accuracy: 0.6663590316071428, test accuracy:0.6634938409854423 train loss:0.6215283, test loss:33.65061569, test precision: 0.5953627524308153,test recall: 0.546328071379547,test f1: 0.5697924123120973\n",
      "train accuracy: 0.6651141826785715, test accuracy:0.6634938409854423 train loss:0.62115279, test loss:33.65061569, test precision: 0.5946148092744952,test recall: 0.5463917525773195,test f1: 0.569484240687679\n",
      "train accuracy: 0.6682853280357143, test accuracy:0.6620940649496081 train loss:0.61838429, test loss:33.79059601, test precision: 0.5976065818997757,test recall: 0.5442779291553134,test f1: 0.5696969696969697\n",
      "train accuracy: 0.66516784, test accuracy:0.6626539753639418 train loss:0.61954421, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6730232657142857, test accuracy:0.6623740201567749 train loss:0.61255145, test loss:33.76259995, test precision: 0.5961106955871354,test recall: 0.544771018455229,test f1: 0.5692857142857143\n",
      "train accuracy: 0.6731842376785714, test accuracy:0.6623740201567749 train loss:0.61292817, test loss:33.76259995, test precision: 0.5961106955871354,test recall: 0.544771018455229,test f1: 0.5692857142857143\n",
      "train accuracy: 0.6659995278571429, test accuracy:0.6623740201567749 train loss:0.61462404, test loss:33.76259995, test precision: 0.5961106955871354,test recall: 0.544771018455229,test f1: 0.5692857142857143\n",
      "train accuracy: 0.6664073232142858, test accuracy:0.6623740201567749 train loss:0.61713126, test loss:33.76259995, test precision: 0.5961106955871354,test recall: 0.544771018455229,test f1: 0.5692857142857143\n",
      "train accuracy: 0.6698735833928572, test accuracy:0.6626539753639418 train loss:0.61540917, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6697877317857143, test accuracy:0.6626539753639418 train loss:0.61233922, test loss:33.73460388, test precision: 0.5961106955871354,test recall: 0.5451436388508892,test f1: 0.5694891032511611\n",
      "train accuracy: 0.6698628519642857, test accuracy:0.6626539753639418 train loss:0.61245951, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6745256696428571, test accuracy:0.6626539753639418 train loss:0.61014343, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6711130666071429, test accuracy:0.6626539753639418 train loss:0.61195857, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6612401271428572, test accuracy:0.6626539753639418 train loss:0.6184561, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6741554344642857, test accuracy:0.6626539753639418 train loss:0.60916796, test loss:33.73460388, test precision: 0.5968586387434555,test recall: 0.5450819672131147,test f1: 0.5697965012495537\n",
      "train accuracy: 0.6653127146428571, test accuracy:0.6618141097424413 train loss:0.61347663, test loss:33.81859207, test precision: 0.5991024682124159,test recall: 0.5437881873727087,test f1: 0.5701067615658363\n",
      "train accuracy: 0.6632415435714286, test accuracy:0.6620940649496081 train loss:0.61415282, test loss:33.79059601, test precision: 0.5983545250560958,test recall: 0.54421768707483,test f1: 0.5700035625222658\n",
      "train accuracy: 0.6703189389285714, test accuracy:0.6623740201567749 train loss:0.6100046, test loss:33.76259995, test precision: 0.5968586387434555,test recall: 0.5447098976109215,test f1: 0.569593147751606\n",
      "train accuracy: 0.6635634873214286, test accuracy:0.6620940649496081 train loss:0.6141073, test loss:33.79059601, test precision: 0.5983545250560958,test recall: 0.54421768707483,test f1: 0.5700035625222658\n",
      "train accuracy: 0.66331666375, test accuracy:0.660414333706607 train loss:0.61275249, test loss:33.95856857, test precision: 0.6073298429319371,test recall: 0.5413333333333333,test f1: 0.572435671483962\n",
      "train accuracy: 0.6765109889285714, test accuracy:0.6637737961926092 train loss:0.60608764, test loss:33.62261963, test precision: 0.5953627524308153,test recall: 0.5467032967032966,test f1: 0.5699964196204798\n",
      "train accuracy: 0.6797626201785715, test accuracy:0.6685330347144457 train loss:0.60575457, test loss:33.146698, test precision: 0.5886312640239342,test recall: 0.553835327234342,test f1: 0.5707034082668601\n",
      "train accuracy: 0.6756256439285714, test accuracy:0.6676931690929452 train loss:0.60595541, test loss:33.23068237, test precision: 0.5908750934928946,test recall: 0.5524475524475524,test f1: 0.5710155402963499\n",
      "train accuracy: 0.6808518630357143, test accuracy:0.6662933930571109 train loss:0.60389788, test loss:33.37066269, test precision: 0.599850411368736,test recall: 0.5496915695681974,test f1: 0.5736766809728183\n",
      "train accuracy: 0.6845381182142857, test accuracy:0.667973124300112 train loss:0.60202215, test loss:33.20269012, test precision: 0.5916230366492147,test recall: 0.5527603074772887,test f1: 0.5715317919075146\n",
      "train accuracy: 0.6717515882142857, test accuracy:0.6668533034714446 train loss:0.6078545, test loss:33.31467056, test precision: 0.599850411368736,test recall: 0.55044612216884,test f1: 0.5740873299928418\n",
      "train accuracy: 0.6828264508928571, test accuracy:0.6668533034714446 train loss:0.60292473, test loss:33.31467056, test precision: 0.599850411368736,test recall: 0.55044612216884,test f1: 0.5740873299928418\n",
      "train accuracy: 0.6726369333928571, test accuracy:0.6668533034714446 train loss:0.6057585, test loss:33.31467056, test precision: 0.599850411368736,test recall: 0.55044612216884,test f1: 0.5740873299928418\n",
      "train accuracy: 0.6754378433928572, test accuracy:0.6674132138857782 train loss:0.60925544, test loss:33.25867844, test precision: 0.599850411368736,test recall: 0.5512027491408935,test f1: 0.5744985673352436\n",
      "train accuracy: 0.6851444453571428, test accuracy:0.6674132138857782 train loss:0.5979783, test loss:33.25867844, test precision: 0.599850411368736,test recall: 0.5512027491408935,test f1: 0.5744985673352436\n",
      "train accuracy: 0.6816030648214285, test accuracy:0.6702127659574468 train loss:0.60126497, test loss:32.97872543, test precision: 0.5991024682124159,test recall: 0.5550935550935551,test f1: 0.5762589928057553\n",
      "train accuracy: 0.6763929430357143, test accuracy:0.6696528555431132 train loss:0.60792182, test loss:33.03471375, test precision: 0.599850411368736,test recall: 0.5542501727712509,test f1: 0.5761494252873564\n",
      "train accuracy: 0.6761514851785714, test accuracy:0.6690929451287794 train loss:0.60604124, test loss:33.09070587, test precision: 0.599850411368736,test recall: 0.5534851621808143,test f1: 0.5757358219669777\n",
      "train accuracy: 0.67796510125, test accuracy:0.6690929451287794 train loss:0.60267114, test loss:33.09070587, test precision: 0.599850411368736,test recall: 0.5534851621808143,test f1: 0.5757358219669777\n",
      "train accuracy: 0.6875912173214286, test accuracy:0.6690929451287794 train loss:0.5988681, test loss:33.09070587, test precision: 0.599850411368736,test recall: 0.5534851621808143,test f1: 0.5757358219669777\n",
      "train accuracy: 0.6754163805357143, test accuracy:0.66993281075028 train loss:0.6073444, test loss:33.0067215, test precision: 0.599850411368736,test recall: 0.5546334716459198,test f1: 0.5763564498742364\n",
      "train accuracy: 0.6793816535714285, test accuracy:0.66993281075028 train loss:0.60151322, test loss:33.0067215, test precision: 0.599850411368736,test recall: 0.5546334716459198,test f1: 0.5763564498742364\n",
      "train accuracy: 0.6792421446428571, test accuracy:0.66993281075028 train loss:0.60345466, test loss:33.0067215, test precision: 0.599850411368736,test recall: 0.5546334716459198,test f1: 0.5763564498742364\n",
      "train accuracy: 0.6786626458928572, test accuracy:0.6702127659574468 train loss:0.60341361, test loss:32.97872543, test precision: 0.599850411368736,test recall: 0.5550173010380622,test f1: 0.5765636232925951\n",
      "train accuracy: 0.6744934753571429, test accuracy:0.6707726763717805 train loss:0.60593983, test loss:32.92273331, test precision: 0.599850411368736,test recall: 0.5557865557865558,test f1: 0.576978417266187\n",
      "train accuracy: 0.6826010903571429, test accuracy:0.6707726763717805 train loss:0.59904201, test loss:32.92273331, test precision: 0.599850411368736,test recall: 0.5557865557865558,test f1: 0.576978417266187\n",
      "train accuracy: 0.6780777816071428, test accuracy:0.6707726763717805 train loss:0.59977891, test loss:32.92273331, test precision: 0.599850411368736,test recall: 0.5557865557865558,test f1: 0.576978417266187\n",
      "train accuracy: 0.6776485233928572, test accuracy:0.6730123180291153 train loss:0.602734, test loss:32.69876862, test precision: 0.6140613313388182,test recall: 0.5573659198913782,test f1: 0.5843416370106762\n",
      "train accuracy: 0.6693853021428572, test accuracy:0.66993281075028 train loss:0.60898544, test loss:33.0067215, test precision: 0.6170531039640987,test recall: 0.5529490616621984,test f1: 0.5832449628844114\n",
      "train accuracy: 0.6827727935714286, test accuracy:0.6693729003359462 train loss:0.60051008, test loss:33.06270981, test precision: 0.6170531039640987,test recall: 0.5522088353413654,test f1: 0.5828329212292477\n",
      "train accuracy: 0.68200012875, test accuracy:0.6707726763717805 train loss:0.60194377, test loss:32.92273331, test precision: 0.6155572176514585,test recall: 0.5542087542087543,test f1: 0.5832742735648477\n",
      "train accuracy: 0.6854020003571428, test accuracy:0.6707726763717805 train loss:0.59896695, test loss:32.92273331, test precision: 0.6155572176514585,test recall: 0.5542087542087543,test f1: 0.5832742735648477\n",
      "train accuracy: 0.68183379125, test accuracy:0.6707726763717805 train loss:0.59704702, test loss:32.92273331, test precision: 0.6155572176514585,test recall: 0.5542087542087543,test f1: 0.5832742735648477\n",
      "train accuracy: 0.6864429516071429, test accuracy:0.6730123180291153 train loss:0.59556308, test loss:32.69876862, test precision: 0.6140613313388182,test recall: 0.5573659198913782,test f1: 0.5843416370106762\n",
      "train accuracy: 0.6745471325, test accuracy:0.6702127659574468 train loss:0.60371259, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.6748368817857143, test accuracy:0.6702127659574468 train loss:0.60584356, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.6809699089285715, test accuracy:0.6702127659574468 train loss:0.60106187, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.6820054944642857, test accuracy:0.6702127659574468 train loss:0.60036597, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.68418398, test accuracy:0.6702127659574468 train loss:0.59816597, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.6837225275, test accuracy:0.6702127659574468 train loss:0.59777364, test loss:32.97872543, test precision: 0.6155572176514585,test recall: 0.5534633490248824,test f1: 0.5828611898016998\n",
      "train accuracy: 0.6792958017857142, test accuracy:0.66993281075028 train loss:0.60036799, test loss:33.0067215, test precision: 0.6170531039640987,test recall: 0.5529490616621984,test f1: 0.5832449628844114\n",
      "train accuracy: 0.6802723642857142, test accuracy:0.66993281075028 train loss:0.59768483, test loss:33.0067215, test precision: 0.6170531039640987,test recall: 0.5529490616621984,test f1: 0.5832449628844114\n",
      "train accuracy: 0.68229524375, test accuracy:0.6727323628219485 train loss:0.59921646, test loss:32.72676468, test precision: 0.6118175018698578,test recall: 0.5572207084468664,test f1: 0.5832442067736185\n",
      "train accuracy: 0.6833898523214286, test accuracy:0.6713325867861142 train loss:0.59673711, test loss:32.86674118, test precision: 0.6155572176514585,test recall: 0.5549561699258261,test f1: 0.5836879432624115\n",
      "train accuracy: 0.6762373369642857, test accuracy:0.6721724524076148 train loss:0.6008222, test loss:32.78275681, test precision: 0.6148092744951383,test recall: 0.5561569688768606,test f1: 0.5840142095914742\n",
      "train accuracy: 0.6900326235714286, test accuracy:0.6710526315789473 train loss:0.59257835, test loss:32.89473724, test precision: 0.6170531039640987,test recall: 0.5544354838709677,test f1: 0.584070796460177\n",
      "train accuracy: 0.6828962053571429, test accuracy:0.6713325867861142 train loss:0.59652972, test loss:32.86674118, test precision: 0.6155572176514585,test recall: 0.5549561699258261,test f1: 0.5836879432624115\n",
      "train accuracy: 0.6817640367857143, test accuracy:0.671892497200448 train loss:0.597672, test loss:32.81075287, test precision: 0.6200448765893792,test recall: 0.5552578700602813,test f1: 0.5858657243816254\n",
      "train accuracy: 0.6816620878571429, test accuracy:0.671892497200448 train loss:0.59963448, test loss:32.81075287, test precision: 0.6200448765893792,test recall: 0.5552578700602813,test f1: 0.5858657243816254\n",
      "train accuracy: 0.6870385473214285, test accuracy:0.6688129899216125 train loss:0.59531601, test loss:33.11870193, test precision: 0.6207928197456993,test recall: 0.5511288180610889,test f1: 0.5838902567710165\n",
      "train accuracy: 0.6877843835714286, test accuracy:0.6688129899216125 train loss:0.59448559, test loss:33.11870193, test precision: 0.6207928197456993,test recall: 0.5511288180610889,test f1: 0.5838902567710165\n",
      "train accuracy: 0.6889863066071429, test accuracy:0.6696528555431132 train loss:0.59587097, test loss:33.03471375, test precision: 0.6200448765893792,test recall: 0.5522984676882079,test f1: 0.5842142353770262\n",
      "train accuracy: 0.6817103794642857, test accuracy:0.6696528555431132 train loss:0.60067979, test loss:33.03471375, test precision: 0.6200448765893792,test recall: 0.5522984676882079,test f1: 0.5842142353770262\n",
      "train accuracy: 0.6863463683928571, test accuracy:0.6702127659574468 train loss:0.59585561, test loss:32.97872543, test precision: 0.6170531039640987,test recall: 0.5533199195171026,test f1: 0.5834512022630834\n",
      "train accuracy: 0.6855790692857143, test accuracy:0.6702127659574468 train loss:0.59408125, test loss:32.97872543, test precision: 0.6170531039640987,test recall: 0.5533199195171026,test f1: 0.5834512022630834\n",
      "train accuracy: 0.6844790951785714, test accuracy:0.6707726763717805 train loss:0.59893208, test loss:32.92273331, test precision: 0.6110695587135377,test recall: 0.5546503733876442,test f1: 0.5814946619217082\n",
      "train accuracy: 0.6909662603571428, test accuracy:0.673572228443449 train loss:0.59364663, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6856166294642857, test accuracy:0.673572228443449 train loss:0.59459881, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6756524725, test accuracy:0.673572228443449 train loss:0.60444168, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6881331558928572, test accuracy:0.673572228443449 train loss:0.59513751, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6840552026785715, test accuracy:0.673572228443449 train loss:0.5986845, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6854771205357143, test accuracy:0.673572228443449 train loss:0.5972501, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6814742875, test accuracy:0.673572228443449 train loss:0.59893014, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6912399125, test accuracy:0.673572228443449 train loss:0.59256387, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6834864353571428, test accuracy:0.6744120940649496 train loss:0.59877074, test loss:32.55879211, test precision: 0.6073298429319371,test recall: 0.56,test f1: 0.5827054180121995\n",
      "train accuracy: 0.6841625171428571, test accuracy:0.6744120940649496 train loss:0.59520792, test loss:32.55879211, test precision: 0.6073298429319371,test recall: 0.56,test f1: 0.5827054180121995\n",
      "train accuracy: 0.6815708705357143, test accuracy:0.6744120940649496 train loss:0.59986319, test loss:32.55879211, test precision: 0.6073298429319371,test recall: 0.56,test f1: 0.5827054180121995\n",
      "train accuracy: 0.6869795244642857, test accuracy:0.6741321388577828 train loss:0.59481846, test loss:32.58678818, test precision: 0.6118175018698578,test recall: 0.5591250854408749,test f1: 0.5842857142857144\n",
      "train accuracy: 0.68284791375, test accuracy:0.6744120940649496 train loss:0.59674275, test loss:32.55879211, test precision: 0.6073298429319371,test recall: 0.56,test f1: 0.5827054180121995\n",
      "train accuracy: 0.6756471067857143, test accuracy:0.6738521836506159 train loss:0.59805782, test loss:32.61478424, test precision: 0.6133133881824981,test recall: 0.55858310626703,test f1: 0.5846702317290552\n",
      "train accuracy: 0.6849351819642857, test accuracy:0.673572228443449 train loss:0.59622768, test loss:32.64277649, test precision: 0.6103216155572176,test recall: 0.5585215605749486,test f1: 0.5832737669764116\n",
      "train accuracy: 0.6782065591071429, test accuracy:0.673572228443449 train loss:0.5998036, test loss:32.64277649, test precision: 0.6133133881824981,test recall: 0.5582028590878149,test f1: 0.5844618674269422\n",
      "train accuracy: 0.6899145776785715, test accuracy:0.6724524076147816 train loss:0.58965332, test loss:32.75476074, test precision: 0.6170531039640987,test recall: 0.5563047875927175,test f1: 0.5851063829787235\n",
      "train accuracy: 0.68642148875, test accuracy:0.6724524076147816 train loss:0.59312094, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.6816889166071428, test accuracy:0.6727323628219485 train loss:0.59770859, test loss:32.72676468, test precision: 0.6110695587135377,test recall: 0.5572987721691678,test f1: 0.5829468426685693\n",
      "train accuracy: 0.6813616071428571, test accuracy:0.6724524076147816 train loss:0.59691083, test loss:32.75476074, test precision: 0.6140613313388182,test recall: 0.5566101694915254,test f1: 0.5839260312944523\n",
      "train accuracy: 0.6880848642857142, test accuracy:0.6730123180291153 train loss:0.59451042, test loss:32.69876862, test precision: 0.6110695587135377,test recall: 0.557679180887372,test f1: 0.5831548893647395\n",
      "train accuracy: 0.6882726648214286, test accuracy:0.6738521836506159 train loss:0.59139478, test loss:32.61478424, test precision: 0.6103216155572176,test recall: 0.5589041095890411,test f1: 0.5834823024669289\n",
      "train accuracy: 0.6864697801785714, test accuracy:0.673572228443449 train loss:0.59319585, test loss:32.64277649, test precision: 0.6103216155572176,test recall: 0.5585215605749486,test f1: 0.5832737669764116\n",
      "train accuracy: 0.6850317651785715, test accuracy:0.6738521836506159 train loss:0.59591095, test loss:32.61478424, test precision: 0.6103216155572176,test recall: 0.5589041095890411,test f1: 0.5834823024669289\n",
      "train accuracy: 0.6809430803571429, test accuracy:0.6741321388577828 train loss:0.59320137, test loss:32.58678818, test precision: 0.6148092744951383,test recall: 0.5588035350101972,test f1: 0.5854700854700855\n",
      "train accuracy: 0.6784587482142858, test accuracy:0.6758118701007839 train loss:0.59722392, test loss:32.41881561, test precision: 0.6043380703066566,test recall: 0.5622825330549757,test f1: 0.5825522710886807\n",
      "train accuracy: 0.6920501373214286, test accuracy:0.6760918253079508 train loss:0.58900235, test loss:32.39081955, test precision: 0.6088257292445775,test recall: 0.5621546961325967,test f1: 0.584560143626571\n",
      "train accuracy: 0.6840444710714285, test accuracy:0.6758118701007839 train loss:0.59294824, test loss:32.41881561, test precision: 0.612565445026178,test recall: 0.5613433858807403,test f1: 0.5858369098712446\n",
      "train accuracy: 0.6870975703571428, test accuracy:0.6772116461366181 train loss:0.59175293, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.68675416375, test accuracy:0.6772116461366181 train loss:0.59222157, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6803313873214286, test accuracy:0.6772116461366181 train loss:0.59732173, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6865073403571429, test accuracy:0.6772116461366181 train loss:0.59433052, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6896999485714286, test accuracy:0.6772116461366181 train loss:0.59015375, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6837708191071429, test accuracy:0.6772116461366181 train loss:0.59471219, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6836903330357142, test accuracy:0.6772116461366181 train loss:0.59413656, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6906711451785714, test accuracy:0.6772116461366181 train loss:0.59037369, test loss:32.2788353, test precision: 0.6080777860882572,test recall: 0.5638002773925104,test f1: 0.5851025548758545\n",
      "train accuracy: 0.6841571514285715, test accuracy:0.6769316909294513 train loss:0.59457791, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.68879850625, test accuracy:0.6760918253079508 train loss:0.58923072, test loss:32.39081955, test precision: 0.6043380703066566,test recall: 0.5626740947075209,test f1: 0.5827623512441399\n",
      "train accuracy: 0.6873604910714286, test accuracy:0.6777715565509519 train loss:0.58809799, test loss:32.22284698, test precision: 0.6013462976813763,test recall: 0.5654008438818565,test f1: 0.582819862268938\n",
      "train accuracy: 0.6974319625, test accuracy:0.6774916013437849 train loss:0.58515661, test loss:32.25083923, test precision: 0.6028421839940165,test recall: 0.5648213034337771,test f1: 0.5832127351664255\n",
      "train accuracy: 0.6803367530357143, test accuracy:0.6766517357222844 train loss:0.59978687, test loss:32.33482742, test precision: 0.605833956619297,test recall: 0.5632823365785814,test f1: 0.5837837837837839\n",
      "train accuracy: 0.6889272835714285, test accuracy:0.6777715565509519 train loss:0.58987696, test loss:32.22284698, test precision: 0.6013462976813763,test recall: 0.5654008438818565,test f1: 0.582819862268938\n",
      "train accuracy: 0.6901560353571429, test accuracy:0.6769316909294513 train loss:0.58583722, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6951837225, test accuracy:0.6769316909294513 train loss:0.58738126, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6891419128571429, test accuracy:0.6769316909294513 train loss:0.58988587, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6929623110714286, test accuracy:0.6769316909294513 train loss:0.58706531, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6873658567857143, test accuracy:0.6769316909294513 train loss:0.58832182, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6823435353571429, test accuracy:0.6763717805151176 train loss:0.59197559, test loss:32.36282349, test precision: 0.6103216155572176,test recall: 0.5623707787732598,test f1: 0.5853658536585366\n",
      "train accuracy: 0.6801274896428572, test accuracy:0.6758118701007839 train loss:0.59485724, test loss:32.41881561, test precision: 0.6110695587135377,test recall: 0.5615120274914089,test f1: 0.585243553008596\n",
      "train accuracy: 0.6948295844642857, test accuracy:0.6763717805151176 train loss:0.58178494, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6832610748214286, test accuracy:0.6763717805151176 train loss:0.59150705, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6902472526785715, test accuracy:0.6763717805151176 train loss:0.58519964, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6906550480357143, test accuracy:0.6769316909294513 train loss:0.58776637, test loss:32.30683136, test precision: 0.6073298429319371,test recall: 0.563497571131159,test f1: 0.5845932325413967\n",
      "train accuracy: 0.6906174880357143, test accuracy:0.6783314669652856 train loss:0.589439, test loss:32.16685486, test precision: 0.605833956619297,test recall: 0.5656424581005587,test f1: 0.5850487540628386\n",
      "train accuracy: 0.6895711710714286, test accuracy:0.6783314669652856 train loss:0.59108215, test loss:32.16685486, test precision: 0.606581899775617,test recall: 0.5655509065550907,test f1: 0.5853482497293395\n",
      "train accuracy: 0.6898394575, test accuracy:0.6783314669652856 train loss:0.58648823, test loss:32.16685486, test precision: 0.606581899775617,test recall: 0.5655509065550907,test f1: 0.5853482497293395\n",
      "train accuracy: 0.6848868905357143, test accuracy:0.6763717805151176 train loss:0.59188664, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6893619076785714, test accuracy:0.6783314669652856 train loss:0.58592402, test loss:32.16685486, test precision: 0.606581899775617,test recall: 0.5655509065550907,test f1: 0.5853482497293395\n",
      "train accuracy: 0.6924096410714285, test accuracy:0.681131019036954 train loss:0.5856169, test loss:31.88689995, test precision: 0.6035901271503366,test recall: 0.5699152542372882,test f1: 0.5862695241554668\n",
      "train accuracy: 0.6910682091071428, test accuracy:0.681131019036954 train loss:0.58456883, test loss:31.88689995, test precision: 0.6035901271503366,test recall: 0.5699152542372882,test f1: 0.5862695241554668\n",
      "train accuracy: 0.6882941276785715, test accuracy:0.6774916013437849 train loss:0.58699394, test loss:32.25083923, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6886482657142857, test accuracy:0.6760918253079508 train loss:0.58832702, test loss:32.39081955, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6855361435714286, test accuracy:0.6774916013437849 train loss:0.59037255, test loss:32.25083923, test precision: 0.6095736724008975,test recall: 0.5640138408304498,test f1: 0.5859094176851186\n",
      "train accuracy: 0.6907677283928572, test accuracy:0.6758118701007839 train loss:0.58848784, test loss:32.41881561, test precision: 0.6110695587135377,test recall: 0.5615120274914089,test f1: 0.585243553008596\n",
      "train accuracy: 0.6878863325, test accuracy:0.6780515117581187 train loss:0.58735072, test loss:32.19485092, test precision: 0.605833956619297,test recall: 0.5652477320307048,test f1: 0.5848375451263538\n",
      "train accuracy: 0.6841732485714286, test accuracy:0.6780515117581187 train loss:0.58826034, test loss:32.19485092, test precision: 0.605833956619297,test recall: 0.5652477320307048,test f1: 0.5848375451263538\n",
      "train accuracy: 0.6865663633928571, test accuracy:0.6780515117581187 train loss:0.58854494, test loss:32.19485092, test precision: 0.605833956619297,test recall: 0.5652477320307048,test f1: 0.5848375451263538\n",
      "train accuracy: 0.6848117701785714, test accuracy:0.6763717805151176 train loss:0.58773892, test loss:32.36282349, test precision: 0.6080777860882572,test recall: 0.5626297577854671,test f1: 0.5844716031631918\n",
      "train accuracy: 0.6901023780357143, test accuracy:0.6777715565509519 train loss:0.58505979, test loss:32.22284698, test precision: 0.606581899775617,test recall: 0.5647632311977716,test f1: 0.584926072845294\n",
      "train accuracy: 0.6928281678571429, test accuracy:0.6774916013437849 train loss:0.58342902, test loss:32.25083923, test precision: 0.606581899775617,test recall: 0.5643702157272095,test f1: 0.5847152126892573\n",
      "train accuracy: 0.68925995875, test accuracy:0.6780515117581187 train loss:0.58558969, test loss:32.19485092, test precision: 0.605833956619297,test recall: 0.5652477320307048,test f1: 0.5848375451263538\n",
      "train accuracy: 0.69508177375, test accuracy:0.6777715565509519 train loss:0.58182429, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6888253348214286, test accuracy:0.6777715565509519 train loss:0.58988967, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6874409769642857, test accuracy:0.6777715565509519 train loss:0.58886821, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6949798248214286, test accuracy:0.6777715565509519 train loss:0.58133702, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6888950892857143, test accuracy:0.6777715565509519 train loss:0.58858832, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6915135646428572, test accuracy:0.6777715565509519 train loss:0.58466375, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6898877489285714, test accuracy:0.6777715565509519 train loss:0.58535967, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6898609203571429, test accuracy:0.6763717805151176 train loss:0.58672258, test loss:32.36282349, test precision: 0.6073298429319371,test recall: 0.5627165627165627,test f1: 0.5841726618705035\n",
      "train accuracy: 0.6929193853571428, test accuracy:0.6777715565509519 train loss:0.58259312, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6889970380357143, test accuracy:0.6777715565509519 train loss:0.584216, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6854771205357143, test accuracy:0.6777715565509519 train loss:0.58526553, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6877146291071429, test accuracy:0.6777715565509519 train loss:0.58319938, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.68469909, test accuracy:0.6777715565509519 train loss:0.58617269, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6871512276785714, test accuracy:0.6774916013437849 train loss:0.58727627, test loss:32.25083923, test precision: 0.605833956619297,test recall: 0.5644599303135889,test f1: 0.5844155844155844\n",
      "train accuracy: 0.6901828639285714, test accuracy:0.6777715565509519 train loss:0.58299804, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6918784341071429, test accuracy:0.6777715565509519 train loss:0.58155714, test loss:32.22284698, test precision: 0.605833956619297,test recall: 0.5648535564853556,test f1: 0.5846264886322626\n",
      "train accuracy: 0.6879131610714285, test accuracy:0.6788913773796192 train loss:0.588082, test loss:32.11086273, test precision: 0.5953627524308153,test recall: 0.5677603423680456,test f1: 0.5812340270171595\n",
      "train accuracy: 0.6903438358928572, test accuracy:0.6788913773796192 train loss:0.58266401, test loss:32.11086273, test precision: 0.5953627524308153,test recall: 0.5677603423680456,test f1: 0.5812340270171595\n",
      "train accuracy: 0.6946095896428571, test accuracy:0.6788913773796192 train loss:0.57880536, test loss:32.11086273, test precision: 0.5953627524308153,test recall: 0.5677603423680456,test f1: 0.5812340270171595\n",
      "train accuracy: 0.6943895948214286, test accuracy:0.6766517357222844 train loss:0.5814834, test loss:32.33482742, test precision: 0.6140613313388182,test recall: 0.5623287671232877,test f1: 0.5870575616732213\n",
      "train accuracy: 0.6957739526785715, test accuracy:0.6763717805151176 train loss:0.57572915, test loss:32.36282349, test precision: 0.6088257292445775,test recall: 0.5625431928127159,test f1: 0.5847701149425287\n",
      "train accuracy: 0.6851229825, test accuracy:0.6780515117581187 train loss:0.58587574, test loss:32.19485092, test precision: 0.5983545250560958,test recall: 0.5661712668082095,test f1: 0.5818181818181819\n",
      "train accuracy: 0.6916155133928571, test accuracy:0.6780515117581187 train loss:0.58023621, test loss:32.19485092, test precision: 0.5983545250560958,test recall: 0.5661712668082095,test f1: 0.5818181818181819\n",
      "train accuracy: 0.6916423419642858, test accuracy:0.6783314669652856 train loss:0.58111373, test loss:32.16685486, test precision: 0.5991024682124159,test recall: 0.5664780763790664,test f1: 0.5823336968375136\n",
      "train accuracy: 0.6944539835714286, test accuracy:0.6788913773796192 train loss:0.57676105, test loss:32.11086273, test precision: 0.5953627524308153,test recall: 0.5677603423680456,test f1: 0.5812340270171595\n",
      "train accuracy: 0.6884068080357143, test accuracy:0.6777715565509519 train loss:0.58542066, test loss:32.22284698, test precision: 0.6035901271503366,test recall: 0.5651260504201681,test f1: 0.5837251356238699\n",
      "train accuracy: 0.6907999226785714, test accuracy:0.6777715565509519 train loss:0.58215258, test loss:32.22284698, test precision: 0.6028421839940165,test recall: 0.5652173913043478,test f1: 0.583423814694173\n",
      "train accuracy: 0.6864107571428572, test accuracy:0.6777715565509519 train loss:0.58434957, test loss:32.22284698, test precision: 0.6028421839940165,test recall: 0.5652173913043478,test f1: 0.583423814694173\n",
      "train accuracy: 0.6840766655357143, test accuracy:0.6760918253079508 train loss:0.58732232, test loss:32.39081955, test precision: 0.6133133881824981,test recall: 0.5616438356164384,test f1: 0.5863425098319628\n",
      "train accuracy: 0.6900004292857143, test accuracy:0.6763717805151176 train loss:0.58423411, test loss:32.36282349, test precision: 0.612565445026178,test recall: 0.5621139327385037,test f1: 0.5862562634216177\n",
      "train accuracy: 0.6940837482142858, test accuracy:0.6783314669652856 train loss:0.57942741, test loss:32.16685486, test precision: 0.5983545250560958,test recall: 0.56657223796034,test f1: 0.5820298290287378\n",
      "train accuracy: 0.6939013135714286, test accuracy:0.6763717805151176 train loss:0.58133429, test loss:32.36282349, test precision: 0.612565445026178,test recall: 0.5621139327385037,test f1: 0.5862562634216177\n",
      "train accuracy: 0.6898501889285714, test accuracy:0.6766517357222844 train loss:0.5798955, test loss:32.33482742, test precision: 0.6140613313388182,test recall: 0.5623287671232877,test f1: 0.5870575616732213\n",
      "train accuracy: 0.6848064044642858, test accuracy:0.6777715565509519 train loss:0.58377319, test loss:32.22284698, test precision: 0.6028421839940165,test recall: 0.5652173913043478,test f1: 0.583423814694173\n",
      "train accuracy: 0.70250794125, test accuracy:0.6766517357222844 train loss:0.57302645, test loss:32.33482742, test precision: 0.6148092744951383,test recall: 0.5622435020519836,test f1: 0.5873526259378349\n",
      "train accuracy: 0.6878648694642857, test accuracy:0.6766517357222844 train loss:0.58315121, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6882029103571429, test accuracy:0.6766517357222844 train loss:0.5803221, test loss:32.33482742, test precision: 0.6148092744951383,test recall: 0.5622435020519836,test f1: 0.5873526259378349\n",
      "train accuracy: 0.6899682348214285, test accuracy:0.6766517357222844 train loss:0.58088371, test loss:32.33482742, test precision: 0.6148092744951383,test recall: 0.5622435020519836,test f1: 0.5873526259378349\n",
      "train accuracy: 0.6878809666071428, test accuracy:0.6766517357222844 train loss:0.58060694, test loss:32.33482742, test precision: 0.6148092744951383,test recall: 0.5622435020519836,test f1: 0.5873526259378349\n",
      "train accuracy: 0.6887126544642858, test accuracy:0.6766517357222844 train loss:0.58182493, test loss:32.33482742, test precision: 0.6140613313388182,test recall: 0.5623287671232877,test f1: 0.5870575616732213\n",
      "train accuracy: 0.6925867101785714, test accuracy:0.6772116461366181 train loss:0.58165039, test loss:32.2788353, test precision: 0.6110695587135377,test recall: 0.5634482758620689,test f1: 0.5862935055615357\n",
      "train accuracy: 0.6919213598214285, test accuracy:0.6772116461366181 train loss:0.57851597, test loss:32.2788353, test precision: 0.6110695587135377,test recall: 0.5634482758620689,test f1: 0.5862935055615357\n",
      "train accuracy: 0.68883606625, test accuracy:0.6783314669652856 train loss:0.58238031, test loss:32.16685486, test precision: 0.600598354525056,test recall: 0.5662905500705219,test f1: 0.582940108892922\n",
      "train accuracy: 0.6954949348214285, test accuracy:0.6783314669652856 train loss:0.57510483, test loss:32.16685486, test precision: 0.6013462976813763,test recall: 0.5661971830985916,test f1: 0.5832426550598477\n",
      "train accuracy: 0.6902472526785715, test accuracy:0.6769316909294513 train loss:0.58105083, test loss:32.30683136, test precision: 0.6013462976813763,test recall: 0.5642105263157895,test f1: 0.5821868211440986\n",
      "train accuracy: 0.6860834478571428, test accuracy:0.6758118701007839 train loss:0.58169228, test loss:32.41881561, test precision: 0.6118175018698578,test recall: 0.5614275909402883,test f1: 0.5855404438081603\n",
      "train accuracy: 0.6943681317857143, test accuracy:0.6774916013437849 train loss:0.57744747, test loss:32.25083923, test precision: 0.6118175018698578,test recall: 0.5637491385251551,test f1: 0.5868005738880918\n",
      "train accuracy: 0.6940461882142858, test accuracy:0.6786114221724524 train loss:0.5755166, test loss:32.1388588, test precision: 0.6013462976813763,test recall: 0.5665961945031712,test f1: 0.5834542815674892\n",
      "train accuracy: 0.69176575375, test accuracy:0.6758118701007839 train loss:0.58298173, test loss:32.41881561, test precision: 0.612565445026178,test recall: 0.5613433858807403,test f1: 0.5858369098712446\n",
      "train accuracy: 0.6899092119642857, test accuracy:0.6786114221724524 train loss:0.57874034, test loss:32.1388588, test precision: 0.6013462976813763,test recall: 0.5665961945031712,test f1: 0.5834542815674892\n",
      "train accuracy: 0.6828157194642858, test accuracy:0.6760918253079508 train loss:0.58385995, test loss:32.39081955, test precision: 0.6043380703066566,test recall: 0.5626740947075209,test f1: 0.5827623512441399\n",
      "train accuracy: 0.6855898008928571, test accuracy:0.6752519596864501 train loss:0.58484294, test loss:32.47480392, test precision: 0.6155572176514585,test recall: 0.5602450646698435,test f1: 0.586600142551675\n",
      "train accuracy: 0.6903706644642857, test accuracy:0.6769316909294513 train loss:0.57861023, test loss:32.30683136, test precision: 0.6118175018698578,test recall: 0.5629731589814178,test f1: 0.5863799283154121\n",
      "train accuracy: 0.6890775241071428, test accuracy:0.6786114221724524 train loss:0.58189289, test loss:32.1388588, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.6876234117857143, test accuracy:0.6769316909294513 train loss:0.58019053, test loss:32.30683136, test precision: 0.6118175018698578,test recall: 0.5629731589814178,test f1: 0.5863799283154121\n",
      "train accuracy: 0.6929730425, test accuracy:0.6763717805151176 train loss:0.57871795, test loss:32.36282349, test precision: 0.6148092744951383,test recall: 0.5618591934381408,test f1: 0.5871428571428572\n",
      "train accuracy: 0.690043355, test accuracy:0.6805711086226204 train loss:0.57877486, test loss:31.94289017, test precision: 0.5991024682124159,test recall: 0.569701280227596,test f1: 0.5840320816624134\n",
      "train accuracy: 0.6950871394642857, test accuracy:0.6794512877939529 train loss:0.5751526, test loss:32.05487061, test precision: 0.6043380703066566,test recall: 0.5674157303370787,test f1: 0.5852951829047447\n",
      "train accuracy: 0.6965090573214285, test accuracy:0.6805711086226204 train loss:0.57310338, test loss:31.94289017, test precision: 0.5991024682124159,test recall: 0.569701280227596,test f1: 0.5840320816624134\n",
      "train accuracy: 0.6914008842857143, test accuracy:0.6797312430011199 train loss:0.5776664, test loss:32.02687836, test precision: 0.6043380703066566,test recall: 0.567814476458187,test f1: 0.5855072463768115\n",
      "train accuracy: 0.6921628176785715, test accuracy:0.6766517357222844 train loss:0.57708039, test loss:32.33482742, test precision: 0.6155572176514585,test recall: 0.5621584699453552,test f1: 0.5876472688325598\n",
      "train accuracy: 0.6809699089285715, test accuracy:0.6791713325867861 train loss:0.58660998, test loss:32.08286667, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6950388478571429, test accuracy:0.6766517357222844 train loss:0.57945849, test loss:32.33482742, test precision: 0.6155572176514585,test recall: 0.5621584699453552,test f1: 0.5876472688325598\n",
      "train accuracy: 0.68473665, test accuracy:0.6780515117581187 train loss:0.58346649, test loss:32.19485092, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6903116414285714, test accuracy:0.6774916013437849 train loss:0.57949171, test loss:32.25083923, test precision: 0.6155572176514585,test recall: 0.5633127994524298,test f1: 0.588277340957827\n",
      "train accuracy: 0.6834971669642858, test accuracy:0.6774916013437849 train loss:0.58076034, test loss:32.25083923, test precision: 0.6192969334330591,test recall: 0.5628823929299797,test f1: 0.5897435897435896\n",
      "train accuracy: 0.6880634014285715, test accuracy:0.6774916013437849 train loss:0.58223773, test loss:32.25083923, test precision: 0.6192969334330591,test recall: 0.5628823929299797,test f1: 0.5897435897435896\n",
      "train accuracy: 0.68968385125, test accuracy:0.6800111982082867 train loss:0.57841354, test loss:31.99888039, test precision: 0.6192969334330591,test recall: 0.5663474692202463,test f1: 0.5916398713826367\n",
      "train accuracy: 0.6898501889285714, test accuracy:0.6805711086226204 train loss:0.57888137, test loss:31.94289017, test precision: 0.6163051608077786,test recall: 0.5674931129476584,test f1: 0.5908927931158121\n",
      "train accuracy: 0.68756438875, test accuracy:0.6805711086226204 train loss:0.58171884, test loss:31.94289017, test precision: 0.6155572176514585,test recall: 0.5675862068965517,test f1: 0.5905992106207391\n",
      "train accuracy: 0.6890345982142857, test accuracy:0.6816909294512878 train loss:0.57901545, test loss:31.83090782, test precision: 0.6050860134629769,test recall: 0.5705218617771509,test f1: 0.5872958257713249\n",
      "train accuracy: 0.6949476305357143, test accuracy:0.6816909294512878 train loss:0.57592802, test loss:31.83090782, test precision: 0.6050860134629769,test recall: 0.5705218617771509,test f1: 0.5872958257713249\n",
      "train accuracy: 0.7015957675, test accuracy:0.6819708846584547 train loss:0.5716542, test loss:31.80291176, test precision: 0.6020942408376964,test recall: 0.5713271823988645,test f1: 0.5863073561544065\n",
      "train accuracy: 0.6940354567857143, test accuracy:0.6808510638297872 train loss:0.57459915, test loss:31.9148941, test precision: 0.6133133881824981,test recall: 0.5682605682605683,test f1: 0.5899280575539568\n",
      "train accuracy: 0.6881653503571429, test accuracy:0.6794512877939529 train loss:0.577719, test loss:32.05487061, test precision: 0.6133133881824981,test recall: 0.5662983425414365,test f1: 0.5888689407540395\n",
      "train accuracy: 0.6897321428571429, test accuracy:0.6794512877939529 train loss:0.58069155, test loss:32.05487061, test precision: 0.6163051608077786,test recall: 0.5659340659340659,test f1: 0.5900465449337631\n",
      "train accuracy: 0.6931876717857143, test accuracy:0.6822508398656215 train loss:0.57602549, test loss:31.7749176, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.6899360405357143, test accuracy:0.6800111982082867 train loss:0.58137516, test loss:31.99888039, test precision: 0.6140613313388182,test recall: 0.5669889502762431,test f1: 0.5895870736086175\n",
      "train accuracy: 0.6900487208928572, test accuracy:0.6808510638297872 train loss:0.57887535, test loss:31.9148941, test precision: 0.605833956619297,test recall: 0.5692199578355587,test f1: 0.5869565217391305\n",
      "train accuracy: 0.6914813701785715, test accuracy:0.6794512877939529 train loss:0.576192, test loss:32.05487061, test precision: 0.6155572176514585,test recall: 0.5660247592847317,test f1: 0.5897527767825153\n",
      "train accuracy: 0.6894101991071429, test accuracy:0.6822508398656215 train loss:0.5755744, test loss:31.7749176, test precision: 0.605833956619297,test recall: 0.5712270803949224,test f1: 0.5880217785843921\n",
      "train accuracy: 0.6858527214285715, test accuracy:0.6822508398656215 train loss:0.58380395, test loss:31.7749176, test precision: 0.6028421839940165,test recall: 0.5716312056737589,test f1: 0.5868219876228614\n",
      "train accuracy: 0.68662538625, test accuracy:0.683090705487122 train loss:0.5809806, test loss:31.69093132, test precision: 0.6020942408376964,test recall: 0.5729537366548043,test f1: 0.5871626549963531\n",
      "train accuracy: 0.6913364955357143, test accuracy:0.683090705487122 train loss:0.58145005, test loss:31.69093132, test precision: 0.6020942408376964,test recall: 0.5729537366548043,test f1: 0.5871626549963531\n",
      "train accuracy: 0.6868292839285715, test accuracy:0.6800111982082867 train loss:0.58482214, test loss:31.99888039, test precision: 0.6043380703066566,test recall: 0.5682137834036568,test f1: 0.5857194635737586\n",
      "train accuracy: 0.6864912432142857, test accuracy:0.6833706606942889 train loss:0.58215328, test loss:31.66293526, test precision: 0.6028421839940165,test recall: 0.5732574679943101,test f1: 0.5876777251184834\n",
      "train accuracy: 0.6928013392857143, test accuracy:0.6833706606942889 train loss:0.57472239, test loss:31.66293526, test precision: 0.6028421839940165,test recall: 0.5732574679943101,test f1: 0.5876777251184834\n",
      "train accuracy: 0.6959724844642857, test accuracy:0.6800111982082867 train loss:0.57437073, test loss:31.99888039, test precision: 0.6035901271503366,test recall: 0.5683098591549296,test f1: 0.5854189336235037\n",
      "train accuracy: 0.69427154875, test accuracy:0.6794512877939529 train loss:0.57174257, test loss:32.05487061, test precision: 0.605833956619297,test recall: 0.5672268907563025,test f1: 0.5858951175406871\n",
      "train accuracy: 0.6932198660714286, test accuracy:0.681131019036954 train loss:0.57659942, test loss:31.88689995, test precision: 0.605833956619297,test recall: 0.569620253164557,test f1: 0.5871692642261689\n",
      "train accuracy: 0.6961173592857143, test accuracy:0.6814109742441209 train loss:0.57388826, test loss:31.85890388, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6937135130357143, test accuracy:0.681131019036954 train loss:0.57327452, test loss:31.88689995, test precision: 0.605833956619297,test recall: 0.569620253164557,test f1: 0.5871692642261689\n",
      "train accuracy: 0.6941964285714286, test accuracy:0.6814109742441209 train loss:0.57412742, test loss:31.85890388, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6914760044642857, test accuracy:0.683090705487122 train loss:0.5772241, test loss:31.69093132, test precision: 0.6050860134629769,test recall: 0.5725406935598019,test f1: 0.5883636363636365\n",
      "train accuracy: 0.69811341, test accuracy:0.6822508398656215 train loss:0.57415398, test loss:31.7749176, test precision: 0.605833956619297,test recall: 0.5712270803949224,test f1: 0.5880217785843921\n",
      "train accuracy: 0.6908696771428572, test accuracy:0.6791713325867861 train loss:0.57418743, test loss:32.08286667, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6979524382142858, test accuracy:0.6805711086226204 train loss:0.56844886, test loss:31.94289017, test precision: 0.6095736724008975,test recall: 0.5683403068340307,test f1: 0.5882352941176471\n",
      "train accuracy: 0.69420716, test accuracy:0.6814109742441209 train loss:0.5779603, test loss:31.85890388, test precision: 0.606581899775617,test recall: 0.5699226985242446,test f1: 0.5876811594202899\n",
      "train accuracy: 0.6954466432142857, test accuracy:0.681131019036954 train loss:0.57370153, test loss:31.88689995, test precision: 0.605833956619297,test recall: 0.569620253164557,test f1: 0.5871692642261689\n",
      "train accuracy: 0.6932198660714286, test accuracy:0.6814109742441209 train loss:0.57492596, test loss:31.85890388, test precision: 0.606581899775617,test recall: 0.5699226985242446,test f1: 0.5876811594202899\n",
      "train accuracy: 0.6952749398214285, test accuracy:0.6881298992161254 train loss:0.57679352, test loss:31.18701172, test precision: 0.6028421839940165,test recall: 0.5802735781137509,test f1: 0.5913426265590608\n",
      "train accuracy: 0.7007372510714286, test accuracy:0.6884098544232923 train loss:0.57364064, test loss:31.15901566, test precision: 0.6035901271503366,test recall: 0.5805755395683453,test f1: 0.5918591859185919\n",
      "train accuracy: 0.6938959478571428, test accuracy:0.6886898096304591 train loss:0.57820701, test loss:31.13101959, test precision: 0.605833956619297,test recall: 0.5806451612903226,test f1: 0.5929721815519765\n",
      "train accuracy: 0.7056254292857143, test accuracy:0.6892497200447928 train loss:0.56958858, test loss:31.07502937, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6951515282142857, test accuracy:0.6867301231802911 train loss:0.5765864, test loss:31.32698822, test precision: 0.6170531039640987,test recall: 0.5761173184357542,test f1: 0.5958829902491874\n",
      "train accuracy: 0.7031840230357143, test accuracy:0.6892497200447928 train loss:0.57288546, test loss:31.07502937, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6951300651785715, test accuracy:0.6878499440089586 train loss:0.57595008, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.7007104223214285, test accuracy:0.6892497200447928 train loss:0.57092815, test loss:31.07502937, test precision: 0.6028421839940165,test recall: 0.5819494584837546,test f1: 0.5922116091109478\n",
      "train accuracy: 0.6956398094642857, test accuracy:0.6903695408734603 train loss:0.57745707, test loss:30.96304703, test precision: 0.6028421839940165,test recall: 0.5836350470673425,test f1: 0.5930831493745401\n",
      "train accuracy: 0.7021001458928572, test accuracy:0.6881298992161254 train loss:0.57134766, test loss:31.18701172, test precision: 0.6043380703066566,test recall: 0.5800430725053841,test f1: 0.591941391941392\n",
      "train accuracy: 0.6979470725, test accuracy:0.6878499440089586 train loss:0.57373936, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.6980973128571428, test accuracy:0.6878499440089586 train loss:0.57364614, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.7023308723214285, test accuracy:0.6878499440089586 train loss:0.57043401, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.7043269230357143, test accuracy:0.6878499440089586 train loss:0.56926135, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.7066341860714286, test accuracy:0.6878499440089586 train loss:0.56691131, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.6935740041071429, test accuracy:0.6878499440089586 train loss:0.57930892, test loss:31.21500587, test precision: 0.606581899775617,test recall: 0.5792857142857143,test f1: 0.5926196565582755\n",
      "train accuracy: 0.6968256353571428, test accuracy:0.6909294512877939 train loss:0.57609693, test loss:30.90705681, test precision: 0.6215407629020194,test recall: 0.5815255423372988,test f1: 0.6008676789587852\n",
      "train accuracy: 0.6998894660714285, test accuracy:0.6898096304591266 train loss:0.57321592, test loss:31.01903725, test precision: 0.6320119670905011,test recall: 0.5783709787816564,test f1: 0.6040028591851323\n",
      "train accuracy: 0.7045952094642857, test accuracy:0.6892497200447928 train loss:0.57048611, test loss:31.07502937, test precision: 0.6043380703066566,test recall: 0.5817134629229662,test f1: 0.5928099779897286\n",
      "train accuracy: 0.6923506182142857, test accuracy:0.6892497200447928 train loss:0.5804959, test loss:31.07502937, test precision: 0.6043380703066566,test recall: 0.5817134629229662,test f1: 0.5928099779897286\n",
      "train accuracy: 0.7030015882142857, test accuracy:0.6892497200447928 train loss:0.56906805, test loss:31.07502937, test precision: 0.6043380703066566,test recall: 0.5817134629229662,test f1: 0.5928099779897286\n",
      "train accuracy: 0.6916745364285715, test accuracy:0.6917693169092946 train loss:0.58117834, test loss:30.82306862, test precision: 0.6020942408376964,test recall: 0.5858806404657934,test f1: 0.5938767982294356\n",
      "train accuracy: 0.6979148780357143, test accuracy:0.6928891377379619 train loss:0.57593458, test loss:30.71108818, test precision: 0.6237845923709798,test recall: 0.5840336134453782,test f1: 0.603254972875226\n",
      "train accuracy: 0.7008552969642857, test accuracy:0.6926091825307951 train loss:0.57403771, test loss:30.73908234, test precision: 0.6192969334330591,test recall: 0.584333098094566,test f1: 0.6013071895424837\n",
      "train accuracy: 0.6950656764285714, test accuracy:0.6892497200447928 train loss:0.57331949, test loss:31.07502937, test precision: 0.6043380703066566,test recall: 0.5817134629229662,test f1: 0.5928099779897286\n",
      "train accuracy: 0.7000826321428572, test accuracy:0.6926091825307951 train loss:0.57534202, test loss:30.73908234, test precision: 0.600598354525056,test recall: 0.5874177029992684,test f1: 0.5939349112426034\n",
      "train accuracy: 0.6983548678571428, test accuracy:0.6898096304591266 train loss:0.57202055, test loss:31.01903725, test precision: 0.606581899775617,test recall: 0.5821966977745873,test f1: 0.5941391941391941\n",
      "train accuracy: 0.6995031335714286, test accuracy:0.6917693169092946 train loss:0.5729908, test loss:30.82306862, test precision: 0.6020942408376964,test recall: 0.5858806404657934,test f1: 0.5938767982294356\n",
      "train accuracy: 0.6995192307142857, test accuracy:0.6926091825307951 train loss:0.57410251, test loss:30.73908234, test precision: 0.600598354525056,test recall: 0.5874177029992684,test f1: 0.5939349112426034\n",
      "train accuracy: 0.6951998196428572, test accuracy:0.6923292273236282 train loss:0.575213, test loss:30.7670784, test precision: 0.6028421839940165,test recall: 0.586608442503639,test f1: 0.5946145333825157\n",
      "train accuracy: 0.7000826321428572, test accuracy:0.6909294512877939 train loss:0.57522286, test loss:30.90705681, test precision: 0.606581899775617,test recall: 0.583873290136789,test f1: 0.5950110051357299\n",
      "train accuracy: 0.7084209735714285, test accuracy:0.694568868980963 train loss:0.56721466, test loss:30.54311371, test precision: 0.5901271503365744,test recall: 0.5923423423423423,test f1: 0.591232671412514\n",
      "train accuracy: 0.7030123196428572, test accuracy:0.6931690929451287 train loss:0.57211977, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.6986607142857143, test accuracy:0.6898096304591266 train loss:0.56972971, test loss:31.01903725, test precision: 0.606581899775617,test recall: 0.5821966977745873,test f1: 0.5941391941391941\n",
      "train accuracy: 0.6997660542857143, test accuracy:0.6931690929451287 train loss:0.57109714, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.6919106283928571, test accuracy:0.6931690929451287 train loss:0.57969594, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.7029479308928571, test accuracy:0.6931690929451287 train loss:0.56906805, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.7050888564285714, test accuracy:0.6920492721164614 train loss:0.56649018, test loss:30.79507446, test precision: 0.6133133881824981,test recall: 0.5844618674269423,test f1: 0.5985401459854015\n",
      "train accuracy: 0.6988699776785714, test accuracy:0.6931690929451287 train loss:0.57121568, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.6990524125, test accuracy:0.696528555431131 train loss:0.57339405, test loss:30.34714508, test precision: 0.6178010471204188,test recall: 0.590421729807005,test f1: 0.6038011695906433\n",
      "train accuracy: 0.7016064989285714, test accuracy:0.6951287793952967 train loss:0.56912483, test loss:30.48712349, test precision: 0.5923709798055348,test recall: 0.592814371257485,test f1: 0.5925925925925927\n",
      "train accuracy: 0.7008177369642857, test accuracy:0.6954087346024636 train loss:0.56975601, test loss:30.45912743, test precision: 0.6282722513089005,test recall: 0.5870020964360587,test f1: 0.6069364161849711\n",
      "train accuracy: 0.6982475532142857, test accuracy:0.6931690929451287 train loss:0.57073879, test loss:30.68309212, test precision: 0.6028421839940165,test recall: 0.587892049598833,test f1: 0.5952732644017725\n",
      "train accuracy: 0.6921789148214286, test accuracy:0.698488241881299 train loss:0.58136105, test loss:30.15117645, test precision: 0.6073298429319371,test recall: 0.5953079178885631,test f1: 0.601258793039615\n",
      "train accuracy: 0.7037205958928572, test accuracy:0.6951287793952967 train loss:0.5713787, test loss:30.48712349, test precision: 0.5923709798055348,test recall: 0.592814371257485,test f1: 0.5925925925925927\n",
      "train accuracy: 0.7011879721428571, test accuracy:0.6962486002239642 train loss:0.56804399, test loss:30.37514114, test precision: 0.6200448765893792,test recall: 0.5896159317211949,test f1: 0.6044476850164054\n",
      "train accuracy: 0.6959510216071428, test accuracy:0.698488241881299 train loss:0.57808183, test loss:30.15117645, test precision: 0.6073298429319371,test recall: 0.5953079178885631,test f1: 0.601258793039615\n",
      "train accuracy: 0.70947265625, test accuracy:0.696528555431131 train loss:0.56789794, test loss:30.34714508, test precision: 0.6178010471204188,test recall: 0.590421729807005,test f1: 0.6038011695906433\n",
      "train accuracy: 0.69932069875, test accuracy:0.6959686450167973 train loss:0.57485655, test loss:30.40313721, test precision: 0.5916230366492147,test recall: 0.594290007513148,test f1: 0.5929535232383808\n",
      "train accuracy: 0.6988270517857142, test accuracy:0.6948488241881299 train loss:0.57812075, test loss:30.51511955, test precision: 0.5878833208676141,test recall: 0.5932075471698113,test f1: 0.5905334335086402\n",
      "train accuracy: 0.7003938444642858, test accuracy:0.6959686450167973 train loss:0.57223003, test loss:30.40313721, test precision: 0.5916230366492147,test recall: 0.594290007513148,test f1: 0.5929535232383808\n",
      "train accuracy: 0.7017728366071428, test accuracy:0.6959686450167973 train loss:0.57085055, test loss:30.40313721, test precision: 0.5916230366492147,test recall: 0.594290007513148,test f1: 0.5929535232383808\n",
      "train accuracy: 0.7054590916071428, test accuracy:0.6959686450167973 train loss:0.5672498, test loss:30.40313721, test precision: 0.5916230366492147,test recall: 0.594290007513148,test f1: 0.5929535232383808\n",
      "train accuracy: 0.7002704326785715, test accuracy:0.6993281075027995 train loss:0.57247421, test loss:30.06719017, test precision: 0.606581899775617,test recall: 0.5967623252391464,test f1: 0.6016320474777448\n",
      "train accuracy: 0.6969866071428571, test accuracy:0.696528555431131 train loss:0.57687856, test loss:30.34714508, test precision: 0.6178010471204188,test recall: 0.590421729807005,test f1: 0.6038011695906433\n",
      "train accuracy: 0.70322694875, test accuracy:0.696528555431131 train loss:0.56940014, test loss:30.34714508, test precision: 0.6178010471204188,test recall: 0.590421729807005,test f1: 0.6038011695906433\n",
      "train accuracy: 0.7047508155357143, test accuracy:0.698488241881299 train loss:0.56823623, test loss:30.15117645, test precision: 0.6073298429319371,test recall: 0.5953079178885631,test f1: 0.601258793039615\n",
      "train accuracy: 0.6982636503571429, test accuracy:0.696528555431131 train loss:0.57368369, test loss:30.34714508, test precision: 0.6178010471204188,test recall: 0.590421729807005,test f1: 0.6038011695906433\n",
      "train accuracy: 0.6979095123214286, test accuracy:0.6962486002239642 train loss:0.57121526, test loss:30.37514114, test precision: 0.6178010471204188,test recall: 0.59,test f1: 0.6035805626598465\n",
      "train accuracy: 0.695017385, test accuracy:0.6962486002239642 train loss:0.57512517, test loss:30.37514114, test precision: 0.6200448765893792,test recall: 0.5896159317211949,test f1: 0.6044476850164054\n",
      "train accuracy: 0.7011826064285714, test accuracy:0.6959686450167973 train loss:0.57044341, test loss:30.40313721, test precision: 0.6207928197456993,test recall: 0.589070262597587,test f1: 0.6045156591405682\n",
      "train accuracy: 0.69889680625, test accuracy:0.6982082866741322 train loss:0.57693951, test loss:30.17917252, test precision: 0.6095736724008975,test recall: 0.5944566010211525,test f1: 0.6019202363367799\n",
      "train accuracy: 0.7016655219642857, test accuracy:0.6982082866741322 train loss:0.57366467, test loss:30.17917252, test precision: 0.6095736724008975,test recall: 0.5944566010211525,test f1: 0.6019202363367799\n",
      "train accuracy: 0.7037957160714285, test accuracy:0.6979283314669653 train loss:0.57302101, test loss:30.20716858, test precision: 0.6103216155572176,test recall: 0.5938864628820961,test f1: 0.6019918849133162\n",
      "train accuracy: 0.7013489441071429, test accuracy:0.6976483762597985 train loss:0.57091918, test loss:30.23516273, test precision: 0.612565445026178,test recall: 0.5930485155684286,test f1: 0.6026490066225165\n",
      "train accuracy: 0.7017084478571428, test accuracy:0.6962486002239642 train loss:0.5715577, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7032162173214286, test accuracy:0.6940089585666294 train loss:0.56962319, test loss:30.59910583, test precision: 0.6230366492146597,test recall: 0.5857946554149086,test f1: 0.6038419717288873\n",
      "train accuracy: 0.7031840230357143, test accuracy:0.6959686450167973 train loss:0.56691961, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.6995675223214286, test accuracy:0.6942889137737962 train loss:0.57390369, test loss:30.57110977, test precision: 0.6163051608077786,test recall: 0.5873129009265858,test f1: 0.6014598540145986\n",
      "train accuracy: 0.7048956901785715, test accuracy:0.6959686450167973 train loss:0.56716485, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7035327953571429, test accuracy:0.6959686450167973 train loss:0.57128951, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7036025498214286, test accuracy:0.6976483762597985 train loss:0.5721316, test loss:30.23516273, test precision: 0.612565445026178,test recall: 0.5930485155684286,test f1: 0.6026490066225165\n",
      "train accuracy: 0.6976358601785714, test accuracy:0.6959686450167973 train loss:0.56901408, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7082224416071429, test accuracy:0.6962486002239642 train loss:0.56391025, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7054483601785714, test accuracy:0.6962486002239642 train loss:0.56734321, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7053195826785714, test accuracy:0.698488241881299 train loss:0.56954769, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7026689130357143, test accuracy:0.698488241881299 train loss:0.56856247, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7050834907142857, test accuracy:0.698488241881299 train loss:0.56634648, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7088395003571428, test accuracy:0.698488241881299 train loss:0.56606458, test loss:30.15117645, test precision: 0.6013462976813763,test recall: 0.5964391691394659,test f1: 0.598882681564246\n",
      "train accuracy: 0.7096228966071428, test accuracy:0.698488241881299 train loss:0.56670104, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.70257233, test accuracy:0.6959686450167973 train loss:0.57038452, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.709537045, test accuracy:0.6959686450167973 train loss:0.56410807, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.701724545, test accuracy:0.698488241881299 train loss:0.57347331, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7035918183928571, test accuracy:0.6959686450167973 train loss:0.56839931, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7040479051785714, test accuracy:0.6962486002239642 train loss:0.56644588, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7048259357142858, test accuracy:0.6959686450167973 train loss:0.56816902, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7029801253571428, test accuracy:0.6962486002239642 train loss:0.56961838, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.6972066019642857, test accuracy:0.6962486002239642 train loss:0.57432639, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.70514251375, test accuracy:0.6942889137737962 train loss:0.56874215, test loss:30.57110977, test precision: 0.6163051608077786,test recall: 0.5873129009265858,test f1: 0.6014598540145986\n",
      "train accuracy: 0.70739075375, test accuracy:0.6959686450167973 train loss:0.56646472, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7043054601785714, test accuracy:0.6962486002239642 train loss:0.56711903, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.70361328125, test accuracy:0.698488241881299 train loss:0.57117718, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7037098642857142, test accuracy:0.6959686450167973 train loss:0.56884737, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.6999001975, test accuracy:0.6959686450167973 train loss:0.57105641, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7061029791071428, test accuracy:0.6959686450167973 train loss:0.56837529, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7049976391071429, test accuracy:0.6959686450167973 train loss:0.56811232, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7088395003571428, test accuracy:0.6962486002239642 train loss:0.56051309, test loss:30.37514114, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7010377317857143, test accuracy:0.6959686450167973 train loss:0.57060786, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.703125, test accuracy:0.6959686450167973 train loss:0.56710174, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7046595982142857, test accuracy:0.6982082866741322 train loss:0.5680809, test loss:30.17917252, test precision: 0.6035901271503366,test recall: 0.5955719557195572,test f1: 0.5995542347696879\n",
      "train accuracy: 0.7017084478571428, test accuracy:0.6959686450167973 train loss:0.57458582, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7026528158928571, test accuracy:0.698488241881299 train loss:0.56773425, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7036401098214285, test accuracy:0.6959686450167973 train loss:0.5678763, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7004367701785714, test accuracy:0.6959686450167973 train loss:0.56954634, test loss:30.40313721, test precision: 0.612565445026178,test recall: 0.5904830569574622,test f1: 0.6013215859030837\n",
      "train accuracy: 0.7068434494642857, test accuracy:0.6982082866741322 train loss:0.56876649, test loss:30.17917252, test precision: 0.6028421839940165,test recall: 0.5957132298595713,test f1: 0.5992565055762082\n",
      "train accuracy: 0.7107121394642857, test accuracy:0.6982082866741322 train loss:0.5618995, test loss:30.17917252, test precision: 0.6035901271503366,test recall: 0.5955719557195572,test f1: 0.5995542347696879\n",
      "train accuracy: 0.7017728366071428, test accuracy:0.6982082866741322 train loss:0.5703342, test loss:30.17917252, test precision: 0.6035901271503366,test recall: 0.5955719557195572,test f1: 0.5995542347696879\n",
      "train accuracy: 0.7020089285714286, test accuracy:0.6968085106382979 train loss:0.56816029, test loss:30.31914902, test precision: 0.6230366492146597,test recall: 0.589943342776204,test f1: 0.6060385594761732\n",
      "train accuracy: 0.69898802375, test accuracy:0.6968085106382979 train loss:0.5722915, test loss:30.31914902, test precision: 0.6230366492146597,test recall: 0.589943342776204,test f1: 0.6060385594761732\n",
      "train accuracy: 0.7025508671428572, test accuracy:0.6968085106382979 train loss:0.56835429, test loss:30.31914902, test precision: 0.6230366492146597,test recall: 0.589943342776204,test f1: 0.6060385594761732\n",
      "train accuracy: 0.7059795673214285, test accuracy:0.698488241881299 train loss:0.56594251, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.7067468664285714, test accuracy:0.6968085106382979 train loss:0.5640092, test loss:30.31914902, test precision: 0.6230366492146597,test recall: 0.589943342776204,test f1: 0.6060385594761732\n",
      "train accuracy: 0.7004475017857142, test accuracy:0.6968085106382979 train loss:0.56928361, test loss:30.31914902, test precision: 0.6230366492146597,test recall: 0.589943342776204,test f1: 0.6060385594761732\n",
      "train accuracy: 0.7012791896428572, test accuracy:0.698488241881299 train loss:0.56833647, test loss:30.15117645, test precision: 0.6020942408376964,test recall: 0.5962962962962963,test f1: 0.5991812430219576\n",
      "train accuracy: 0.6996211796428572, test accuracy:0.698488241881299 train loss:0.56676319, test loss:30.15117645, test precision: 0.6013462976813763,test recall: 0.5964391691394659,test f1: 0.598882681564246\n",
      "train accuracy: 0.7050244676785714, test accuracy:0.6993281075027995 train loss:0.5680814, test loss:30.06719017, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7011235833928572, test accuracy:0.698488241881299 train loss:0.57314896, test loss:30.15117645, test precision: 0.6013462976813763,test recall: 0.5964391691394659,test f1: 0.598882681564246\n",
      "train accuracy: 0.706221025, test accuracy:0.6990481522956327 train loss:0.56339253, test loss:30.09518623, test precision: 0.6140613313388182,test recall: 0.5949275362318841,test f1: 0.604343025395657\n",
      "train accuracy: 0.7074658739285714, test accuracy:0.6993281075027995 train loss:0.5645093, test loss:30.06719017, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7073478280357143, test accuracy:0.6996080627099664 train loss:0.56354521, test loss:30.03919411, test precision: 0.6095736724008975,test recall: 0.5966325036603221,test f1: 0.6030336662967073\n",
      "train accuracy: 0.7063927283928572, test accuracy:0.6993281075027995 train loss:0.56570284, test loss:30.06719017, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7026528158928571, test accuracy:0.6990481522956327 train loss:0.57056996, test loss:30.09518623, test precision: 0.6140613313388182,test recall: 0.5949275362318841,test f1: 0.604343025395657\n",
      "train accuracy: 0.7053893371428571, test accuracy:0.6990481522956327 train loss:0.56239638, test loss:30.09518623, test precision: 0.6133133881824981,test recall: 0.5950653120464441,test f1: 0.6040515653775322\n",
      "train accuracy: 0.7073049021428571, test accuracy:0.6990481522956327 train loss:0.5632895, test loss:30.09518623, test precision: 0.6133133881824981,test recall: 0.5950653120464441,test f1: 0.6040515653775322\n",
      "train accuracy: 0.7038976648214286, test accuracy:0.6990481522956327 train loss:0.56654711, test loss:30.09518623, test precision: 0.6133133881824981,test recall: 0.5950653120464441,test f1: 0.6040515653775322\n",
      "train accuracy: 0.7095209478571428, test accuracy:0.6993281075027995 train loss:0.56283869, test loss:30.06719017, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7004635989285715, test accuracy:0.7001679731243001 train loss:0.56977083, test loss:29.98320389, test precision: 0.6095736724008975,test recall: 0.5975073313782991,test f1: 0.6034801925212885\n",
      "train accuracy: 0.7045791123214286, test accuracy:0.6996080627099664 train loss:0.56665168, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.7111789576785714, test accuracy:0.6990481522956327 train loss:0.56714495, test loss:30.09518623, test precision: 0.6133133881824981,test recall: 0.5950653120464441,test f1: 0.6040515653775322\n",
      "train accuracy: 0.6986070569642857, test accuracy:0.6998880179171333 train loss:0.57382115, test loss:30.01119995, test precision: 0.6110695587135377,test recall: 0.5967859751643535,test f1: 0.6038433111603844\n",
      "train accuracy: 0.70348450375, test accuracy:0.7015677491601344 train loss:0.56692108, test loss:29.84322548, test precision: 0.605833956619297,test recall: 0.6004447739065975,test f1: 0.6031273268801192\n",
      "train accuracy: 0.71087311125, test accuracy:0.7007278835386338 train loss:0.56083636, test loss:29.92721176, test precision: 0.605833956619297,test recall: 0.599112426035503,test f1: 0.6024544440312384\n",
      "train accuracy: 0.7074390453571429, test accuracy:0.6996080627099664 train loss:0.56390364, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.7001040951785714, test accuracy:0.6998880179171333 train loss:0.57111486, test loss:30.01119995, test precision: 0.6110695587135377,test recall: 0.5967859751643535,test f1: 0.6038433111603844\n",
      "train accuracy: 0.7044020432142857, test accuracy:0.7010078387458006 train loss:0.56848912, test loss:29.89921761, test precision: 0.6095736724008975,test recall: 0.5988243938280676,test f1: 0.6041512231282431\n",
      "train accuracy: 0.7045737466071429, test accuracy:0.7026875699888018 train loss:0.56748374, test loss:29.73124313, test precision: 0.6095736724008975,test recall: 0.6014760147601476,test f1: 0.6054977711738485\n",
      "train accuracy: 0.7007211539285715, test accuracy:0.6998880179171333 train loss:0.56908828, test loss:30.01119995, test precision: 0.6110695587135377,test recall: 0.5967859751643535,test f1: 0.6038433111603844\n",
      "train accuracy: 0.6981831644642857, test accuracy:0.7007278835386338 train loss:0.57239438, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.70097870875, test accuracy:0.7026875699888018 train loss:0.57090735, test loss:29.73124313, test precision: 0.6095736724008975,test recall: 0.6014760147601476,test f1: 0.6054977711738485\n",
      "train accuracy: 0.706183465, test accuracy:0.7007278835386338 train loss:0.56389219, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.6998465401785714, test accuracy:0.7007278835386338 train loss:0.57070024, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.7080829326785715, test accuracy:0.7007278835386338 train loss:0.56519169, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.7030337826785714, test accuracy:0.7007278835386338 train loss:0.56738783, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.7057488410714285, test accuracy:0.700447928331467 train loss:0.56838222, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7013006525, test accuracy:0.700447928331467 train loss:0.57156132, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7120643028571428, test accuracy:0.700447928331467 train loss:0.56316633, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7061727335714286, test accuracy:0.6996080627099664 train loss:0.56172353, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.7103365383928572, test accuracy:0.700447928331467 train loss:0.56563607, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.70371523, test accuracy:0.700447928331467 train loss:0.56713603, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7047239869642857, test accuracy:0.700447928331467 train loss:0.5712193, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7030069539285714, test accuracy:0.700447928331467 train loss:0.56725361, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7018855167857143, test accuracy:0.700447928331467 train loss:0.56812344, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7029479308928571, test accuracy:0.7007278835386338 train loss:0.5705558, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.702867445, test accuracy:0.7007278835386338 train loss:0.56694462, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.7067629635714285, test accuracy:0.7007278835386338 train loss:0.56130855, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.7111413976785714, test accuracy:0.7024076147816349 train loss:0.56284441, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.70670930625, test accuracy:0.7024076147816349 train loss:0.56503523, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7083834133928572, test accuracy:0.7024076147816349 train loss:0.56341711, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7054644575, test accuracy:0.7007278835386338 train loss:0.56608064, test loss:29.92721176, test precision: 0.6110695587135377,test recall: 0.5980966325036603,test f1: 0.6045135035146133\n",
      "train accuracy: 0.6979148780357143, test accuracy:0.6993281075027995 train loss:0.56926151, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7003187242857143, test accuracy:0.698488241881299 train loss:0.56883706, test loss:30.15117645, test precision: 0.6140613313388182,test recall: 0.5940665701881331,test f1: 0.6038984920926811\n",
      "train accuracy: 0.7047776442857143, test accuracy:0.6993281075027995 train loss:0.56657853, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7056093321428571, test accuracy:0.6993281075027995 train loss:0.56692111, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7137437757142857, test accuracy:0.6993281075027995 train loss:0.56039854, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7055986005357143, test accuracy:0.698488241881299 train loss:0.56669902, test loss:30.15117645, test precision: 0.6140613313388182,test recall: 0.5940665701881331,test f1: 0.6038984920926811\n",
      "train accuracy: 0.7047776442857143, test accuracy:0.7001679731243001 train loss:0.56713024, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7035810869642857, test accuracy:0.6993281075027995 train loss:0.56587425, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7073209992857142, test accuracy:0.6993281075027995 train loss:0.56131905, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7009626116071429, test accuracy:0.7001679731243001 train loss:0.56523535, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.6991704583928572, test accuracy:0.698488241881299 train loss:0.56932017, test loss:30.15117645, test precision: 0.6148092744951383,test recall: 0.5939306358381503,test f1: 0.6041896361631753\n",
      "train accuracy: 0.7098482571428572, test accuracy:0.7001679731243001 train loss:0.56447581, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7064034598214286, test accuracy:0.7001679731243001 train loss:0.56462821, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.6961495535714286, test accuracy:0.6993281075027995 train loss:0.57099213, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7093868046428572, test accuracy:0.700447928331467 train loss:0.56180676, test loss:29.95520782, test precision: 0.6110695587135377,test recall: 0.5976591075347476,test f1: 0.6042899408284025\n",
      "train accuracy: 0.7131374485714286, test accuracy:0.7001679731243001 train loss:0.56144998, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7071600275, test accuracy:0.7001679731243001 train loss:0.56229067, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7026259873214286, test accuracy:0.7001679731243001 train loss:0.56473498, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7137169471428572, test accuracy:0.7001679731243001 train loss:0.56295313, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7039674192857143, test accuracy:0.698488241881299 train loss:0.56919446, test loss:30.15117645, test precision: 0.6148092744951383,test recall: 0.5939306358381503,test f1: 0.6041896361631753\n",
      "train accuracy: 0.6962836967857143, test accuracy:0.6993281075027995 train loss:0.57365555, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7077878176785715, test accuracy:0.7001679731243001 train loss:0.56477542, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7046274039285715, test accuracy:0.7021276595744681 train loss:0.56569181, test loss:29.78723526, test precision: 0.6110695587135377,test recall: 0.6002939015429831,test f1: 0.6056338028169014\n",
      "train accuracy: 0.7102453210714286, test accuracy:0.7021276595744681 train loss:0.56051308, test loss:29.78723526, test precision: 0.6110695587135377,test recall: 0.6002939015429831,test f1: 0.6056338028169014\n",
      "train accuracy: 0.70433228875, test accuracy:0.7001679731243001 train loss:0.56819738, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.6997177626785714, test accuracy:0.6993281075027995 train loss:0.56909286, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.6988431491071428, test accuracy:0.7001679731243001 train loss:0.56862859, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7046274039285715, test accuracy:0.7001679731243001 train loss:0.56617588, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7030445141071429, test accuracy:0.7001679731243001 train loss:0.56939401, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7043859460714286, test accuracy:0.7001679731243001 train loss:0.56633325, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7022450205357142, test accuracy:0.7001679731243001 train loss:0.56967221, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7116887019642857, test accuracy:0.7001679731243001 train loss:0.55959442, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7078951321428572, test accuracy:0.700447928331467 train loss:0.56562867, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7030337826785714, test accuracy:0.7029675251959686 train loss:0.56628424, test loss:29.70324898, test precision: 0.6118175018698578,test recall: 0.6014705882352941,test f1: 0.6065999258435297\n",
      "train accuracy: 0.7030713426785714, test accuracy:0.7001679731243001 train loss:0.56337691, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.70458984375, test accuracy:0.7001679731243001 train loss:0.56504137, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7139101133928571, test accuracy:0.700447928331467 train loss:0.56069657, test loss:29.95520782, test precision: 0.6110695587135377,test recall: 0.5976591075347476,test f1: 0.6042899408284025\n",
      "train accuracy: 0.7052283653571428, test accuracy:0.700447928331467 train loss:0.5614163, test loss:29.95520782, test precision: 0.6110695587135377,test recall: 0.5976591075347476,test f1: 0.6042899408284025\n",
      "train accuracy: 0.7139208448214286, test accuracy:0.7001679731243001 train loss:0.55841122, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7080507383928571, test accuracy:0.7010078387458006 train loss:0.56449952, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7065322373214286, test accuracy:0.7001679731243001 train loss:0.56519675, test loss:29.98320389, test precision: 0.6073298429319371,test recall: 0.5979381443298969,test f1: 0.6025974025974026\n",
      "train accuracy: 0.7063658996428571, test accuracy:0.700447928331467 train loss:0.56499699, test loss:29.95520782, test precision: 0.6073298429319371,test recall: 0.5983787767133383,test f1: 0.6028210838901262\n",
      "train accuracy: 0.7006996908928571, test accuracy:0.7001679731243001 train loss:0.56778662, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7013328467857143, test accuracy:0.6998880179171333 train loss:0.56602452, test loss:30.01119995, test precision: 0.6095736724008975,test recall: 0.5970695970695971,test f1: 0.6032568467801629\n",
      "train accuracy: 0.7064463857142858, test accuracy:0.700447928331467 train loss:0.56231875, test loss:29.95520782, test precision: 0.606581899775617,test recall: 0.5985239852398524,test f1: 0.6025260029717682\n",
      "train accuracy: 0.7040103451785714, test accuracy:0.6998880179171333 train loss:0.5627083, test loss:30.01119995, test precision: 0.6095736724008975,test recall: 0.5970695970695971,test f1: 0.6032568467801629\n",
      "train accuracy: 0.7068917410714286, test accuracy:0.7001679731243001 train loss:0.56452528, test loss:29.98320389, test precision: 0.6073298429319371,test recall: 0.5979381443298969,test f1: 0.6025974025974026\n",
      "train accuracy: 0.7093009530357143, test accuracy:0.6998880179171333 train loss:0.56467813, test loss:30.01119995, test precision: 0.606581899775617,test recall: 0.5976418570375829,test f1: 0.6020786933927246\n",
      "train accuracy: 0.7016762533928571, test accuracy:0.7001679731243001 train loss:0.56583015, test loss:29.98320389, test precision: 0.6073298429319371,test recall: 0.5979381443298969,test f1: 0.6025974025974026\n",
      "train accuracy: 0.7102292239285715, test accuracy:0.700447928331467 train loss:0.55836339, test loss:29.95520782, test precision: 0.606581899775617,test recall: 0.5985239852398524,test f1: 0.6025260029717682\n",
      "train accuracy: 0.7063498025, test accuracy:0.7001679731243001 train loss:0.5608712, test loss:29.98320389, test precision: 0.6095736724008975,test recall: 0.5975073313782991,test f1: 0.6034801925212885\n",
      "train accuracy: 0.7010162689285714, test accuracy:0.6976483762597985 train loss:0.56932319, test loss:30.23516273, test precision: 0.6222887060583395,test recall: 0.5913290689410092,test f1: 0.6064139941690961\n",
      "train accuracy: 0.7077878176785715, test accuracy:0.7012877939529675 train loss:0.55937813, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7026742789285715, test accuracy:0.7012877939529675 train loss:0.56364312, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7078629378571428, test accuracy:0.700447928331467 train loss:0.56592134, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7112433464285715, test accuracy:0.700447928331467 train loss:0.55908935, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7117584564285714, test accuracy:0.6990481522956327 train loss:0.56104545, test loss:30.09518623, test precision: 0.6148092744951383,test recall: 0.5947901591895803,test f1: 0.60463405663847\n",
      "train accuracy: 0.7144681491071428, test accuracy:0.6996080627099664 train loss:0.55730289, test loss:30.03919411, test precision: 0.6140613313388182,test recall: 0.5957910014513788,test f1: 0.6047882136279926\n",
      "train accuracy: 0.7092204669642858, test accuracy:0.6996080627099664 train loss:0.56475184, test loss:30.03919411, test precision: 0.6140613313388182,test recall: 0.5957910014513788,test f1: 0.6047882136279926\n",
      "train accuracy: 0.7025455014285714, test accuracy:0.6993281075027995 train loss:0.56809192, test loss:30.06719017, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.70713319875, test accuracy:0.6998880179171333 train loss:0.56266778, test loss:30.01119995, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7111253005357143, test accuracy:0.7001679731243001 train loss:0.56150739, test loss:29.98320389, test precision: 0.6088257292445775,test recall: 0.5976505139500734,test f1: 0.6031863653204891\n",
      "train accuracy: 0.708394145, test accuracy:0.6998880179171333 train loss:0.56322435, test loss:30.01119995, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7079541551785714, test accuracy:0.6987681970884658 train loss:0.5614561, test loss:30.12318039, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.7064356541071428, test accuracy:0.6987681970884658 train loss:0.56489662, test loss:30.12318039, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.6995675223214286, test accuracy:0.7001679731243001 train loss:0.56819146, test loss:29.98320389, test precision: 0.6088257292445775,test recall: 0.5976505139500734,test f1: 0.6031863653204891\n",
      "train accuracy: 0.7102292239285715, test accuracy:0.6998880179171333 train loss:0.55838825, test loss:30.01119995, test precision: 0.6095736724008975,test recall: 0.5970695970695971,test f1: 0.6032568467801629\n",
      "train accuracy: 0.7088395003571428, test accuracy:0.7001679731243001 train loss:0.55948295, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7037259616071428, test accuracy:0.7010078387458006 train loss:0.56425718, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7140066964285714, test accuracy:0.7010078387458006 train loss:0.55895581, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7096067994642857, test accuracy:0.7012877939529675 train loss:0.56270563, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7052069025, test accuracy:0.7035274356103024 train loss:0.56424328, test loss:29.64725685, test precision: 0.6110695587135377,test recall: 0.6025073746312685,test f1: 0.6067582621611586\n",
      "train accuracy: 0.7055449433928571, test accuracy:0.7029675251959686 train loss:0.55957808, test loss:29.70324898, test precision: 0.612565445026178,test recall: 0.6013215859030837,test f1: 0.6068914412745462\n",
      "train accuracy: 0.70927949, test accuracy:0.7032474804031354 train loss:0.55899214, test loss:29.67525291, test precision: 0.6103216155572176,test recall: 0.6022140221402214,test f1: 0.6062407132243685\n",
      "train accuracy: 0.7073692908928572, test accuracy:0.7010078387458006 train loss:0.5613269, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7043966775, test accuracy:0.6998880179171333 train loss:0.56602728, test loss:30.01119995, test precision: 0.6133133881824981,test recall: 0.5963636363636363,test f1: 0.6047197640117994\n",
      "train accuracy: 0.7044986264285714, test accuracy:0.7029675251959686 train loss:0.56202472, test loss:29.70324898, test precision: 0.612565445026178,test recall: 0.6013215859030837,test f1: 0.6068914412745462\n",
      "train accuracy: 0.7044074089285715, test accuracy:0.7029675251959686 train loss:0.56555821, test loss:29.70324898, test precision: 0.612565445026178,test recall: 0.6013215859030837,test f1: 0.6068914412745462\n",
      "train accuracy: 0.70849609375, test accuracy:0.7001679731243001 train loss:0.56305169, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7069829583928572, test accuracy:0.7001679731243001 train loss:0.56135261, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7128745278571429, test accuracy:0.7010078387458006 train loss:0.55765192, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7049386160714286, test accuracy:0.6993281075027995 train loss:0.56487219, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.714033525, test accuracy:0.7001679731243001 train loss:0.55809312, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7102238582142857, test accuracy:0.6993281075027995 train loss:0.56004642, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7037527901785714, test accuracy:0.6990481522956327 train loss:0.56516291, test loss:30.09518623, test precision: 0.6140613313388182,test recall: 0.5949275362318841,test f1: 0.604343025395657\n",
      "train accuracy: 0.7016333276785715, test accuracy:0.6993281075027995 train loss:0.56643018, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7077663548214286, test accuracy:0.6993281075027995 train loss:0.56385324, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7051639766071428, test accuracy:0.6993281075027995 train loss:0.56523012, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7060385903571429, test accuracy:0.700447928331467 train loss:0.56122941, test loss:29.95520782, test precision: 0.6133133881824981,test recall: 0.5972323379461034,test f1: 0.6051660516605166\n",
      "train accuracy: 0.7064249226785714, test accuracy:0.7001679731243001 train loss:0.55723555, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7031303657142857, test accuracy:0.7001679731243001 train loss:0.56532665, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7088341346428572, test accuracy:0.6993281075027995 train loss:0.56581588, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7045683808928571, test accuracy:0.6993281075027995 train loss:0.5611568, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7062746823214285, test accuracy:0.6993281075027995 train loss:0.56553205, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7088877919642858, test accuracy:0.6993281075027995 train loss:0.56159623, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7097463083928571, test accuracy:0.6993281075027995 train loss:0.56098725, test loss:30.06719017, test precision: 0.6170531039640987,test recall: 0.5948089401586157,test f1: 0.6057268722466962\n",
      "train accuracy: 0.6987948575, test accuracy:0.6993281075027995 train loss:0.56895489, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7004099416071429, test accuracy:0.6993281075027995 train loss:0.56474791, test loss:30.06719017, test precision: 0.6178010471204188,test recall: 0.5946724262059035,test f1: 0.6060161408657374\n",
      "train accuracy: 0.7084531678571429, test accuracy:0.6993281075027995 train loss:0.56300258, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7055556748214286, test accuracy:0.6993281075027995 train loss:0.56119811, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7060171273214285, test accuracy:0.6993281075027995 train loss:0.56079411, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7039191276785715, test accuracy:0.6993281075027995 train loss:0.56334611, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7091614441071429, test accuracy:0.6993281075027995 train loss:0.560208, test loss:30.06719017, test precision: 0.6170531039640987,test recall: 0.5948089401586157,test f1: 0.6057268722466962\n",
      "train accuracy: 0.7063927283928572, test accuracy:0.6993281075027995 train loss:0.55764117, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7118443080357143, test accuracy:0.6993281075027995 train loss:0.55674803, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7171885732142858, test accuracy:0.6993281075027995 train loss:0.55439578, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7082063444642858, test accuracy:0.6993281075027995 train loss:0.56344921, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7058132298214286, test accuracy:0.6982082866741322 train loss:0.56421985, test loss:30.17917252, test precision: 0.6245325355272999,test recall: 0.5917788802267895,test f1: 0.6077147016011644\n",
      "train accuracy: 0.70518007375, test accuracy:0.7001679731243001 train loss:0.56359542, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7061780992857143, test accuracy:0.7018477043673013 train loss:0.55890697, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7042196085714286, test accuracy:0.7018477043673013 train loss:0.56750985, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7027708619642857, test accuracy:0.7018477043673013 train loss:0.56816541, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7042142428571428, test accuracy:0.7024076147816349 train loss:0.56507893, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7060439560714286, test accuracy:0.7024076147816349 train loss:0.56990363, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7093814389285714, test accuracy:0.7024076147816349 train loss:0.56105299, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7046220380357143, test accuracy:0.7024076147816349 train loss:0.56227646, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.710089715, test accuracy:0.7018477043673013 train loss:0.55643797, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7015367444642857, test accuracy:0.7001679731243001 train loss:0.56572111, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7022879464285714, test accuracy:0.7001679731243001 train loss:0.56723124, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7000236092857143, test accuracy:0.6993281075027995 train loss:0.56468918, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7052498282142857, test accuracy:0.6993281075027995 train loss:0.56135642, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7017728366071428, test accuracy:0.6993281075027995 train loss:0.56169893, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7079112294642858, test accuracy:0.6993281075027995 train loss:0.55888112, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7047347183928572, test accuracy:0.7018477043673013 train loss:0.56088939, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7127350189285714, test accuracy:0.6993281075027995 train loss:0.55743313, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7054268973214286, test accuracy:0.7026875699888018 train loss:0.56452067, test loss:29.73124313, test precision: 0.6118175018698578,test recall: 0.6010286554004408,test f1: 0.6063750926612305\n",
      "train accuracy: 0.7092311985714286, test accuracy:0.6993281075027995 train loss:0.55486276, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7016172303571429, test accuracy:0.6993281075027995 train loss:0.56419105, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7019928314285714, test accuracy:0.6993281075027995 train loss:0.56614865, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7024328210714286, test accuracy:0.6993281075027995 train loss:0.56506389, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7065376030357143, test accuracy:0.6993281075027995 train loss:0.55874205, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7027333017857142, test accuracy:0.7043673012318029 train loss:0.5670102, test loss:29.56327057, test precision: 0.6118175018698578,test recall: 0.603690036900369,test f1: 0.6077265973254087\n",
      "train accuracy: 0.70790586375, test accuracy:0.7001679731243001 train loss:0.55782698, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7032806060714286, test accuracy:0.7018477043673013 train loss:0.56301017, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7031357314285714, test accuracy:0.7043673012318029 train loss:0.56088643, test loss:29.56327057, test precision: 0.6118175018698578,test recall: 0.603690036900369,test f1: 0.6077265973254087\n",
      "train accuracy: 0.7074175825, test accuracy:0.7026875699888018 train loss:0.56105748, test loss:29.73124313, test precision: 0.6118175018698578,test recall: 0.6010286554004408,test f1: 0.6063750926612305\n",
      "train accuracy: 0.7020035628571428, test accuracy:0.7001679731243001 train loss:0.56289266, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7030069539285714, test accuracy:0.6993281075027995 train loss:0.56113941, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7083190246428571, test accuracy:0.7001679731243001 train loss:0.55949542, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7058561555357142, test accuracy:0.7001679731243001 train loss:0.55714208, test loss:29.98320389, test precision: 0.6133133881824981,test recall: 0.5967976710334789,test f1: 0.6049428255256364\n",
      "train accuracy: 0.7069024725, test accuracy:0.7018477043673013 train loss:0.55797723, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7072995364285715, test accuracy:0.7018477043673013 train loss:0.55995563, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7033074348214285, test accuracy:0.7018477043673013 train loss:0.56662726, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7033235319642858, test accuracy:0.6954087346024636 train loss:0.56032326, test loss:30.45912743, test precision: 0.62528047868362,test recall: 0.5874912157413914,test f1: 0.6057971014492755\n",
      "train accuracy: 0.69941191625, test accuracy:0.7018477043673013 train loss:0.56132033, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.6998572716071428, test accuracy:0.7043673012318029 train loss:0.56326738, test loss:29.56327057, test precision: 0.6118175018698578,test recall: 0.603690036900369,test f1: 0.6077265973254087\n",
      "train accuracy: 0.7006889594642857, test accuracy:0.7043673012318029 train loss:0.56245775, test loss:29.56327057, test precision: 0.6118175018698578,test recall: 0.603690036900369,test f1: 0.6077265973254087\n",
      "train accuracy: 0.7026635473214285, test accuracy:0.7040873460246361 train loss:0.56465789, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.6945237380357143, test accuracy:0.7040873460246361 train loss:0.5695268, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7047722785714285, test accuracy:0.7043673012318029 train loss:0.56012238, test loss:29.56327057, test precision: 0.6080777860882572,test recall: 0.6044609665427509,test f1: 0.6062639821029083\n",
      "train accuracy: 0.7084531678571429, test accuracy:0.7043673012318029 train loss:0.56068231, test loss:29.56327057, test precision: 0.6080777860882572,test recall: 0.6044609665427509,test f1: 0.6062639821029083\n",
      "train accuracy: 0.7062800480357143, test accuracy:0.7026875699888018 train loss:0.56288541, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7050834907142857, test accuracy:0.7024076147816349 train loss:0.56355902, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.7019660026785715, test accuracy:0.7024076147816349 train loss:0.5633156, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.70794342375, test accuracy:0.6976483762597985 train loss:0.55761521, test loss:30.23516273, test precision: 0.6163051608077786,test recall: 0.5923795830337887,test f1: 0.6041055718475075\n",
      "train accuracy: 0.7044181405357143, test accuracy:0.7046472564389697 train loss:0.56371959, test loss:29.53527451, test precision: 0.606581899775617,test recall: 0.6052238805970149,test f1: 0.6059021292491596\n",
      "train accuracy: 0.7075463598214285, test accuracy:0.7015677491601344 train loss:0.55914323, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7086034083928572, test accuracy:0.7043673012318029 train loss:0.55911606, test loss:29.56327057, test precision: 0.6088257292445775,test recall: 0.6043058648849294,test f1: 0.6065573770491803\n",
      "train accuracy: 0.7055073832142857, test accuracy:0.7018477043673013 train loss:0.56222959, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.7091936383928571, test accuracy:0.7018477043673013 train loss:0.55345457, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.70387083625, test accuracy:0.7007278835386338 train loss:0.55981554, test loss:29.92721176, test precision: 0.6200448765893792,test recall: 0.5964028776978417,test f1: 0.607994132746608\n",
      "train accuracy: 0.7090970553571428, test accuracy:0.6982082866741322 train loss:0.55586285, test loss:30.17917252, test precision: 0.6245325355272999,test recall: 0.5917788802267895,test f1: 0.6077147016011644\n",
      "train accuracy: 0.7049386160714286, test accuracy:0.696528555431131 train loss:0.56243454, test loss:30.34714508, test precision: 0.6297681376215407,test recall: 0.5883997204751922,test f1: 0.6083815028901733\n",
      "train accuracy: 0.7048366673214286, test accuracy:0.6962486002239642 train loss:0.56511113, test loss:30.37514114, test precision: 0.6297681376215407,test recall: 0.5879888268156425,test f1: 0.6081617912603828\n",
      "train accuracy: 0.7058400583928571, test accuracy:0.698488241881299 train loss:0.5638084, test loss:30.15117645, test precision: 0.6260284218399401,test recall: 0.5919377652050919,test f1: 0.6085059978189749\n",
      "train accuracy: 0.7030176853571428, test accuracy:0.6962486002239642 train loss:0.56264477, test loss:30.37514114, test precision: 0.6297681376215407,test recall: 0.5879888268156425,test f1: 0.6081617912603828\n",
      "train accuracy: 0.7047025241071428, test accuracy:0.6996080627099664 train loss:0.55887084, test loss:30.03919411, test precision: 0.6155572176514585,test recall: 0.5955137481910275,test f1: 0.605369621184259\n",
      "train accuracy: 0.7061941964285714, test accuracy:0.698488241881299 train loss:0.5574837, test loss:30.15117645, test precision: 0.6260284218399401,test recall: 0.5919377652050919,test f1: 0.6085059978189749\n",
      "train accuracy: 0.7053786057142857, test accuracy:0.7018477043673013 train loss:0.56496908, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.70615663625, test accuracy:0.7018477043673013 train loss:0.5614766, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.7121501544642858, test accuracy:0.7018477043673013 train loss:0.55537115, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.7035220639285714, test accuracy:0.7018477043673013 train loss:0.56136415, test loss:29.81523132, test precision: 0.6095736724008975,test recall: 0.6001472754050073,test f1: 0.6048237476808906\n",
      "train accuracy: 0.70306061125, test accuracy:0.698488241881299 train loss:0.56076931, test loss:30.15117645, test precision: 0.6230366492146597,test recall: 0.5924608819345661,test f1: 0.6073641997812613\n",
      "train accuracy: 0.7133896376785714, test accuracy:0.7021276595744681 train loss:0.55571629, test loss:29.78723526, test precision: 0.6118175018698578,test recall: 0.6001467351430667,test f1: 0.605925925925926\n",
      "train accuracy: 0.715101305, test accuracy:0.7043673012318029 train loss:0.55143917, test loss:29.56327057, test precision: 0.6088257292445775,test recall: 0.6043058648849294,test f1: 0.6065573770491803\n",
      "train accuracy: 0.7042357057142857, test accuracy:0.7046472564389697 train loss:0.56106782, test loss:29.53527451, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7057381094642857, test accuracy:0.700447928331467 train loss:0.56114041, test loss:29.95520782, test precision: 0.6118175018698578,test recall: 0.5975164353542732,test f1: 0.6045824094604582\n",
      "train accuracy: 0.7139905992857143, test accuracy:0.706047032474804 train loss:0.55222977, test loss:29.395298, test precision: 0.605833956619297,test recall: 0.6076519129782446,test f1: 0.6067415730337079\n",
      "train accuracy: 0.7092526614285715, test accuracy:0.706047032474804 train loss:0.5576302, test loss:29.395298, test precision: 0.605833956619297,test recall: 0.6076519129782446,test f1: 0.6067415730337079\n",
      "train accuracy: 0.7047454498214286, test accuracy:0.7046472564389697 train loss:0.56312697, test loss:29.53527451, test precision: 0.6103216155572176,test recall: 0.6044444444444445,test f1: 0.6073688128023818\n",
      "train accuracy: 0.7136579241071429, test accuracy:0.7046472564389697 train loss:0.5573102, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7079541551785714, test accuracy:0.7046472564389697 train loss:0.55910356, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7071385646428572, test accuracy:0.7024076147816349 train loss:0.55899931, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7030767083928572, test accuracy:0.7046472564389697 train loss:0.56080209, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7047722785714285, test accuracy:0.7049272116461366 train loss:0.55844516, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.6966271033928572, test accuracy:0.7049272116461366 train loss:0.56599835, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.70488495875, test accuracy:0.7049272116461366 train loss:0.55798726, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7054966517857143, test accuracy:0.7032474804031354 train loss:0.56240051, test loss:29.67525291, test precision: 0.6103216155572176,test recall: 0.6022140221402214,test f1: 0.6062407132243685\n",
      "train accuracy: 0.7063229739285715, test accuracy:0.7021276595744681 train loss:0.56035186, test loss:29.78723526, test precision: 0.6110695587135377,test recall: 0.6002939015429831,test f1: 0.6056338028169014\n",
      "train accuracy: 0.7067951580357142, test accuracy:0.7024076147816349 train loss:0.56043841, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7095048505357143, test accuracy:0.7046472564389697 train loss:0.55818861, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.710127275, test accuracy:0.7021276595744681 train loss:0.55758066, test loss:29.78723526, test precision: 0.6110695587135377,test recall: 0.6002939015429831,test f1: 0.6056338028169014\n",
      "train accuracy: 0.7114848042857143, test accuracy:0.7049272116461366 train loss:0.55666831, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7097785026785715, test accuracy:0.7049272116461366 train loss:0.55589142, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7053034855357143, test accuracy:0.7040873460246361 train loss:0.557766, test loss:29.59126663, test precision: 0.6110695587135377,test recall: 0.603397341211226,test f1: 0.6072092159048681\n",
      "train accuracy: 0.7082170758928571, test accuracy:0.7024076147816349 train loss:0.55766126, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7061673678571428, test accuracy:0.7024076147816349 train loss:0.56256481, test loss:29.7592392, test precision: 0.6118175018698578,test recall: 0.6005873715124816,test f1: 0.6061504260837346\n",
      "train accuracy: 0.7102882469642857, test accuracy:0.7024076147816349 train loss:0.55768973, test loss:29.7592392, test precision: 0.6118175018698578,test recall: 0.6005873715124816,test f1: 0.6061504260837346\n",
      "train accuracy: 0.7034576751785714, test accuracy:0.7024076147816349 train loss:0.56573072, test loss:29.7592392, test precision: 0.6118175018698578,test recall: 0.6005873715124816,test f1: 0.6061504260837346\n",
      "train accuracy: 0.7095263135714286, test accuracy:0.7021276595744681 train loss:0.5621463, test loss:29.78723526, test precision: 0.6095736724008975,test recall: 0.6005895357406043,test f1: 0.605048255382331\n",
      "train accuracy: 0.7079756182142857, test accuracy:0.698488241881299 train loss:0.55886392, test loss:30.15117645, test precision: 0.6230366492146597,test recall: 0.5924608819345661,test f1: 0.6073641997812613\n",
      "train accuracy: 0.7062371223214285, test accuracy:0.7038073908174692 train loss:0.56457646, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7014455271428571, test accuracy:0.6996080627099664 train loss:0.56378465, test loss:30.03919411, test precision: 0.612565445026178,test recall: 0.5960698689956332,test f1: 0.6042050903725562\n",
      "train accuracy: 0.7049171532142857, test accuracy:0.6996080627099664 train loss:0.55819718, test loss:30.03919411, test precision: 0.612565445026178,test recall: 0.5960698689956332,test f1: 0.6042050903725562\n",
      "train accuracy: 0.7052015367857143, test accuracy:0.7012877939529675 train loss:0.56442243, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7024381867857142, test accuracy:0.7012877939529675 train loss:0.56369113, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7143286401785715, test accuracy:0.7012877939529675 train loss:0.55396969, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7077609889285714, test accuracy:0.7021276595744681 train loss:0.56109639, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7102721496428571, test accuracy:0.7021276595744681 train loss:0.55899257, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7107389680357142, test accuracy:0.7021276595744681 train loss:0.55844309, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7030015882142857, test accuracy:0.7021276595744681 train loss:0.56367255, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7093546101785714, test accuracy:0.7012877939529675 train loss:0.55404683, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.703972785, test accuracy:0.7046472564389697 train loss:0.5601622, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7048366673214286, test accuracy:0.7021276595744681 train loss:0.55614658, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7003562842857143, test accuracy:0.7012877939529675 train loss:0.56361643, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7113184666071428, test accuracy:0.7012877939529675 train loss:0.5537982, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7036562071428571, test accuracy:0.7046472564389697 train loss:0.56239471, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.70641419125, test accuracy:0.7046472564389697 train loss:0.56172041, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7028996394642857, test accuracy:0.7046472564389697 train loss:0.56193197, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.7071278330357142, test accuracy:0.700447928331467 train loss:0.56265465, test loss:29.95520782, test precision: 0.6245325355272999,test recall: 0.5951532430506058,test f1: 0.6094890510948905\n",
      "train accuracy: 0.7029264680357142, test accuracy:0.7038073908174692 train loss:0.56143652, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7058776183928571, test accuracy:0.7038073908174692 train loss:0.56117393, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7012899210714286, test accuracy:0.7015677491601344 train loss:0.56386618, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7074712396428572, test accuracy:0.6998880179171333 train loss:0.56002287, test loss:30.01119995, test precision: 0.6148092744951383,test recall: 0.5960841189267585,test f1: 0.605301914580265\n",
      "train accuracy: 0.7102989783928572, test accuracy:0.7040873460246361 train loss:0.55638531, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7015260130357143, test accuracy:0.7040873460246361 train loss:0.56637425, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7112004207142857, test accuracy:0.7040873460246361 train loss:0.55366774, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.6989290007142858, test accuracy:0.7024076147816349 train loss:0.56594963, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.7047454498214286, test accuracy:0.7024076147816349 train loss:0.55934003, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7058561555357142, test accuracy:0.7024076147816349 train loss:0.55726156, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.7023737980357143, test accuracy:0.7024076147816349 train loss:0.5633108, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.70930631875, test accuracy:0.7024076147816349 train loss:0.56132719, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7037849844642857, test accuracy:0.7040873460246361 train loss:0.56094956, test loss:29.59126663, test precision: 0.6103216155572176,test recall: 0.6035502958579881,test f1: 0.606917069542581\n",
      "train accuracy: 0.7059849330357143, test accuracy:0.7024076147816349 train loss:0.55745611, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7074980683928571, test accuracy:0.7024076147816349 train loss:0.55944151, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.7044771633928572, test accuracy:0.7024076147816349 train loss:0.56263657, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7085873110714286, test accuracy:0.7024076147816349 train loss:0.55932596, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.70149381875, test accuracy:0.7024076147816349 train loss:0.56344425, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.70820097875, test accuracy:0.7024076147816349 train loss:0.55596005, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7125847785714285, test accuracy:0.7024076147816349 train loss:0.55664831, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.70420351125, test accuracy:0.7024076147816349 train loss:0.56319057, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7043591175, test accuracy:0.7024076147816349 train loss:0.5601734, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7039620535714286, test accuracy:0.7024076147816349 train loss:0.56247163, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7013596755357143, test accuracy:0.7038073908174692 train loss:0.56374842, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.7109160371428571, test accuracy:0.7038073908174692 train loss:0.55703283, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.70433228875, test accuracy:0.7024076147816349 train loss:0.55955485, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7002328726785715, test accuracy:0.7024076147816349 train loss:0.56447754, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.7074980683928571, test accuracy:0.7024076147816349 train loss:0.55864777, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7049010558928571, test accuracy:0.7012877939529675 train loss:0.55925044, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7002382383928571, test accuracy:0.698488241881299 train loss:0.566576, test loss:30.15117645, test precision: 0.6275243081525804,test recall: 0.5916784203102962,test f1: 0.6090744101633394\n",
      "train accuracy: 0.702314775, test accuracy:0.7024076147816349 train loss:0.5645402, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7094243646428572, test accuracy:0.7024076147816349 train loss:0.55430035, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7063283396428571, test accuracy:0.7012877939529675 train loss:0.56019794, test loss:29.87122154, test precision: 0.6237845923709798,test recall: 0.5965665236051502,test f1: 0.609872029250457\n",
      "train accuracy: 0.7055127489285714, test accuracy:0.698488241881299 train loss:0.5560981, test loss:30.15117645, test precision: 0.6275243081525804,test recall: 0.5916784203102962,test f1: 0.6090744101633394\n",
      "train accuracy: 0.7033664576785714, test accuracy:0.6993281075027995 train loss:0.56140369, test loss:30.06719017, test precision: 0.6282722513089005,test recall: 0.592801693719125,test f1: 0.6100217864923747\n",
      "train accuracy: 0.6999967805357142, test accuracy:0.7012877939529675 train loss:0.56113895, test loss:29.87122154, test precision: 0.6260284218399401,test recall: 0.5961538461538461,test f1: 0.610726012404232\n",
      "train accuracy: 0.7047669128571429, test accuracy:0.7024076147816349 train loss:0.5609322, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7053249485714286, test accuracy:0.7024076147816349 train loss:0.55989429, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7104223901785715, test accuracy:0.7024076147816349 train loss:0.55537415, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.70367767, test accuracy:0.7024076147816349 train loss:0.56098713, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.70514251375, test accuracy:0.7024076147816349 train loss:0.55930926, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7022718492857143, test accuracy:0.7024076147816349 train loss:0.56141684, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.7119891826785715, test accuracy:0.7040873460246361 train loss:0.55699778, test loss:29.59126663, test precision: 0.606581899775617,test recall: 0.6043219076005961,test f1: 0.6054497946995149\n",
      "train accuracy: 0.7029371994642857, test accuracy:0.7024076147816349 train loss:0.56322724, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7074927026785715, test accuracy:0.7024076147816349 train loss:0.55738777, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7033771892857142, test accuracy:0.7024076147816349 train loss:0.56266155, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7083082932142857, test accuracy:0.7024076147816349 train loss:0.56127334, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.7048044728571429, test accuracy:0.7024076147816349 train loss:0.55757715, test loss:29.7592392, test precision: 0.612565445026178,test recall: 0.6004398826979472,test f1: 0.6064420584968531\n",
      "train accuracy: 0.7074551425, test accuracy:0.7007278835386338 train loss:0.56089016, test loss:29.92721176, test precision: 0.6178010471204188,test recall: 0.596820809248555,test f1: 0.6071297317162808\n",
      "train accuracy: 0.7051854396428572, test accuracy:0.7024076147816349 train loss:0.55908117, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.7024059925, test accuracy:0.7012877939529675 train loss:0.5617977, test loss:29.87122154, test precision: 0.6237845923709798,test recall: 0.5965665236051502,test f1: 0.609872029250457\n",
      "train accuracy: 0.70836731625, test accuracy:0.7024076147816349 train loss:0.55874667, test loss:29.7592392, test precision: 0.6133133881824981,test recall: 0.6002928257686676,test f1: 0.6067332593414725\n",
      "train accuracy: 0.7129067221428571, test accuracy:0.7021276595744681 train loss:0.55509653, test loss:29.78723526, test precision: 0.6095736724008975,test recall: 0.6005895357406043,test f1: 0.605048255382331\n",
      "train accuracy: 0.7119516226785715, test accuracy:0.7024076147816349 train loss:0.55395572, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7066663805357143, test accuracy:0.7021276595744681 train loss:0.55672713, test loss:29.78723526, test precision: 0.606581899775617,test recall: 0.6011860637509266,test f1: 0.6038719285182428\n",
      "train accuracy: 0.7024113582142857, test accuracy:0.7021276595744681 train loss:0.56300269, test loss:29.78723526, test precision: 0.606581899775617,test recall: 0.6011860637509266,test f1: 0.6038719285182428\n",
      "train accuracy: 0.7001362894642857, test accuracy:0.7038073908174692 train loss:0.56399444, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.7126438014285714, test accuracy:0.7024076147816349 train loss:0.55240315, test loss:29.7592392, test precision: 0.606581899775617,test recall: 0.6016320474777448,test f1: 0.6040968342644322\n",
      "train accuracy: 0.7012684580357142, test accuracy:0.7012877939529675 train loss:0.56148149, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7041766826785715, test accuracy:0.7012877939529675 train loss:0.55741111, test loss:29.87122154, test precision: 0.6230366492146597,test recall: 0.5967048710601719,test f1: 0.6095865349432859\n",
      "train accuracy: 0.7137974330357143, test accuracy:0.7012877939529675 train loss:0.55114139, test loss:29.87122154, test precision: 0.6230366492146597,test recall: 0.5967048710601719,test f1: 0.6095865349432859\n",
      "train accuracy: 0.7089951064285714, test accuracy:0.7012877939529675 train loss:0.5584086, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7093170501785714, test accuracy:0.7012877939529675 train loss:0.54962087, test loss:29.87122154, test precision: 0.6230366492146597,test recall: 0.5967048710601719,test f1: 0.6095865349432859\n",
      "train accuracy: 0.7055825033928571, test accuracy:0.7012877939529675 train loss:0.55825768, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7042839973214285, test accuracy:0.7024076147816349 train loss:0.56125566, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7024811126785714, test accuracy:0.7012877939529675 train loss:0.56021711, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7069614955357143, test accuracy:0.7012877939529675 train loss:0.55661681, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.6999109289285714, test accuracy:0.7012877939529675 train loss:0.56083704, test loss:29.87122154, test precision: 0.6230366492146597,test recall: 0.5967048710601719,test f1: 0.6095865349432859\n",
      "train accuracy: 0.7049922733928572, test accuracy:0.7021276595744681 train loss:0.55755649, test loss:29.78723526, test precision: 0.6222887060583395,test recall: 0.5981308411214953,test f1: 0.6099706744868034\n",
      "train accuracy: 0.7107496994642857, test accuracy:0.6979283314669653 train loss:0.55287573, test loss:30.20716858, test precision: 0.6245325355272999,test recall: 0.5913597733711048,test f1: 0.607493634048745\n",
      "train accuracy: 0.7046274039285715, test accuracy:0.6987681970884658 train loss:0.56110542, test loss:30.12318039, test precision: 0.6245325355272999,test recall: 0.5926188786373314,test f1: 0.6081573197378004\n",
      "train accuracy: 0.7032591432142857, test accuracy:0.7012877939529675 train loss:0.56162596, test loss:29.87122154, test precision: 0.6230366492146597,test recall: 0.5967048710601719,test f1: 0.6095865349432859\n",
      "train accuracy: 0.70588835, test accuracy:0.7012877939529675 train loss:0.55869858, test loss:29.87122154, test precision: 0.6237845923709798,test recall: 0.5965665236051502,test f1: 0.609872029250457\n",
      "train accuracy: 0.7087697458928571, test accuracy:0.7012877939529675 train loss:0.55576472, test loss:29.87122154, test precision: 0.6237845923709798,test recall: 0.5965665236051502,test f1: 0.609872029250457\n",
      "train accuracy: 0.7025562328571429, test accuracy:0.7024076147816349 train loss:0.56100623, test loss:29.7592392, test precision: 0.6095736724008975,test recall: 0.6010324483775811,test f1: 0.6052729298180468\n",
      "train accuracy: 0.7015957675, test accuracy:0.7012877939529675 train loss:0.55914896, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7102775155357143, test accuracy:0.7032474804031354 train loss:0.55774832, test loss:29.67525291, test precision: 0.6088257292445775,test recall: 0.6025166543301258,test f1: 0.6056547619047619\n",
      "train accuracy: 0.71363646125, test accuracy:0.7012877939529675 train loss:0.55153605, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7064571171428572, test accuracy:0.7015677491601344 train loss:0.55779384, test loss:29.84322548, test precision: 0.6230366492146597,test recall: 0.5971326164874552,test f1: 0.6098096632503661\n",
      "train accuracy: 0.7037688873214286, test accuracy:0.7012877939529675 train loss:0.5608661, test loss:29.87122154, test precision: 0.6207928197456993,test recall: 0.5971223021582733,test f1: 0.6087275394206086\n",
      "train accuracy: 0.7120482057142857, test accuracy:0.6996080627099664 train loss:0.55135468, test loss:30.03919411, test precision: 0.6282722513089005,test recall: 0.5932203389830508,test f1: 0.6102433708681438\n",
      "train accuracy: 0.704487895, test accuracy:0.7007278835386338 train loss:0.55990943, test loss:29.92721176, test precision: 0.6178010471204188,test recall: 0.596820809248555,test f1: 0.6071297317162808\n",
      "train accuracy: 0.6982690160714285, test accuracy:0.7007278835386338 train loss:0.56107308, test loss:29.92721176, test precision: 0.6155572176514585,test recall: 0.5972423802612482,test f1: 0.6062615101289134\n",
      "train accuracy: 0.7089736435714286, test accuracy:0.7007278835386338 train loss:0.55709013, test loss:29.92721176, test precision: 0.6178010471204188,test recall: 0.596820809248555,test f1: 0.6071297317162808\n",
      "train accuracy: 0.7063819969642857, test accuracy:0.7024076147816349 train loss:0.55916523, test loss:29.7592392, test precision: 0.6103216155572176,test recall: 0.6008836524300442,test f1: 0.6055658627087199\n",
      "train accuracy: 0.7017674708928572, test accuracy:0.7021276595744681 train loss:0.55863024, test loss:29.78723526, test precision: 0.6095736724008975,test recall: 0.6005895357406043,test f1: 0.605048255382331\n",
      "train accuracy: 0.7072834392857142, test accuracy:0.7026875699888018 train loss:0.5583859, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7162495707142857, test accuracy:0.7026875699888018 train loss:0.54857658, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7070419814285714, test accuracy:0.7026875699888018 train loss:0.55768126, test loss:29.73124313, test precision: 0.612565445026178,test recall: 0.6008804108584006,test f1: 0.6066666666666667\n",
      "train accuracy: 0.7113560267857143, test accuracy:0.7049272116461366 train loss:0.55826825, test loss:29.50728035, test precision: 0.6088257292445775,test recall: 0.6052044609665428,test f1: 0.6070096942580163\n",
      "train accuracy: 0.7077019660714285, test accuracy:0.7052071668533034 train loss:0.55541468, test loss:29.47928429, test precision: 0.6118175018698578,test recall: 0.6050295857988166,test f1: 0.608404611379695\n",
      "train accuracy: 0.7037527901785714, test accuracy:0.7026875699888018 train loss:0.56167626, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7046005751785714, test accuracy:0.7007278835386338 train loss:0.56077588, test loss:29.92721176, test precision: 0.6148092744951383,test recall: 0.5973837209302325,test f1: 0.6059712495392554\n",
      "train accuracy: 0.7101487380357143, test accuracy:0.7007278835386338 train loss:0.55734498, test loss:29.92721176, test precision: 0.6148092744951383,test recall: 0.5973837209302325,test f1: 0.6059712495392554\n",
      "train accuracy: 0.7091507125, test accuracy:0.7024076147816349 train loss:0.55533665, test loss:29.7592392, test precision: 0.6095736724008975,test recall: 0.6010324483775811,test f1: 0.6052729298180468\n",
      "train accuracy: 0.7080882983928571, test accuracy:0.7026875699888018 train loss:0.55605161, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7086141398214286, test accuracy:0.7026875699888018 train loss:0.55416103, test loss:29.73124313, test precision: 0.6103216155572176,test recall: 0.6013264554163597,test f1: 0.6057906458797327\n",
      "train accuracy: 0.7025455014285714, test accuracy:0.7035274356103024 train loss:0.56331556, test loss:29.64725685, test precision: 0.6095736724008975,test recall: 0.602810650887574,test f1: 0.6061732986240238\n",
      "train accuracy: 0.7040532708928572, test accuracy:0.6973684210526315 train loss:0.56168096, test loss:30.2631588, test precision: 0.6163051608077786,test recall: 0.5919540229885057,test f1: 0.6038842066691096\n",
      "train accuracy: 0.7021591689285714, test accuracy:0.6993281075027995 train loss:0.56124727, test loss:30.06719017, test precision: 0.6140613313388182,test recall: 0.5953589557650472,test f1: 0.6045655375552283\n",
      "train accuracy: 0.7008821257142858, test accuracy:0.7052071668533034 train loss:0.55737696, test loss:29.47928429, test precision: 0.6118175018698578,test recall: 0.6050295857988166,test f1: 0.608404611379695\n",
      "train accuracy: 0.7095960680357143, test accuracy:0.7052071668533034 train loss:0.55902203, test loss:29.47928429, test precision: 0.6118175018698578,test recall: 0.6050295857988166,test f1: 0.608404611379695\n",
      "train accuracy: 0.70488495875, test accuracy:0.7026875699888018 train loss:0.55821225, test loss:29.73124313, test precision: 0.6133133881824981,test recall: 0.6007326007326007,test f1: 0.6069578090303479\n",
      "train accuracy: 0.7106531164285714, test accuracy:0.7054871220604704 train loss:0.55650048, test loss:29.45128822, test precision: 0.6095736724008975,test recall: 0.6059479553903345,test f1: 0.6077554064131244\n",
      "train accuracy: 0.7021752660714285, test accuracy:0.7026875699888018 train loss:0.56308273, test loss:29.73124313, test precision: 0.6133133881824981,test recall: 0.6007326007326007,test f1: 0.6069578090303479\n",
      "train accuracy: 0.7134486607142857, test accuracy:0.7052071668533034 train loss:0.55373371, test loss:29.47928429, test precision: 0.6118175018698578,test recall: 0.6050295857988166,test f1: 0.608404611379695\n",
      "train accuracy: 0.7100038633928571, test accuracy:0.7001679731243001 train loss:0.55722288, test loss:29.98320389, test precision: 0.6140613313388182,test recall: 0.596656976744186,test f1: 0.6052340582381127\n",
      "train accuracy: 0.7056468921428571, test accuracy:0.7026875699888018 train loss:0.56211573, test loss:29.73124313, test precision: 0.612565445026178,test recall: 0.6008804108584006,test f1: 0.6066666666666667\n",
      "train accuracy: 0.7109428657142857, test accuracy:0.7026875699888018 train loss:0.55634782, test loss:29.73124313, test precision: 0.612565445026178,test recall: 0.6008804108584006,test f1: 0.6066666666666667\n",
      "train accuracy: 0.7024006267857142, test accuracy:0.698488241881299 train loss:0.56338578, test loss:30.15117645, test precision: 0.6207928197456993,test recall: 0.5928571428571429,test f1: 0.6065034709535989\n",
      "train accuracy: 0.7097570398214286, test accuracy:0.7038073908174692 train loss:0.55485815, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7045093578571429, test accuracy:0.7038073908174692 train loss:0.55805333, test loss:29.6192627, test precision: 0.6073298429319371,test recall: 0.6037174721189591,test f1: 0.6055182699478001\n",
      "train accuracy: 0.7019713683928571, test accuracy:0.7038073908174692 train loss:0.56497016, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7082760989285715, test accuracy:0.7001679731243001 train loss:0.55606083, test loss:29.98320389, test precision: 0.6140613313388182,test recall: 0.596656976744186,test f1: 0.6052340582381127\n",
      "train accuracy: 0.7083082932142857, test accuracy:0.7035274356103024 train loss:0.55648395, test loss:29.64725685, test precision: 0.606581899775617,test recall: 0.6034226190476191,test f1: 0.6049981350242447\n",
      "train accuracy: 0.7052122682142857, test accuracy:0.6996080627099664 train loss:0.55807692, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.7044932607142858, test accuracy:0.7035274356103024 train loss:0.55973488, test loss:29.64725685, test precision: 0.6073298429319371,test recall: 0.6032689450222882,test f1: 0.6052925829295565\n",
      "train accuracy: 0.7072995364285715, test accuracy:0.706047032474804 train loss:0.55743703, test loss:29.395298, test precision: 0.605833956619297,test recall: 0.6076519129782446,test f1: 0.6067415730337079\n",
      "train accuracy: 0.7046649639285715, test accuracy:0.7043673012318029 train loss:0.55664942, test loss:29.56327057, test precision: 0.605833956619297,test recall: 0.6049290515309933,test f1: 0.6053811659192826\n",
      "train accuracy: 0.7112648094642857, test accuracy:0.7038073908174692 train loss:0.55380906, test loss:29.6192627, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7080775669642857, test accuracy:0.7063269876819709 train loss:0.55831968, test loss:29.36730194, test precision: 0.6035901271503366,test recall: 0.6085972850678733,test f1: 0.6060833646263611\n",
      "train accuracy: 0.7075409941071429, test accuracy:0.7038073908174692 train loss:0.55767375, test loss:29.6192627, test precision: 0.6073298429319371,test recall: 0.6037174721189591,test f1: 0.6055182699478001\n",
      "train accuracy: 0.7064034598214286, test accuracy:0.7063269876819709 train loss:0.55850525, test loss:29.36730194, test precision: 0.605833956619297,test recall: 0.6081081081081081,test f1: 0.6069689022105658\n",
      "train accuracy: 0.7146183894642857, test accuracy:0.7038073908174692 train loss:0.55008941, test loss:29.6192627, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7045308207142857, test accuracy:0.7038073908174692 train loss:0.55798691, test loss:29.6192627, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7086034083928572, test accuracy:0.7038073908174692 train loss:0.55840985, test loss:29.6192627, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7011611435714286, test accuracy:0.7021276595744681 train loss:0.55896415, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.70556640625, test accuracy:0.7038073908174692 train loss:0.5593277, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7130354996428572, test accuracy:0.6996080627099664 train loss:0.54919036, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.7152944710714285, test accuracy:0.7012877939529675 train loss:0.55055036, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.70458984375, test accuracy:0.7021276595744681 train loss:0.55938204, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.7038225446428571, test accuracy:0.7021276595744681 train loss:0.55988752, test loss:29.78723526, test precision: 0.6103216155572176,test recall: 0.6004415011037527,test f1: 0.6053412462908012\n",
      "train accuracy: 0.70879120875, test accuracy:0.706047032474804 train loss:0.55651309, test loss:29.395298, test precision: 0.6080777860882572,test recall: 0.6071695294996265,test f1: 0.6076233183856502\n",
      "train accuracy: 0.7073478280357143, test accuracy:0.7046472564389697 train loss:0.56096677, test loss:29.53527451, test precision: 0.6088257292445775,test recall: 0.6047548291233283,test f1: 0.6067834513604174\n",
      "train accuracy: 0.70934387875, test accuracy:0.7012877939529675 train loss:0.55745258, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7016279619642857, test accuracy:0.7043673012318029 train loss:0.56087281, test loss:29.56327057, test precision: 0.6080777860882572,test recall: 0.6044609665427509,test f1: 0.6062639821029083\n",
      "train accuracy: 0.7043000944642858, test accuracy:0.7012877939529675 train loss:0.55915195, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.71019166375, test accuracy:0.6993281075027995 train loss:0.55753404, test loss:30.06719017, test precision: 0.6178010471204188,test recall: 0.5946724262059035,test f1: 0.6060161408657374\n",
      "train accuracy: 0.7076322116071428, test accuracy:0.6990481522956327 train loss:0.55597433, test loss:30.09518623, test precision: 0.6133133881824981,test recall: 0.5950653120464441,test f1: 0.6040515653775322\n",
      "train accuracy: 0.7058078639285714, test accuracy:0.6993281075027995 train loss:0.55867087, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.70142943, test accuracy:0.6993281075027995 train loss:0.55989214, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.7079970810714286, test accuracy:0.6993281075027995 train loss:0.55517208, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.6993528932142857, test accuracy:0.6993281075027995 train loss:0.56283703, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.7074444110714285, test accuracy:0.6993281075027995 train loss:0.55938931, test loss:30.06719017, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.7024972098214286, test accuracy:0.6993281075027995 train loss:0.56266109, test loss:30.06719017, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.7015904017857143, test accuracy:0.6987681970884658 train loss:0.56455643, test loss:30.12318039, test precision: 0.6133133881824981,test recall: 0.5946337926033357,test f1: 0.6038291605301915\n",
      "train accuracy: 0.7070741758928571, test accuracy:0.6976483762597985 train loss:0.55625193, test loss:30.23516273, test precision: 0.6163051608077786,test recall: 0.5923795830337887,test f1: 0.6041055718475075\n",
      "train accuracy: 0.70257233, test accuracy:0.6996080627099664 train loss:0.56057585, test loss:30.03919411, test precision: 0.6133133881824981,test recall: 0.5959302325581395,test f1: 0.6044968669369701\n",
      "train accuracy: 0.70403717375, test accuracy:0.6993281075027995 train loss:0.56322527, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.70420351125, test accuracy:0.6990481522956327 train loss:0.56259255, test loss:30.09518623, test precision: 0.612565445026178,test recall: 0.595203488372093,test f1: 0.6037596756358276\n",
      "train accuracy: 0.7101058121428572, test accuracy:0.6993281075027995 train loss:0.55424869, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.6986392514285714, test accuracy:0.7018477043673013 train loss:0.56394012, test loss:29.81523132, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7125364869642857, test accuracy:0.7018477043673013 train loss:0.55664952, test loss:29.81523132, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7092258326785714, test accuracy:0.7018477043673013 train loss:0.55820175, test loss:29.81523132, test precision: 0.6110695587135377,test recall: 0.5998531571218796,test f1: 0.6054094108929233\n",
      "train accuracy: 0.7164159083928572, test accuracy:0.6993281075027995 train loss:0.54857657, test loss:30.06719017, test precision: 0.6155572176514585,test recall: 0.5950831525668836,test f1: 0.6051470588235294\n",
      "train accuracy: 0.7157129978571428, test accuracy:0.6993281075027995 train loss:0.55292575, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.7079326923214285, test accuracy:0.6993281075027995 train loss:0.5538827, test loss:30.06719017, test precision: 0.6133133881824981,test recall: 0.5954974582425563,test f1: 0.604274134119381\n",
      "train accuracy: 0.7134862208928572, test accuracy:0.6990481522956327 train loss:0.55283272, test loss:30.09518623, test precision: 0.6155572176514585,test recall: 0.5946531791907514,test f1: 0.6049246600514516\n",
      "train accuracy: 0.7125901442857143, test accuracy:0.6987681970884658 train loss:0.55500863, test loss:30.12318039, test precision: 0.6155572176514585,test recall: 0.5942238267148015,test f1: 0.6047024246877296\n",
      "train accuracy: 0.70442350625, test accuracy:0.6993281075027995 train loss:0.56560042, test loss:30.06719017, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.7034684066071428, test accuracy:0.6993281075027995 train loss:0.55949089, test loss:30.06719017, test precision: 0.612565445026178,test recall: 0.5956363636363636,test f1: 0.6039823008849557\n",
      "train accuracy: 0.7041927798214286, test accuracy:0.6996080627099664 train loss:0.55706353, test loss:30.03919411, test precision: 0.612565445026178,test recall: 0.5960698689956332,test f1: 0.6042050903725562\n",
      "train accuracy: 0.7115009014285715, test accuracy:0.7012877939529675 train loss:0.55357168, test loss:29.87122154, test precision: 0.6103216155572176,test recall: 0.5991189427312775,test f1: 0.6046683957021118\n",
      "train accuracy: 0.7191202351785714, test accuracy:0.7012877939529675 train loss:0.54860583, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7058346926785715, test accuracy:0.7010078387458006 train loss:0.55650422, test loss:29.89921761, test precision: 0.6110695587135377,test recall: 0.5985347985347985,test f1: 0.6047372316802369\n",
      "train accuracy: 0.7065322373214286, test accuracy:0.7010078387458006 train loss:0.55863913, test loss:29.89921761, test precision: 0.6080777860882572,test recall: 0.5991156963890936,test f1: 0.6035634743875279\n",
      "train accuracy: 0.7114579755357143, test accuracy:0.7012877939529675 train loss:0.55380633, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7070849073214286, test accuracy:0.7012877939529675 train loss:0.5577933, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7057864010714285, test accuracy:0.7007278835386338 train loss:0.55388542, test loss:29.92721176, test precision: 0.6133133881824981,test recall: 0.597667638483965,test f1: 0.6053894425987449\n",
      "train accuracy: 0.7096550910714285, test accuracy:0.7012877939529675 train loss:0.55380685, test loss:29.87122154, test precision: 0.6110695587135377,test recall: 0.5989736070381232,test f1: 0.6049611255090707\n",
      "train accuracy: 0.7057864010714285, test accuracy:0.6987681970884658 train loss:0.56062882, test loss:30.12318039, test precision: 0.631264023934181,test recall: 0.5914505956552207,test f1: 0.6107091172214182\n",
      "train accuracy: 0.7078736692857143, test accuracy:0.7012877939529675 train loss:0.55810268, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7063444367857142, test accuracy:0.7012877939529675 train loss:0.55864578, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7075356283928571, test accuracy:0.7012877939529675 train loss:0.5569147, test loss:29.87122154, test precision: 0.6155572176514585,test recall: 0.5981104651162791,test f1: 0.6067084408403982\n",
      "train accuracy: 0.7090594951785715, test accuracy:0.7012877939529675 train loss:0.55400561, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7110931060714286, test accuracy:0.7012877939529675 train loss:0.55347166, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7058668869642857, test accuracy:0.7010078387458006 train loss:0.56015172, test loss:29.89921761, test precision: 0.6103216155572176,test recall: 0.5986793837123991,test f1: 0.6044444444444443\n",
      "train accuracy: 0.7087375514285714, test accuracy:0.7012877939529675 train loss:0.55548024, test loss:29.87122154, test precision: 0.6155572176514585,test recall: 0.5981104651162791,test f1: 0.6067084408403982\n",
      "train accuracy: 0.7097570398214286, test accuracy:0.7010078387458006 train loss:0.5563941, test loss:29.89921761, test precision: 0.6103216155572176,test recall: 0.5986793837123991,test f1: 0.6044444444444443\n",
      "train accuracy: 0.7082170758928571, test accuracy:0.7007278835386338 train loss:0.55260263, test loss:29.92721176, test precision: 0.62528047868362,test recall: 0.5954415954415955,test f1: 0.609996351696461\n",
      "train accuracy: 0.7067307692857143, test accuracy:0.7007278835386338 train loss:0.55674546, test loss:29.92721176, test precision: 0.62528047868362,test recall: 0.5954415954415955,test f1: 0.609996351696461\n",
      "train accuracy: 0.7084799966071429, test accuracy:0.6998880179171333 train loss:0.55795221, test loss:30.01119995, test precision: 0.6207928197456993,test recall: 0.5949820788530465,test f1: 0.6076134699853587\n",
      "train accuracy: 0.7049225189285714, test accuracy:0.7012877939529675 train loss:0.55690953, test loss:29.87122154, test precision: 0.6103216155572176,test recall: 0.5991189427312775,test f1: 0.6046683957021118\n",
      "train accuracy: 0.7129603794642857, test accuracy:0.7012877939529675 train loss:0.55147417, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7101487380357143, test accuracy:0.7040873460246361 train loss:0.55469143, test loss:29.59126663, test precision: 0.605833956619297,test recall: 0.6044776119402985,test f1: 0.6051550242809115\n",
      "train accuracy: 0.718492445, test accuracy:0.7012877939529675 train loss:0.55179107, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7110501803571428, test accuracy:0.7012877939529675 train loss:0.55729353, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7130784255357143, test accuracy:0.7040873460246361 train loss:0.55282373, test loss:29.59126663, test precision: 0.605833956619297,test recall: 0.6044776119402985,test f1: 0.6051550242809115\n",
      "train accuracy: 0.7086999914285714, test accuracy:0.7038073908174692 train loss:0.55572364, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.7010216346428572, test accuracy:0.7012877939529675 train loss:0.56509008, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.70276549625, test accuracy:0.7012877939529675 train loss:0.55675225, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7037903503571429, test accuracy:0.7038073908174692 train loss:0.5622049, test loss:29.6192627, test precision: 0.6095736724008975,test recall: 0.6032568467801629,test f1: 0.6063988095238095\n",
      "train accuracy: 0.7055503091071429, test accuracy:0.7010078387458006 train loss:0.55684596, test loss:29.89921761, test precision: 0.6110695587135377,test recall: 0.5985347985347985,test f1: 0.6047372316802369\n",
      "train accuracy: 0.7166573660714286, test accuracy:0.7035274356103024 train loss:0.55314061, test loss:29.64725685, test precision: 0.606581899775617,test recall: 0.6034226190476191,test f1: 0.6049981350242447\n",
      "train accuracy: 0.7104062928571429, test accuracy:0.7040873460246361 train loss:0.5536929, test loss:29.59126663, test precision: 0.605833956619297,test recall: 0.6044776119402985,test f1: 0.6051550242809115\n",
      "train accuracy: 0.7042839973214285, test accuracy:0.7012877939529675 train loss:0.56252626, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7120750342857143, test accuracy:0.7038073908174692 train loss:0.55329804, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.7054912860714285, test accuracy:0.7038073908174692 train loss:0.55672454, test loss:29.6192627, test precision: 0.606581899775617,test recall: 0.6038719285182428,test f1: 0.6052238805970149\n",
      "train accuracy: 0.7070527128571429, test accuracy:0.7012877939529675 train loss:0.55407178, test loss:29.87122154, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7072190505357143, test accuracy:0.7007278835386338 train loss:0.55816382, test loss:29.92721176, test precision: 0.62528047868362,test recall: 0.5954415954415955,test f1: 0.609996351696461\n",
      "train accuracy: 0.7061298076785715, test accuracy:0.6998880179171333 train loss:0.56103509, test loss:30.01119995, test precision: 0.6185489902767389,test recall: 0.5953923686105111,test f1: 0.6067498165810712\n",
      "train accuracy: 0.7063658996428571, test accuracy:0.7001679731243001 train loss:0.55921811, test loss:29.98320389, test precision: 0.6043380703066566,test recall: 0.5985185185185186,test f1: 0.601414216598437\n",
      "train accuracy: 0.7102077610714286, test accuracy:0.7015677491601344 train loss:0.55421256, test loss:29.84322548, test precision: 0.6035901271503366,test recall: 0.6008935219657483,test f1: 0.6022388059701492\n",
      "train accuracy: 0.7039566878571428, test accuracy:0.6998880179171333 train loss:0.55993788, test loss:30.01119995, test precision: 0.6050860134629769,test recall: 0.597930524759793,test f1: 0.6014869888475838\n",
      "train accuracy: 0.7050244676785714, test accuracy:0.700447928331467 train loss:0.55693971, test loss:29.95520782, test precision: 0.62528047868362,test recall: 0.5950177935943061,test f1: 0.6097738876732313\n",
      "train accuracy: 0.7082707332142857, test accuracy:0.7007278835386338 train loss:0.5554303, test loss:29.92721176, test precision: 0.6118175018698578,test recall: 0.597953216374269,test f1: 0.6048059149722735\n",
      "train accuracy: 0.7099931317857143, test accuracy:0.7001679731243001 train loss:0.55330015, test loss:29.98320389, test precision: 0.6043380703066566,test recall: 0.5985185185185186,test f1: 0.601414216598437\n",
      "train accuracy: 0.70094114875, test accuracy:0.7001679731243001 train loss:0.56298154, test loss:29.98320389, test precision: 0.6043380703066566,test recall: 0.5985185185185186,test f1: 0.601414216598437\n",
      "train accuracy: 0.70403717375, test accuracy:0.700447928331467 train loss:0.5564557, test loss:29.95520782, test precision: 0.6095736724008975,test recall: 0.5979457079970653,test f1: 0.6037037037037036\n",
      "train accuracy: 0.6995728880357143, test accuracy:0.7012877939529675 train loss:0.56580752, test loss:29.87122154, test precision: 0.6148092744951383,test recall: 0.5982532751091703,test f1: 0.6064182958317963\n",
      "train accuracy: 0.7128047733928572, test accuracy:0.7001679731243001 train loss:0.55235341, test loss:29.98320389, test precision: 0.6043380703066566,test recall: 0.5985185185185186,test f1: 0.601414216598437\n",
      "train accuracy: 0.7090004721428571, test accuracy:0.7010078387458006 train loss:0.55534127, test loss:29.89921761, test precision: 0.6073298429319371,test recall: 0.5992619926199262,test f1: 0.6032689450222883\n",
      "train accuracy: 0.70644102, test accuracy:0.7015677491601344 train loss:0.55575374, test loss:29.84322548, test precision: 0.612565445026178,test recall: 0.5991221653255303,test f1: 0.6057692307692308\n",
      "train accuracy: 0.7113238325, test accuracy:0.7010078387458006 train loss:0.55429958, test loss:29.89921761, test precision: 0.6073298429319371,test recall: 0.5992619926199262,test f1: 0.6032689450222883\n",
      "train accuracy: 0.7052873883928571, test accuracy:0.7012877939529675 train loss:0.55563554, test loss:29.87122154, test precision: 0.6155572176514585,test recall: 0.5981104651162791,test f1: 0.6067084408403982\n",
      "train accuracy: 0.7122467376785714, test accuracy:0.7010078387458006 train loss:0.55260181, test loss:29.89921761, test precision: 0.6073298429319371,test recall: 0.5992619926199262,test f1: 0.6032689450222883\n",
      "train accuracy: 0.7066180889285715, test accuracy:0.7012877939529675 train loss:0.55548361, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7026581816071429, test accuracy:0.7012877939529675 train loss:0.56219271, test loss:29.87122154, test precision: 0.6148092744951383,test recall: 0.5982532751091703,test f1: 0.6064182958317963\n",
      "train accuracy: 0.7096336280357143, test accuracy:0.7035274356103024 train loss:0.55638664, test loss:29.64725685, test precision: 0.605833956619297,test recall: 0.6035767511177347,test f1: 0.604703247480403\n",
      "train accuracy: 0.70556640625, test accuracy:0.7035274356103024 train loss:0.55354103, test loss:29.64725685, test precision: 0.605833956619297,test recall: 0.6035767511177347,test f1: 0.604703247480403\n",
      "train accuracy: 0.70094114875, test accuracy:0.7021276595744681 train loss:0.56167465, test loss:29.78723526, test precision: 0.6118175018698578,test recall: 0.6001467351430667,test f1: 0.605925925925926\n",
      "train accuracy: 0.7136149982142858, test accuracy:0.7012877939529675 train loss:0.55242416, test loss:29.87122154, test precision: 0.6073298429319371,test recall: 0.5997045790251108,test f1: 0.6034931252322556\n",
      "train accuracy: 0.7126867273214286, test accuracy:0.7010078387458006 train loss:0.55274443, test loss:29.89921761, test precision: 0.6073298429319371,test recall: 0.5992619926199262,test f1: 0.6032689450222883\n",
      "train accuracy: 0.7083136589285715, test accuracy:0.700447928331467 train loss:0.55364083, test loss:29.95520782, test precision: 0.6260284218399401,test recall: 0.5948827292110874,test f1: 0.6100583090379009\n",
      "train accuracy: 0.7108677455357143, test accuracy:0.7018477043673013 train loss:0.55408738, test loss:29.81523132, test precision: 0.6148092744951383,test recall: 0.5991253644314869,test f1: 0.6068660022148394\n",
      "train accuracy: 0.7043483860714286, test accuracy:0.7012877939529675 train loss:0.56094031, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7105136075, test accuracy:0.7012877939529675 train loss:0.55304678, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7155520260714285, test accuracy:0.7012877939529675 train loss:0.54893981, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7112540780357143, test accuracy:0.7021276595744681 train loss:0.55305167, test loss:29.78723526, test precision: 0.6118175018698578,test recall: 0.6001467351430667,test f1: 0.605925925925926\n",
      "train accuracy: 0.7110984717857143, test accuracy:0.7018477043673013 train loss:0.55507824, test loss:29.81523132, test precision: 0.6118175018698578,test recall: 0.5997067448680352,test f1: 0.6057015920029618\n",
      "train accuracy: 0.7094672905357143, test accuracy:0.7012877939529675 train loss:0.55379356, test loss:29.87122154, test precision: 0.6073298429319371,test recall: 0.5997045790251108,test f1: 0.6034931252322556\n",
      "train accuracy: 0.7099663032142857, test accuracy:0.7018477043673013 train loss:0.5569505, test loss:29.81523132, test precision: 0.6118175018698578,test recall: 0.5997067448680352,test f1: 0.6057015920029618\n",
      "train accuracy: 0.7067575978571429, test accuracy:0.7012877939529675 train loss:0.55557121, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7148169214285715, test accuracy:0.7018477043673013 train loss:0.54858606, test loss:29.81523132, test precision: 0.6118175018698578,test recall: 0.5997067448680352,test f1: 0.6057015920029618\n",
      "train accuracy: 0.70344694375, test accuracy:0.7015677491601344 train loss:0.56152329, test loss:29.84322548, test precision: 0.6207928197456993,test recall: 0.597552195824334,test f1: 0.6089508437270725\n",
      "train accuracy: 0.7043913117857142, test accuracy:0.7015677491601344 train loss:0.56054755, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7079756182142857, test accuracy:0.7012877939529675 train loss:0.5547391, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7124989267857142, test accuracy:0.7015677491601344 train loss:0.55065508, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7026420844642857, test accuracy:0.7012877939529675 train loss:0.55747034, test loss:29.87122154, test precision: 0.612565445026178,test recall: 0.5986842105263158,test f1: 0.6055452865064695\n",
      "train accuracy: 0.7093653416071428, test accuracy:0.7010078387458006 train loss:0.5557652, test loss:29.89921761, test precision: 0.612565445026178,test recall: 0.5982468955441929,test f1: 0.6053215077605323\n",
      "train accuracy: 0.7017942994642857, test accuracy:0.6987681970884658 train loss:0.5605365, test loss:30.12318039, test precision: 0.62528047868362,test recall: 0.592487597448618,test f1: 0.6084425036390102\n",
      "train accuracy: 0.7036186469642857, test accuracy:0.6996080627099664 train loss:0.55661312, test loss:30.03919411, test precision: 0.6260284218399401,test recall: 0.5936170212765958,test f1: 0.6093920640698945\n",
      "train accuracy: 0.7101004464285714, test accuracy:0.6996080627099664 train loss:0.55460574, test loss:30.03919411, test precision: 0.6178010471204188,test recall: 0.5951008645533141,test f1: 0.6062385321100918\n",
      "train accuracy: 0.7035059666071428, test accuracy:0.6998880179171333 train loss:0.55647728, test loss:30.01119995, test precision: 0.6170531039640987,test recall: 0.5956678700361011,test f1: 0.6061719324026451\n",
      "train accuracy: 0.7123862466071429, test accuracy:0.6990481522956327 train loss:0.55244075, test loss:30.09518623, test precision: 0.612565445026178,test recall: 0.595203488372093,test f1: 0.6037596756358276\n",
      "train accuracy: 0.7099126458928572, test accuracy:0.6998880179171333 train loss:0.55453329, test loss:30.01119995, test precision: 0.6170531039640987,test recall: 0.5956678700361011,test f1: 0.6061719324026451\n",
      "train accuracy: 0.7108945741071429, test accuracy:0.6998880179171333 train loss:0.55495488, test loss:30.01119995, test precision: 0.6170531039640987,test recall: 0.5956678700361011,test f1: 0.6061719324026451\n",
      "train accuracy: 0.7103258069642857, test accuracy:0.6998880179171333 train loss:0.55367199, test loss:30.01119995, test precision: 0.6170531039640987,test recall: 0.5956678700361011,test f1: 0.6061719324026451\n",
      "train accuracy: 0.7117530907142857, test accuracy:0.6987681970884658 train loss:0.55122956, test loss:30.12318039, test precision: 0.6275243081525804,test recall: 0.5920959774170783,test f1: 0.6092955700798839\n",
      "train accuracy: 0.71465058375, test accuracy:0.6979283314669653 train loss:0.55265646, test loss:30.20716858, test precision: 0.6200448765893792,test recall: 0.5921428571428572,test f1: 0.6057727438801608\n",
      "train accuracy: 0.7123433207142857, test accuracy:0.6979283314669653 train loss:0.55278252, test loss:30.20716858, test precision: 0.6200448765893792,test recall: 0.5921428571428572,test f1: 0.6057727438801608\n",
      "train accuracy: 0.7009089542857143, test accuracy:0.6987681970884658 train loss:0.5611251, test loss:30.12318039, test precision: 0.6245325355272999,test recall: 0.5926188786373314,test f1: 0.6081573197378004\n",
      "train accuracy: 0.7105297046428571, test accuracy:0.6987681970884658 train loss:0.554371, test loss:30.12318039, test precision: 0.6364996260284218,test recall: 0.5905621096460791,test f1: 0.6126709863210944\n",
      "train accuracy: 0.7112218835714286, test accuracy:0.700447928331467 train loss:0.54860621, test loss:29.95520782, test precision: 0.62528047868362,test recall: 0.5950177935943061,test f1: 0.6097738876732313\n",
      "train accuracy: 0.70225038625, test accuracy:0.6987681970884658 train loss:0.5603917, test loss:30.12318039, test precision: 0.6357516828721017,test recall: 0.590687977762335,test f1: 0.612391930835735\n",
      "train accuracy: 0.70832975625, test accuracy:0.6998880179171333 train loss:0.55581791, test loss:30.01119995, test precision: 0.6178010471204188,test recall: 0.5955299206921413,test f1: 0.606461086637298\n",
      "train accuracy: 0.7048688616071429, test accuracy:0.6996080627099664 train loss:0.56149795, test loss:30.03919411, test precision: 0.6178010471204188,test recall: 0.5951008645533141,test f1: 0.6062385321100918\n",
      "train accuracy: 0.7076966003571429, test accuracy:0.6990481522956327 train loss:0.55827111, test loss:30.09518623, test precision: 0.6327599102468212,test recall: 0.5916083916083916,test f1: 0.6114925912540656\n",
      "train accuracy: 0.7100950807142857, test accuracy:0.6996080627099664 train loss:0.55199157, test loss:30.03919411, test precision: 0.6178010471204188,test recall: 0.5951008645533141,test f1: 0.6062385321100918\n",
      "train accuracy: 0.7071653932142857, test accuracy:0.7007278835386338 train loss:0.55360675, test loss:29.92721176, test precision: 0.6305160807778609,test recall: 0.5944992947813822,test f1: 0.611978221415608\n",
      "train accuracy: 0.71044921875, test accuracy:0.700447928331467 train loss:0.55886119, test loss:29.95520782, test precision: 0.6222887060583395,test recall: 0.595561918396564,test f1: 0.6086320409656181\n",
      "train accuracy: 0.7078307433928571, test accuracy:0.7007278835386338 train loss:0.55571335, test loss:29.92721176, test precision: 0.6170531039640987,test recall: 0.5969609261939218,test f1: 0.6068407502758366\n",
      "train accuracy: 0.7096497253571429, test accuracy:0.7015677491601344 train loss:0.55348978, test loss:29.84322548, test precision: 0.6215407629020194,test recall: 0.597411933860532,test f1: 0.6092375366568915\n",
      "train accuracy: 0.7026474501785714, test accuracy:0.7007278835386338 train loss:0.56098188, test loss:29.92721176, test precision: 0.6305160807778609,test recall: 0.5944992947813822,test f1: 0.611978221415608\n",
      "train accuracy: 0.7006728623214286, test accuracy:0.700447928331467 train loss:0.563286, test loss:29.95520782, test precision: 0.6170531039640987,test recall: 0.596529284164859,test f1: 0.6066176470588236\n",
      "train accuracy: 0.7090755923214286, test accuracy:0.7007278835386338 train loss:0.55308262, test loss:29.92721176, test precision: 0.6170531039640987,test recall: 0.5969609261939218,test f1: 0.6068407502758366\n",
      "train accuracy: 0.7090594951785715, test accuracy:0.7012877939529675 train loss:0.55426449, test loss:29.87122154, test precision: 0.6215407629020194,test recall: 0.5969827586206896,test f1: 0.6090142909490656\n",
      "train accuracy: 0.7104223901785715, test accuracy:0.7012877939529675 train loss:0.5574337, test loss:29.87122154, test precision: 0.6215407629020194,test recall: 0.5969827586206896,test f1: 0.6090142909490656\n",
      "train accuracy: 0.7066878433928572, test accuracy:0.7012877939529675 train loss:0.5570832, test loss:29.87122154, test precision: 0.6215407629020194,test recall: 0.5969827586206896,test f1: 0.6090142909490656\n",
      "train accuracy: 0.7071600275, test accuracy:0.7015677491601344 train loss:0.55638654, test loss:29.84322548, test precision: 0.6297681376215407,test recall: 0.5958952583156405,test f1: 0.6123636363636363\n",
      "train accuracy: 0.7053464114285715, test accuracy:0.7015677491601344 train loss:0.55676659, test loss:29.84322548, test precision: 0.6297681376215407,test recall: 0.5958952583156405,test f1: 0.6123636363636363\n",
      "train accuracy: 0.7058507898214286, test accuracy:0.7015677491601344 train loss:0.55515432, test loss:29.84322548, test precision: 0.6215407629020194,test recall: 0.597411933860532,test f1: 0.6092375366568915\n",
      "train accuracy: 0.7075517255357143, test accuracy:0.7035274356103024 train loss:0.55425644, test loss:29.64725685, test precision: 0.606581899775617,test recall: 0.6034226190476191,test f1: 0.6049981350242447\n",
      "train accuracy: 0.7118604051785714, test accuracy:0.7024076147816349 train loss:0.55129447, test loss:29.7592392, test precision: 0.6110695587135377,test recall: 0.600735294117647,test f1: 0.6058583611420096\n",
      "train accuracy: 0.7075517255357143, test accuracy:0.7040873460246361 train loss:0.55611242, test loss:29.59126663, test precision: 0.6110695587135377,test recall: 0.603397341211226,test f1: 0.6072092159048681\n",
      "train accuracy: 0.71337890625, test accuracy:0.7018477043673013 train loss:0.55307472, test loss:29.81523132, test precision: 0.6050860134629769,test recall: 0.6010401188707281,test f1: 0.603056280283265\n",
      "train accuracy: 0.7108140882142857, test accuracy:0.7035274356103024 train loss:0.55603219, test loss:29.64725685, test precision: 0.6050860134629769,test recall: 0.6037313432835821,test f1: 0.6044079193126635\n",
      "train accuracy: 0.7134379292857143, test accuracy:0.7015677491601344 train loss:0.54810691, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7179719694642858, test accuracy:0.7007278835386338 train loss:0.54766806, test loss:29.92721176, test precision: 0.6103216155572176,test recall: 0.5982404692082112,test f1: 0.6042206590151796\n",
      "train accuracy: 0.7025937928571429, test accuracy:0.7007278835386338 train loss:0.5613179, test loss:29.92721176, test precision: 0.6103216155572176,test recall: 0.5982404692082112,test f1: 0.6042206590151796\n",
      "train accuracy: 0.7184495192857143, test accuracy:0.7010078387458006 train loss:0.54580514, test loss:29.89921761, test precision: 0.6088257292445775,test recall: 0.5989698307579102,test f1: 0.6038575667655787\n",
      "train accuracy: 0.7049708103571428, test accuracy:0.7015677491601344 train loss:0.55812302, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7079541551785714, test accuracy:0.7015677491601344 train loss:0.54985511, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7108462826785714, test accuracy:0.7015677491601344 train loss:0.55311193, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7022933121428572, test accuracy:0.7015677491601344 train loss:0.56386147, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.70726197625, test accuracy:0.7015677491601344 train loss:0.55289568, test loss:29.84322548, test precision: 0.6118175018698578,test recall: 0.5992673992673992,test f1: 0.6054774241302738\n",
      "train accuracy: 0.7067039405357143, test accuracy:0.7015677491601344 train loss:0.55481111, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7030928057142857, test accuracy:0.7015677491601344 train loss:0.56419734, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7144359546428571, test accuracy:0.7018477043673013 train loss:0.55160846, test loss:29.81523132, test precision: 0.6133133881824981,test recall: 0.5994152046783626,test f1: 0.6062846580406654\n",
      "train accuracy: 0.7071653932142857, test accuracy:0.7015677491601344 train loss:0.55145295, test loss:29.84322548, test precision: 0.6148092744951383,test recall: 0.5986890021849963,test f1: 0.6066420664206641\n",
      "train accuracy: 0.7134325635714286, test accuracy:0.7038073908174692 train loss:0.55392395, test loss:29.6192627, test precision: 0.6103216155572176,test recall: 0.6031042128603105,test f1: 0.6066914498141264\n",
      "train accuracy: 0.7062961451785714, test accuracy:0.7021276595744681 train loss:0.55741601, test loss:29.78723526, test precision: 0.6222887060583395,test recall: 0.5981308411214953,test f1: 0.6099706744868034\n",
      "train accuracy: 0.7093653416071428, test accuracy:0.7029675251959686 train loss:0.54996589, test loss:29.70324898, test precision: 0.605833956619297,test recall: 0.6026785714285714,test f1: 0.6042521447221186\n",
      "train accuracy: 0.7069775926785714, test accuracy:0.7007278835386338 train loss:0.55425612, test loss:29.92721176, test precision: 0.6207928197456993,test recall: 0.5962643678160919,test f1: 0.6082814217662147\n",
      "train accuracy: 0.7088931576785714, test accuracy:0.700447928331467 train loss:0.55531818, test loss:29.95520782, test precision: 0.6222887060583395,test recall: 0.595561918396564,test f1: 0.6086320409656181\n",
      "train accuracy: 0.7173388135714286, test accuracy:0.7054871220604704 train loss:0.54739743, test loss:29.45128822, test precision: 0.6192969334330591,test recall: 0.6039387308533917,test f1: 0.6115214180206795\n",
      "train accuracy: 0.7093921703571429, test accuracy:0.7010078387458006 train loss:0.55266364, test loss:29.89921761, test precision: 0.6207928197456993,test recall: 0.5966930265995687,test f1: 0.6085043988269795\n",
      "train accuracy: 0.7126169728571429, test accuracy:0.7012877939529675 train loss:0.55253502, test loss:29.87122154, test precision: 0.6163051608077786,test recall: 0.5979680696661829,test f1: 0.6069981583793739\n",
      "train accuracy: 0.7054161658928572, test accuracy:0.7035274356103024 train loss:0.55633206, test loss:29.64725685, test precision: 0.6297681376215407,test recall: 0.5988620199146515,test f1: 0.6139263580021873\n",
      "train accuracy: 0.7077502575, test accuracy:0.7066069428891377 train loss:0.55008326, test loss:29.33930588, test precision: 0.6088257292445775,test recall: 0.607916355489171,test f1: 0.6083707025411061\n",
      "train accuracy: 0.7042464371428572, test accuracy:0.706047032474804 train loss:0.55569149, test loss:29.395298, test precision: 0.6035901271503366,test recall: 0.6081386586284853,test f1: 0.6058558558558558\n",
      "train accuracy: 0.7048688616071429, test accuracy:0.7066069428891377 train loss:0.55893457, test loss:29.33930588, test precision: 0.6185489902767389,test recall: 0.6058608058608058,test f1: 0.6121391561806069\n",
      "train accuracy: 0.7037903503571429, test accuracy:0.7021276595744681 train loss:0.55642107, test loss:29.78723526, test precision: 0.6305160807778609,test recall: 0.5966029723991507,test f1: 0.6130909090909091\n",
      "train accuracy: 0.7076322116071428, test accuracy:0.7049272116461366 train loss:0.55350225, test loss:29.50728035, test precision: 0.6200448765893792,test recall: 0.602909090909091,test f1: 0.6113569321533924\n",
      "train accuracy: 0.7094565591071429, test accuracy:0.7049272116461366 train loss:0.54922699, test loss:29.50728035, test precision: 0.6103216155572176,test recall: 0.6048925129725723,test f1: 0.6075949367088608\n",
      "train accuracy: 0.7091829069642858, test accuracy:0.7021276595744681 train loss:0.55331299, test loss:29.78723526, test precision: 0.6207928197456993,test recall: 0.5984138428262437,test f1: 0.6093979441997064\n",
      "train accuracy: 0.7075087998214286, test accuracy:0.7018477043673013 train loss:0.55546824, test loss:29.81523132, test precision: 0.6305160807778609,test recall: 0.5961810466760962,test f1: 0.6128680479825518\n",
      "train accuracy: 0.7097033825, test accuracy:0.7026875699888018 train loss:0.553224, test loss:29.73124313, test precision: 0.6305160807778609,test recall: 0.5974486180014175,test f1: 0.6135371179039302\n",
      "train accuracy: 0.7130676941071429, test accuracy:0.7007278835386338 train loss:0.54823131, test loss:29.92721176, test precision: 0.6305160807778609,test recall: 0.5944992947813822,test f1: 0.611978221415608\n",
      "train accuracy: 0.7104009271428572, test accuracy:0.7007278835386338 train loss:0.55018265, test loss:29.92721176, test precision: 0.6335078534031413,test recall: 0.593969144460028,test f1: 0.6131017010495838\n",
      "train accuracy: 0.7043913117857142, test accuracy:0.6982082866741322 train loss:0.56296658, test loss:30.17917252, test precision: 0.6357516828721017,test recall: 0.5898681471200555,test f1: 0.6119510439164867\n",
      "train accuracy: 0.7112487121428571, test accuracy:0.7007278835386338 train loss:0.55191716, test loss:29.92721176, test precision: 0.6335078534031413,test recall: 0.593969144460028,test f1: 0.6131017010495838\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[32m[I 2023-04-03 12:20:11,299]\u001b[0m Trial 7 pruned. \u001b[0m\n"
=======
      "\u001b[32m[I 2023-04-03 00:56:26,884]\u001b[0m Trial 1 finished with value: 0.5502296771321978 and parameters: {'n_layers': 2, 'n_units_l0': 311, 'n_units_l1': 785, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5502296771321978.\u001b[0m\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train accuracy: 0.6387344128571427, test accuracy:0.6570548712206047 train loss:0.68781561, test loss:0.68729061, test precision: 0.5347793567688855,test recall: 0.5424886191198786,test f1: 0.5386064030131826\n",
      "train accuracy: 0.5040890535714286, test accuracy:0.6256998880179171 train loss:0.69288009, test loss:0.68792635, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5023283553571428, test accuracy:0.6256998880179171 train loss:0.69240093, test loss:0.68763918, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4991004078571429, test accuracy:0.6265397536394177 train loss:0.69200727, test loss:0.68734831, test precision: 0.002243829468960359,test recall: 1.0,test f1: 0.004477611940298507\n",
      "train accuracy: 0.5025087557142858, test accuracy:0.6282194848824189 train loss:0.69148487, test loss:0.6870324, test precision: 0.006731488406881077,test recall: 1.0,test f1: 0.013372956909361071\n",
      "train accuracy: 0.52604247, test accuracy:0.6704927211646137 train loss:0.6909359, test loss:0.68686426, test precision: 0.1593118922961855,test recall: 0.8007518796992481,test f1: 0.26575171553337495\n",
      "train accuracy: 0.5709547221428571, test accuracy:0.6766517357222844 train loss:0.6907492, test loss:0.68666679, test precision: 0.193717277486911,test recall: 0.7708333333333334,test f1: 0.30962343096234307\n",
      "train accuracy: 0.5848551035714287, test accuracy:0.68505039193729 train loss:0.69020021, test loss:0.68631887, test precision: 0.22213911742707554,test recall: 0.7774869109947644,test f1: 0.34554973821989526\n",
      "train accuracy: 0.5996887514285715, test accuracy:0.6791713325867861 train loss:0.68966182, test loss:0.68610895, test precision: 0.29020194465220644,test recall: 0.6632478632478632,test f1: 0.4037460978147763\n",
      "train accuracy: 0.6104092907142858, test accuracy:0.6797312430011199 train loss:0.68900083, test loss:0.68574375, test precision: 0.30142109199700823,test recall: 0.6574225122349103,test f1: 0.41333333333333333\n",
      "train accuracy: 0.613206685, test accuracy:0.6822508398656215 train loss:0.68847054, test loss:0.68541408, test precision: 0.31114435302916976,test recall: 0.6603174603174603,test f1: 0.42297915607524145\n",
      "train accuracy: 0.61125356, test accuracy:0.6816909294512878 train loss:0.6882457, test loss:0.68523908, test precision: 0.3395661929693343,test recall: 0.6412429378531074,test f1: 0.44400977995110025\n",
      "train accuracy: 0.6184839710714286, test accuracy:0.6814109742441209 train loss:0.68760924, test loss:0.68477476, test precision: 0.3380703066566941,test recall: 0.6411347517730497,test f1: 0.4427032321253673\n",
      "train accuracy: 0.6175025982142858, test accuracy:0.6825307950727884 train loss:0.68748635, test loss:0.68439865, test precision: 0.34405385190725507,test recall: 0.6415620641562064,test f1: 0.447906523855891\n",
      "train accuracy: 0.6246464171428572, test accuracy:0.6836506159014558 train loss:0.68639126, test loss:0.684089, test precision: 0.368735976065819,test recall: 0.6328626444159179,test f1: 0.4659735349716446\n",
      "train accuracy: 0.6247089553571429, test accuracy:0.6842105263157895 train loss:0.68652889, test loss:0.68376195, test precision: 0.381451009723261,test recall: 0.6288532675709001,test f1: 0.4748603351955307\n",
      "train accuracy: 0.6324204328571428, test accuracy:0.681131019036954 train loss:0.68584778, test loss:0.68345231, test precision: 0.38967838444278236,test recall: 0.6172985781990521,test f1: 0.477762494268684\n",
      "train accuracy: 0.6338227360714287, test accuracy:0.6794512877939529 train loss:0.68544395, test loss:0.68315226, test precision: 0.39341810022438295,test recall: 0.6116279069767442,test f1: 0.47883477469276287\n",
      "train accuracy: 0.6305081964285714, test accuracy:0.6819708846584547 train loss:0.68490226, test loss:0.6827178, test precision: 0.4016454749439043,test recall: 0.6151202749140894,test f1: 0.4859728506787331\n",
      "train accuracy: 0.6341209982142857, test accuracy:0.681131019036954 train loss:0.68469667, test loss:0.68233603, test precision: 0.40762902019446523,test recall: 0.6109865470852018,test f1: 0.48900852400179456\n",
      "train accuracy: 0.6335340967857143, test accuracy:0.6797312430011199 train loss:0.68430219, test loss:0.68189234, test precision: 0.418848167539267,test recall: 0.6040992448759439,test f1: 0.49469964664310956\n",
      "train accuracy: 0.6416496682142857, test accuracy:0.6794512877939529 train loss:0.68379668, test loss:0.68148613, test precision: 0.418848167539267,test recall: 0.603448275862069,test f1: 0.49448123620309054\n",
      "train accuracy: 0.6399009957142857, test accuracy:0.6794512877939529 train loss:0.68332595, test loss:0.68113172, test precision: 0.4465220643231114,test recall: 0.5958083832335329,test f1: 0.5104745617785378\n",
      "train accuracy: 0.6469461982142858, test accuracy:0.6791713325867861 train loss:0.68234759, test loss:0.68062705, test precision: 0.44502617801047123,test recall: 0.5955955955955956,test f1: 0.5094178082191781\n",
      "train accuracy: 0.6389316514285713, test accuracy:0.6780515117581187 train loss:0.68218438, test loss:0.68019384, test precision: 0.42333582647718776,test recall: 0.5989417989417989,test f1: 0.4960560911481157\n",
      "train accuracy: 0.6418637425, test accuracy:0.675531914893617 train loss:0.68187139, test loss:0.67975831, test precision: 0.4495138369483919,test recall: 0.5869140625,test f1: 0.5091063108852181\n",
      "train accuracy: 0.6432492114285715, test accuracy:0.673572228443449 train loss:0.68164943, test loss:0.67937988, test precision: 0.47943156320119673,test recall: 0.576957695769577,test f1: 0.5236928104575164\n",
      "train accuracy: 0.6583474450000001, test accuracy:0.6721724524076148 train loss:0.68030349, test loss:0.67893481, test precision: 0.4816753926701571,test recall: 0.5739750445632799,test f1: 0.5237901586010573\n",
      "train accuracy: 0.6522258889285714, test accuracy:0.6702127659574468 train loss:0.68023335, test loss:0.67836785, test precision: 0.4839192221391174,test recall: 0.5700440528634361,test f1: 0.523462783171521\n",
      "train accuracy: 0.6479852989285714, test accuracy:0.6615341545352743 train loss:0.68019764, test loss:0.67820543, test precision: 0.5100972326103216,test recall: 0.551779935275081,test f1: 0.5301204819277109\n",
      "train accuracy: 0.6560238985714287, test accuracy:0.6581746920492721 train loss:0.67890628, test loss:0.67776126, test precision: 0.5265519820493643,test recall: 0.544891640866873,test f1: 0.5355648535564854\n",
      "train accuracy: 0.6491566939285713, test accuracy:0.6573348264277715 train loss:0.67953537, test loss:0.6773228, test precision: 0.5302916978309649,test recall: 0.5432950191570881,test f1: 0.5367146101438304\n",
      "train accuracy: 0.6565362339285714, test accuracy:0.6578947368421053 train loss:0.67837177, test loss:0.67688644, test precision: 0.5347793567688855,test recall: 0.5437262357414449,test f1: 0.5392156862745098\n",
      "train accuracy: 0.6559445239285715, test accuracy:0.658454647256439 train loss:0.67802024, test loss:0.67638099, test precision: 0.537023186237846,test recall: 0.5443517816527672,test f1: 0.5406626506024096\n",
      "train accuracy: 0.6600576314285714, test accuracy:0.6640537513997761 train loss:0.67739569, test loss:0.67575872, test precision: 0.543754674644727,test recall: 0.5520121488230828,test f1: 0.5478522984174832\n",
      "train accuracy: 0.6619939196428571, test accuracy:0.6620940649496081 train loss:0.67604496, test loss:0.67535591, test precision: 0.5519820493642483,test recall: 0.5482912332838039,test f1: 0.5501304509877004\n",
      "train accuracy: 0.663018587857143, test accuracy:0.6581746920492721 train loss:0.67638742, test loss:0.67504579, test precision: 0.5557217651458489,test recall: 0.5423357664233577,test f1: 0.5489471739933505\n",
      "train accuracy: 0.6583763082142857, test accuracy:0.6595744680851063 train loss:0.67610574, test loss:0.67443615, test precision: 0.5549738219895288,test recall: 0.5443873807776962,test f1: 0.5496296296296297\n",
      "train accuracy: 0.656177839642857, test accuracy:0.6601343784994401 train loss:0.67597181, test loss:0.67377347, test precision: 0.5512341062079282,test recall: 0.5455218356772761,test f1: 0.5483630952380952\n",
      "train accuracy: 0.6612314317857144, test accuracy:0.6601343784994401 train loss:0.67494335, test loss:0.67322314, test precision: 0.5512341062079282,test recall: 0.5455218356772761,test f1: 0.5483630952380952\n",
      "train accuracy: 0.6600888992857143, test accuracy:0.6573348264277715 train loss:0.67416959, test loss:0.67269945, test precision: 0.556469708302169,test recall: 0.5410909090909091,test f1: 0.5486725663716814\n",
      "train accuracy: 0.6574526632142856, test accuracy:0.658454647256439 train loss:0.67407452, test loss:0.67199796, test precision: 0.5534779356768885,test recall: 0.5429200293470287,test f1: 0.548148148148148\n",
      "train accuracy: 0.6572746675000001, test accuracy:0.6578947368421053 train loss:0.67251752, test loss:0.67145425, test precision: 0.5534779356768885,test recall: 0.5421245421245421,test f1: 0.547742413027387\n",
      "train accuracy: 0.6497291607142858, test accuracy:0.6576147816349384 train loss:0.67346928, test loss:0.67094427, test precision: 0.5534779356768885,test recall: 0.541727672035139,test f1: 0.5475397706252312\n",
      "train accuracy: 0.6574069625, test accuracy:0.6567749160134378 train loss:0.67211488, test loss:0.67056501, test precision: 0.5534779356768885,test recall: 0.5405405405405406,test f1: 0.5469327420546932\n",
      "train accuracy: 0.662665004642857, test accuracy:0.6578947368421053 train loss:0.67094093, test loss:0.67021197, test precision: 0.5721765145848915,test recall: 0.5406360424028268,test f1: 0.5559593023255813\n",
      "train accuracy: 0.6678629153571428, test accuracy:0.6576147816349384 train loss:0.6702577, test loss:0.66972846, test precision: 0.5774121166791324,test recall: 0.5398601398601398,test f1: 0.5580050596313697\n",
      "train accuracy: 0.6595669446428571, test accuracy:0.6556550951847704 train loss:0.67047117, test loss:0.66950101, test precision: 0.5796559461480928,test recall: 0.5370755370755371,test f1: 0.5575539568345325\n",
      "train accuracy: 0.6538470789285714, test accuracy:0.6520156774916014 train loss:0.67073267, test loss:0.66908222, test precision: 0.5856394913986537,test recall: 0.5319293478260869,test f1: 0.5574937700249198\n",
      "train accuracy: 0.6551315235714286, test accuracy:0.6517357222844344 train loss:0.67035195, test loss:0.66859913, test precision: 0.5886312640239342,test recall: 0.5313977042538826,test f1: 0.5585521646557843\n",
      "train accuracy: 0.6578904332142856, test accuracy:0.6525755879059351 train loss:0.66908917, test loss:0.66806501, test precision: 0.5886312640239342,test recall: 0.5324763193504736,test f1: 0.5591474245115452\n",
      "train accuracy: 0.6602957578571429, test accuracy:0.6511758118701008 train loss:0.66797545, test loss:0.66770267, test precision: 0.5908750934928946,test recall: 0.5305574210879785,test f1: 0.5590941259731069\n",
      "train accuracy: 0.6646469942857143, test accuracy:0.6503359462486002 train loss:0.66755581, test loss:0.66720414, test precision: 0.5983545250560958,test recall: 0.5291005291005291,test f1: 0.5616005616005616\n",
      "train accuracy: 0.6608898742857142, test accuracy:0.6514557670772676 train loss:0.66723084, test loss:0.66672701, test precision: 0.6013462976813763,test recall: 0.5303430079155673,test f1: 0.5636172450052577\n",
      "train accuracy: 0.6595934035714286, test accuracy:0.6480963045912654 train loss:0.66693165, test loss:0.66634107, test precision: 0.6043380703066566,test recall: 0.5260416666666666,test f1: 0.5624782457361642\n",
      "train accuracy: 0.6487093024999998, test accuracy:0.6508958566629339 train loss:0.66798409, test loss:0.66575223, test precision: 0.6020942408376964,test recall: 0.5296052631578947,test f1: 0.5635281764088204\n",
      "train accuracy: 0.6607984714285714, test accuracy:0.6486562150055991 train loss:0.66574413, test loss:0.6654191, test precision: 0.6043380703066566,test recall: 0.5267275097783573,test f1: 0.5628700801114594\n",
      "train accuracy: 0.6574574742857143, test accuracy:0.6472564389697648 train loss:0.66614633, test loss:0.6649307, test precision: 0.6043380703066566,test recall: 0.5250162443144899,test f1: 0.5618915159944365\n",
      "train accuracy: 0.6646277517857142, test accuracy:0.6461366181410975 train loss:0.664228, test loss:0.6643092, test precision: 0.605833956619297,test recall: 0.5235940530058177,test f1: 0.5617198335644937\n",
      "train accuracy: 0.6609403875, test accuracy:0.6492161254199328 train loss:0.66408273, test loss:0.66359162, test precision: 0.5983545250560958,test recall: 0.5277044854881267,test f1: 0.5608131791097091\n",
      "train accuracy: 0.6647287760714287, test accuracy:0.6494960806270996 train loss:0.66241691, test loss:0.66308451, test precision: 0.5991024682124159,test recall: 0.5280158206987475,test f1: 0.5613174491941136\n",
      "train accuracy: 0.6643294910714286, test accuracy:0.6494960806270996 train loss:0.66109707, test loss:0.66237402, test precision: 0.5953627524308153,test recall: 0.5282017252820173,test f1: 0.559774964838256\n",
      "train accuracy: 0.6643583557142857, test accuracy:0.6483762597984323 train loss:0.66110727, test loss:0.66191709, test precision: 0.6043380703066566,test recall: 0.5263843648208469,test f1: 0.5626740947075209\n",
      "train accuracy: 0.6610991378571428, test accuracy:0.6452967525195968 train loss:0.66024154, test loss:0.6614899, test precision: 0.606581899775617,test recall: 0.5225515463917526,test f1: 0.5614399446175147\n",
      "train accuracy: 0.6618688421428571, test accuracy:0.6452967525195968 train loss:0.65974796, test loss:0.66094065, test precision: 0.606581899775617,test recall: 0.5225515463917526,test f1: 0.5614399446175147\n",
      "train accuracy: 0.6650126039285714, test accuracy:0.6447368421052632 train loss:0.66020032, test loss:0.66060299, test precision: 0.6088257292445775,test recall: 0.5217948717948718,test f1: 0.5619606489471868\n",
      "train accuracy: 0.6646421839285714, test accuracy:0.646976483762598 train loss:0.65884295, test loss:0.65978652, test precision: 0.6020942408376964,test recall: 0.5247718383311604,test f1: 0.5607802159526297\n",
      "train accuracy: 0.6660324628571429, test accuracy:0.6466965285554311 train loss:0.65749994, test loss:0.65937865, test precision: 0.606581899775617,test recall: 0.524240465416936,test f1: 0.5624133148404993\n",
      "train accuracy: 0.6622921796428571, test accuracy:0.6464165733482643 train loss:0.65894988, test loss:0.65871948, test precision: 0.5953627524308153,test recall: 0.5243741765480896,test f1: 0.5576182136602452\n",
      "train accuracy: 0.6621262117857142, test accuracy:0.6483762597984323 train loss:0.65789952, test loss:0.65802133, test precision: 0.5901271503365744,test recall: 0.5270541082164328,test f1: 0.5568101623147494\n",
      "train accuracy: 0.6619867042857143, test accuracy:0.6483762597984323 train loss:0.65662821, test loss:0.65736371, test precision: 0.5901271503365744,test recall: 0.5270541082164328,test f1: 0.5568101623147494\n",
      "train accuracy: 0.6554562425, test accuracy:0.648936170212766 train loss:0.65779437, test loss:0.65672588, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6589872614285713, test accuracy:0.648936170212766 train loss:0.65741239, test loss:0.65620643, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.664009582142857, test accuracy:0.648936170212766 train loss:0.65452905, test loss:0.65549147, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6635597875, test accuracy:0.648936170212766 train loss:0.65384433, test loss:0.65503007, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6655826653571429, test accuracy:0.6486562150055991 train loss:0.65376785, test loss:0.65463674, test precision: 0.5901271503365744,test recall: 0.5274064171122995,test f1: 0.5570067066713731\n",
      "train accuracy: 0.6624749839285714, test accuracy:0.6486562150055991 train loss:0.65275177, test loss:0.6543377, test precision: 0.5901271503365744,test recall: 0.5274064171122995,test f1: 0.5570067066713731\n",
      "train accuracy: 0.6621791296428572, test accuracy:0.6483762597984323 train loss:0.65329919, test loss:0.65380561, test precision: 0.5908750934928946,test recall: 0.5270180120080054,test f1: 0.5571227080394923\n",
      "train accuracy: 0.6655225335714287, test accuracy:0.648936170212766 train loss:0.6518539, test loss:0.65288466, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6626000614285715, test accuracy:0.648936170212766 train loss:0.65172739, test loss:0.6523217, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6662465353571428, test accuracy:0.648936170212766 train loss:0.64932673, test loss:0.65162235, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6679422910714286, test accuracy:0.648936170212766 train loss:0.64815162, test loss:0.65107316, test precision: 0.5901271503365744,test recall: 0.5277591973244147,test f1: 0.5572033898305084\n",
      "train accuracy: 0.6566468789285714, test accuracy:0.6492161254199328 train loss:0.65047742, test loss:0.65050107, test precision: 0.5908750934928946,test recall: 0.5280748663101604,test f1: 0.5577126720790682\n",
      "train accuracy: 0.6643944339285716, test accuracy:0.6492161254199328 train loss:0.64770227, test loss:0.65010154, test precision: 0.5908750934928946,test recall: 0.5280748663101604,test f1: 0.5577126720790682\n",
      "train accuracy: 0.6655056964285715, test accuracy:0.6492161254199328 train loss:0.64837043, test loss:0.64986879, test precision: 0.5908750934928946,test recall: 0.5280748663101604,test f1: 0.5577126720790682\n",
      "train accuracy: 0.6587226749999999, test accuracy:0.646976483762598 train loss:0.64863235, test loss:0.64947724, test precision: 0.5938668661181751,test recall: 0.5251322751322751,test f1: 0.5573885573885575\n",
      "train accuracy: 0.6676151660714285, test accuracy:0.646976483762598 train loss:0.64670721, test loss:0.64894229, test precision: 0.5938668661181751,test recall: 0.5251322751322751,test f1: 0.5573885573885575\n",
      "train accuracy: 0.6526877114285714, test accuracy:0.6466965285554311 train loss:0.64848813, test loss:0.64844173, test precision: 0.5953627524308153,test recall: 0.5247198417930126,test f1: 0.5578135949544498\n",
      "train accuracy: 0.6538254314285714, test accuracy:0.6475363941769317 train loss:0.64664858, test loss:0.64802605, test precision: 0.5976065818997757,test recall: 0.5256578947368421,test f1: 0.5593279663983199\n",
      "train accuracy: 0.6627251385714287, test accuracy:0.6466965285554311 train loss:0.64432994, test loss:0.6476317, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6618977067857142, test accuracy:0.6466965285554311 train loss:0.64617233, test loss:0.64700967, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6594899739285714, test accuracy:0.6466965285554311 train loss:0.64574977, test loss:0.64654863, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6694167571428571, test accuracy:0.6475363941769317 train loss:0.64231215, test loss:0.64589769, test precision: 0.5976065818997757,test recall: 0.5256578947368421,test f1: 0.5593279663983199\n",
      "train accuracy: 0.6638724785714285, test accuracy:0.6475363941769317 train loss:0.64221539, test loss:0.64537007, test precision: 0.5976065818997757,test recall: 0.5256578947368421,test f1: 0.5593279663983199\n",
      "train accuracy: 0.6643679778571429, test accuracy:0.6475363941769317 train loss:0.64079571, test loss:0.64485538, test precision: 0.5976065818997757,test recall: 0.5256578947368421,test f1: 0.5593279663983199\n",
      "train accuracy: 0.6570990789285714, test accuracy:0.6466965285554311 train loss:0.64365701, test loss:0.64467758, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6622681253571429, test accuracy:0.6458566629339306 train loss:0.64178781, test loss:0.6443488, test precision: 0.5983545250560958,test recall: 0.5235602094240838,test f1: 0.5584642233856894\n",
      "train accuracy: 0.6665015014285715, test accuracy:0.6466965285554311 train loss:0.63947419, test loss:0.64365137, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6642116296428571, test accuracy:0.6466965285554311 train loss:0.64008528, test loss:0.64306521, test precision: 0.5983545250560958,test recall: 0.5245901639344263,test f1: 0.5590496156533893\n",
      "train accuracy: 0.6585446814285714, test accuracy:0.6458566629339306 train loss:0.64101719, test loss:0.64283091, test precision: 0.5983545250560958,test recall: 0.5235602094240838,test f1: 0.5584642233856894\n",
      "train accuracy: 0.6634563578571429, test accuracy:0.6458566629339306 train loss:0.63843824, test loss:0.64249766, test precision: 0.5983545250560958,test recall: 0.5235602094240838,test f1: 0.5584642233856894\n",
      "train accuracy: 0.6586481103571428, test accuracy:0.6458566629339306 train loss:0.63920569, test loss:0.64193928, test precision: 0.5983545250560958,test recall: 0.5235602094240838,test f1: 0.5584642233856894\n",
      "train accuracy: 0.6590449892857143, test accuracy:0.6458566629339306 train loss:0.63957649, test loss:0.64165831, test precision: 0.5983545250560958,test recall: 0.5235602094240838,test f1: 0.5584642233856894\n",
      "train accuracy: 0.6626289253571428, test accuracy:0.6492161254199328 train loss:0.63806464, test loss:0.64121783, test precision: 0.5983545250560958,test recall: 0.5277044854881267,test f1: 0.5608131791097091\n",
      "train accuracy: 0.6630522635714284, test accuracy:0.6492161254199328 train loss:0.63730061, test loss:0.64115584, test precision: 0.5983545250560958,test recall: 0.5277044854881267,test f1: 0.5608131791097091\n",
      "train accuracy: 0.6619963260714286, test accuracy:0.648936170212766 train loss:0.6375534, test loss:0.6408928, test precision: 0.600598354525056,test recall: 0.5272488509520683,test f1: 0.5615384615384615\n",
      "train accuracy: 0.6708334935714285, test accuracy:0.6500559910414334 train loss:0.63377655, test loss:0.64004886, test precision: 0.5976065818997757,test recall: 0.528788881535407,test f1: 0.5610955056179775\n",
      "train accuracy: 0.6634972485714284, test accuracy:0.6508958566629339 train loss:0.63684501, test loss:0.63929152, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6734649221428571, test accuracy:0.6508958566629339 train loss:0.63312545, test loss:0.63859493, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.65946111, test accuracy:0.6508958566629339 train loss:0.63775713, test loss:0.63845181, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6650775471428572, test accuracy:0.6508958566629339 train loss:0.63484344, test loss:0.63809985, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6652266778571428, test accuracy:0.6508958566629339 train loss:0.63372913, test loss:0.63746202, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6651761667857142, test accuracy:0.6508958566629339 train loss:0.63199908, test loss:0.63731551, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6704510471428572, test accuracy:0.6508958566629339 train loss:0.63165819, test loss:0.63668662, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6669945928571429, test accuracy:0.6508958566629339 train loss:0.63068137, test loss:0.63654768, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6698400939285715, test accuracy:0.6508958566629339 train loss:0.62984041, test loss:0.63594246, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6649789300000001, test accuracy:0.6508958566629339 train loss:0.63214783, test loss:0.63556498, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6646734521428572, test accuracy:0.6508958566629339 train loss:0.63113606, test loss:0.63531864, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6646734525, test accuracy:0.6508958566629339 train loss:0.62908593, test loss:0.63524777, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6717643542857142, test accuracy:0.6508958566629339 train loss:0.62675032, test loss:0.63457811, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6687961821428571, test accuracy:0.6508958566629339 train loss:0.62840753, test loss:0.6337471, test precision: 0.5976065818997757,test recall: 0.5298408488063661,test f1: 0.5616871704745168\n",
      "train accuracy: 0.6707661446428571, test accuracy:0.6500559910414334 train loss:0.62744376, test loss:0.63324428, test precision: 0.5953627524308153,test recall: 0.5289036544850498,test f1: 0.5601688951442647\n",
      "train accuracy: 0.6612843485714285, test accuracy:0.6520156774916014 train loss:0.63075876, test loss:0.6331383, test precision: 0.5961106955871354,test recall: 0.5313333333333333,test f1: 0.5618611209023615\n",
      "train accuracy: 0.6636151092857142, test accuracy:0.6520156774916014 train loss:0.6279135, test loss:0.63305104, test precision: 0.5961106955871354,test recall: 0.5313333333333333,test f1: 0.5618611209023615\n",
      "train accuracy: 0.6641659303571429, test accuracy:0.6520156774916014 train loss:0.62780776, test loss:0.63286144, test precision: 0.5961106955871354,test recall: 0.5313333333333333,test f1: 0.5618611209023615\n",
      "train accuracy: 0.6746194778571429, test accuracy:0.6511758118701008 train loss:0.62442917, test loss:0.63278627, test precision: 0.5991024682124159,test recall: 0.5301125082726671,test f1: 0.5625\n",
      "train accuracy: 0.6646878839285714, test accuracy:0.6522956326987682 train loss:0.62703575, test loss:0.63224894, test precision: 0.5961106955871354,test recall: 0.5316877918612408,test f1: 0.5620592383638928\n",
      "train accuracy: 0.6623907982142858, test accuracy:0.6522956326987682 train loss:0.6278908, test loss:0.63182861, test precision: 0.5961106955871354,test recall: 0.5316877918612408,test f1: 0.5620592383638928\n",
      "train accuracy: 0.6659218182142856, test accuracy:0.6517357222844344 train loss:0.62703963, test loss:0.6309604, test precision: 0.5938668661181751,test recall: 0.5311036789297658,test f1: 0.5607344632768363\n",
      "train accuracy: 0.6689789871428572, test accuracy:0.6517357222844344 train loss:0.62458166, test loss:0.63060254, test precision: 0.5938668661181751,test recall: 0.5311036789297658,test f1: 0.5607344632768363\n",
      "train accuracy: 0.6634443314285715, test accuracy:0.6517357222844344 train loss:0.62704026, test loss:0.63020754, test precision: 0.5938668661181751,test recall: 0.5311036789297658,test f1: 0.5607344632768363\n",
      "train accuracy: 0.667369825, test accuracy:0.6539753639417694 train loss:0.6258801, test loss:0.62945372, test precision: 0.5916230366492147,test recall: 0.5340985820391627,test f1: 0.5613910574875798\n",
      "train accuracy: 0.6717980292857142, test accuracy:0.6517357222844344 train loss:0.61986069, test loss:0.62935477, test precision: 0.5938668661181751,test recall: 0.5311036789297658,test f1: 0.5607344632768363\n",
      "train accuracy: 0.6652314892857143, test accuracy:0.6542553191489362 train loss:0.6258954, test loss:0.62849391, test precision: 0.5916230366492147,test recall: 0.5344594594594595,test f1: 0.5615903443379482\n",
      "train accuracy: 0.6736934271428572, test accuracy:0.6517357222844344 train loss:0.62146761, test loss:0.62860054, test precision: 0.5938668661181751,test recall: 0.5311036789297658,test f1: 0.5607344632768363\n",
      "train accuracy: 0.6694263782142856, test accuracy:0.6520156774916014 train loss:0.62074192, test loss:0.62832421, test precision: 0.5938668661181751,test recall: 0.5314591700133868,test f1: 0.5609325326739667\n",
      "train accuracy: 0.6659603014285714, test accuracy:0.6522956326987682 train loss:0.62367393, test loss:0.62834883, test precision: 0.5946148092744952,test recall: 0.5317725752508361,test f1: 0.5614406779661016\n",
      "train accuracy: 0.6650053867857143, test accuracy:0.6522956326987682 train loss:0.62368984, test loss:0.62815237, test precision: 0.5946148092744952,test recall: 0.5317725752508361,test f1: 0.5614406779661016\n",
      "train accuracy: 0.6668310296428571, test accuracy:0.6522956326987682 train loss:0.62331449, test loss:0.62777126, test precision: 0.5946148092744952,test recall: 0.5317725752508361,test f1: 0.5614406779661016\n",
      "train accuracy: 0.6747349328571428, test accuracy:0.6542553191489362 train loss:0.61758367, test loss:0.62740946, test precision: 0.5901271503365744,test recall: 0.5345528455284553,test f1: 0.560966939210807\n",
      "train accuracy: 0.6619193535714285, test accuracy:0.6542553191489362 train loss:0.62501388, test loss:0.62712985, test precision: 0.5901271503365744,test recall: 0.5345528455284553,test f1: 0.560966939210807\n",
      "train accuracy: 0.6707012010714285, test accuracy:0.654535274356103 train loss:0.61977306, test loss:0.62676698, test precision: 0.5901271503365744,test recall: 0.5349152542372881,test f1: 0.5611664295874822\n",
      "train accuracy: 0.6674347671428571, test accuracy:0.6500559910414334 train loss:0.61997184, test loss:0.62663257, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6604328628571426, test accuracy:0.6500559910414334 train loss:0.62300803, test loss:0.62660789, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6709008435714285, test accuracy:0.6500559910414334 train loss:0.61957012, test loss:0.62664902, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6697462867857144, test accuracy:0.6492161254199328 train loss:0.61934734, test loss:0.62665343, test precision: 0.6013462976813763,test recall: 0.5275590551181102,test f1: 0.5620412443201677\n",
      "train accuracy: 0.6668815425, test accuracy:0.6522956326987682 train loss:0.62073825, test loss:0.62572545, test precision: 0.5991024682124159,test recall: 0.5315195753151958,test f1: 0.5632911392405063\n",
      "train accuracy: 0.6712423989285714, test accuracy:0.6500559910414334 train loss:0.61916866, test loss:0.62563777, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6672712060714286, test accuracy:0.6522956326987682 train loss:0.62098671, test loss:0.62549472, test precision: 0.5991024682124159,test recall: 0.5315195753151958,test f1: 0.5632911392405063\n",
      "train accuracy: 0.6721828814285715, test accuracy:0.6522956326987682 train loss:0.61788344, test loss:0.62540257, test precision: 0.5991024682124159,test recall: 0.5315195753151958,test f1: 0.5632911392405063\n",
      "train accuracy: 0.6656500153571429, test accuracy:0.6500559910414334 train loss:0.61876657, test loss:0.62557209, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6653012432142856, test accuracy:0.6500559910414334 train loss:0.62092963, test loss:0.62517089, test precision: 0.6013462976813763,test recall: 0.5285996055226825,test f1: 0.562631210636809\n",
      "train accuracy: 0.6649404439285714, test accuracy:0.6522956326987682 train loss:0.61920535, test loss:0.62473494, test precision: 0.5991024682124159,test recall: 0.5315195753151958,test f1: 0.5632911392405063\n",
      "train accuracy: 0.6658087664285715, test accuracy:0.6522956326987682 train loss:0.61554469, test loss:0.62461531, test precision: 0.5991024682124159,test recall: 0.5315195753151958,test f1: 0.5632911392405063\n",
      "train accuracy: 0.6621093753571429, test accuracy:0.6494960806270996 train loss:0.61620294, test loss:0.62492949, test precision: 0.6073298429319371,test recall: 0.5276153346328785,test f1: 0.564673157162726\n",
      "train accuracy: 0.6689549332142857, test accuracy:0.6494960806270996 train loss:0.6168591, test loss:0.62526911, test precision: 0.6267763649962603,test recall: 0.5267127592708988,test f1: 0.5724043715846994\n",
      "train accuracy: 0.6712327782142857, test accuracy:0.6494960806270996 train loss:0.61682626, test loss:0.62512988, test precision: 0.6267763649962603,test recall: 0.5267127592708988,test f1: 0.5724043715846994\n",
      "train accuracy: 0.6737824242857142, test accuracy:0.6494960806270996 train loss:0.61603497, test loss:0.62468338, test precision: 0.6267763649962603,test recall: 0.5267127592708988,test f1: 0.5724043715846994\n",
      "train accuracy: 0.6753723446428571, test accuracy:0.6486562150055991 train loss:0.61585698, test loss:0.62417454, test precision: 0.606581899775617,test recall: 0.5266233766233767,test f1: 0.5637817170663886\n",
      "train accuracy: 0.6701551914285714, test accuracy:0.6497760358342665 train loss:0.61512182, test loss:0.6243335, test precision: 0.62528047868362,test recall: 0.5271122320302648,test f1: 0.5720150530277113\n",
      "train accuracy: 0.6775275175000001, test accuracy:0.6492161254199328 train loss:0.61212383, test loss:0.62457764, test precision: 0.6282722513089005,test recall: 0.5263157894736842,test f1: 0.5727923627684964\n",
      "train accuracy: 0.6772653364285715, test accuracy:0.6500559910414334 train loss:0.6134819, test loss:0.62456918, test precision: 0.6245325355272999,test recall: 0.527479469361971,test f1: 0.5719178082191781\n",
      "train accuracy: 0.674773417857143, test accuracy:0.6500559910414334 train loss:0.61508397, test loss:0.62409306, test precision: 0.6245325355272999,test recall: 0.527479469361971,test f1: 0.5719178082191781\n",
      "train accuracy: 0.670879195, test accuracy:0.6500559910414334 train loss:0.61477336, test loss:0.62367421, test precision: 0.6245325355272999,test recall: 0.527479469361971,test f1: 0.5719178082191781\n",
      "train accuracy: 0.6675814939285714, test accuracy:0.6500559910414334 train loss:0.61557042, test loss:0.62368232, test precision: 0.6245325355272999,test recall: 0.527479469361971,test f1: 0.5719178082191781\n",
      "train accuracy: 0.6742851364285715, test accuracy:0.6506159014557671 train loss:0.61384339, test loss:0.62305439, test precision: 0.6215407629020194,test recall: 0.5282898919262555,test f1: 0.5711340206185568\n",
      "train accuracy: 0.6721371814285716, test accuracy:0.6500559910414334 train loss:0.61574128, test loss:0.62306058, test precision: 0.6245325355272999,test recall: 0.527479469361971,test f1: 0.5719178082191781\n",
      "train accuracy: 0.6731690664285715, test accuracy:0.6511758118701008 train loss:0.61208514, test loss:0.62232912, test precision: 0.6192969334330591,test recall: 0.529073482428115,test f1: 0.5706409372846313\n",
      "train accuracy: 0.6706723367857144, test accuracy:0.6508958566629339 train loss:0.61419461, test loss:0.62212622, test precision: 0.6192969334330591,test recall: 0.5287356321839081,test f1: 0.5704443678952807\n",
      "train accuracy: 0.6740830896428571, test accuracy:0.6503359462486002 train loss:0.61468649, test loss:0.62218219, test precision: 0.6207928197456993,test recall: 0.5279898218829516,test f1: 0.5706428325885184\n",
      "train accuracy: 0.6734985939285715, test accuracy:0.6506159014557671 train loss:0.61273769, test loss:0.62232637, test precision: 0.6215407629020194,test recall: 0.5282898919262555,test f1: 0.5711340206185568\n",
      "train accuracy: 0.6661070282142856, test accuracy:0.6503359462486002 train loss:0.61622719, test loss:0.62223679, test precision: 0.6207928197456993,test recall: 0.5279898218829516,test f1: 0.5706428325885184\n",
      "train accuracy: 0.6703283757142857, test accuracy:0.6503359462486002 train loss:0.61421022, test loss:0.62226415, test precision: 0.6207928197456993,test recall: 0.5279898218829516,test f1: 0.5706428325885184\n",
      "train accuracy: 0.6723151749999999, test accuracy:0.6528555431131019 train loss:0.61174705, test loss:0.62177259, test precision: 0.6192969334330591,test recall: 0.531109685695959,test f1: 0.5718232044198895\n",
      "train accuracy: 0.6718461371428571, test accuracy:0.6528555431131019 train loss:0.61270543, test loss:0.62152743, test precision: 0.6185489902767389,test recall: 0.5311496467565832,test f1: 0.5715272978576365\n",
      "train accuracy: 0.6735803760714284, test accuracy:0.6556550951847704 train loss:0.61047087, test loss:0.62100828, test precision: 0.6140613313388182,test recall: 0.5348534201954397,test f1: 0.5717270194986072\n",
      "train accuracy: 0.6788937425, test accuracy:0.6590145576707727 train loss:0.61209848, test loss:0.62099916, test precision: 0.6133133881824981,test recall: 0.5391190006574622,test f1: 0.5738278516445067\n",
      "train accuracy: 0.6779340175, test accuracy:0.6590145576707727 train loss:0.61315257, test loss:0.6206674, test precision: 0.6133133881824981,test recall: 0.5391190006574622,test f1: 0.5738278516445067\n",
      "train accuracy: 0.6768323771428572, test accuracy:0.6590145576707727 train loss:0.61073527, test loss:0.62078696, test precision: 0.6133133881824981,test recall: 0.5391190006574622,test f1: 0.5738278516445067\n",
      "train accuracy: 0.6771691228571429, test accuracy:0.6590145576707727 train loss:0.6105786, test loss:0.62029731, test precision: 0.6133133881824981,test recall: 0.5391190006574622,test f1: 0.5738278516445067\n",
      "train accuracy: 0.67335187, test accuracy:0.660414333706607 train loss:0.61177341, test loss:0.61999255, test precision: 0.612565445026178,test recall: 0.5409511228533685,test f1: 0.5745352507891968\n",
      "train accuracy: 0.6794974796428572, test accuracy:0.660414333706607 train loss:0.60734919, test loss:0.61966211, test precision: 0.612565445026178,test recall: 0.5409511228533685,test f1: 0.5745352507891968\n",
      "train accuracy: 0.6806327939285716, test accuracy:0.660414333706607 train loss:0.61007532, test loss:0.61954212, test precision: 0.612565445026178,test recall: 0.5409511228533685,test f1: 0.5745352507891968\n",
      "train accuracy: 0.6767361650000001, test accuracy:0.660414333706607 train loss:0.60900736, test loss:0.61912221, test precision: 0.612565445026178,test recall: 0.5409511228533685,test f1: 0.5745352507891968\n",
      "train accuracy: 0.6750211671428572, test accuracy:0.6606942889137738 train loss:0.61272391, test loss:0.61877787, test precision: 0.612565445026178,test recall: 0.5413086582947786,test f1: 0.5747368421052631\n",
      "train accuracy: 0.6764210671428571, test accuracy:0.6615341545352743 train loss:0.60949805, test loss:0.61882687, test precision: 0.6110695587135377,test recall: 0.5424966799468791,test f1: 0.5747449876890608\n",
      "train accuracy: 0.6826171878571429, test accuracy:0.6606942889137738 train loss:0.60823675, test loss:0.61857224, test precision: 0.612565445026178,test recall: 0.5413086582947786,test f1: 0.5747368421052631\n",
      "train accuracy: 0.6731209596428572, test accuracy:0.6606942889137738 train loss:0.61201155, test loss:0.61890781, test precision: 0.612565445026178,test recall: 0.5413086582947786,test f1: 0.5747368421052631\n",
      "train accuracy: 0.6818667260714285, test accuracy:0.6598544232922733 train loss:0.60788975, test loss:0.61951011, test precision: 0.6148092744951383,test recall: 0.5400788436268068,test f1: 0.5750262329485833\n",
      "train accuracy: 0.6772509050000001, test accuracy:0.6615341545352743 train loss:0.6111334, test loss:0.61900449, test precision: 0.6110695587135377,test recall: 0.5424966799468791,test f1: 0.5747449876890608\n",
      "train accuracy: 0.6837741496428571, test accuracy:0.6615341545352743 train loss:0.60790777, test loss:0.61882192, test precision: 0.6110695587135377,test recall: 0.5424966799468791,test f1: 0.5747449876890608\n",
      "train accuracy: 0.6743236217857144, test accuracy:0.6615341545352743 train loss:0.61247618, test loss:0.61826372, test precision: 0.6080777860882572,test recall: 0.5427236315086782,test f1: 0.5735449735449735\n",
      "train accuracy: 0.6803922607142857, test accuracy:0.6618141097424413 train loss:0.6089226, test loss:0.61811006, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6706386610714284, test accuracy:0.6618141097424413 train loss:0.61534152, test loss:0.61812615, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6749634382142856, test accuracy:0.6618141097424413 train loss:0.60980276, test loss:0.61825264, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6800074078571428, test accuracy:0.6612541993281075 train loss:0.60593094, test loss:0.61842734, test precision: 0.6088257292445775,test recall: 0.5423051299133911,test f1: 0.5736434108527132\n",
      "train accuracy: 0.6763416914285715, test accuracy:0.6618141097424413 train loss:0.60782517, test loss:0.61798143, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6759472171428571, test accuracy:0.6618141097424413 train loss:0.61097377, test loss:0.61785734, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6741239803571428, test accuracy:0.6618141097424413 train loss:0.61060441, test loss:0.61765081, test precision: 0.6073298429319371,test recall: 0.5431438127090301,test f1: 0.5734463276836159\n",
      "train accuracy: 0.6776766464285713, test accuracy:0.6618141097424413 train loss:0.60972185, test loss:0.61747491, test precision: 0.6080777860882572,test recall: 0.5430861723446894,test f1: 0.5737473535638672\n",
      "train accuracy: 0.6754156400000001, test accuracy:0.6615341545352743 train loss:0.61116129, test loss:0.61775345, test precision: 0.6080777860882572,test recall: 0.5427236315086782,test f1: 0.5735449735449735\n",
      "train accuracy: 0.6795119107142857, test accuracy:0.6634938409854423 train loss:0.60480992, test loss:0.6173988, test precision: 0.6050860134629769,test recall: 0.545515846257586,test f1: 0.5737588652482271\n",
      "train accuracy: 0.6768155396428571, test accuracy:0.6632138857782754 train loss:0.6077459, test loss:0.61762172, test precision: 0.6103216155572176,test recall: 0.5447263017356475,test f1: 0.5756613756613757\n",
      "train accuracy: 0.6810657517857143, test accuracy:0.6634938409854423 train loss:0.60301895, test loss:0.61730903, test precision: 0.6073298429319371,test recall: 0.5453324378777703,test f1: 0.5746638358103326\n",
      "train accuracy: 0.6782972217857143, test accuracy:0.6634938409854423 train loss:0.60723018, test loss:0.61704016, test precision: 0.6050860134629769,test recall: 0.545515846257586,test f1: 0.5737588652482271\n",
      "train accuracy: 0.6791414914285713, test accuracy:0.6646136618141097 train loss:0.60655539, test loss:0.61664021, test precision: 0.6043380703066566,test recall: 0.5470548408937035,test f1: 0.574271499644634\n",
      "train accuracy: 0.6788985525, test accuracy:0.6654535274356103 train loss:0.60294058, test loss:0.61637592, test precision: 0.6043380703066566,test recall: 0.5481682496607869,test f1: 0.5748843827819281\n",
      "train accuracy: 0.6614262617857143, test accuracy:0.6651735722284434 train loss:0.61580055, test loss:0.61634082, test precision: 0.6050860134629769,test recall: 0.5477318889641164,test f1: 0.5749822316986496\n",
      "train accuracy: 0.6763032067857144, test accuracy:0.6651735722284434 train loss:0.60649502, test loss:0.6163407, test precision: 0.606581899775617,test recall: 0.5476029709655638,test f1: 0.5755855216465579\n",
      "train accuracy: 0.676377770357143, test accuracy:0.6674132138857782 train loss:0.60752033, test loss:0.61591065, test precision: 0.6028421839940165,test recall: 0.5509227614490773,test f1: 0.5757142857142857\n",
      "train accuracy: 0.6723656860714288, test accuracy:0.6674132138857782 train loss:0.6089982, test loss:0.61578739, test precision: 0.6050860134629769,test recall: 0.55071477195371,test f1: 0.5766215253029223\n",
      "train accuracy: 0.6807434389285715, test accuracy:0.6674132138857782 train loss:0.60622857, test loss:0.61566979, test precision: 0.6050860134629769,test recall: 0.55071477195371,test f1: 0.5766215253029223\n",
      "train accuracy: 0.6843538342857143, test accuracy:0.6671332586786114 train loss:0.60059484, test loss:0.61594892, test precision: 0.605833956619297,test recall: 0.5502717391304348,test f1: 0.5767176931292275\n",
      "train accuracy: 0.67409271, test accuracy:0.6674132138857782 train loss:0.60871648, test loss:0.61673486, test precision: 0.6118175018698578,test recall: 0.5501008742434432,test f1: 0.5793201133144477\n",
      "train accuracy: 0.6786026989285714, test accuracy:0.6668533034714446 train loss:0.60528537, test loss:0.6164391, test precision: 0.6088257292445775,test recall: 0.5496286293045239,test f1: 0.5777146912704045\n",
      "train accuracy: 0.6783477339285716, test accuracy:0.6671332586786114 train loss:0.60387113, test loss:0.61617738, test precision: 0.6080777860882572,test recall: 0.5500676589986468,test f1: 0.577619893428064\n",
      "train accuracy: 0.6769358067857143, test accuracy:0.6674132138857782 train loss:0.60687111, test loss:0.61549836, test precision: 0.605833956619297,test recall: 0.5506458191706323,test f1: 0.576923076923077\n",
      "train accuracy: 0.6770127782142856, test accuracy:0.6682530795072789 train loss:0.6082663, test loss:0.61463511, test precision: 0.6050860134629769,test recall: 0.5518417462482946,test f1: 0.5772386728505172\n",
      "train accuracy: 0.6778907217857143, test accuracy:0.6682530795072789 train loss:0.60893129, test loss:0.61479455, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6860423717857144, test accuracy:0.6682530795072789 train loss:0.60029239, test loss:0.6147722, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6842576185714285, test accuracy:0.6682530795072789 train loss:0.60306249, test loss:0.61466753, test precision: 0.605833956619297,test recall: 0.5517711171662125,test f1: 0.5775401069518716\n",
      "train accuracy: 0.6789490646428572, test accuracy:0.667973124300112 train loss:0.6070199, test loss:0.61437869, test precision: 0.6050860134629769,test recall: 0.5514655760054533,test f1: 0.5770328102710414\n",
      "train accuracy: 0.6775395432142857, test accuracy:0.667973124300112 train loss:0.6057852, test loss:0.61419576, test precision: 0.6050860134629769,test recall: 0.5514655760054533,test f1: 0.5770328102710414\n",
      "train accuracy: 0.6819124267857143, test accuracy:0.6685330347144457 train loss:0.60368766, test loss:0.61434042, test precision: 0.6050860134629769,test recall: 0.5522184300341297,test f1: 0.577444682369736\n",
      "train accuracy: 0.6802311035714286, test accuracy:0.6685330347144457 train loss:0.60438214, test loss:0.61445719, test precision: 0.6050860134629769,test recall: 0.5522184300341297,test f1: 0.577444682369736\n",
      "train accuracy: 0.6782996260714287, test accuracy:0.6688129899216125 train loss:0.60424232, test loss:0.61412865, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6751943496428571, test accuracy:0.6688129899216125 train loss:0.60640741, test loss:0.61415154, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6846184185714287, test accuracy:0.6688129899216125 train loss:0.60211996, test loss:0.61366862, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6742105725, test accuracy:0.6688129899216125 train loss:0.60523759, test loss:0.61362821, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6778570475, test accuracy:0.6688129899216125 train loss:0.60490325, test loss:0.61372447, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6752280246428571, test accuracy:0.6685330347144457 train loss:0.6080539, test loss:0.61412996, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.6702393764285715, test accuracy:0.6685330347144457 train loss:0.60783421, test loss:0.61406225, test precision: 0.6073298429319371,test recall: 0.5520054384772264,test f1: 0.5783475783475783\n",
      "train accuracy: 0.6755864189285715, test accuracy:0.6688129899216125 train loss:0.60344275, test loss:0.61389059, test precision: 0.6050860134629769,test recall: 0.5525956284153005,test f1: 0.5776508389860764\n",
      "train accuracy: 0.6833267589285714, test accuracy:0.6690929451287794 train loss:0.6020837, test loss:0.61290807, test precision: 0.6028421839940165,test recall: 0.5531914893617021,test f1: 0.5769506084466715\n",
      "train accuracy: 0.6819364803571428, test accuracy:0.6693729003359462 train loss:0.60008262, test loss:0.61249518, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6775178957142857, test accuracy:0.6690929451287794 train loss:0.60485428, test loss:0.61276311, test precision: 0.6028421839940165,test recall: 0.5531914893617021,test f1: 0.5769506084466715\n",
      "train accuracy: 0.6811595600000001, test accuracy:0.6693729003359462 train loss:0.60398968, test loss:0.61258119, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6890418132142858, test accuracy:0.6693729003359462 train loss:0.59742469, test loss:0.61248219, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6853159635714287, test accuracy:0.6693729003359462 train loss:0.59861961, test loss:0.61162609, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6804403675, test accuracy:0.6693729003359462 train loss:0.60306142, test loss:0.61197948, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6788528521428574, test accuracy:0.6693729003359462 train loss:0.60428236, test loss:0.61167043, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6774216814285714, test accuracy:0.6693729003359462 train loss:0.60503416, test loss:0.61175561, test precision: 0.6020942408376964,test recall: 0.5536451169188445,test f1: 0.5768541741311358\n",
      "train accuracy: 0.6764090400000001, test accuracy:0.6690929451287794 train loss:0.60528167, test loss:0.61211109, test precision: 0.6020942408376964,test recall: 0.5532646048109966,test f1: 0.576647564469914\n",
      "train accuracy: 0.6688515053571429, test accuracy:0.66993281075028 train loss:0.60996933, test loss:0.61230236, test precision: 0.6050860134629769,test recall: 0.5541095890410959,test f1: 0.5784769395781193\n",
      "train accuracy: 0.6783164639285715, test accuracy:0.6690929451287794 train loss:0.60518127, test loss:0.61201793, test precision: 0.6020942408376964,test recall: 0.5532646048109966,test f1: 0.576647564469914\n",
      "train accuracy: 0.6780542828571428, test accuracy:0.671892497200448 train loss:0.6035209, test loss:0.61283505, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6841734346428572, test accuracy:0.671892497200448 train loss:0.59971008, test loss:0.61234629, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6766399514285714, test accuracy:0.671612541993281 train loss:0.60332709, test loss:0.61320239, test precision: 0.6230366492146597,test recall: 0.5545938748335553,test f1: 0.5868263473053892\n",
      "train accuracy: 0.6788624735714286, test accuracy:0.671892497200448 train loss:0.6024811, test loss:0.61307925, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.678434325357143, test accuracy:0.671892497200448 train loss:0.60475527, test loss:0.61278588, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6833796757142857, test accuracy:0.671892497200448 train loss:0.6014173, test loss:0.61248201, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6755551492857144, test accuracy:0.671892497200448 train loss:0.60698858, test loss:0.61200976, test precision: 0.6215407629020194,test recall: 0.5551102204408818,test f1: 0.5864502470007057\n",
      "train accuracy: 0.6831607925, test accuracy:0.671892497200448 train loss:0.60085607, test loss:0.61196625, test precision: 0.6215407629020194,test recall: 0.5551102204408818,test f1: 0.5864502470007057\n",
      "train accuracy: 0.6801733760714285, test accuracy:0.671892497200448 train loss:0.60364882, test loss:0.61252314, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6795022896428572, test accuracy:0.671612541993281 train loss:0.60286351, test loss:0.61286187, test precision: 0.6230366492146597,test recall: 0.5545938748335553,test f1: 0.5868263473053892\n",
      "train accuracy: 0.6806015239285715, test accuracy:0.671892497200448 train loss:0.60291306, test loss:0.61259216, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6895325010714285, test accuracy:0.671892497200448 train loss:0.59815832, test loss:0.61227489, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6854001492857142, test accuracy:0.671892497200448 train loss:0.59976034, test loss:0.6120342, test precision: 0.6215407629020194,test recall: 0.5551102204408818,test f1: 0.5864502470007057\n",
      "train accuracy: 0.6830092546428572, test accuracy:0.671892497200448 train loss:0.59817086, test loss:0.61211413, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6851956971428571, test accuracy:0.671892497200448 train loss:0.59849099, test loss:0.61199838, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6826316192857141, test accuracy:0.6721724524076148 train loss:0.59917677, test loss:0.61168927, test precision: 0.6192969334330591,test recall: 0.5557046979865772,test f1: 0.5857799787760877\n",
      "train accuracy: 0.6846785517857142, test accuracy:0.671892497200448 train loss:0.59825216, test loss:0.61234313, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6775299217857143, test accuracy:0.671892497200448 train loss:0.60612832, test loss:0.61204672, test precision: 0.6222887060583395,test recall: 0.5550366911274183,test f1: 0.5867418899858956\n",
      "train accuracy: 0.6803706139285713, test accuracy:0.671612541993281 train loss:0.60239795, test loss:0.61124378, test precision: 0.6148092744951383,test recall: 0.5554054054054054,test f1: 0.5835995740149095\n",
      "train accuracy: 0.6843514267857141, test accuracy:0.671612541993281 train loss:0.59898796, test loss:0.61134428, test precision: 0.6148092744951383,test recall: 0.5554054054054054,test f1: 0.5835995740149095\n",
      "train accuracy: 0.6848565460714285, test accuracy:0.671612541993281 train loss:0.59877358, test loss:0.6113016, test precision: 0.6148092744951383,test recall: 0.5554054054054054,test f1: 0.5835995740149095\n",
      "train accuracy: 0.6811788025, test accuracy:0.6724524076147816 train loss:0.60046713, test loss:0.6113714, test precision: 0.6185489902767389,test recall: 0.5561533288500337,test f1: 0.5856940509915014\n",
      "train accuracy: 0.678472809642857, test accuracy:0.6732922732362822 train loss:0.60283289, test loss:0.61123806, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.68325941, test accuracy:0.6732922732362822 train loss:0.6000869, test loss:0.61141568, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6787470175000001, test accuracy:0.6710526315789473 train loss:0.60257686, test loss:0.61165148, test precision: 0.6230366492146597,test recall: 0.5538563829787234,test f1: 0.5864132347764871\n",
      "train accuracy: 0.6810753735714287, test accuracy:0.6710526315789473 train loss:0.60394885, test loss:0.61133826, test precision: 0.6230366492146597,test recall: 0.5538563829787234,test f1: 0.5864132347764871\n",
      "train accuracy: 0.6796442042857143, test accuracy:0.6710526315789473 train loss:0.60037241, test loss:0.61104035, test precision: 0.6230366492146597,test recall: 0.5538563829787234,test f1: 0.5864132347764871\n",
      "train accuracy: 0.6911416635714286, test accuracy:0.6707726763717805 train loss:0.59626687, test loss:0.61127251, test precision: 0.62528047868362,test recall: 0.5532759761747187,test f1: 0.5870786516853932\n",
      "train accuracy: 0.6841132999999999, test accuracy:0.6707726763717805 train loss:0.60098994, test loss:0.61149216, test precision: 0.62528047868362,test recall: 0.5532759761747187,test f1: 0.5870786516853932\n",
      "train accuracy: 0.6820447203571429, test accuracy:0.6710526315789473 train loss:0.59809076, test loss:0.61091065, test precision: 0.6230366492146597,test recall: 0.5538563829787234,test f1: 0.5864132347764871\n",
      "train accuracy: 0.6840603839285714, test accuracy:0.6710526315789473 train loss:0.60036755, test loss:0.61113465, test precision: 0.6230366492146597,test recall: 0.5538563829787234,test f1: 0.5864132347764871\n",
      "train accuracy: 0.6893304542857143, test accuracy:0.671612541993281 train loss:0.59784123, test loss:0.6108095, test precision: 0.6222887060583395,test recall: 0.5546666666666666,test f1: 0.5865350722594289\n",
      "train accuracy: 0.6875745657142858, test accuracy:0.671612541993281 train loss:0.59500269, test loss:0.61073941, test precision: 0.6222887060583395,test recall: 0.5546666666666666,test f1: 0.5865350722594289\n",
      "train accuracy: 0.6878632046428572, test accuracy:0.671612541993281 train loss:0.5956557, test loss:0.61081451, test precision: 0.6222887060583395,test recall: 0.5546666666666666,test f1: 0.5865350722594289\n",
      "train accuracy: 0.6797404171428572, test accuracy:0.671612541993281 train loss:0.59974396, test loss:0.61069238, test precision: 0.6215407629020194,test recall: 0.554739652870494,test f1: 0.5862433862433861\n",
      "train accuracy: 0.6831150903571429, test accuracy:0.671612541993281 train loss:0.59648479, test loss:0.6108095, test precision: 0.6215407629020194,test recall: 0.554739652870494,test f1: 0.5862433862433861\n",
      "train accuracy: 0.6879473917857143, test accuracy:0.6732922732362822 train loss:0.59693167, test loss:0.61032915, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6831078732142858, test accuracy:0.6724524076147816 train loss:0.59913659, test loss:0.60934502, test precision: 0.6178010471204188,test recall: 0.5562289562289562,test f1: 0.585400425230333\n",
      "train accuracy: 0.6809286482142857, test accuracy:0.6732922732362822 train loss:0.59820598, test loss:0.60941046, test precision: 0.6207928197456993,test recall: 0.5570469798657718,test f1: 0.5871949062610541\n",
      "train accuracy: 0.6788384196428572, test accuracy:0.6724524076147816 train loss:0.60218364, test loss:0.60916632, test precision: 0.6178010471204188,test recall: 0.5562289562289562,test f1: 0.585400425230333\n",
      "train accuracy: 0.6819292635714286, test accuracy:0.6732922732362822 train loss:0.59983535, test loss:0.60951287, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6801998339285715, test accuracy:0.6732922732362822 train loss:0.60037697, test loss:0.60979491, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6772148242857143, test accuracy:0.6732922732362822 train loss:0.60243951, test loss:0.6099295, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6934026703571429, test accuracy:0.6732922732362822 train loss:0.59096228, test loss:0.60945064, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6880532253571429, test accuracy:0.6732922732362822 train loss:0.59530258, test loss:0.60969925, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6813688235714286, test accuracy:0.6732922732362822 train loss:0.59997618, test loss:0.60994059, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6831992757142856, test accuracy:0.6732922732362822 train loss:0.5990377, test loss:0.60955453, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6923371103571428, test accuracy:0.6732922732362822 train loss:0.58761934, test loss:0.60931528, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6789634957142857, test accuracy:0.6732922732362822 train loss:0.59985233, test loss:0.60891563, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6900664828571428, test accuracy:0.6732922732362822 train loss:0.59556886, test loss:0.60865241, test precision: 0.6207928197456993,test recall: 0.5570469798657718,test f1: 0.5871949062610541\n",
      "train accuracy: 0.6808901624999999, test accuracy:0.6732922732362822 train loss:0.59829748, test loss:0.60909933, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6780735260714286, test accuracy:0.6732922732362822 train loss:0.59800111, test loss:0.60928178, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6790284403571428, test accuracy:0.6732922732362822 train loss:0.60236482, test loss:0.60917515, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6794205082142858, test accuracy:0.6732922732362822 train loss:0.59882804, test loss:0.60946554, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6782322782142858, test accuracy:0.6730123180291153 train loss:0.59782121, test loss:0.60974532, test precision: 0.6237845923709798,test recall: 0.5563709139426284,test f1: 0.5881523272214386\n",
      "train accuracy: 0.6894074246428571, test accuracy:0.6732922732362822 train loss:0.59480825, test loss:0.60931432, test precision: 0.6215407629020194,test recall: 0.556970509383378,test f1: 0.5874867444326617\n",
      "train accuracy: 0.6832570042857142, test accuracy:0.6730123180291153 train loss:0.59822589, test loss:0.60978246, test precision: 0.6237845923709798,test recall: 0.5563709139426284,test f1: 0.5881523272214386\n",
      "train accuracy: 0.6805894960714286, test accuracy:0.6730123180291153 train loss:0.59903006, test loss:0.60984647, test precision: 0.6237845923709798,test recall: 0.5563709139426284,test f1: 0.5881523272214386\n",
      "train accuracy: 0.6886521517857143, test accuracy:0.6730123180291153 train loss:0.59149766, test loss:0.60940075, test precision: 0.6237845923709798,test recall: 0.5563709139426284,test f1: 0.5881523272214386\n",
      "train accuracy: 0.6816694885714286, test accuracy:0.6758118701007839 train loss:0.59990388, test loss:0.60860568, test precision: 0.6185489902767389,test recall: 0.560677966101695,test f1: 0.5881934566145093\n",
      "train accuracy: 0.6871945235714286, test accuracy:0.6760918253079508 train loss:0.59614165, test loss:0.60843241, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6793363221428571, test accuracy:0.6760918253079508 train loss:0.60101163, test loss:0.60828573, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6838920121428572, test accuracy:0.6760918253079508 train loss:0.59761578, test loss:0.60818619, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6860784517857145, test accuracy:0.6760918253079508 train loss:0.59484742, test loss:0.60821605, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6859678089285716, test accuracy:0.6760918253079508 train loss:0.59591118, test loss:0.60803157, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6918464257142857, test accuracy:0.6760918253079508 train loss:0.58923947, test loss:0.60804337, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6847507128571427, test accuracy:0.6760918253079508 train loss:0.59348457, test loss:0.60777384, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6869130996428571, test accuracy:0.6758118701007839 train loss:0.59530823, test loss:0.60801673, test precision: 0.6192969334330591,test recall: 0.5605958023019635,test f1: 0.5884861407249468\n",
      "train accuracy: 0.6827494792857143, test accuracy:0.6758118701007839 train loss:0.5993673, test loss:0.60914671, test precision: 0.6192969334330591,test recall: 0.5605958023019635,test f1: 0.5884861407249468\n",
      "train accuracy: 0.6890273814285715, test accuracy:0.6730123180291153 train loss:0.59239038, test loss:0.60929132, test precision: 0.6215407629020194,test recall: 0.5565974547890155,test f1: 0.5872791519434629\n",
      "train accuracy: 0.6861265578571428, test accuracy:0.6730123180291153 train loss:0.59383434, test loss:0.6087454, test precision: 0.6215407629020194,test recall: 0.5565974547890155,test f1: 0.5872791519434629\n",
      "train accuracy: 0.6787999357142857, test accuracy:0.6758118701007839 train loss:0.60223751, test loss:0.60823041, test precision: 0.6192969334330591,test recall: 0.5605958023019635,test f1: 0.5884861407249468\n",
      "train accuracy: 0.6861770685714286, test accuracy:0.6760918253079508 train loss:0.59317185, test loss:0.60811514, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.688368322142857, test accuracy:0.6760918253079508 train loss:0.59282184, test loss:0.60759056, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6811379110714286, test accuracy:0.6752519596864501 train loss:0.60054593, test loss:0.60712737, test precision: 0.6163051608077786,test recall: 0.5601631543167913,test f1: 0.586894586894587\n",
      "train accuracy: 0.6871873075, test accuracy:0.6752519596864501 train loss:0.59594146, test loss:0.60684037, test precision: 0.6163051608077786,test recall: 0.5601631543167913,test f1: 0.586894586894587\n",
      "train accuracy: 0.6855613085714285, test accuracy:0.6758118701007839 train loss:0.59509629, test loss:0.60715526, test precision: 0.6185489902767389,test recall: 0.560677966101695,test f1: 0.5881934566145093\n",
      "train accuracy: 0.6787181539285714, test accuracy:0.6758118701007839 train loss:0.59851163, test loss:0.60752428, test precision: 0.6185489902767389,test recall: 0.560677966101695,test f1: 0.5881934566145093\n",
      "train accuracy: 0.6784054607142858, test accuracy:0.6760918253079508 train loss:0.59963691, test loss:0.6078524, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6891332171428572, test accuracy:0.6760918253079508 train loss:0.59425196, test loss:0.60779446, test precision: 0.6192969334330591,test recall: 0.5609756097560976,test f1: 0.5886953430501244\n",
      "train accuracy: 0.6812341257142857, test accuracy:0.6752519596864501 train loss:0.59856074, test loss:0.60800225, test precision: 0.6185489902767389,test recall: 0.5599187542315505,test f1: 0.587775408670931\n",
      "train accuracy: 0.6896070660714286, test accuracy:0.6763717805151176 train loss:0.59122481, test loss:0.60802788, test precision: 0.6222887060583395,test recall: 0.5610249494268374,test f1: 0.5900709219858156\n",
      "train accuracy: 0.6890682721428573, test accuracy:0.6758118701007839 train loss:0.59041811, test loss:0.60753548, test precision: 0.6185489902767389,test recall: 0.560677966101695,test f1: 0.5881934566145093\n",
      "train accuracy: 0.6965175682142857, test accuracy:0.6758118701007839 train loss:0.58897026, test loss:0.6074152, test precision: 0.6185489902767389,test recall: 0.560677966101695,test f1: 0.5881934566145093\n",
      "train accuracy: 0.6854674982142857, test accuracy:0.6772116461366181 train loss:0.59452874, test loss:0.60727906, test precision: 0.6222887060583395,test recall: 0.5621621621621622,test f1: 0.5906993255236067\n",
      "train accuracy: 0.6878583935714285, test accuracy:0.6772116461366181 train loss:0.59271229, test loss:0.60706675, test precision: 0.6222887060583395,test recall: 0.5621621621621622,test f1: 0.5906993255236067\n",
      "train accuracy: 0.6793363217857141, test accuracy:0.6772116461366181 train loss:0.5974302, test loss:0.60723239, test precision: 0.6222887060583395,test recall: 0.5621621621621622,test f1: 0.5906993255236067\n",
      "train accuracy: 0.6841036792857143, test accuracy:0.6772116461366181 train loss:0.59496856, test loss:0.60709506, test precision: 0.6222887060583395,test recall: 0.5621621621621622,test f1: 0.5906993255236067\n",
      "train accuracy: 0.6809166228571428, test accuracy:0.6763717805151176 train loss:0.59810367, test loss:0.60808903, test precision: 0.6222887060583395,test recall: 0.5610249494268374,test f1: 0.5900709219858156\n",
      "train accuracy: 0.6857176532142857, test accuracy:0.6763717805151176 train loss:0.59455656, test loss:0.60759938, test precision: 0.6222887060583395,test recall: 0.5610249494268374,test f1: 0.5900709219858156\n",
      "train accuracy: 0.6876611567857143, test accuracy:0.6772116461366181 train loss:0.5931168, test loss:0.60715514, test precision: 0.6163051608077786,test recall: 0.5628415300546448,test f1: 0.5883612995358799\n",
      "train accuracy: 0.6865980028571429, test accuracy:0.6777715565509519 train loss:0.59600309, test loss:0.60670984, test precision: 0.6163051608077786,test recall: 0.5636114911080712,test f1: 0.588781707752769\n",
      "train accuracy: 0.6838799842857143, test accuracy:0.6772116461366181 train loss:0.59539638, test loss:0.60703093, test precision: 0.6163051608077786,test recall: 0.5628415300546448,test f1: 0.5883612995358799\n",
      "train accuracy: 0.6846112028571428, test accuracy:0.6777715565509519 train loss:0.59130189, test loss:0.60616869, test precision: 0.6163051608077786,test recall: 0.5636114911080712,test f1: 0.588781707752769\n",
      "train accuracy: 0.6871151475, test accuracy:0.6772116461366181 train loss:0.59361403, test loss:0.60652447, test precision: 0.6163051608077786,test recall: 0.5628415300546448,test f1: 0.5883612995358799\n",
      "train accuracy: 0.688753174642857, test accuracy:0.6777715565509519 train loss:0.59215749, test loss:0.60627943, test precision: 0.6163051608077786,test recall: 0.5636114911080712,test f1: 0.588781707752769\n",
      "train accuracy: 0.6836105874999999, test accuracy:0.6772116461366181 train loss:0.5977882, test loss:0.60634542, test precision: 0.6163051608077786,test recall: 0.5628415300546448,test f1: 0.5883612995358799\n",
      "train accuracy: 0.6844476421428572, test accuracy:0.6780515117581187 train loss:0.5945908, test loss:0.60640967, test precision: 0.6155572176514585,test recall: 0.5640849897189856,test f1: 0.5886981402002861\n",
      "train accuracy: 0.688274515, test accuracy:0.6786114221724524 train loss:0.59537933, test loss:0.60612631, test precision: 0.6155572176514585,test recall: 0.5648592999313659,test f1: 0.5891195418754475\n",
      "train accuracy: 0.6850946746428571, test accuracy:0.6794512877939529 train loss:0.59646675, test loss:0.60587448, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6747205014285714, test accuracy:0.6794512877939529 train loss:0.60423628, test loss:0.60534108, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6828889896428573, test accuracy:0.6794512877939529 train loss:0.59509017, test loss:0.60571599, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6864777364285715, test accuracy:0.6794512877939529 train loss:0.59454027, test loss:0.60586971, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6887507700000001, test accuracy:0.6794512877939529 train loss:0.59223931, test loss:0.6057201, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6801589446428571, test accuracy:0.6780515117581187 train loss:0.5963767, test loss:0.60598862, test precision: 0.6148092744951383,test recall: 0.5641729581331503,test f1: 0.5884037222619899\n",
      "train accuracy: 0.6772677421428571, test accuracy:0.6788913773796192 train loss:0.59891841, test loss:0.60621488, test precision: 0.6155572176514585,test recall: 0.5652472527472527,test f1: 0.5893304690297172\n",
      "train accuracy: 0.6840122771428572, test accuracy:0.6788913773796192 train loss:0.59517168, test loss:0.60571235, test precision: 0.6140613313388182,test recall: 0.5654269972451791,test f1: 0.5887414844030118\n",
      "train accuracy: 0.6854217971428571, test accuracy:0.6794512877939529 train loss:0.59432464, test loss:0.60543424, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6892510785714288, test accuracy:0.6802911534154535 train loss:0.59421749, test loss:0.60492331, test precision: 0.6133133881824981,test recall: 0.5674740484429066,test f1: 0.5895039539899353\n",
      "train accuracy: 0.6895733917857143, test accuracy:0.6802911534154535 train loss:0.59047826, test loss:0.60540533, test precision: 0.6133133881824981,test recall: 0.5674740484429066,test f1: 0.5895039539899353\n",
      "train accuracy: 0.6897008739285715, test accuracy:0.6794512877939529 train loss:0.59277824, test loss:0.60528803, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6894627457142858, test accuracy:0.6766517357222844 train loss:0.5913644, test loss:0.6055944, test precision: 0.6148092744951383,test recall: 0.5622435020519836,test f1: 0.5873526259378349\n",
      "train accuracy: 0.6878607985714285, test accuracy:0.6786114221724524 train loss:0.59471639, test loss:0.6051358, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6906509774999999, test accuracy:0.6772116461366181 train loss:0.59034287, test loss:0.60548961, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6881422221428571, test accuracy:0.6769316909294513 train loss:0.59345412, test loss:0.60547829, test precision: 0.6148092744951383,test recall: 0.5626283367556468,test f1: 0.5875625446747677\n",
      "train accuracy: 0.6920989839285713, test accuracy:0.6769316909294513 train loss:0.58750423, test loss:0.60544872, test precision: 0.6148092744951383,test recall: 0.5626283367556468,test f1: 0.5875625446747677\n",
      "train accuracy: 0.6842840782142857, test accuracy:0.6780515117581187 train loss:0.59020317, test loss:0.60473311, test precision: 0.6140613313388182,test recall: 0.5642611683848797,test f1: 0.58810888252149\n",
      "train accuracy: 0.6866340832142858, test accuracy:0.6780515117581187 train loss:0.59199948, test loss:0.60474688, test precision: 0.6140613313388182,test recall: 0.5642611683848797,test f1: 0.58810888252149\n",
      "train accuracy: 0.6866052167857142, test accuracy:0.6788913773796192 train loss:0.5909657, test loss:0.60431248, test precision: 0.6133133881824981,test recall: 0.5655172413793104,test f1: 0.5884463580911374\n",
      "train accuracy: 0.6834374039285714, test accuracy:0.6786114221724524 train loss:0.5949443, test loss:0.60378283, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6832449775, test accuracy:0.6786114221724524 train loss:0.59505949, test loss:0.60393989, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6940545139285713, test accuracy:0.6786114221724524 train loss:0.58392318, test loss:0.60399455, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6870838771428572, test accuracy:0.6786114221724524 train loss:0.59402091, test loss:0.6035226, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6810392946428572, test accuracy:0.6783314669652856 train loss:0.59387817, test loss:0.6040135, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6893737478571429, test accuracy:0.6788913773796192 train loss:0.59396448, test loss:0.60385358, test precision: 0.6133133881824981,test recall: 0.5655172413793104,test f1: 0.5884463580911374\n",
      "train accuracy: 0.688950412857143, test accuracy:0.6794512877939529 train loss:0.59290504, test loss:0.60334277, test precision: 0.6103216155572176,test recall: 0.5666666666666667,test f1: 0.5876845516744688\n",
      "train accuracy: 0.6872907364285714, test accuracy:0.6780515117581187 train loss:0.59219549, test loss:0.60338211, test precision: 0.6103216155572176,test recall: 0.5647058823529412,test f1: 0.5866283249460819\n",
      "train accuracy: 0.6913316842857142, test accuracy:0.6783314669652856 train loss:0.59041505, test loss:0.60336459, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6894819889285715, test accuracy:0.6786114221724524 train loss:0.58977555, test loss:0.60332114, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6887146900000001, test accuracy:0.6786114221724524 train loss:0.59154806, test loss:0.60323006, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6836274242857144, test accuracy:0.6800111982082867 train loss:0.5918107, test loss:0.60284299, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.6869371535714286, test accuracy:0.6786114221724524 train loss:0.59309049, test loss:0.60355061, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6860856685714285, test accuracy:0.6786114221724524 train loss:0.59209338, test loss:0.60325044, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6866773792857144, test accuracy:0.6783314669652856 train loss:0.59148859, test loss:0.60416806, test precision: 0.6163051608077786,test recall: 0.5643835616438356,test f1: 0.5892027171969968\n",
      "train accuracy: 0.6813399592857143, test accuracy:0.6788913773796192 train loss:0.59390464, test loss:0.60400569, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6865763539285714, test accuracy:0.6788913773796192 train loss:0.58992085, test loss:0.60370857, test precision: 0.6163051608077786,test recall: 0.5651577503429356,test f1: 0.5896243291592129\n",
      "train accuracy: 0.6909781017857143, test accuracy:0.6786114221724524 train loss:0.58685253, test loss:0.60366982, test precision: 0.6170531039640987,test recall: 0.5646817248459959,test f1: 0.5897069335239457\n",
      "train accuracy: 0.6895926339285714, test accuracy:0.6783314669652856 train loss:0.59108937, test loss:0.60323626, test precision: 0.6155572176514585,test recall: 0.5644718792866941,test f1: 0.5889087656529517\n",
      "train accuracy: 0.6858619724999999, test accuracy:0.6780515117581187 train loss:0.59369961, test loss:0.60430902, test precision: 0.6170531039640987,test recall: 0.5639097744360902,test f1: 0.5892857142857143\n",
      "train accuracy: 0.6856070078571428, test accuracy:0.6786114221724524 train loss:0.5916775, test loss:0.60357618, test precision: 0.6170531039640987,test recall: 0.5646817248459959,test f1: 0.5897069335239457\n",
      "train accuracy: 0.6890081403571429, test accuracy:0.6794512877939529 train loss:0.58879607, test loss:0.60334307, test precision: 0.6163051608077786,test recall: 0.5659340659340659,test f1: 0.5900465449337631\n",
      "train accuracy: 0.6859052689285715, test accuracy:0.6780515117581187 train loss:0.5925295, test loss:0.60374999, test precision: 0.6170531039640987,test recall: 0.5639097744360902,test f1: 0.5892857142857143\n",
      "train accuracy: 0.689342480357143, test accuracy:0.6786114221724524 train loss:0.59052318, test loss:0.60340291, test precision: 0.6170531039640987,test recall: 0.5646817248459959,test f1: 0.5897069335239457\n",
      "train accuracy: 0.6870117196428571, test accuracy:0.6777715565509519 train loss:0.59064505, test loss:0.60425723, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6872883314285714, test accuracy:0.6777715565509519 train loss:0.59140198, test loss:0.60455942, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6868072671428571, test accuracy:0.6777715565509519 train loss:0.59287597, test loss:0.60451317, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6804331517857144, test accuracy:0.6777715565509519 train loss:0.59569609, test loss:0.60502207, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6890297875, test accuracy:0.6794512877939529 train loss:0.58850379, test loss:0.60454303, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.688493399642857, test accuracy:0.6794512877939529 train loss:0.5859825, test loss:0.60451227, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6824872996428571, test accuracy:0.6791713325867861 train loss:0.59357102, test loss:0.60429561, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6872498467857143, test accuracy:0.6791713325867861 train loss:0.58906868, test loss:0.6037358, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6856984107142857, test accuracy:0.6791713325867861 train loss:0.59077674, test loss:0.60368228, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6845967710714286, test accuracy:0.6791713325867861 train loss:0.59276234, test loss:0.60370886, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6873075735714285, test accuracy:0.6791713325867861 train loss:0.58793682, test loss:0.60402578, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6799087896428571, test accuracy:0.6791713325867861 train loss:0.59295066, test loss:0.60411483, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6865955982142858, test accuracy:0.6791713325867861 train loss:0.58776899, test loss:0.6038596, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6825209739285715, test accuracy:0.6791713325867861 train loss:0.59244467, test loss:0.60320163, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6840146825000001, test accuracy:0.6791713325867861 train loss:0.59390211, test loss:0.60342103, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6857753796428572, test accuracy:0.6791713325867861 train loss:0.59658403, test loss:0.60337609, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6855589017857141, test accuracy:0.6791713325867861 train loss:0.58905392, test loss:0.60369253, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6888157135714286, test accuracy:0.6791713325867861 train loss:0.58784015, test loss:0.60378718, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6862444185714285, test accuracy:0.6791713325867861 train loss:0.58838365, test loss:0.60371703, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6877621817857144, test accuracy:0.6791713325867861 train loss:0.58640392, test loss:0.60349512, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6849744078571429, test accuracy:0.6791713325867861 train loss:0.58920751, test loss:0.60299242, test precision: 0.6140613313388182,test recall: 0.565816678152998,test f1: 0.5889526542324247\n",
      "train accuracy: 0.6933978589285715, test accuracy:0.6800111982082867 train loss:0.58653474, test loss:0.6026541, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6878463671428571, test accuracy:0.6800111982082867 train loss:0.58940771, test loss:0.60291904, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6860928842857144, test accuracy:0.6800111982082867 train loss:0.59115682, test loss:0.60283017, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6834374042857144, test accuracy:0.6800111982082867 train loss:0.59111247, test loss:0.60322225, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6904465242857142, test accuracy:0.6800111982082867 train loss:0.58848431, test loss:0.60269654, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6871367971428571, test accuracy:0.6800111982082867 train loss:0.5892597, test loss:0.60254747, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6896960625, test accuracy:0.6800111982082867 train loss:0.58746039, test loss:0.60231656, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6847867917857143, test accuracy:0.6800111982082867 train loss:0.59177944, test loss:0.60217452, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6879738492857143, test accuracy:0.6800111982082867 train loss:0.5888851, test loss:0.60199064, test precision: 0.6133133881824981,test recall: 0.5670816044260027,test f1: 0.589292130794107\n",
      "train accuracy: 0.6804211264285713, test accuracy:0.6805711086226204 train loss:0.58986141, test loss:0.60161173, test precision: 0.6133133881824981,test recall: 0.5678670360110804,test f1: 0.5897159295217548\n",
      "train accuracy: 0.6799929767857142, test accuracy:0.6797312430011199 train loss:0.5929938, test loss:0.60219693, test precision: 0.6133133881824981,test recall: 0.5666897028334485,test f1: 0.589080459770115\n",
      "train accuracy: 0.6895349064285714, test accuracy:0.6797312430011199 train loss:0.59280632, test loss:0.602121, test precision: 0.6133133881824981,test recall: 0.5666897028334485,test f1: 0.589080459770115\n",
      "train accuracy: 0.6912523096428572, test accuracy:0.6797312430011199 train loss:0.58716305, test loss:0.60179687, test precision: 0.6133133881824981,test recall: 0.5666897028334485,test f1: 0.589080459770115\n",
      "train accuracy: 0.6827374535714286, test accuracy:0.6797312430011199 train loss:0.58931171, test loss:0.60185432, test precision: 0.6133133881824981,test recall: 0.5666897028334485,test f1: 0.589080459770115\n",
      "train accuracy: 0.6884645367857143, test accuracy:0.6794512877939529 train loss:0.58857148, test loss:0.60180175, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6885463160714285, test accuracy:0.6788913773796192 train loss:0.58346861, test loss:0.60227752, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6969673657142856, test accuracy:0.6794512877939529 train loss:0.58168228, test loss:0.60146737, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6862660682142857, test accuracy:0.6794512877939529 train loss:0.59010254, test loss:0.60128915, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6896599835714285, test accuracy:0.6794512877939529 train loss:0.58908098, test loss:0.6016314, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6791968132142856, test accuracy:0.6788913773796192 train loss:0.59177367, test loss:0.60197979, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6839136578571428, test accuracy:0.6788913773796192 train loss:0.59255419, test loss:0.6018582, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6913076321428572, test accuracy:0.6805711086226204 train loss:0.58660817, test loss:0.60120207, test precision: 0.6140613313388182,test recall: 0.5677731673582296,test f1: 0.5900107797340999\n",
      "train accuracy: 0.6879642278571428, test accuracy:0.6805711086226204 train loss:0.587794, test loss:0.60077667, test precision: 0.6140613313388182,test recall: 0.5677731673582296,test f1: 0.5900107797340999\n",
      "train accuracy: 0.683346002142857, test accuracy:0.6788913773796192 train loss:0.59100044, test loss:0.60145193, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6844187760714285, test accuracy:0.6788913773796192 train loss:0.59071514, test loss:0.60212624, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6862901207142856, test accuracy:0.6788913773796192 train loss:0.58855187, test loss:0.60265118, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6846905782142857, test accuracy:0.6788913773796192 train loss:0.58861727, test loss:0.60327631, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6870742578571429, test accuracy:0.6788913773796192 train loss:0.59099256, test loss:0.60217208, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6934916678571429, test accuracy:0.6788913773796192 train loss:0.58615927, test loss:0.60124099, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6885391003571427, test accuracy:0.6794512877939529 train loss:0.58758519, test loss:0.60097581, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6861121275000001, test accuracy:0.6788913773796192 train loss:0.59184989, test loss:0.60135913, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6887627960714285, test accuracy:0.6788913773796192 train loss:0.58693086, test loss:0.60143417, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6893857767857144, test accuracy:0.6788913773796192 train loss:0.58976534, test loss:0.601879, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6825546482142857, test accuracy:0.6788913773796192 train loss:0.5938311, test loss:0.60208076, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6845991767857144, test accuracy:0.6788913773796192 train loss:0.58812848, test loss:0.60158712, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6888373607142857, test accuracy:0.6788913773796192 train loss:0.58552871, test loss:0.60166842, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6864969789285714, test accuracy:0.6788913773796192 train loss:0.58845567, test loss:0.60255706, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6888517939285714, test accuracy:0.6788913773796192 train loss:0.58459261, test loss:0.60254139, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6849479485714286, test accuracy:0.6788913773796192 train loss:0.58875987, test loss:0.60211289, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6873316275, test accuracy:0.6788913773796192 train loss:0.5893953, test loss:0.60247004, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6904441192857143, test accuracy:0.6788913773796192 train loss:0.58691399, test loss:0.60224724, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6841445700000001, test accuracy:0.6788913773796192 train loss:0.58912322, test loss:0.602153, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6921398735714285, test accuracy:0.6788913773796192 train loss:0.58459141, test loss:0.60196298, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6824969217857142, test accuracy:0.6788913773796192 train loss:0.58955215, test loss:0.60128623, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6902228296428571, test accuracy:0.6788913773796192 train loss:0.58596091, test loss:0.60138851, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6874446789285714, test accuracy:0.6788913773796192 train loss:0.58915179, test loss:0.60151815, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6905836264285715, test accuracy:0.6788913773796192 train loss:0.58364367, test loss:0.60090816, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6897610082142858, test accuracy:0.6788913773796192 train loss:0.58513679, test loss:0.60105777, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6811860189285716, test accuracy:0.6788913773796192 train loss:0.58904223, test loss:0.60143346, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6845077732142857, test accuracy:0.6788913773796192 train loss:0.58917593, test loss:0.60157621, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6831752239285714, test accuracy:0.6788913773796192 train loss:0.59147531, test loss:0.6015687, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6894699632142858, test accuracy:0.6788913773796192 train loss:0.58597753, test loss:0.60173792, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6865523014285715, test accuracy:0.6788913773796192 train loss:0.5886274, test loss:0.60177916, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6897682214285714, test accuracy:0.6788913773796192 train loss:0.58557674, test loss:0.60125005, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6856021978571428, test accuracy:0.6788913773796192 train loss:0.58741225, test loss:0.60134953, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6901795332142857, test accuracy:0.6788913773796192 train loss:0.58558277, test loss:0.60090762, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6884044032142856, test accuracy:0.6788913773796192 train loss:0.58542087, test loss:0.60017955, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6901097792857144, test accuracy:0.6788913773796192 train loss:0.58520346, test loss:0.60032296, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6903551214285714, test accuracy:0.6788913773796192 train loss:0.58495437, test loss:0.60020566, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6876395089285714, test accuracy:0.6788913773796192 train loss:0.58651413, test loss:0.60027874, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6901699121428573, test accuracy:0.6788913773796192 train loss:0.58390659, test loss:0.60039788, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6798294135714286, test accuracy:0.6788913773796192 train loss:0.59537915, test loss:0.60014427, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6913677653571428, test accuracy:0.6788913773796192 train loss:0.58341965, test loss:0.59994465, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6859365367857142, test accuracy:0.6788913773796192 train loss:0.58544869, test loss:0.60010999, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6843851021428572, test accuracy:0.6788913773796192 train loss:0.58992988, test loss:0.59950876, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6817055692857144, test accuracy:0.6788913773796192 train loss:0.58843233, test loss:0.60001683, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6892510782142859, test accuracy:0.6788913773796192 train loss:0.58712741, test loss:0.60006493, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6938741146428571, test accuracy:0.6788913773796192 train loss:0.5826275, test loss:0.59999365, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6865330585714285, test accuracy:0.6788913773796192 train loss:0.58746698, test loss:0.59989744, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6832064928571429, test accuracy:0.6788913773796192 train loss:0.58808948, test loss:0.59999162, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6822395514285714, test accuracy:0.6780515117581187 train loss:0.590404, test loss:0.59928489, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.683384487142857, test accuracy:0.6788913773796192 train loss:0.58758005, test loss:0.59951836, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.6860880728571429, test accuracy:0.6788913773796192 train loss:0.58527645, test loss:0.5992552, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6793074582142857, test accuracy:0.6788913773796192 train loss:0.59227794, test loss:0.59920675, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6875865925, test accuracy:0.6788913773796192 train loss:0.586023, test loss:0.59967011, test precision: 0.6148092744951383,test recall: 0.5653370013755158,test f1: 0.5890361877463275\n",
      "train accuracy: 0.681125885, test accuracy:0.6777715565509519 train loss:0.59070804, test loss:0.59991819, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6877092625, test accuracy:0.6797312430011199 train loss:0.58344387, test loss:0.59952331, test precision: 0.6148092744951383,test recall: 0.5665058580289456,test f1: 0.5896700143472023\n",
      "train accuracy: 0.6883322425000001, test accuracy:0.6797312430011199 train loss:0.58472056, test loss:0.59941888, test precision: 0.6148092744951383,test recall: 0.5665058580289456,test f1: 0.5896700143472023\n",
      "train accuracy: 0.6809382703571428, test accuracy:0.6777715565509519 train loss:0.59440074, test loss:0.5997262, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6917357803571428, test accuracy:0.6777715565509519 train loss:0.58561599, test loss:0.59968758, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6913605489285715, test accuracy:0.6777715565509519 train loss:0.58405164, test loss:0.59975541, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6877044528571429, test accuracy:0.6774916013437849 train loss:0.58504086, test loss:0.60022193, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6906678150000001, test accuracy:0.6774916013437849 train loss:0.58421532, test loss:0.60030299, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6807867332142857, test accuracy:0.6783314669652856 train loss:0.591787, test loss:0.59985536, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6784896467857144, test accuracy:0.6783314669652856 train loss:0.5914041, test loss:0.59985143, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6853303953571428, test accuracy:0.6786114221724524 train loss:0.5864099, test loss:0.59931332, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6778690728571428, test accuracy:0.6786114221724524 train loss:0.59132175, test loss:0.59910798, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.685068215, test accuracy:0.6797312430011199 train loss:0.58877091, test loss:0.59848738, test precision: 0.6140613313388182,test recall: 0.5665976535541752,test f1: 0.589375448671931\n",
      "train accuracy: 0.6883587017857142, test accuracy:0.6783314669652856 train loss:0.58515392, test loss:0.59939259, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6920244189285715, test accuracy:0.6783314669652856 train loss:0.58144447, test loss:0.59937489, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6901506692857142, test accuracy:0.6783314669652856 train loss:0.58508961, test loss:0.59920567, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6914134649999999, test accuracy:0.6783314669652856 train loss:0.58193105, test loss:0.59973776, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6909540499999999, test accuracy:0.6783314669652856 train loss:0.58379053, test loss:0.59960079, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6909516442857143, test accuracy:0.6783314669652856 train loss:0.58468248, test loss:0.5990712, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6891356221428572, test accuracy:0.6786114221724524 train loss:0.58451524, test loss:0.59878421, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6901723175, test accuracy:0.6786114221724524 train loss:0.58309079, test loss:0.59861684, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6837885814285715, test accuracy:0.6783314669652856 train loss:0.58443161, test loss:0.598818, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6887146900000001, test accuracy:0.6783314669652856 train loss:0.58651831, test loss:0.59888464, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6885391014285714, test accuracy:0.6786114221724524 train loss:0.58437362, test loss:0.59869802, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6866196510714285, test accuracy:0.6777715565509519 train loss:0.58747809, test loss:0.59848976, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6866316775000001, test accuracy:0.6786114221724524 train loss:0.58753839, test loss:0.59830296, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6842167285714285, test accuracy:0.6783314669652856 train loss:0.58890447, test loss:0.59914666, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6854915525, test accuracy:0.6783314669652856 train loss:0.58727037, test loss:0.59890997, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6872209825000001, test accuracy:0.6783314669652856 train loss:0.58866613, test loss:0.59953284, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6908963207142857, test accuracy:0.6783314669652856 train loss:0.58460347, test loss:0.59887546, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6866292710714286, test accuracy:0.6783314669652856 train loss:0.58438393, test loss:0.59907931, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6887988757142857, test accuracy:0.6777715565509519 train loss:0.58419944, test loss:0.59851992, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6835504539285714, test accuracy:0.6783314669652856 train loss:0.58701731, test loss:0.59875143, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6875817810714285, test accuracy:0.6783314669652856 train loss:0.58512173, test loss:0.59897059, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6891163792857142, test accuracy:0.6783314669652856 train loss:0.58482021, test loss:0.59881717, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6844981532142856, test accuracy:0.6783314669652856 train loss:0.5885109, test loss:0.59848452, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6909684810714285, test accuracy:0.6780515117581187 train loss:0.5814915, test loss:0.59802157, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6871560367857142, test accuracy:0.6780515117581187 train loss:0.58560461, test loss:0.59775496, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6868794253571429, test accuracy:0.6788913773796192 train loss:0.58725353, test loss:0.59763807, test precision: 0.6110695587135377,test recall: 0.5657894736842105,test f1: 0.5875584322186264\n",
      "train accuracy: 0.6859461585714285, test accuracy:0.6788913773796192 train loss:0.58631627, test loss:0.59731936, test precision: 0.6110695587135377,test recall: 0.5657894736842105,test f1: 0.5875584322186264\n",
      "train accuracy: 0.6807987610714286, test accuracy:0.6777715565509519 train loss:0.59139354, test loss:0.59825355, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6894675567857143, test accuracy:0.6783314669652856 train loss:0.58294477, test loss:0.59889543, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6825907289285714, test accuracy:0.6783314669652856 train loss:0.58609446, test loss:0.59858882, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6863021489285714, test accuracy:0.6783314669652856 train loss:0.58336412, test loss:0.59816206, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6837043953571429, test accuracy:0.6780515117581187 train loss:0.58529791, test loss:0.59761786, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6901434539285715, test accuracy:0.6777715565509519 train loss:0.58175471, test loss:0.59774697, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6917429942857144, test accuracy:0.6777715565509519 train loss:0.58197121, test loss:0.59776813, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6885246675000001, test accuracy:0.6786114221724524 train loss:0.58336435, test loss:0.59806758, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6757932764285713, test accuracy:0.6786114221724524 train loss:0.59220522, test loss:0.59802657, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6901530749999999, test accuracy:0.6786114221724524 train loss:0.58384715, test loss:0.59742695, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6893256428571429, test accuracy:0.6783314669652856 train loss:0.5831457, test loss:0.59715402, test precision: 0.6118175018698578,test recall: 0.5649171270718232,test f1: 0.5874326750448832\n",
      "train accuracy: 0.6874206235714285, test accuracy:0.6780515117581187 train loss:0.58287541, test loss:0.59726769, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6918728817857144, test accuracy:0.6780515117581187 train loss:0.5804619, test loss:0.59722245, test precision: 0.6118175018698578,test recall: 0.5645272601794341,test f1: 0.5872218234027279\n",
      "train accuracy: 0.6910165864285714, test accuracy:0.6777715565509519 train loss:0.58153026, test loss:0.59725577, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6915409475, test accuracy:0.6786114221724524 train loss:0.58383428, test loss:0.59799212, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6918536410714287, test accuracy:0.6786114221724524 train loss:0.58264161, test loss:0.59832525, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6807121689285714, test accuracy:0.6786114221724524 train loss:0.59110394, test loss:0.59811336, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6815420057142856, test accuracy:0.6777715565509519 train loss:0.58605368, test loss:0.5977329, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6851042957142858, test accuracy:0.6777715565509519 train loss:0.5857057, test loss:0.59716469, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6952235035714286, test accuracy:0.6777715565509519 train loss:0.57748621, test loss:0.59758705, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6863959535714285, test accuracy:0.6786114221724524 train loss:0.58448934, test loss:0.59791285, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.68794258, test accuracy:0.6777715565509519 train loss:0.58181108, test loss:0.59724331, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6813423642857143, test accuracy:0.6777715565509519 train loss:0.58725847, test loss:0.59778225, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6941242682142856, test accuracy:0.6786114221724524 train loss:0.57973781, test loss:0.59804589, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6801950232142857, test accuracy:0.6786114221724524 train loss:0.59103878, test loss:0.59824485, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.692534347857143, test accuracy:0.6786114221724524 train loss:0.58120782, test loss:0.59814048, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6847651442857143, test accuracy:0.6786114221724524 train loss:0.58548758, test loss:0.59817338, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6906678139285715, test accuracy:0.6777715565509519 train loss:0.58204834, test loss:0.59743768, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6934868574999999, test accuracy:0.6777715565509519 train loss:0.57889087, test loss:0.59767288, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6835408328571428, test accuracy:0.6777715565509519 train loss:0.58529337, test loss:0.59732544, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6859726185714285, test accuracy:0.6777715565509519 train loss:0.5838794, test loss:0.59741491, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6886762042857143, test accuracy:0.6777715565509519 train loss:0.58491002, test loss:0.59718585, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6877116696428571, test accuracy:0.6777715565509519 train loss:0.58172242, test loss:0.59712678, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6870069075, test accuracy:0.6786114221724524 train loss:0.58636748, test loss:0.59660792, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6861530175, test accuracy:0.6786114221724524 train loss:0.58442587, test loss:0.59676749, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6910238035714286, test accuracy:0.6786114221724524 train loss:0.58077907, test loss:0.59674764, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6915313285714285, test accuracy:0.6786114221724524 train loss:0.58057939, test loss:0.59633529, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6837741496428571, test accuracy:0.6786114221724524 train loss:0.58442559, test loss:0.59634316, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6877766128571429, test accuracy:0.6786114221724524 train loss:0.58257403, test loss:0.59682548, test precision: 0.6110695587135377,test recall: 0.5653979238754325,test f1: 0.5873472322070453\n",
      "train accuracy: 0.6793796196428571, test accuracy:0.6794512877939529 train loss:0.58858894, test loss:0.5970583, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6838944157142857, test accuracy:0.6794512877939529 train loss:0.58402288, test loss:0.59741729, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6861097214285714, test accuracy:0.6794512877939529 train loss:0.58381578, test loss:0.5973559, test precision: 0.6140613313388182,test recall: 0.5662068965517242,test f1: 0.5891639756010048\n",
      "train accuracy: 0.6861482067857143, test accuracy:0.6786114221724524 train loss:0.58348908, test loss:0.59763426, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.690905942857143, test accuracy:0.6777715565509519 train loss:0.58048855, test loss:0.59753555, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6916924828571427, test accuracy:0.6786114221724524 train loss:0.58113237, test loss:0.59849447, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6847771707142857, test accuracy:0.6783314669652856 train loss:0.58165811, test loss:0.59908909, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6832353557142857, test accuracy:0.6783314669652856 train loss:0.58445244, test loss:0.59906024, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6964862982142858, test accuracy:0.6783314669652856 train loss:0.5781137, test loss:0.59858567, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6914567625, test accuracy:0.6786114221724524 train loss:0.57815839, test loss:0.59790558, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6912715517857143, test accuracy:0.6777715565509519 train loss:0.58116498, test loss:0.59727389, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6855468746428571, test accuracy:0.6777715565509519 train loss:0.58394754, test loss:0.59688568, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6905643867857144, test accuracy:0.6777715565509519 train loss:0.58042612, test loss:0.5971663, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6904801989285715, test accuracy:0.6777715565509519 train loss:0.58018932, test loss:0.59710371, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6894795835714286, test accuracy:0.6786114221724524 train loss:0.58071793, test loss:0.5970521, test precision: 0.6148092744951383,test recall: 0.5649484536082474,test f1: 0.5888252148997135\n",
      "train accuracy: 0.6934435610714286, test accuracy:0.6777715565509519 train loss:0.58047323, test loss:0.59659344, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6857008142857142, test accuracy:0.6777715565509519 train loss:0.5860329, test loss:0.59690583, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6851163207142857, test accuracy:0.6783314669652856 train loss:0.58202345, test loss:0.59723288, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6783164635714286, test accuracy:0.6783314669652856 train loss:0.5910084, test loss:0.59712642, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6888397660714285, test accuracy:0.6783314669652856 train loss:0.58504882, test loss:0.59774554, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6882119767857143, test accuracy:0.6783314669652856 train loss:0.58535905, test loss:0.59772491, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6892775364285715, test accuracy:0.6783314669652856 train loss:0.58317129, test loss:0.59734654, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6824488146428571, test accuracy:0.6783314669652856 train loss:0.58294253, test loss:0.59797919, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6927075314285714, test accuracy:0.6783314669652856 train loss:0.57886499, test loss:0.59802455, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6904585517857144, test accuracy:0.6783314669652856 train loss:0.57852398, test loss:0.59752387, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.69167324, test accuracy:0.6777715565509519 train loss:0.582126, test loss:0.59663755, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.6830693885714286, test accuracy:0.6783314669652856 train loss:0.58559386, test loss:0.5967468, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6836707200000001, test accuracy:0.6774916013437849 train loss:0.58494112, test loss:0.59645319, test precision: 0.6118175018698578,test recall: 0.5637491385251551,test f1: 0.5868005738880918\n",
      "train accuracy: 0.691810345, test accuracy:0.6777715565509519 train loss:0.5778351, test loss:0.59588534, test precision: 0.6118175018698578,test recall: 0.5641379310344827,test f1: 0.587011123071403\n",
      "train accuracy: 0.68746392, test accuracy:0.6788913773796192 train loss:0.58182763, test loss:0.59571993, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6916636196428572, test accuracy:0.6786114221724524 train loss:0.58075481, test loss:0.59578788, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6905210903571428, test accuracy:0.681131019036954 train loss:0.58041544, test loss:0.5952388, test precision: 0.600598354525056,test recall: 0.5703125,test f1: 0.5850637522768669\n",
      "train accuracy: 0.6889263596428571, test accuracy:0.6800111982082867 train loss:0.58412604, test loss:0.59515566, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.6902300450000001, test accuracy:0.6800111982082867 train loss:0.57828873, test loss:0.59504497, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.6864320346428572, test accuracy:0.6797312430011199 train loss:0.58162158, test loss:0.59580547, test precision: 0.6148092744951383,test recall: 0.5665058580289456,test f1: 0.5896700143472023\n",
      "train accuracy: 0.6874350560714285, test accuracy:0.6800111982082867 train loss:0.58551029, test loss:0.59493083, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.6849431375000001, test accuracy:0.6800111982082867 train loss:0.58441978, test loss:0.5949173, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.692074930357143, test accuracy:0.6800111982082867 train loss:0.58032207, test loss:0.59467697, test precision: 0.6110695587135377,test recall: 0.5673611111111111,test f1: 0.5884047533309327\n",
      "train accuracy: 0.688693042142857, test accuracy:0.6791713325867861 train loss:0.58182285, test loss:0.5950321, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6925704282142858, test accuracy:0.6791713325867861 train loss:0.57992205, test loss:0.59462953, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6858619721428572, test accuracy:0.6788913773796192 train loss:0.58821451, test loss:0.59558928, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6886617739285715, test accuracy:0.6791713325867861 train loss:0.58235565, test loss:0.5949325, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6899365960714284, test accuracy:0.6791713325867861 train loss:0.58339636, test loss:0.5949477, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6882889471428572, test accuracy:0.6791713325867861 train loss:0.57824093, test loss:0.59482068, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6859245117857143, test accuracy:0.6791713325867861 train loss:0.58149015, test loss:0.59486419, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6884501025, test accuracy:0.6788913773796192 train loss:0.58081992, test loss:0.59495407, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6886088542857143, test accuracy:0.6791713325867861 train loss:0.58160078, test loss:0.59456992, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6852967217857143, test accuracy:0.6791713325867861 train loss:0.58551173, test loss:0.59468412, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6964838957142857, test accuracy:0.6791713325867861 train loss:0.57622515, test loss:0.59464765, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.69244054, test accuracy:0.6791713325867861 train loss:0.57794864, test loss:0.5946312, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6956853246428573, test accuracy:0.6791713325867861 train loss:0.57589415, test loss:0.59484762, test precision: 0.6118175018698578,test recall: 0.5660899653979239,test f1: 0.5880661394680086\n",
      "train accuracy: 0.6887868499999998, test accuracy:0.6786114221724524 train loss:0.5801139, test loss:0.59501219, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6864344403571428, test accuracy:0.6786114221724524 train loss:0.57891817, test loss:0.59546632, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.68945553, test accuracy:0.6794512877939529 train loss:0.58178016, test loss:0.59502882, test precision: 0.6110695587135377,test recall: 0.5665742024965326,test f1: 0.5879812882331774\n",
      "train accuracy: 0.6913196582142858, test accuracy:0.6794512877939529 train loss:0.58040301, test loss:0.59484458, test precision: 0.6110695587135377,test recall: 0.5665742024965326,test f1: 0.5879812882331774\n",
      "train accuracy: 0.6861939082142857, test accuracy:0.6794512877939529 train loss:0.58344792, test loss:0.59463567, test precision: 0.6110695587135377,test recall: 0.5665742024965326,test f1: 0.5879812882331774\n",
      "train accuracy: 0.6917694535714286, test accuracy:0.681131019036954 train loss:0.57945211, test loss:0.59392738, test precision: 0.600598354525056,test recall: 0.5703125,test f1: 0.5850637522768669\n",
      "train accuracy: 0.6927628535714285, test accuracy:0.681131019036954 train loss:0.57730721, test loss:0.59424335, test precision: 0.600598354525056,test recall: 0.5703125,test f1: 0.5850637522768669\n",
      "train accuracy: 0.6877164785714286, test accuracy:0.6786114221724524 train loss:0.58259098, test loss:0.59507978, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6877236960714285, test accuracy:0.6786114221724524 train loss:0.58282721, test loss:0.59527993, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6832521935714284, test accuracy:0.6786114221724524 train loss:0.58364205, test loss:0.59534389, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6877285053571428, test accuracy:0.6786114221724524 train loss:0.582229, test loss:0.59550929, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6916203249999999, test accuracy:0.6786114221724524 train loss:0.57877843, test loss:0.59501147, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6922890039285715, test accuracy:0.6786114221724524 train loss:0.57758896, test loss:0.59494555, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6843826978571429, test accuracy:0.6786114221724524 train loss:0.58378607, test loss:0.59510213, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6780254203571427, test accuracy:0.6794512877939529 train loss:0.58960704, test loss:0.59555918, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6924886474999999, test accuracy:0.6797312430011199 train loss:0.57852415, test loss:0.59458673, test precision: 0.6110695587135377,test recall: 0.5669673837612769,test f1: 0.5881929445644347\n",
      "train accuracy: 0.682896207142857, test accuracy:0.6797312430011199 train loss:0.58326686, test loss:0.59463412, test precision: 0.6110695587135377,test recall: 0.5669673837612769,test f1: 0.5881929445644347\n",
      "train accuracy: 0.6937418210714286, test accuracy:0.6797312430011199 train loss:0.57092053, test loss:0.59449732, test precision: 0.6110695587135377,test recall: 0.5669673837612769,test f1: 0.5881929445644347\n",
      "train accuracy: 0.6876900207142856, test accuracy:0.6786114221724524 train loss:0.5825607, test loss:0.59525275, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6805750646428571, test accuracy:0.6786114221724524 train loss:0.58529207, test loss:0.59518754, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6851644285714286, test accuracy:0.6797312430011199 train loss:0.58570686, test loss:0.59466082, test precision: 0.6110695587135377,test recall: 0.5669673837612769,test f1: 0.5881929445644347\n",
      "train accuracy: 0.6889672485714285, test accuracy:0.6797312430011199 train loss:0.57710429, test loss:0.59446675, test precision: 0.6110695587135377,test recall: 0.5669673837612769,test f1: 0.5881929445644347\n",
      "train accuracy: 0.6875914014285714, test accuracy:0.6788913773796192 train loss:0.58120476, test loss:0.59450525, test precision: 0.6118175018698578,test recall: 0.5656984785615491,test f1: 0.5878548329141216\n",
      "train accuracy: 0.6850874571428572, test accuracy:0.6786114221724524 train loss:0.58137495, test loss:0.59466577, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6840627882142857, test accuracy:0.6788913773796192 train loss:0.58269661, test loss:0.59496403, test precision: 0.612565445026178,test recall: 0.5656077348066298,test f1: 0.5881508078994615\n",
      "train accuracy: 0.6899630542857143, test accuracy:0.6786114221724524 train loss:0.57856624, test loss:0.59453535, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6872041446428572, test accuracy:0.6786114221724524 train loss:0.57993342, test loss:0.59432185, test precision: 0.6118175018698578,test recall: 0.5653075328265377,test f1: 0.5876436781609196\n",
      "train accuracy: 0.6890273825000001, test accuracy:0.6788913773796192 train loss:0.57837145, test loss:0.59453773, test precision: 0.612565445026178,test recall: 0.5656077348066298,test f1: 0.5881508078994615\n",
      "train accuracy: 0.6827975864285714, test accuracy:0.6786114221724524 train loss:0.58323846, test loss:0.59447289, test precision: 0.612565445026178,test recall: 0.5652173913043478,test f1: 0.5879396984924623\n",
      "train accuracy: 0.6918127496428571, test accuracy:0.6786114221724524 train loss:0.57537082, test loss:0.59473109, test precision: 0.612565445026178,test recall: 0.5652173913043478,test f1: 0.5879396984924623\n",
      "train accuracy: 0.6873364375, test accuracy:0.6788913773796192 train loss:0.58027302, test loss:0.59458148, test precision: 0.612565445026178,test recall: 0.5656077348066298,test f1: 0.5881508078994615\n",
      "train accuracy: 0.686617245, test accuracy:0.6786114221724524 train loss:0.58163469, test loss:0.59492481, test precision: 0.612565445026178,test recall: 0.5652173913043478,test f1: 0.5879396984924623\n",
      "train accuracy: 0.6907231375, test accuracy:0.6791713325867861 train loss:0.57855812, test loss:0.59448093, test precision: 0.612565445026178,test recall: 0.5659986178299931,test f1: 0.5883620689655172\n",
      "train accuracy: 0.6910767203571428, test accuracy:0.6788913773796192 train loss:0.57515581, test loss:0.5945006, test precision: 0.612565445026178,test recall: 0.5656077348066298,test f1: 0.5881508078994615\n",
      "train accuracy: 0.6850441621428571, test accuracy:0.6791713325867861 train loss:0.58089512, test loss:0.59396231, test precision: 0.612565445026178,test recall: 0.5659986178299931,test f1: 0.5883620689655172\n",
      "train accuracy: 0.6884861839285714, test accuracy:0.6788913773796192 train loss:0.58168491, test loss:0.59498399, test precision: 0.612565445026178,test recall: 0.5656077348066298,test f1: 0.5881508078994615\n",
      "train accuracy: 0.6918921264285715, test accuracy:0.6791713325867861 train loss:0.57866441, test loss:0.59526324, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6901819392857143, test accuracy:0.6800111982082867 train loss:0.58160946, test loss:0.59585983, test precision: 0.6178010471204188,test recall: 0.5665294924554184,test f1: 0.5910554561717353\n",
      "train accuracy: 0.6884092128571428, test accuracy:0.6797312430011199 train loss:0.57793144, test loss:0.59559667, test precision: 0.6200448765893792,test recall: 0.5658703071672355,test f1: 0.5917201998572448\n",
      "train accuracy: 0.6922577360714286, test accuracy:0.6791713325867861 train loss:0.5771595, test loss:0.59506571, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6858451346428571, test accuracy:0.6791713325867861 train loss:0.5834928, test loss:0.59474212, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6895902292857142, test accuracy:0.6791713325867861 train loss:0.58306177, test loss:0.59460258, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6926113189285715, test accuracy:0.6791713325867861 train loss:0.57525671, test loss:0.59440577, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6853736917857143, test accuracy:0.6791713325867861 train loss:0.58402264, test loss:0.59485865, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6973618385714285, test accuracy:0.6791713325867861 train loss:0.5734459, test loss:0.59448707, test precision: 0.6170531039640987,test recall: 0.5654557916381083,test f1: 0.5901287553648069\n",
      "train accuracy: 0.6900063489285715, test accuracy:0.6788913773796192 train loss:0.57858283, test loss:0.59466112, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6909251846428572, test accuracy:0.6788913773796192 train loss:0.57448678, test loss:0.59514213, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.681573275, test accuracy:0.6788913773796192 train loss:0.58550947, test loss:0.5946697, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6951296960714286, test accuracy:0.6788913773796192 train loss:0.5747648, test loss:0.59489048, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6849335153571429, test accuracy:0.6788913773796192 train loss:0.58069384, test loss:0.59469277, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6866821889285715, test accuracy:0.6788913773796192 train loss:0.57929925, test loss:0.59497511, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6869563964285714, test accuracy:0.6805711086226204 train loss:0.58268919, test loss:0.59432125, test precision: 0.6043380703066566,test recall: 0.5690140845070423,test f1: 0.5861443598113892\n",
      "train accuracy: 0.6895782021428571, test accuracy:0.6791713325867861 train loss:0.57757482, test loss:0.59492493, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6895132578571428, test accuracy:0.6794512877939529 train loss:0.57939161, test loss:0.59425217, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6938789249999999, test accuracy:0.6794512877939529 train loss:0.5740765, test loss:0.59413618, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6896118771428572, test accuracy:0.6794512877939529 train loss:0.57635665, test loss:0.59422147, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6850706207142857, test accuracy:0.6802911534154535 train loss:0.58359048, test loss:0.59392041, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6864224139285715, test accuracy:0.6802911534154535 train loss:0.57972685, test loss:0.59403461, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6911560960714286, test accuracy:0.6802911534154535 train loss:0.5768479, test loss:0.5937385, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6859245110714286, test accuracy:0.6794512877939529 train loss:0.58045075, test loss:0.59390122, test precision: 0.6148092744951383,test recall: 0.5661157024793388,test f1: 0.5894585873072786\n",
      "train accuracy: 0.6935590167857143, test accuracy:0.6802911534154535 train loss:0.57536487, test loss:0.59346581, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6856166296428572, test accuracy:0.6802911534154535 train loss:0.58132634, test loss:0.59369725, test precision: 0.6140613313388182,test recall: 0.5673807878369039,test f1: 0.5897988505747126\n",
      "train accuracy: 0.6865787603571428, test accuracy:0.6791713325867861 train loss:0.57975066, test loss:0.5940268, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6902372610714285, test accuracy:0.6791713325867861 train loss:0.57754708, test loss:0.59384781, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.677645377857143, test accuracy:0.6791713325867861 train loss:0.58808999, test loss:0.5939604, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6804090971428571, test accuracy:0.6800111982082867 train loss:0.5860951, test loss:0.59449947, test precision: 0.6178010471204188,test recall: 0.5665294924554184,test f1: 0.5910554561717353\n",
      "train accuracy: 0.6880291714285715, test accuracy:0.6800111982082867 train loss:0.57940447, test loss:0.59494716, test precision: 0.6178010471204188,test recall: 0.5665294924554184,test f1: 0.5910554561717353\n",
      "train accuracy: 0.6902011807142856, test accuracy:0.6794512877939529 train loss:0.57990553, test loss:0.59624612, test precision: 0.6207928197456993,test recall: 0.5653950953678474,test f1: 0.5918003565062389\n",
      "train accuracy: 0.6849744064285713, test accuracy:0.6800111982082867 train loss:0.57911658, test loss:0.59509957, test precision: 0.6178010471204188,test recall: 0.5665294924554184,test f1: 0.5910554561717353\n",
      "train accuracy: 0.6938356292857144, test accuracy:0.6800111982082867 train loss:0.5735074, test loss:0.59485763, test precision: 0.6178010471204188,test recall: 0.5665294924554184,test f1: 0.5910554561717353\n",
      "train accuracy: 0.6858427314285714, test accuracy:0.6791713325867861 train loss:0.5815305, test loss:0.59448051, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6916708371428572, test accuracy:0.6797312430011199 train loss:0.57436955, test loss:0.59509718, test precision: 0.6200448765893792,test recall: 0.5658703071672355,test f1: 0.5917201998572448\n",
      "train accuracy: 0.6874206239285714, test accuracy:0.6802911534154535 train loss:0.58035223, test loss:0.59439486, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6838679571428571, test accuracy:0.6802911534154535 train loss:0.58360481, test loss:0.59431279, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6962866585714285, test accuracy:0.6808510638297872 train loss:0.57441706, test loss:0.59471619, test precision: 0.6095736724008975,test recall: 0.5687369155617585,test f1: 0.5884476534296028\n",
      "train accuracy: 0.6964550307142856, test accuracy:0.6800111982082867 train loss:0.57361158, test loss:0.59446985, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6905283057142857, test accuracy:0.6802911534154535 train loss:0.57557482, test loss:0.59314001, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6869155057142857, test accuracy:0.6802911534154535 train loss:0.5789591, test loss:0.59263992, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6942926428571428, test accuracy:0.6802911534154535 train loss:0.57735834, test loss:0.59279585, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6875625385714285, test accuracy:0.6800111982082867 train loss:0.58190266, test loss:0.59348798, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6941699707142858, test accuracy:0.6788913773796192 train loss:0.57296397, test loss:0.5931918, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6830934417857143, test accuracy:0.6802911534154535 train loss:0.57896452, test loss:0.59336174, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6876106446428573, test accuracy:0.6800111982082867 train loss:0.57941185, test loss:0.59362042, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6826268089285715, test accuracy:0.6788913773796192 train loss:0.582101, test loss:0.59398144, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6883202164285713, test accuracy:0.6788913773796192 train loss:0.57852149, test loss:0.59371626, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6902757478571429, test accuracy:0.6788913773796192 train loss:0.57924458, test loss:0.59383368, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6882528671428573, test accuracy:0.6788913773796192 train loss:0.58026952, test loss:0.59362853, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6868457510714288, test accuracy:0.6788913773796192 train loss:0.58081996, test loss:0.59348977, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6830164721428572, test accuracy:0.6788913773796192 train loss:0.58626315, test loss:0.59424102, test precision: 0.6170531039640987,test recall: 0.565068493150685,test f1: 0.5899177690382553\n",
      "train accuracy: 0.6910670999999999, test accuracy:0.6786114221724524 train loss:0.57692907, test loss:0.59451842, test precision: 0.6178010471204188,test recall: 0.5645933014354066,test f1: 0.59\n",
      "train accuracy: 0.6907399749999998, test accuracy:0.6791713325867861 train loss:0.57522175, test loss:0.5937168, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6905475485714286, test accuracy:0.6791713325867861 train loss:0.57622208, test loss:0.59306926, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.690889105, test accuracy:0.6791713325867861 train loss:0.5764313, test loss:0.59327871, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6925151046428571, test accuracy:0.6802911534154535 train loss:0.57444841, test loss:0.59287816, test precision: 0.6043380703066566,test recall: 0.5686136523574947,test f1: 0.5859318346627991\n",
      "train accuracy: 0.6916756457142857, test accuracy:0.6791713325867861 train loss:0.57354926, test loss:0.59228045, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6902565049999999, test accuracy:0.6791713325867861 train loss:0.57605198, test loss:0.59234697, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6913052267857144, test accuracy:0.6791713325867861 train loss:0.57610583, test loss:0.59215772, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6907664346428571, test accuracy:0.6791713325867861 train loss:0.57599958, test loss:0.59175283, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6878223128571428, test accuracy:0.6805711086226204 train loss:0.57854847, test loss:0.59124494, test precision: 0.6043380703066566,test recall: 0.5690140845070423,test f1: 0.5861443598113892\n",
      "train accuracy: 0.6886160710714285, test accuracy:0.6791713325867861 train loss:0.57989695, test loss:0.5921337, test precision: 0.6148092744951383,test recall: 0.565726083964212,test f1: 0.589247311827957\n",
      "train accuracy: 0.6925584014285714, test accuracy:0.6814109742441209 train loss:0.57640662, test loss:0.5921334, test precision: 0.6035901271503366,test recall: 0.5703180212014134,test f1: 0.5864825581395348\n",
      "train accuracy: 0.6933257007142857, test accuracy:0.6800111982082867 train loss:0.57280853, test loss:0.59227484, test precision: 0.6148092744951383,test recall: 0.5668965517241379,test f1: 0.589881593110872\n",
      "train accuracy: 0.6916467821428572, test accuracy:0.6800111982082867 train loss:0.57682575, test loss:0.59211898, test precision: 0.6148092744951383,test recall: 0.5668965517241379,test f1: 0.589881593110872\n",
      "train accuracy: 0.6960389085714286, test accuracy:0.6814109742441209 train loss:0.57482392, test loss:0.59159178, test precision: 0.6043380703066566,test recall: 0.5702187720536345,test f1: 0.5867828612926651\n",
      "train accuracy: 0.6837308532142856, test accuracy:0.6802911534154535 train loss:0.58489423, test loss:0.59239388, test precision: 0.6148092744951383,test recall: 0.567287784679089,test f1: 0.5900933237616655\n",
      "train accuracy: 0.6873123839285713, test accuracy:0.6800111982082867 train loss:0.57972388, test loss:0.59237319, test precision: 0.6148092744951383,test recall: 0.5668965517241379,test f1: 0.589881593110872\n",
      "train accuracy: 0.6895180685714285, test accuracy:0.6786114221724524 train loss:0.57908706, test loss:0.5934177, test precision: 0.6163051608077786,test recall: 0.564770390678547,test f1: 0.5894134477825466\n",
      "train accuracy: 0.6880676571428571, test accuracy:0.6788913773796192 train loss:0.57815559, test loss:0.59268075, test precision: 0.6155572176514585,test recall: 0.5652472527472527,test f1: 0.5893304690297172\n",
      "train accuracy: 0.6899822978571428, test accuracy:0.6791713325867861 train loss:0.57757701, test loss:0.59215957, test precision: 0.6155572176514585,test recall: 0.5656357388316151,test f1: 0.5895415472779371\n",
      "train accuracy: 0.6901314282142856, test accuracy:0.6780515117581187 train loss:0.57780328, test loss:0.59312701, test precision: 0.6163051608077786,test recall: 0.5639972621492129,test f1: 0.5889921372408864\n",
      "train accuracy: 0.6854867421428572, test accuracy:0.6777715565509519 train loss:0.58268979, test loss:0.59340829, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6956805153571429, test accuracy:0.6788913773796192 train loss:0.5738895, test loss:0.59289718, test precision: 0.606581899775617,test recall: 0.5663407821229051,test f1: 0.5857710364752619\n",
      "train accuracy: 0.6962938721428572, test accuracy:0.6777715565509519 train loss:0.57255733, test loss:0.593768, test precision: 0.6170531039640987,test recall: 0.5635245901639344,test f1: 0.5890753302392002\n",
      "train accuracy: 0.6811956400000001, test accuracy:0.6788913773796192 train loss:0.58124512, test loss:0.59369624, test precision: 0.6073298429319371,test recall: 0.5662482566248257,test f1: 0.5860700108264164\n",
      "train accuracy: 0.6930178189285715, test accuracy:0.6788913773796192 train loss:0.57439535, test loss:0.5936473, test precision: 0.6073298429319371,test recall: 0.5662482566248257,test f1: 0.5860700108264164\n",
      "train accuracy: 0.6912763621428571, test accuracy:0.6788913773796192 train loss:0.57462893, test loss:0.59351271, test precision: 0.606581899775617,test recall: 0.5663407821229051,test f1: 0.5857710364752619\n",
      "train accuracy: 0.6872714946428572, test accuracy:0.6791713325867861 train loss:0.58014926, test loss:0.59345299, test precision: 0.606581899775617,test recall: 0.5667365478686234,test f1: 0.5859826589595376\n",
      "train accuracy: 0.6894507196428571, test accuracy:0.6791713325867861 train loss:0.57992564, test loss:0.59368825, test precision: 0.6073298429319371,test recall: 0.5666434054431263,test f1: 0.5862815884476534\n",
      "train accuracy: 0.6955698696428572, test accuracy:0.6800111982082867 train loss:0.57250993, test loss:0.59312308, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6868986692857143, test accuracy:0.6800111982082867 train loss:0.5793093, test loss:0.59289145, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6869443678571429, test accuracy:0.6800111982082867 train loss:0.58085216, test loss:0.59213853, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6924934578571428, test accuracy:0.6800111982082867 train loss:0.57496599, test loss:0.5924629, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6827855610714286, test accuracy:0.6800111982082867 train loss:0.58233863, test loss:0.59281486, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6881157646428572, test accuracy:0.6800111982082867 train loss:0.57507555, test loss:0.5932917, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6902661253571428, test accuracy:0.6797312430011199 train loss:0.57782454, test loss:0.59346098, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6985284203571427, test accuracy:0.6800111982082867 train loss:0.57229169, test loss:0.59264332, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6889985175000001, test accuracy:0.6800111982082867 train loss:0.57974978, test loss:0.59305722, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6906437610714286, test accuracy:0.6800111982082867 train loss:0.57554402, test loss:0.59333307, test precision: 0.606581899775617,test recall: 0.5679271708683473,test f1: 0.5866184448462929\n",
      "train accuracy: 0.6900328082142856, test accuracy:0.6800111982082867 train loss:0.57578753, test loss:0.59243524, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6903815803571429, test accuracy:0.6800111982082867 train loss:0.57685569, test loss:0.59228355, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6821914450000001, test accuracy:0.6800111982082867 train loss:0.58204408, test loss:0.59240979, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6897634117857142, test accuracy:0.6800111982082867 train loss:0.57476528, test loss:0.59214914, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6916155146428571, test accuracy:0.6797312430011199 train loss:0.57533645, test loss:0.59278202, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.7019006885714285, test accuracy:0.6797312430011199 train loss:0.56891503, test loss:0.59202766, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6926810721428572, test accuracy:0.6800111982082867 train loss:0.57444998, test loss:0.59154564, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6948578935714286, test accuracy:0.6800111982082867 train loss:0.57249, test loss:0.59091276, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6971333317857142, test accuracy:0.6800111982082867 train loss:0.5762424, test loss:0.59164059, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6891909453571429, test accuracy:0.6800111982082867 train loss:0.5763788, test loss:0.59181106, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6808661103571428, test accuracy:0.6797312430011199 train loss:0.58356691, test loss:0.59156036, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6923371117857143, test accuracy:0.6797312430011199 train loss:0.57695541, test loss:0.59155828, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6894122346428572, test accuracy:0.6797312430011199 train loss:0.57734638, test loss:0.59186947, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6872570625, test accuracy:0.6797312430011199 train loss:0.57891834, test loss:0.59194267, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6957671071428572, test accuracy:0.6797312430011199 train loss:0.57303088, test loss:0.59183806, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6891668903571428, test accuracy:0.6797312430011199 train loss:0.57909027, test loss:0.59229475, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6902420714285714, test accuracy:0.6797312430011199 train loss:0.57708362, test loss:0.5929355, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6935662335714285, test accuracy:0.6766517357222844 train loss:0.57385189, test loss:0.59316087, test precision: 0.6095736724008975,test recall: 0.5628453038674033,test f1: 0.5852782764811489\n",
      "train accuracy: 0.6884645353571429, test accuracy:0.6797312430011199 train loss:0.57660212, test loss:0.59283775, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6930996007142857, test accuracy:0.6800111982082867 train loss:0.57655974, test loss:0.5910511, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6909516428571428, test accuracy:0.6797312430011199 train loss:0.57833175, test loss:0.59117913, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.681486685, test accuracy:0.6797312430011199 train loss:0.58039706, test loss:0.59166282, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6967701282142856, test accuracy:0.6797312430011199 train loss:0.57010091, test loss:0.59210545, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6987665482142856, test accuracy:0.6797312430011199 train loss:0.56785545, test loss:0.59183592, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6881061428571428, test accuracy:0.6797312430011199 train loss:0.57704279, test loss:0.59260988, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6815853042857143, test accuracy:0.6758118701007839 train loss:0.58352555, test loss:0.59330457, test precision: 0.6103216155572176,test recall: 0.5615966964900206,test f1: 0.5849462365591398\n",
      "train accuracy: 0.694578875, test accuracy:0.6797312430011199 train loss:0.57430373, test loss:0.59240323, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.685116320357143, test accuracy:0.6797312430011199 train loss:0.58058728, test loss:0.59179336, test precision: 0.6080777860882572,test recall: 0.567341242149337,test f1: 0.5870036101083032\n",
      "train accuracy: 0.6868649942857142, test accuracy:0.6797312430011199 train loss:0.57777593, test loss:0.59233522, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6967965864285715, test accuracy:0.6797312430011199 train loss:0.57024558, test loss:0.59216809, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6874663242857142, test accuracy:0.6797312430011199 train loss:0.57752816, test loss:0.59186643, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6886305032142858, test accuracy:0.6797312430011199 train loss:0.57790119, test loss:0.59181166, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6868601842857143, test accuracy:0.6797312430011199 train loss:0.57845771, test loss:0.59242731, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6950431035714286, test accuracy:0.6797312430011199 train loss:0.57321987, test loss:0.59190232, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6924790246428572, test accuracy:0.6797312430011199 train loss:0.57420245, test loss:0.59204257, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6905619785714288, test accuracy:0.6797312430011199 train loss:0.57705953, test loss:0.59198278, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6843369957142856, test accuracy:0.6797312430011199 train loss:0.58224287, test loss:0.59196681, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6935012892857143, test accuracy:0.6797312430011199 train loss:0.57301152, test loss:0.59125775, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6899053253571428, test accuracy:0.6797312430011199 train loss:0.574151, test loss:0.59115964, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6929961703571428, test accuracy:0.6797312430011199 train loss:0.56911181, test loss:0.59119064, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6931549225, test accuracy:0.6797312430011199 train loss:0.57131229, test loss:0.59154123, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6874013821428572, test accuracy:0.6797312430011199 train loss:0.576487, test loss:0.59166527, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6871921171428571, test accuracy:0.6797312430011199 train loss:0.57634106, test loss:0.59161592, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6843875078571429, test accuracy:0.6797312430011199 train loss:0.5800531, test loss:0.59102893, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6918223707142858, test accuracy:0.6788913773796192 train loss:0.57681486, test loss:0.5912106, test precision: 0.6095736724008975,test recall: 0.5659722222222222,test f1: 0.5869643500180051\n",
      "train accuracy: 0.6917670492857143, test accuracy:0.6797312430011199 train loss:0.57822479, test loss:0.59091926, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6932679725, test accuracy:0.6797312430011199 train loss:0.57431506, test loss:0.59142745, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6937418228571429, test accuracy:0.6797312430011199 train loss:0.57387297, test loss:0.59162641, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6904513357142857, test accuracy:0.6797312430011199 train loss:0.57817931, test loss:0.59094638, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6964502199999999, test accuracy:0.6797312430011199 train loss:0.57312295, test loss:0.59087408, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6848252785714287, test accuracy:0.6797312430011199 train loss:0.58218653, test loss:0.59104121, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6864560889285716, test accuracy:0.6797312430011199 train loss:0.57637945, test loss:0.59115839, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6894531257142857, test accuracy:0.6794512877939529 train loss:0.57502689, test loss:0.59215748, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6857080328571429, test accuracy:0.6794512877939529 train loss:0.58084499, test loss:0.59180355, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6914832217857142, test accuracy:0.6797312430011199 train loss:0.57518431, test loss:0.59059936, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.684753117857143, test accuracy:0.6797312430011199 train loss:0.58370212, test loss:0.59038085, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6920099867857142, test accuracy:0.6797312430011199 train loss:0.57428217, test loss:0.59050447, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6958921835714286, test accuracy:0.6797312430011199 train loss:0.57359058, test loss:0.59117848, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6931380857142857, test accuracy:0.6797312430011199 train loss:0.57452016, test loss:0.5910567, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6848974364285715, test accuracy:0.6797312430011199 train loss:0.57857417, test loss:0.59099108, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6851644267857143, test accuracy:0.6794512877939529 train loss:0.57625247, test loss:0.59163654, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6885030217857143, test accuracy:0.6797312430011199 train loss:0.57961564, test loss:0.59123069, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6826388364285715, test accuracy:0.6797312430011199 train loss:0.58326464, test loss:0.59098053, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6924862410714285, test accuracy:0.6797312430011199 train loss:0.5738329, test loss:0.59090561, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6899919175000001, test accuracy:0.6797312430011199 train loss:0.57637996, test loss:0.59069705, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6931501117857143, test accuracy:0.6797312430011199 train loss:0.57381106, test loss:0.59110242, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.694408097857143, test accuracy:0.6794512877939529 train loss:0.57254, test loss:0.59101254, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6967629117857143, test accuracy:0.6794512877939529 train loss:0.57159477, test loss:0.59101254, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6880171442857143, test accuracy:0.6794512877939529 train loss:0.57957895, test loss:0.59052372, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6921783592857143, test accuracy:0.6794512877939529 train loss:0.57160165, test loss:0.59077168, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6960316942857142, test accuracy:0.6794512877939529 train loss:0.57369247, test loss:0.59048831, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6940593250000001, test accuracy:0.6797312430011199 train loss:0.57208523, test loss:0.58994877, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6856286564285714, test accuracy:0.6794512877939529 train loss:0.58090426, test loss:0.59041262, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6950791824999999, test accuracy:0.6794512877939529 train loss:0.5719101, test loss:0.59064949, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6967508846428572, test accuracy:0.6797312430011199 train loss:0.56997719, test loss:0.59033138, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6958705357142857, test accuracy:0.6797312430011199 train loss:0.57190042, test loss:0.59006691, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6900424296428571, test accuracy:0.6794512877939529 train loss:0.57574233, test loss:0.59067357, test precision: 0.6088257292445775,test recall: 0.5668523676880223,test f1: 0.5870897944464478\n",
      "train accuracy: 0.6859413492857142, test accuracy:0.6797312430011199 train loss:0.57851363, test loss:0.59008396, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6908891064285714, test accuracy:0.6788913773796192 train loss:0.57558815, test loss:0.59058148, test precision: 0.6095736724008975,test recall: 0.5659722222222222,test f1: 0.5869643500180051\n",
      "train accuracy: 0.6927628553571429, test accuracy:0.6797312430011199 train loss:0.57365934, test loss:0.59036952, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6888253342857142, test accuracy:0.6797312430011199 train loss:0.57688689, test loss:0.59019458, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6860616139285715, test accuracy:0.6797312430011199 train loss:0.57572645, test loss:0.59011853, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6913172535714286, test accuracy:0.6788913773796192 train loss:0.56984271, test loss:0.59025311, test precision: 0.6095736724008975,test recall: 0.5659722222222222,test f1: 0.5869643500180051\n",
      "train accuracy: 0.6892823467857143, test accuracy:0.6786114221724524 train loss:0.57823515, test loss:0.59030163, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.688454915, test accuracy:0.6786114221724524 train loss:0.57896177, test loss:0.5910899, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.6807482496428572, test accuracy:0.6786114221724524 train loss:0.58446233, test loss:0.59098482, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.6927676642857142, test accuracy:0.6786114221724524 train loss:0.57327382, test loss:0.59014535, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.6947352221428572, test accuracy:0.6786114221724524 train loss:0.57096801, test loss:0.58979952, test precision: 0.6095736724008975,test recall: 0.5655794587092297,test f1: 0.5867530597552196\n",
      "train accuracy: 0.6930370607142856, test accuracy:0.6794512877939529 train loss:0.57353045, test loss:0.5891946, test precision: 0.6095736724008975,test recall: 0.566759388038943,test f1: 0.5873873873873874\n",
      "train accuracy: 0.6996901935714286, test accuracy:0.6802911534154535 train loss:0.5679777, test loss:0.58897173, test precision: 0.6088257292445775,test recall: 0.5680390788555478,test f1: 0.5877256317689532\n",
      "train accuracy: 0.6865523021428572, test accuracy:0.6797312430011199 train loss:0.57999568, test loss:0.5897209, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.69675329, test accuracy:0.6797312430011199 train loss:0.56807219, test loss:0.58962238, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6893905857142857, test accuracy:0.6797312430011199 train loss:0.57510561, test loss:0.58979595, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6875192414285715, test accuracy:0.6797312430011199 train loss:0.57705083, test loss:0.58981001, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6915770274999999, test accuracy:0.6797312430011199 train loss:0.57437677, test loss:0.59030145, test precision: 0.6088257292445775,test recall: 0.5672473867595819,test f1: 0.5873015873015873\n",
      "train accuracy: 0.6870477996428571, test accuracy:0.6802911534154535 train loss:0.57644821, test loss:0.58944255, test precision: 0.6088257292445775,test recall: 0.5680390788555478,test f1: 0.5877256317689532\n",
      "train accuracy: 0.6816791103571429, test accuracy:0.6802911534154535 train loss:0.5833545, test loss:0.58927441, test precision: 0.6088257292445775,test recall: 0.5680390788555478,test f1: 0.5877256317689532\n",
      "train accuracy: 0.6931789760714286, test accuracy:0.6800111982082867 train loss:0.57338575, test loss:0.58940458, test precision: 0.6095736724008975,test recall: 0.5675487465181058,test f1: 0.5878110349801658\n",
      "train accuracy: 0.6899077324999999, test accuracy:0.6791713325867861 train loss:0.5756398, test loss:0.59016502, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6873701117857143, test accuracy:0.6800111982082867 train loss:0.57860641, test loss:0.59034026, test precision: 0.6095736724008975,test recall: 0.5675487465181058,test f1: 0.5878110349801658\n",
      "train accuracy: 0.6936648510714285, test accuracy:0.6800111982082867 train loss:0.57306043, test loss:0.58956271, test precision: 0.6095736724008975,test recall: 0.5675487465181058,test f1: 0.5878110349801658\n",
      "train accuracy: 0.6881422210714285, test accuracy:0.6800111982082867 train loss:0.57588664, test loss:0.58923322, test precision: 0.6095736724008975,test recall: 0.5675487465181058,test f1: 0.5878110349801658\n",
      "train accuracy: 0.6885823975, test accuracy:0.6788913773796192 train loss:0.57403037, test loss:0.59005386, test precision: 0.6103216155572176,test recall: 0.565880721220527,test f1: 0.5872616048938466\n",
      "train accuracy: 0.6887676074999999, test accuracy:0.6791713325867861 train loss:0.57891053, test loss:0.58987141, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6875962146428571, test accuracy:0.6791713325867861 train loss:0.57850228, test loss:0.59018058, test precision: 0.6103216155572176,test recall: 0.5662734212352533,test f1: 0.5874730021598272\n",
      "train accuracy: 0.6929432535714286, test accuracy:0.6794512877939529 train loss:0.57281046, test loss:0.59021401, test precision: 0.6095736724008975,test recall: 0.566759388038943,test f1: 0.5873873873873874\n",
      "train accuracy: 0.6922986264285714, test accuracy:0.6802911534154535 train loss:0.57210035, test loss:0.5900045, test precision: 0.6088257292445775,test recall: 0.5680390788555478,test f1: 0.5877256317689532\n",
      "train accuracy: 0.6917261578571428, test accuracy:0.687010078387458 train loss:0.57757275, test loss:0.58944815, test precision: 0.6080777860882572,test recall: 0.5778251599147122,test f1: 0.5925655976676385\n",
      "train accuracy: 0.695391875, test accuracy:0.687010078387458 train loss:0.5742657, test loss:0.58925319, test precision: 0.6080777860882572,test recall: 0.5778251599147122,test f1: 0.5925655976676385\n",
      "train accuracy: 0.6950671574999999, test accuracy:0.687010078387458 train loss:0.5724727, test loss:0.58933556, test precision: 0.6080777860882572,test recall: 0.5778251599147122,test f1: 0.5925655976676385\n",
      "train accuracy: 0.6960870153571429, test accuracy:0.6872900335946248 train loss:0.57563687, test loss:0.58903015, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.7005464896428572, test accuracy:0.6872900335946248 train loss:0.57246722, test loss:0.58908373, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.6945043096428573, test accuracy:0.6872900335946248 train loss:0.57407055, test loss:0.58874482, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.6945115260714285, test accuracy:0.6872900335946248 train loss:0.57219629, test loss:0.58915114, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.6933689964285714, test accuracy:0.6872900335946248 train loss:0.57017242, test loss:0.58883566, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.688919142857143, test accuracy:0.6872900335946248 train loss:0.57693622, test loss:0.58910328, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.7001568278571428, test accuracy:0.6872900335946248 train loss:0.57049671, test loss:0.5889256, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.699139375, test accuracy:0.6872900335946248 train loss:0.56773655, test loss:0.58931673, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.7043060146428571, test accuracy:0.6872900335946248 train loss:0.56556039, test loss:0.58974904, test precision: 0.6080777860882572,test recall: 0.5782361308677099,test f1: 0.5927816259569814\n",
      "train accuracy: 0.7005994075, test accuracy:0.6886898096304591 train loss:0.56882534, test loss:0.58865172, test precision: 0.606581899775617,test recall: 0.5805297065139585,test f1: 0.5932699341623994\n",
      "train accuracy: 0.6948987846428573, test accuracy:0.6886898096304591 train loss:0.57471671, test loss:0.58905107, test precision: 0.606581899775617,test recall: 0.5805297065139585,test f1: 0.5932699341623994\n",
      "train accuracy: 0.6978380921428571, test accuracy:0.687010078387458 train loss:0.57271899, test loss:0.58907193, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.692849445357143, test accuracy:0.6884098544232923 train loss:0.57668194, test loss:0.58930051, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.696344385, test accuracy:0.6884098544232923 train loss:0.57005931, test loss:0.58936918, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6910695039285715, test accuracy:0.6884098544232923 train loss:0.57667505, test loss:0.58937347, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6969673642857144, test accuracy:0.6886898096304591 train loss:0.57449877, test loss:0.58863795, test precision: 0.606581899775617,test recall: 0.5805297065139585,test f1: 0.5932699341623994\n",
      "train accuracy: 0.6924934578571428, test accuracy:0.6886898096304591 train loss:0.57391036, test loss:0.58885819, test precision: 0.606581899775617,test recall: 0.5805297065139585,test f1: 0.5932699341623994\n",
      "train accuracy: 0.6988363032142857, test accuracy:0.6886898096304591 train loss:0.57267478, test loss:0.5892508, test precision: 0.606581899775617,test recall: 0.5805297065139585,test f1: 0.5932699341623994\n",
      "train accuracy: 0.6935085049999999, test accuracy:0.687010078387458 train loss:0.57533139, test loss:0.58983737, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6894242625000001, test accuracy:0.687010078387458 train loss:0.57788561, test loss:0.59019858, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6918800978571428, test accuracy:0.687010078387458 train loss:0.5791674, test loss:0.58986837, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6936768782142858, test accuracy:0.687010078387458 train loss:0.57229664, test loss:0.58941466, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6962722260714287, test accuracy:0.687010078387458 train loss:0.57227639, test loss:0.58978921, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6989060578571429, test accuracy:0.6884098544232923 train loss:0.57121262, test loss:0.58892649, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6964574360714285, test accuracy:0.687010078387458 train loss:0.5727446, test loss:0.58939159, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6982494046428572, test accuracy:0.6884098544232923 train loss:0.57028222, test loss:0.58924997, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6934459660714285, test accuracy:0.6884098544232923 train loss:0.57425778, test loss:0.58908361, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6955939228571429, test accuracy:0.6900895856662934 train loss:0.57059624, test loss:0.58819866, test precision: 0.6073298429319371,test recall: 0.5824964131994261,test f1: 0.5946539729036983\n",
      "train accuracy: 0.6984538557142858, test accuracy:0.6898096304591266 train loss:0.5704321, test loss:0.58894855, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6950839939285715, test accuracy:0.687010078387458 train loss:0.57773966, test loss:0.58964294, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6951248842857142, test accuracy:0.6898096304591266 train loss:0.57105016, test loss:0.58898997, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7031971596428572, test accuracy:0.6884098544232923 train loss:0.56576489, test loss:0.58925271, test precision: 0.6088257292445775,test recall: 0.5797720797720798,test f1: 0.5939438161255016\n",
      "train accuracy: 0.6947616807142857, test accuracy:0.6898096304591266 train loss:0.57654986, test loss:0.58842158, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6956829203571429, test accuracy:0.6898096304591266 train loss:0.57419054, test loss:0.58880705, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6898500042857144, test accuracy:0.6898096304591266 train loss:0.57706699, test loss:0.58845389, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7020546285714285, test accuracy:0.6884098544232923 train loss:0.57196367, test loss:0.58887815, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6890851092857143, test accuracy:0.6884098544232923 train loss:0.5763855, test loss:0.58896452, test precision: 0.6073298429319371,test recall: 0.58,test f1: 0.5933503836317134\n",
      "train accuracy: 0.6981676225, test accuracy:0.6898096304591266 train loss:0.56994698, test loss:0.5884552, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6904417135714285, test accuracy:0.6898096304591266 train loss:0.58039146, test loss:0.58836019, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6979294939285713, test accuracy:0.6898096304591266 train loss:0.57464955, test loss:0.58831292, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6942782096428571, test accuracy:0.6898096304591266 train loss:0.5749844, test loss:0.58857167, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6971910596428571, test accuracy:0.6898096304591266 train loss:0.57092571, test loss:0.58829492, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7008447503571428, test accuracy:0.6898096304591266 train loss:0.56992161, test loss:0.58867794, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7011766860714286, test accuracy:0.6898096304591266 train loss:0.56918045, test loss:0.5889498, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6958320503571428, test accuracy:0.6898096304591266 train loss:0.57237872, test loss:0.58895236, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6938620885714285, test accuracy:0.6898096304591266 train loss:0.57523347, test loss:0.58838642, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6868192924999998, test accuracy:0.6898096304591266 train loss:0.5821699, test loss:0.58838397, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6997310839285715, test accuracy:0.6900895856662934 train loss:0.56991981, test loss:0.58803296, test precision: 0.606581899775617,test recall: 0.5826149425287356,test f1: 0.5943569072920484\n",
      "train accuracy: 0.6948651089285713, test accuracy:0.6884098544232923 train loss:0.57256007, test loss:0.58884126, test precision: 0.6088257292445775,test recall: 0.5797720797720798,test f1: 0.5939438161255016\n",
      "train accuracy: 0.6983047253571427, test accuracy:0.6858902575587906 train loss:0.57413924, test loss:0.58947289, test precision: 0.6192969334330591,test recall: 0.5746009715475364,test f1: 0.5961123110151189\n",
      "train accuracy: 0.6999355357142856, test accuracy:0.6872900335946248 train loss:0.56958443, test loss:0.58836049, test precision: 0.6192969334330591,test recall: 0.5766016713091922,test f1: 0.5971871619184999\n",
      "train accuracy: 0.6950358867857143, test accuracy:0.6900895856662934 train loss:0.57405413, test loss:0.58722699, test precision: 0.606581899775617,test recall: 0.5826149425287356,test f1: 0.5943569072920484\n",
      "train accuracy: 0.6985188007142856, test accuracy:0.6898096304591266 train loss:0.56815887, test loss:0.58777225, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6947688960714284, test accuracy:0.6872900335946248 train loss:0.57448501, test loss:0.5883348, test precision: 0.6192969334330591,test recall: 0.5766016713091922,test f1: 0.5971871619184999\n",
      "train accuracy: 0.6912354707142858, test accuracy:0.6872900335946248 train loss:0.57490115, test loss:0.58873212, test precision: 0.6192969334330591,test recall: 0.5766016713091922,test f1: 0.5971871619184999\n",
      "train accuracy: 0.6899125428571429, test accuracy:0.6858902575587906 train loss:0.57614737, test loss:0.58918422, test precision: 0.6192969334330591,test recall: 0.5746009715475364,test f1: 0.5961123110151189\n",
      "train accuracy: 0.6957935657142856, test accuracy:0.6856103023516238 train loss:0.57017718, test loss:0.58950669, test precision: 0.6192969334330591,test recall: 0.5742024965325936,test f1: 0.595897804965815\n",
      "train accuracy: 0.6989349221428572, test accuracy:0.6898096304591266 train loss:0.57018707, test loss:0.58873093, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6982638360714286, test accuracy:0.6898096304591266 train loss:0.5697014, test loss:0.58840764, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7055207060714286, test accuracy:0.6898096304591266 train loss:0.56764372, test loss:0.58812207, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6936864996428572, test accuracy:0.6898096304591266 train loss:0.57592847, test loss:0.5882895, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6911392599999999, test accuracy:0.6898096304591266 train loss:0.57352445, test loss:0.58822602, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6938813314285716, test accuracy:0.6898096304591266 train loss:0.57339984, test loss:0.58860695, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7022085707142856, test accuracy:0.6898096304591266 train loss:0.56913331, test loss:0.58828968, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6957478646428571, test accuracy:0.6898096304591266 train loss:0.57704478, test loss:0.58769518, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6940881892857141, test accuracy:0.6898096304591266 train loss:0.57492012, test loss:0.58773255, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6937153639285712, test accuracy:0.6898096304591266 train loss:0.57383068, test loss:0.5882597, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6950551285714285, test accuracy:0.6853303471444568 train loss:0.57434702, test loss:0.58915317, test precision: 0.6095736724008975,test recall: 0.5751587861679605,test f1: 0.5918663761801017\n",
      "train accuracy: 0.6946366039285714, test accuracy:0.6898096304591266 train loss:0.57524792, test loss:0.58853734, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.6930202246428572, test accuracy:0.6898096304591266 train loss:0.57371619, test loss:0.5882622, test precision: 0.6073298429319371,test recall: 0.582078853046595,test f1: 0.5944363103953147\n",
      "train accuracy: 0.7051142053571429, test accuracy:0.6906494960806271 train loss:0.56664756, test loss:0.58795518, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.689195755, test accuracy:0.6906494960806271 train loss:0.57732719, test loss:0.58774632, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.6973329742857143, test accuracy:0.6926091825307951 train loss:0.57308411, test loss:0.58703148, test precision: 0.5968586387434555,test recall: 0.5880619012527635,test f1: 0.5924276169265034\n",
      "train accuracy: 0.7013041678571429, test accuracy:0.6926091825307951 train loss:0.56849088, test loss:0.58685273, test precision: 0.5968586387434555,test recall: 0.5880619012527635,test f1: 0.5924276169265034\n",
      "train accuracy: 0.7002891210714285, test accuracy:0.6906494960806271 train loss:0.57304929, test loss:0.58789682, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.6893472910714287, test accuracy:0.6906494960806271 train loss:0.57719218, test loss:0.58837962, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.6945692542857141, test accuracy:0.6906494960806271 train loss:0.57433283, test loss:0.58811754, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.6978573346428573, test accuracy:0.6906494960806271 train loss:0.57218464, test loss:0.58837426, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.7006667564285715, test accuracy:0.6867301231802911 train loss:0.56797504, test loss:0.58884424, test precision: 0.6080777860882572,test recall: 0.5774147727272727,test f1: 0.5923497267759563\n",
      "train accuracy: 0.6915048689285715, test accuracy:0.6839305711086227 train loss:0.57806619, test loss:0.5904566, test precision: 0.6207928197456993,test recall: 0.571625344352617,test f1: 0.5951954105414128\n",
      "train accuracy: 0.6971285203571428, test accuracy:0.6822508398656215 train loss:0.57210728, test loss:0.59040779, test precision: 0.6230366492146597,test recall: 0.5689890710382514,test f1: 0.5947875758657623\n",
      "train accuracy: 0.6891861346428572, test accuracy:0.6853303471444568 train loss:0.57451876, test loss:0.58930093, test precision: 0.6103216155572176,test recall: 0.5750528541226215,test f1: 0.5921625544267054\n",
      "train accuracy: 0.7013282214285714, test accuracy:0.6875699888017918 train loss:0.56769697, test loss:0.58847803, test precision: 0.6080777860882572,test recall: 0.5786476868327403,test f1: 0.5929978118161926\n",
      "train accuracy: 0.6974965378571428, test accuracy:0.6906494960806271 train loss:0.57349262, test loss:0.58719999, test precision: 0.6073298429319371,test recall: 0.5833333333333334,test f1: 0.5950897764748991\n",
      "train accuracy: 0.6964165453571429, test accuracy:0.6875699888017918 train loss:0.57271756, test loss:0.58770835, test precision: 0.6080777860882572,test recall: 0.5786476868327403,test f1: 0.5929978118161926\n",
      "train accuracy: 0.700375712142857, test accuracy:0.6895296752519597 train loss:0.57144523, test loss:0.58746332, test precision: 0.5976065818997757,test recall: 0.5832116788321168,test f1: 0.5903213889915035\n",
      "train accuracy: 0.6944537992857144, test accuracy:0.6875699888017918 train loss:0.57345594, test loss:0.58834368, test precision: 0.6088257292445775,test recall: 0.5785358919687278,test f1: 0.5932944606413993\n",
      "train accuracy: 0.6916997, test accuracy:0.6898096304591266 train loss:0.5791079, test loss:0.58733809, test precision: 0.5968586387434555,test recall: 0.5837600585223116,test f1: 0.5902366863905325\n",
      "train accuracy: 0.6984730992857143, test accuracy:0.6937290033594625 train loss:0.56979824, test loss:0.58667505, test precision: 0.5953627524308153,test recall: 0.5900667160859896,test f1: 0.5927029039463886\n",
      "train accuracy: 0.6969240692857144, test accuracy:0.6878499440089586 train loss:0.56758001, test loss:0.58736861, test precision: 0.6073298429319371,test recall: 0.579172610556348,test f1: 0.592917123037605\n",
      "train accuracy: 0.7001159360714285, test accuracy:0.6898096304591266 train loss:0.57292223, test loss:0.58704215, test precision: 0.5968586387434555,test recall: 0.5837600585223116,test f1: 0.5902366863905325\n",
      "train accuracy: 0.69604853, test accuracy:0.6898096304591266 train loss:0.57391434, test loss:0.58700699, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6988916260714285, test accuracy:0.6895296752519597 train loss:0.57230556, test loss:0.58740538, test precision: 0.5983545250560958,test recall: 0.5830903790087464,test f1: 0.5906238464378\n",
      "train accuracy: 0.6958897789285714, test accuracy:0.6898096304591266 train loss:0.57701944, test loss:0.58734196, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6936456085714285, test accuracy:0.6895296752519597 train loss:0.5720359, test loss:0.58772242, test precision: 0.5983545250560958,test recall: 0.5830903790087464,test f1: 0.5906238464378\n",
      "train accuracy: 0.7021195735714285, test accuracy:0.6898096304591266 train loss:0.57157171, test loss:0.58764559, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6981628114285714, test accuracy:0.6898096304591266 train loss:0.57145472, test loss:0.58773524, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.693506099642857, test accuracy:0.6898096304591266 train loss:0.57601269, test loss:0.58777225, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.7029349789285714, test accuracy:0.6898096304591266 train loss:0.56623351, test loss:0.58658516, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6995482807142857, test accuracy:0.6898096304591266 train loss:0.57162538, test loss:0.58697546, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.7046812457142856, test accuracy:0.6898096304591266 train loss:0.56441975, test loss:0.58710217, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6992307767857142, test accuracy:0.6898096304591266 train loss:0.57138789, test loss:0.58704001, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.7029229528571429, test accuracy:0.6906494960806271 train loss:0.56645985, test loss:0.58647752, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6976456660714285, test accuracy:0.6898096304591266 train loss:0.57241584, test loss:0.58644664, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.7006330814285714, test accuracy:0.6898096304591266 train loss:0.57142403, test loss:0.58685941, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.700346847142857, test accuracy:0.6898096304591266 train loss:0.57113296, test loss:0.58704591, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.7012825207142858, test accuracy:0.6906494960806271 train loss:0.57017361, test loss:0.58735877, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.7004334392857142, test accuracy:0.6906494960806271 train loss:0.56691965, test loss:0.58743793, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6988892196428572, test accuracy:0.6909294512877939 train loss:0.57049726, test loss:0.58667016, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7018886617857144, test accuracy:0.6909294512877939 train loss:0.5703869, test loss:0.58671403, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7000317507142857, test accuracy:0.6912094064949608 train loss:0.56812425, test loss:0.58630824, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.7042049928571429, test accuracy:0.6912094064949608 train loss:0.56806192, test loss:0.58599466, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6984249921428571, test accuracy:0.6912094064949608 train loss:0.57559583, test loss:0.58601218, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6966931589285715, test accuracy:0.6912094064949608 train loss:0.57264339, test loss:0.58581096, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6962265250000002, test accuracy:0.6906494960806271 train loss:0.57522501, test loss:0.58650535, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6983287778571429, test accuracy:0.6898096304591266 train loss:0.57007195, test loss:0.58697164, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6968519096428573, test accuracy:0.6906494960806271 train loss:0.57374942, test loss:0.58655363, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6964790824999999, test accuracy:0.6906494960806271 train loss:0.56926405, test loss:0.58651549, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6906654110714286, test accuracy:0.6898096304591266 train loss:0.57663415, test loss:0.58689564, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6964887032142856, test accuracy:0.6898096304591266 train loss:0.57228071, test loss:0.58713496, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6870045024999999, test accuracy:0.6898096304591266 train loss:0.5783241, test loss:0.58741796, test precision: 0.5976065818997757,test recall: 0.5836376917457998,test f1: 0.590539541759054\n",
      "train accuracy: 0.6997142478571428, test accuracy:0.6906494960806271 train loss:0.56834096, test loss:0.58725721, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.7046692200000001, test accuracy:0.6909294512877939 train loss:0.56665132, test loss:0.58665299, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7080366760714286, test accuracy:0.6909294512877939 train loss:0.56411291, test loss:0.5862093, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7035940382142857, test accuracy:0.6909294512877939 train loss:0.5652709, test loss:0.58635241, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7036277128571428, test accuracy:0.6909294512877939 train loss:0.56706006, test loss:0.5857175, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.6979415210714286, test accuracy:0.6942889137737962 train loss:0.56845737, test loss:0.58498472, test precision: 0.5938668661181751,test recall: 0.5912137006701415,test f1: 0.5925373134328359\n",
      "train accuracy: 0.7010660407142858, test accuracy:0.6909294512877939 train loss:0.56614038, test loss:0.58664739, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.6942782082142857, test accuracy:0.6906494960806271 train loss:0.57566412, test loss:0.58682567, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.7034593414285714, test accuracy:0.6906494960806271 train loss:0.56774975, test loss:0.58643371, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.7011141478571429, test accuracy:0.6909294512877939 train loss:0.5671036, test loss:0.58633566, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.705056477857143, test accuracy:0.6909294512877939 train loss:0.56380008, test loss:0.58623141, test precision: 0.5968586387434555,test recall: 0.5854732208363903,test f1: 0.591111111111111\n",
      "train accuracy: 0.6966161867857142, test accuracy:0.6906494960806271 train loss:0.57185453, test loss:0.58640969, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.7029085203571428, test accuracy:0.6912094064949608 train loss:0.56833717, test loss:0.58592999, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6996468992857142, test accuracy:0.6912094064949608 train loss:0.57009944, test loss:0.58592695, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6943335321428571, test accuracy:0.6912094064949608 train loss:0.57568588, test loss:0.58593565, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6980136810714285, test accuracy:0.6912094064949608 train loss:0.5760902, test loss:0.58653325, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6972319503571428, test accuracy:0.6909294512877939 train loss:0.57316254, test loss:0.58694619, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.6953846592857144, test accuracy:0.6909294512877939 train loss:0.5712104, test loss:0.58705527, test precision: 0.5946148092744952,test recall: 0.5858511422254974,test f1: 0.5902004454342985\n",
      "train accuracy: 0.7032621035714285, test accuracy:0.6912094064949608 train loss:0.57015778, test loss:0.58688378, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6886569617857142, test accuracy:0.6912094064949608 train loss:0.57951186, test loss:0.58656758, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.6974027282142856, test accuracy:0.6912094064949608 train loss:0.57036441, test loss:0.58614337, test precision: 0.5946148092744952,test recall: 0.5862831858407079,test f1: 0.5904196063869291\n",
      "train accuracy: 0.7010492035714285, test accuracy:0.6909294512877939 train loss:0.56748838, test loss:0.58593678, test precision: 0.5968586387434555,test recall: 0.5854732208363903,test f1: 0.591111111111111\n",
      "train accuracy: 0.7042963939285715, test accuracy:0.6909294512877939 train loss:0.56507582, test loss:0.58603132, test precision: 0.5968586387434555,test recall: 0.5854732208363903,test f1: 0.591111111111111\n",
      "train accuracy: 0.6974941307142857, test accuracy:0.6900895856662934 train loss:0.57026184, test loss:0.58598822, test precision: 0.6050860134629769,test recall: 0.5828530259365994,test f1: 0.5937614678899084\n",
      "train accuracy: 0.7032212132142858, test accuracy:0.6895296752519597 train loss:0.56604279, test loss:0.58664107, test precision: 0.6073298429319371,test recall: 0.5816618911174785,test f1: 0.5942188071716062\n",
      "train accuracy: 0.6943191007142858, test accuracy:0.6903695408734603 train loss:0.57243282, test loss:0.5860883, test precision: 0.5976065818997757,test recall: 0.584491587417703,test f1: 0.5909763313609468\n",
      "train accuracy: 0.6927436114285713, test accuracy:0.6884098544232923 train loss:0.57516667, test loss:0.58633041, test precision: 0.6088257292445775,test recall: 0.5797720797720798,test f1: 0.5939438161255016\n"
=======
      "train accuracy: 0.7119140625, test accuracy:0.7057670772676372 train loss:0.55022968, test loss:29.42329407, test precision: 0.6043380703066566,test recall: 0.6075187969924812,test f1: 0.6059242594675666\n",
      "train accuracy: 0.5040028330357142, test accuracy:0.40313549832026874 train loss:0.69300787, test loss:59.68645096, test precision: 0.9768137621540763,test recall: 0.38332844144408573,test f1: 0.5505902192242833\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[32m[I 2023-04-03 12:25:04,468]\u001b[0m Trial 8 finished with value: 0.5725821788821902 and parameters: {'n_layers': 1, 'n_units_l0': 1020, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.5502296771321978.\u001b[0m\n"
=======
      "\u001b[32m[I 2023-04-03 00:56:28,134]\u001b[0m Trial 2 pruned. \u001b[0m\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train accuracy: 0.6966570775, test accuracy:0.6884098544232923 train loss:0.57258218, test loss:0.58704287, test precision: 0.6088257292445775,test recall: 0.5797720797720798,test f1: 0.5939438161255016\n",
      "train accuracy: 0.4993962625, test accuracy:0.6256998880179171 train loss:0.69325003, test loss:0.68851161, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4925386778571429, test accuracy:0.6256998880179171 train loss:0.69334989, test loss:0.68864977, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5050078892857143, test accuracy:0.6256998880179171 train loss:0.69277999, test loss:0.68864131, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.49804687464285713, test accuracy:0.6256998880179171 train loss:0.69287993, test loss:0.68866074, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4998484642857143, test accuracy:0.6256998880179171 train loss:0.69269731, test loss:0.68871647, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5001202664285714, test accuracy:0.6256998880179171 train loss:0.69255401, test loss:0.68871254, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4965122778571428, test accuracy:0.6256998880179171 train loss:0.69251394, test loss:0.68879014, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4963078239285714, test accuracy:0.6256998880179171 train loss:0.69232127, test loss:0.68885094, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4959205657142857, test accuracy:0.6256998880179171 train loss:0.69221536, test loss:0.68892193, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5035550714285714, test accuracy:0.6256998880179171 train loss:0.69180033, test loss:0.68882334, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4962476910714286, test accuracy:0.6256998880179171 train loss:0.69180914, test loss:0.68880755, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5319475442857142, test accuracy:0.6601343784994401 train loss:0.6914129, test loss:0.68869215, test precision: 0.1256544502617801,test recall: 0.7887323943661971,test f1: 0.21677419354838706\n",
      "train accuracy: 0.5519309953571429, test accuracy:0.6531354983202687 train loss:0.69136363, test loss:0.68866086, test precision: 0.13313388182498131,test recall: 0.689922480620155,test f1: 0.2231974921630094\n",
      "train accuracy: 0.559810845, test accuracy:0.6522956326987682 train loss:0.69097683, test loss:0.68844652, test precision: 0.1338818249813014,test recall: 0.6806083650190115,test f1: 0.22375\n",
      "train accuracy: 0.5603135582142856, test accuracy:0.6587346024636058 train loss:0.69067859, test loss:0.68820912, test precision: 0.15706806282722513,test recall: 0.695364238410596,test f1: 0.2562538133007931\n",
      "train accuracy: 0.570103235, test accuracy:0.6710526315789473 train loss:0.69047094, test loss:0.68800461, test precision: 0.18997756170531038,test recall: 0.7341040462427746,test f1: 0.3018419489007724\n",
      "train accuracy: 0.5980242646428572, test accuracy:0.687010078387458 train loss:0.69013695, test loss:0.68789744, test precision: 0.28421839940164545,test recall: 0.7024029574861368,test f1: 0.40468583599574015\n",
      "train accuracy: 0.6099979792857143, test accuracy:0.6895296752519597 train loss:0.68986186, test loss:0.68767828, test precision: 0.31338818249813016,test recall: 0.6868852459016394,test f1: 0.4304057524396508\n",
      "train accuracy: 0.6259236471428571, test accuracy:0.6917693169092946 train loss:0.68917491, test loss:0.68748951, test precision: 0.3231114435302917,test recall: 0.6878980891719745,test f1: 0.4396946564885496\n",
      "train accuracy: 0.6299814314285715, test accuracy:0.6920492721164614 train loss:0.68870416, test loss:0.68692261, test precision: 0.3261032161555722,test recall: 0.6866141732283465,test f1: 0.4421906693711968\n",
      "train accuracy: 0.622274765, test accuracy:0.6895296752519597 train loss:0.68856077, test loss:0.68655765, test precision: 0.3492894540014959,test recall: 0.6614730878186968,test f1: 0.45717082721488006\n",
      "train accuracy: 0.6409809882142857, test accuracy:0.6898096304591266 train loss:0.68784194, test loss:0.68609607, test precision: 0.3754674644727001,test recall: 0.6477419354838709,test f1: 0.4753787878787879\n",
      "train accuracy: 0.6474032092857142, test accuracy:0.683090705487122 train loss:0.68708822, test loss:0.68559653, test precision: 0.3956619296933433,test recall: 0.6201641266119577,test f1: 0.4831050228310502\n",
      "train accuracy: 0.6447092446428572, test accuracy:0.683090705487122 train loss:0.68675931, test loss:0.68508536, test precision: 0.4023934181002244,test recall: 0.6176808266360505,test f1: 0.4873188405797101\n",
      "train accuracy: 0.6416544810714286, test accuracy:0.681131019036954 train loss:0.6860959, test loss:0.68447834, test precision: 0.4158563949139865,test recall: 0.6083150984682714,test f1: 0.494002665482008\n",
      "train accuracy: 0.6557833657142856, test accuracy:0.6772116461366181 train loss:0.68510112, test loss:0.68375164, test precision: 0.45474943904263276,test recall: 0.5891472868217055,test f1: 0.5132967496834109\n",
      "train accuracy: 0.6490652896428571, test accuracy:0.6696528555431132 train loss:0.68458716, test loss:0.6830101, test precision: 0.4599850411368736,test recall: 0.5731593662628145,test f1: 0.5103734439834025\n",
      "train accuracy: 0.6437471125, test accuracy:0.6640537513997761 train loss:0.68395783, test loss:0.68241036, test precision: 0.4667165295437547,test recall: 0.5616561656165616,test f1: 0.5098039215686274\n",
      "train accuracy: 0.6454909750000001, test accuracy:0.6637737961926092 train loss:0.6829576, test loss:0.68156409, test precision: 0.47643979057591623,test recall: 0.5597539543057997,test f1: 0.5147474747474748\n",
      "train accuracy: 0.6460899017857143, test accuracy:0.6640537513997761 train loss:0.68201481, test loss:0.6805405, test precision: 0.47643979057591623,test recall: 0.5602462620932278,test f1: 0.5149555375909458\n",
      "train accuracy: 0.6374451585714286, test accuracy:0.6620940649496081 train loss:0.68189735, test loss:0.67962861, test precision: 0.5026178010471204,test recall: 0.5535420098846787,test f1: 0.5268522148177186\n",
      "train accuracy: 0.6498229689285714, test accuracy:0.6581746920492721 train loss:0.6798371, test loss:0.67857486, test precision: 0.5160807778608826,test recall: 0.5458860759493671,test f1: 0.530565167243368\n",
      "train accuracy: 0.6463496771428572, test accuracy:0.654535274356103 train loss:0.67945963, test loss:0.67755651, test precision: 0.5235602094240838,test recall: 0.5397070161912105,test f1: 0.5315110098709188\n",
      "train accuracy: 0.6417843682142857, test accuracy:0.643057110862262 train loss:0.67805619, test loss:0.67663318, test precision: 0.5295437546746448,test recall: 0.5228951255539144,test f1: 0.5261984392419176\n",
      "train accuracy: 0.6451686607142858, test accuracy:0.6422172452407615 train loss:0.6765809, test loss:0.67534065, test precision: 0.5392670157068062,test recall: 0.5213304410701374,test f1: 0.5301470588235293\n",
      "train accuracy: 0.6406514589285714, test accuracy:0.6377379619260918 train loss:0.67588411, test loss:0.67426777, test precision: 0.5445026178010471,test recall: 0.5152158527954707,test f1: 0.5294545454545454\n",
      "train accuracy: 0.6477423603571429, test accuracy:0.6371780515117581 train loss:0.67347421, test loss:0.67332006, test precision: 0.5572176514584891,test recall: 0.5141476880607315,test f1: 0.5348169418521177\n",
      "train accuracy: 0.6472396482142857, test accuracy:0.6374580067189249 train loss:0.67237309, test loss:0.67162621, test precision: 0.5534779356768885,test recall: 0.5146036161335188,test f1: 0.5333333333333333\n",
      "train accuracy: 0.6409473146428571, test accuracy:0.6357782754759238 train loss:0.67132674, test loss:0.67051011, test precision: 0.5587135377711294,test recall: 0.5123456790123457,test f1: 0.534525939177102\n",
      "train accuracy: 0.6485673867857142, test accuracy:0.6343784994400896 train loss:0.66926177, test loss:0.66903615, test precision: 0.5669409124906507,test recall: 0.5104377104377105,test f1: 0.5372076541459957\n",
      "train accuracy: 0.6466214782142856, test accuracy:0.635498320268757 train loss:0.66788306, test loss:0.66768056, test precision: 0.5699326851159312,test recall: 0.5117528542646071,test f1: 0.5392781316348196\n",
      "train accuracy: 0.6420152782142857, test accuracy:0.635498320268757 train loss:0.66700156, test loss:0.66648549, test precision: 0.5744203440538519,test recall: 0.5116588940706196,test f1: 0.5412262156448203\n",
      "train accuracy: 0.6445553025, test accuracy:0.6340985442329228 train loss:0.66431159, test loss:0.66508079, test precision: 0.5759162303664922,test recall: 0.5099337748344371,test f1: 0.5409202669476643\n",
      "train accuracy: 0.6529450824999999, test accuracy:0.6352183650615901 train loss:0.66176343, test loss:0.66308737, test precision: 0.5736724008975318,test recall: 0.5113333333333333,test f1: 0.540712019739161\n",
      "train accuracy: 0.6470833010714285, test accuracy:0.6377379619260918 train loss:0.6617109, test loss:0.66187525, test precision: 0.599850411368736,test recall: 0.5137732222934016,test f1: 0.5534851621808143\n",
      "train accuracy: 0.65550435, test accuracy:0.635498320268757 train loss:0.6587355, test loss:0.66025203, test precision: 0.6020942408376964,test recall: 0.5111111111111111,test f1: 0.5528846153846154\n",
      "train accuracy: 0.6530028096428572, test accuracy:0.6382978723404256 train loss:0.65768876, test loss:0.65834284, test precision: 0.5983545250560958,test recall: 0.5144694533762058,test f1: 0.553250345781466\n",
      "train accuracy: 0.6560383307142856, test accuracy:0.6382978723404256 train loss:0.65507204, test loss:0.65667951, test precision: 0.5976065818997757,test recall: 0.5144880875724405,test f1: 0.5529411764705883\n",
      "train accuracy: 0.6541693935714284, test accuracy:0.6363381858902576 train loss:0.653619, test loss:0.65520215, test precision: 0.599850411368736,test recall: 0.51213282247765,test f1: 0.5525318635893902\n",
      "train accuracy: 0.6507850989285714, test accuracy:0.6357782754759238 train loss:0.65167438, test loss:0.65361005, test precision: 0.600598354525056,test recall: 0.5114649681528662,test f1: 0.5524595803233574\n",
      "train accuracy: 0.6457194803571429, test accuracy:0.6357782754759238 train loss:0.65289242, test loss:0.65216321, test precision: 0.600598354525056,test recall: 0.5114649681528662,test f1: 0.5524595803233574\n",
      "train accuracy: 0.6555452400000001, test accuracy:0.6357782754759238 train loss:0.64803976, test loss:0.65024561, test precision: 0.600598354525056,test recall: 0.5114649681528662,test f1: 0.5524595803233574\n",
      "train accuracy: 0.6496618121428571, test accuracy:0.6360582306830908 train loss:0.64767095, test loss:0.64861667, test precision: 0.599850411368736,test recall: 0.5118059987236758,test f1: 0.5523415977961433\n",
      "train accuracy: 0.6596246728571428, test accuracy:0.6436170212765957 train loss:0.64549789, test loss:0.64674979, test precision: 0.5976065818997757,test recall: 0.5208604954367666,test f1: 0.5566004876349704\n",
      "train accuracy: 0.6686711060714287, test accuracy:0.643057110862262 train loss:0.64010535, test loss:0.64599091, test precision: 0.5983545250560958,test recall: 0.5201560468140443,test f1: 0.5565217391304349\n",
      "train accuracy: 0.661075085, test accuracy:0.6475363941769317 train loss:0.64079695, test loss:0.6448133, test precision: 0.6013462976813763,test recall: 0.5254901960784314,test f1: 0.5608650156958493\n",
      "train accuracy: 0.6701046792857143, test accuracy:0.6522956326987682 train loss:0.63641851, test loss:0.64195281, test precision: 0.5946148092744952,test recall: 0.5317725752508361,test f1: 0.5614406779661016\n",
      "train accuracy: 0.6690631728571429, test accuracy:0.6534154535274356 train loss:0.63655433, test loss:0.64064658, test precision: 0.5976065818997757,test recall: 0.5330220146764509,test f1: 0.5634696755994358\n",
      "train accuracy: 0.6666891153571429, test accuracy:0.6534154535274356 train loss:0.6356827, test loss:0.63865793, test precision: 0.5953627524308153,test recall: 0.5331547220361688,test f1: 0.5625441696113075\n",
      "train accuracy: 0.6743909707142857, test accuracy:0.6536954087346024 train loss:0.63135582, test loss:0.63818175, test precision: 0.5991024682124159,test recall: 0.533288948069241,test f1: 0.5642831983092639\n",
      "train accuracy: 0.669551455, test accuracy:0.6536954087346024 train loss:0.63220095, test loss:0.6365909, test precision: 0.5991024682124159,test recall: 0.533288948069241,test f1: 0.5642831983092639\n",
      "train accuracy: 0.6660541110714286, test accuracy:0.6503359462486002 train loss:0.62977724, test loss:0.63551718, test precision: 0.5841436050860135,test recall: 0.5298507462686567,test f1: 0.5556741373176806\n",
      "train accuracy: 0.6709417328571429, test accuracy:0.6514557670772676 train loss:0.62881888, test loss:0.63422394, test precision: 0.5833956619296934,test recall: 0.5313351498637602,test f1: 0.5561497326203209\n",
      "train accuracy: 0.6669512975, test accuracy:0.6525755879059351 train loss:0.62682406, test loss:0.63337886, test precision: 0.5833956619296934,test recall: 0.5327868852459017,test f1: 0.5569439485897895\n",
      "train accuracy: 0.6690078514285714, test accuracy:0.6534154535274356 train loss:0.62553954, test loss:0.63300347, test precision: 0.581151832460733,test recall: 0.534020618556701,test f1: 0.5565902578796562\n",
      "train accuracy: 0.6742225985714285, test accuracy:0.6553751399776035 train loss:0.62317336, test loss:0.63056892, test precision: 0.5766641735228123,test recall: 0.536908077994429,test f1: 0.5560764514965741\n",
      "train accuracy: 0.6666554410714286, test accuracy:0.6542553191489362 train loss:0.62490643, test loss:0.63110507, test precision: 0.599850411368736,test recall: 0.5339547270306259,test f1: 0.5649876717153927\n",
      "train accuracy: 0.6735611335714285, test accuracy:0.6542553191489362 train loss:0.61968417, test loss:0.63048309, test precision: 0.599850411368736,test recall: 0.5339547270306259,test f1: 0.5649876717153927\n",
      "train accuracy: 0.6690655785714286, test accuracy:0.6601343784994401 train loss:0.62417476, test loss:0.62894911, test precision: 0.5938668661181751,test recall: 0.5419795221843003,test f1: 0.5667380442541042\n",
      "train accuracy: 0.6726495157142859, test accuracy:0.6612541993281075 train loss:0.62145498, test loss:0.626315, test precision: 0.5908750934928946,test recall: 0.5437026841018582,test f1: 0.5663082437275986\n",
      "train accuracy: 0.6716056039285714, test accuracy:0.6612541993281075 train loss:0.61890587, test loss:0.62584788, test precision: 0.5908750934928946,test recall: 0.5437026841018582,test f1: 0.5663082437275986\n",
      "train accuracy: 0.6770320189285715, test accuracy:0.6612541993281075 train loss:0.61690393, test loss:0.62536037, test precision: 0.5908750934928946,test recall: 0.5437026841018582,test f1: 0.5663082437275986\n",
      "train accuracy: 0.6809190278571429, test accuracy:0.6612541993281075 train loss:0.6153883, test loss:0.62492067, test precision: 0.5908750934928946,test recall: 0.5437026841018582,test f1: 0.5663082437275986\n",
      "train accuracy: 0.6764763899999998, test accuracy:0.6606942889137738 train loss:0.61636477, test loss:0.62522775, test precision: 0.5916230366492147,test recall: 0.5428963623884695,test f1: 0.5662133142448103\n",
      "train accuracy: 0.6772436882142856, test accuracy:0.6626539753639418 train loss:0.61285442, test loss:0.62274313, test precision: 0.5856394913986537,test recall: 0.5460251046025104,test f1: 0.5651389390111872\n",
      "train accuracy: 0.678191387857143, test accuracy:0.6626539753639418 train loss:0.61247543, test loss:0.62252611, test precision: 0.5856394913986537,test recall: 0.5460251046025104,test f1: 0.5651389390111872\n",
      "train accuracy: 0.6755864196428573, test accuracy:0.6626539753639418 train loss:0.61520191, test loss:0.62213975, test precision: 0.5826477187733732,test recall: 0.5462833099579243,test f1: 0.563879840752805\n",
      "train accuracy: 0.6749586285714285, test accuracy:0.6648936170212766 train loss:0.6107821, test loss:0.62097514, test precision: 0.5796559461480928,test recall: 0.549645390070922,test f1: 0.5642519111758282\n",
      "train accuracy: 0.6792112453571428, test accuracy:0.6646136618141097 train loss:0.60745549, test loss:0.62037939, test precision: 0.587135377711294,test recall: 0.5485674353598882,test f1: 0.5671965317919075\n",
      "train accuracy: 0.6816117603571429, test accuracy:0.666013437849944 train loss:0.60768024, test loss:0.62083858, test precision: 0.5908750934928946,test recall: 0.5501392757660167,test f1: 0.5697800216372161\n",
      "train accuracy: 0.6801685653571428, test accuracy:0.6693729003359462 train loss:0.6083123, test loss:0.61814314, test precision: 0.5848915482423336,test recall: 0.5553977272727273,test f1: 0.5697632058287796\n",
      "train accuracy: 0.6770416410714286, test accuracy:0.6665733482642777 train loss:0.6101915, test loss:0.61943662, test precision: 0.5893792071802543,test recall: 0.551048951048951,test f1: 0.5695699313335743\n",
      "train accuracy: 0.6806929267857144, test accuracy:0.6665733482642777 train loss:0.60711079, test loss:0.61984807, test precision: 0.5893792071802543,test recall: 0.551048951048951,test f1: 0.5695699313335743\n",
      "train accuracy: 0.6780999853571429, test accuracy:0.6671332586786114 train loss:0.60887718, test loss:0.61903757, test precision: 0.5893792071802543,test recall: 0.5518207282913166,test f1: 0.5699819168173599\n",
      "train accuracy: 0.6795672339285714, test accuracy:0.6648936170212766 train loss:0.60915853, test loss:0.61931276, test precision: 0.5901271503365744,test recall: 0.5486787204450626,test f1: 0.5686486486486485\n",
      "train accuracy: 0.6727096489285714, test accuracy:0.6671332586786114 train loss:0.61453345, test loss:0.61835915, test precision: 0.5893792071802543,test recall: 0.5518207282913166,test f1: 0.5699819168173599\n",
      "train accuracy: 0.6757740339285715, test accuracy:0.6657334826427772 train loss:0.61220961, test loss:0.61966234, test precision: 0.6073298429319371,test recall: 0.5482781904118839,test f1: 0.5762952448545067\n",
      "train accuracy: 0.6827566964285714, test accuracy:0.6674132138857782 train loss:0.60584589, test loss:0.61947483, test precision: 0.6095736724008975,test recall: 0.550303848750844,test f1: 0.5784244144783535\n",
      "train accuracy: 0.6804644207142856, test accuracy:0.6674132138857782 train loss:0.60715701, test loss:0.62051553, test precision: 0.6095736724008975,test recall: 0.550303848750844,test f1: 0.5784244144783535\n",
      "train accuracy: 0.6748527939285714, test accuracy:0.6676931690929452 train loss:0.61263746, test loss:0.61979222, test precision: 0.6088257292445775,test recall: 0.550744248985115,test f1: 0.5783303730017761\n",
      "train accuracy: 0.6875625382142856, test accuracy:0.6730123180291153 train loss:0.60324855, test loss:0.61593604, test precision: 0.6013462976813763,test recall: 0.5587213342599027,test f1: 0.579250720461095\n",
      "train accuracy: 0.6835672910714286, test accuracy:0.6738521836506159 train loss:0.6058408, test loss:0.61463022, test precision: 0.6043380703066566,test recall: 0.5595567867036011,test f1: 0.5810859403092412\n",
      "train accuracy: 0.6775756242857144, test accuracy:0.667973124300112 train loss:0.60830495, test loss:0.61783588, test precision: 0.6088257292445775,test recall: 0.5511171293161814,test f1: 0.5785358919687277\n",
      "train accuracy: 0.6821216910714286, test accuracy:0.667973124300112 train loss:0.60657898, test loss:0.61707568, test precision: 0.6088257292445775,test recall: 0.5511171293161814,test f1: 0.5785358919687277\n",
      "train accuracy: 0.6751751089285714, test accuracy:0.667973124300112 train loss:0.60901938, test loss:0.6161921, test precision: 0.6080777860882572,test recall: 0.5511864406779661,test f1: 0.5782361308677098\n",
      "train accuracy: 0.6795503971428571, test accuracy:0.6682530795072789 train loss:0.60923664, test loss:0.61678058, test precision: 0.6088257292445775,test recall: 0.551490514905149,test f1: 0.5787415570565232\n",
      "train accuracy: 0.6786123192857143, test accuracy:0.6710526315789473 train loss:0.60633108, test loss:0.61503345, test precision: 0.6073298429319371,test recall: 0.5554035567715458,test f1: 0.5802072168631655\n",
      "train accuracy: 0.6884693464285715, test accuracy:0.6682530795072789 train loss:0.60063866, test loss:0.6162867, test precision: 0.6088257292445775,test recall: 0.551490514905149,test f1: 0.5787415570565232\n",
      "train accuracy: 0.6818739414285714, test accuracy:0.6713325867861142 train loss:0.60364264, test loss:0.61522824, test precision: 0.6080777860882572,test recall: 0.5557074504442926,test f1: 0.5807142857142857\n",
      "train accuracy: 0.6747902553571429, test accuracy:0.667973124300112 train loss:0.60766079, test loss:0.6172666, test precision: 0.6103216155572176,test recall: 0.550979068197164,test f1: 0.5791341376863022\n",
      "train accuracy: 0.6848348978571429, test accuracy:0.6682530795072789 train loss:0.60268121, test loss:0.61480135, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6838559310714286, test accuracy:0.6682530795072789 train loss:0.60110192, test loss:0.6142875, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6793242960714286, test accuracy:0.6682530795072789 train loss:0.60614923, test loss:0.61457741, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6884236460714286, test accuracy:0.6682530795072789 train loss:0.59837353, test loss:0.61462468, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6833075160714286, test accuracy:0.6682530795072789 train loss:0.60078746, test loss:0.61509931, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6846785521428572, test accuracy:0.6682530795072789 train loss:0.60106519, test loss:0.61356485, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6821505546428571, test accuracy:0.6682530795072789 train loss:0.60257445, test loss:0.61402351, test precision: 0.6095736724008975,test recall: 0.5514208389715832,test f1: 0.5790408525754884\n",
      "train accuracy: 0.6856094128571427, test accuracy:0.6690929451287794 train loss:0.59630158, test loss:0.61245614, test precision: 0.6035901271503366,test recall: 0.5531185743660041,test f1: 0.5772532188841202\n",
      "train accuracy: 0.6849383278571429, test accuracy:0.6744120940649496 train loss:0.59725315, test loss:0.61127633, test precision: 0.599850411368736,test recall: 0.5608391608391609,test f1: 0.5796891940730033\n",
      "train accuracy: 0.6809599192857142, test accuracy:0.6676931690929452 train loss:0.60185564, test loss:0.61504781, test precision: 0.6110695587135377,test recall: 0.5505390835579514,test f1: 0.5792272243885148\n",
      "train accuracy: 0.6777343746428572, test accuracy:0.6682530795072789 train loss:0.60290904, test loss:0.61424601, test precision: 0.6050860134629769,test recall: 0.5518417462482946,test f1: 0.5772386728505172\n",
      "train accuracy: 0.6878223139285715, test accuracy:0.6707726763717805 train loss:0.5963047, test loss:0.61207038, test precision: 0.6035901271503366,test recall: 0.5554026152787337,test f1: 0.578494623655914\n",
      "train accuracy: 0.6766736253571429, test accuracy:0.6707726763717805 train loss:0.60269505, test loss:0.61187071, test precision: 0.6035901271503366,test recall: 0.5554026152787337,test f1: 0.578494623655914\n",
      "train accuracy: 0.6812196925, test accuracy:0.6710526315789473 train loss:0.60284261, test loss:0.61190486, test precision: 0.6013462976813763,test recall: 0.5560165975103735,test f1: 0.5777937477542221\n",
      "train accuracy: 0.690540332142857, test accuracy:0.6707726763717805 train loss:0.59688696, test loss:0.61118442, test precision: 0.6035901271503366,test recall: 0.5554026152787337,test f1: 0.578494623655914\n",
      "train accuracy: 0.6791631400000001, test accuracy:0.671892497200448 train loss:0.60192862, test loss:0.60961479, test precision: 0.600598354525056,test recall: 0.5572519083969466,test f1: 0.578113750899928\n",
      "train accuracy: 0.6817151903571429, test accuracy:0.671612541993281 train loss:0.60084164, test loss:0.60950017, test precision: 0.599850411368736,test recall: 0.5569444444444445,test f1: 0.5776017284839755\n",
      "train accuracy: 0.6785112957142857, test accuracy:0.671612541993281 train loss:0.6025328, test loss:0.60976034, test precision: 0.600598354525056,test recall: 0.5568654646324549,test f1: 0.5779057214825476\n",
      "train accuracy: 0.6936961214285715, test accuracy:0.6710526315789473 train loss:0.59262497, test loss:0.61037093, test precision: 0.6020942408376964,test recall: 0.555939226519337,test f1: 0.578096947935368\n",
      "train accuracy: 0.6826244032142859, test accuracy:0.6710526315789473 train loss:0.59819061, test loss:0.61203909, test precision: 0.6028421839940165,test recall: 0.5558620689655173,test f1: 0.5783997129529961\n",
      "train accuracy: 0.6827013732142858, test accuracy:0.671892497200448 train loss:0.59886622, test loss:0.60866195, test precision: 0.600598354525056,test recall: 0.5572519083969466,test f1: 0.578113750899928\n",
      "train accuracy: 0.6785690239285714, test accuracy:0.671892497200448 train loss:0.60069788, test loss:0.60766041, test precision: 0.599850411368736,test recall: 0.5573314801945796,test f1: 0.5778097982708933\n",
      "train accuracy: 0.67835976, test accuracy:0.671892497200448 train loss:0.60273992, test loss:0.60976404, test precision: 0.6020942408376964,test recall: 0.5570934256055363,test f1: 0.5787203450754852\n",
      "train accuracy: 0.6852822885714286, test accuracy:0.671892497200448 train loss:0.59638299, test loss:0.60990083, test precision: 0.6020942408376964,test recall: 0.5570934256055363,test f1: 0.5787203450754852\n",
      "train accuracy: 0.6845053685714285, test accuracy:0.6707726763717805 train loss:0.59766689, test loss:0.61086297, test precision: 0.6035901271503366,test recall: 0.5554026152787337,test f1: 0.578494623655914\n",
      "train accuracy: 0.6782948157142857, test accuracy:0.6730123180291153 train loss:0.60242254, test loss:0.60879445, test precision: 0.6028421839940165,test recall: 0.5585585585585585,test f1: 0.5798561151079136\n",
      "train accuracy: 0.6844668824999999, test accuracy:0.6732922732362822 train loss:0.60039082, test loss:0.60769349, test precision: 0.6028421839940165,test recall: 0.5589459084604715,test f1: 0.5800647715005397\n",
      "train accuracy: 0.6817344332142857, test accuracy:0.6738521836506159 train loss:0.60014092, test loss:0.60631639, test precision: 0.6013462976813763,test recall: 0.5598885793871866,test f1: 0.5798773891092679\n",
      "train accuracy: 0.6883298375000001, test accuracy:0.673572228443449 train loss:0.59016849, test loss:0.60554326, test precision: 0.600598354525056,test recall: 0.5595818815331011,test f1: 0.5793650793650794\n",
      "train accuracy: 0.6855805492857143, test accuracy:0.6732922732362822 train loss:0.59564788, test loss:0.60630041, test precision: 0.6013462976813763,test recall: 0.5591098748261474,test f1: 0.5794594594594594\n",
      "train accuracy: 0.6919065560714286, test accuracy:0.6730123180291153 train loss:0.59103824, test loss:0.60716259, test precision: 0.6028421839940165,test recall: 0.5585585585585585,test f1: 0.5798561151079136\n",
      "train accuracy: 0.6869058853571429, test accuracy:0.6730123180291153 train loss:0.59303184, test loss:0.6072439, test precision: 0.6028421839940165,test recall: 0.5585585585585585,test f1: 0.5798561151079136\n",
      "train accuracy: 0.6798462510714286, test accuracy:0.6727323628219485 train loss:0.59814958, test loss:0.60832405, test precision: 0.6028421839940165,test recall: 0.5581717451523546,test f1: 0.5796476087738224\n",
      "train accuracy: 0.6877693957142856, test accuracy:0.6738521836506159 train loss:0.59142747, test loss:0.60474211, test precision: 0.6013462976813763,test recall: 0.5598885793871866,test f1: 0.5798773891092679\n",
      "train accuracy: 0.6853568539285714, test accuracy:0.6732922732362822 train loss:0.59258607, test loss:0.60581911, test precision: 0.6028421839940165,test recall: 0.5589459084604715,test f1: 0.5800647715005397\n",
      "train accuracy: 0.6828240457142857, test accuracy:0.6727323628219485 train loss:0.59544801, test loss:0.60836768, test precision: 0.6028421839940165,test recall: 0.5581717451523546,test f1: 0.5796476087738224\n",
      "train accuracy: 0.6845294225, test accuracy:0.6727323628219485 train loss:0.59435023, test loss:0.60594243, test precision: 0.6028421839940165,test recall: 0.5581717451523546,test f1: 0.5796476087738224\n",
      "train accuracy: 0.682083205, test accuracy:0.6727323628219485 train loss:0.5955964, test loss:0.60661769, test precision: 0.6028421839940165,test recall: 0.5581717451523546,test f1: 0.5796476087738224\n",
      "train accuracy: 0.6888710353571428, test accuracy:0.6727323628219485 train loss:0.59495457, test loss:0.60582703, test precision: 0.6028421839940165,test recall: 0.5581717451523546,test f1: 0.5796476087738224\n",
      "train accuracy: 0.6850658089285714, test accuracy:0.6727323628219485 train loss:0.59859298, test loss:0.60431468, test precision: 0.6020942408376964,test recall: 0.558252427184466,test f1: 0.5793450881612091\n",
      "train accuracy: 0.6899365967857142, test accuracy:0.6727323628219485 train loss:0.59257254, test loss:0.6039381, test precision: 0.6020942408376964,test recall: 0.558252427184466,test f1: 0.5793450881612091\n",
      "train accuracy: 0.685395340357143, test accuracy:0.6724524076147816 train loss:0.58815524, test loss:0.60504889, test precision: 0.6028421839940165,test recall: 0.5577854671280277,test f1: 0.5794392523364486\n",
      "train accuracy: 0.6855757385714286, test accuracy:0.671612541993281 train loss:0.59242313, test loss:0.60835516, test precision: 0.6035901271503366,test recall: 0.5565517241379311,test f1: 0.5791173304628632\n",
      "train accuracy: 0.6844644789285715, test accuracy:0.6721724524076148 train loss:0.59601679, test loss:0.60642999, test precision: 0.6028421839940165,test recall: 0.5573997233748271,test f1: 0.5792310456342076\n",
      "train accuracy: 0.6872113596428571, test accuracy:0.675531914893617 train loss:0.59247909, test loss:0.60295779, test precision: 0.5983545250560958,test recall: 0.5625879043600562,test f1: 0.5799202609641174\n",
      "train accuracy: 0.684375479642857, test accuracy:0.6721724524076148 train loss:0.59496298, test loss:0.6067639, test precision: 0.6028421839940165,test recall: 0.5573997233748271,test f1: 0.5792310456342076\n",
      "train accuracy: 0.6884717510714286, test accuracy:0.6724524076147816 train loss:0.59315926, test loss:0.604487, test precision: 0.6028421839940165,test recall: 0.5577854671280277,test f1: 0.5794392523364486\n",
      "train accuracy: 0.6889576267857144, test accuracy:0.6724524076147816 train loss:0.58756642, test loss:0.60357308, test precision: 0.6020942408376964,test recall: 0.5578655578655579,test f1: 0.579136690647482\n",
      "train accuracy: 0.6878415557142856, test accuracy:0.6732922732362822 train loss:0.58786323, test loss:0.60369951, test precision: 0.6013462976813763,test recall: 0.5591098748261474,test f1: 0.5794594594594594\n",
      "train accuracy: 0.6831872499999999, test accuracy:0.6721724524076148 train loss:0.59516042, test loss:0.60562879, test precision: 0.6028421839940165,test recall: 0.5573997233748271,test f1: 0.5792310456342076\n",
      "train accuracy: 0.6871319853571428, test accuracy:0.671612541993281 train loss:0.59366334, test loss:0.60740161, test precision: 0.606581899775617,test recall: 0.556241426611797,test f1: 0.5803220035778176\n",
      "train accuracy: 0.6866966210714286, test accuracy:0.6724524076147816 train loss:0.59196021, test loss:0.60572022, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6834758892857142, test accuracy:0.6760918253079508 train loss:0.59615099, test loss:0.60190815, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6865186278571428, test accuracy:0.6760918253079508 train loss:0.58997767, test loss:0.60120654, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6887291217857143, test accuracy:0.6760918253079508 train loss:0.59013395, test loss:0.60171694, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6904128510714287, test accuracy:0.6758118701007839 train loss:0.58741118, test loss:0.60285407, test precision: 0.5976065818997757,test recall: 0.5630725863284003,test f1: 0.5798258345428158\n",
      "train accuracy: 0.6872738992857144, test accuracy:0.675531914893617 train loss:0.59073653, test loss:0.60319263, test precision: 0.5983545250560958,test recall: 0.5625879043600562,test f1: 0.5799202609641174\n",
      "train accuracy: 0.6956901364285715, test accuracy:0.6760918253079508 train loss:0.58545384, test loss:0.60117787, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6838198510714285, test accuracy:0.6760918253079508 train loss:0.59395023, test loss:0.60013914, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6931020057142857, test accuracy:0.675531914893617 train loss:0.58598172, test loss:0.60354906, test precision: 0.6020942408376964,test recall: 0.5621508379888268,test f1: 0.5814373420007223\n",
      "train accuracy: 0.6897874664285714, test accuracy:0.675531914893617 train loss:0.59011404, test loss:0.60238367, test precision: 0.5983545250560958,test recall: 0.5625879043600562,test f1: 0.5799202609641174\n",
      "train accuracy: 0.6929360371428571, test accuracy:0.6760918253079508 train loss:0.58879529, test loss:0.60091799, test precision: 0.5961106955871354,test recall: 0.5636492220650636,test f1: 0.5794256633951291\n",
      "train accuracy: 0.6915938671428571, test accuracy:0.675531914893617 train loss:0.58790302, test loss:0.60185462, test precision: 0.5983545250560958,test recall: 0.5625879043600562,test f1: 0.5799202609641174\n",
      "train accuracy: 0.6900881314285715, test accuracy:0.6752519596864501 train loss:0.5868724, test loss:0.60214198, test precision: 0.6013462976813763,test recall: 0.5618448637316562,test f1: 0.5809248554913294\n",
      "train accuracy: 0.6899558378571429, test accuracy:0.6752519596864501 train loss:0.58611488, test loss:0.60276479, test precision: 0.6073298429319371,test recall: 0.5611610228058052,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6849792182142856, test accuracy:0.675531914893617 train loss:0.59250644, test loss:0.60022163, test precision: 0.5968586387434555,test recall: 0.5627644569816643,test f1: 0.5793103448275863\n",
      "train accuracy: 0.6943263153571427, test accuracy:0.6783314669652856 train loss:0.58382809, test loss:0.5991866, test precision: 0.5931189229618549,test recall: 0.567238912732475,test f1: 0.5798903107861061\n",
      "train accuracy: 0.6889937078571429, test accuracy:0.6780515117581187 train loss:0.58887014, test loss:0.60015082, test precision: 0.5961106955871354,test recall: 0.566453447050462,test f1: 0.5809037900874635\n",
      "train accuracy: 0.6885126435714285, test accuracy:0.6783314669652856 train loss:0.59017761, test loss:0.59807217, test precision: 0.5931189229618549,test recall: 0.567238912732475,test f1: 0.5798903107861061\n",
      "train accuracy: 0.6925752389285715, test accuracy:0.6788913773796192 train loss:0.58644986, test loss:0.59640276, test precision: 0.5923709798055348,test recall: 0.5681492109038737,test f1: 0.5800073233247894\n",
      "train accuracy: 0.68970809, test accuracy:0.673572228443449 train loss:0.58975539, test loss:0.60247076, test precision: 0.605833956619297,test recall: 0.5590062111801242,test f1: 0.5814788226848528\n",
      "train accuracy: 0.681542005, test accuracy:0.6724524076147816 train loss:0.58965129, test loss:0.60503054, test precision: 0.612565445026178,test recall: 0.5567641060503059,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6924212985714285, test accuracy:0.6777715565509519 train loss:0.58635886, test loss:0.59967691, test precision: 0.6020942408376964,test recall: 0.5653089887640449,test f1: 0.5831220572256428\n",
      "train accuracy: 0.6932607564285714, test accuracy:0.6780515117581187 train loss:0.58445844, test loss:0.59804356, test precision: 0.5968586387434555,test recall: 0.5663591199432222,test f1: 0.5812090313182812\n",
      "train accuracy: 0.6841686239285714, test accuracy:0.6777715565509519 train loss:0.59054328, test loss:0.59828854, test precision: 0.5968586387434555,test recall: 0.5659574468085107,test f1: 0.5809974517655623\n",
      "train accuracy: 0.6851211332142858, test accuracy:0.6780515117581187 train loss:0.59138407, test loss:0.59808147, test precision: 0.5976065818997757,test recall: 0.5662650602409639,test f1: 0.5815138282387191\n",
      "train accuracy: 0.688717095, test accuracy:0.6746920492721165 train loss:0.58443718, test loss:0.59937799, test precision: 0.6035901271503366,test recall: 0.5608061153578874,test f1: 0.5814121037463977\n",
      "train accuracy: 0.6926089142857142, test accuracy:0.6744120940649496 train loss:0.5859215, test loss:0.59966666, test precision: 0.605833956619297,test recall: 0.5601659751037344,test f1: 0.582105641394179\n",
      "train accuracy: 0.6806159557142857, test accuracy:0.6744120940649496 train loss:0.59043642, test loss:0.60016233, test precision: 0.605833956619297,test recall: 0.5601659751037344,test f1: 0.582105641394179\n",
      "train accuracy: 0.6867062417857143, test accuracy:0.6746920492721165 train loss:0.58712645, test loss:0.59980035, test precision: 0.6043380703066566,test recall: 0.5607217210270645,test f1: 0.5817134629229661\n",
      "train accuracy: 0.6897898717857143, test accuracy:0.6752519596864501 train loss:0.58704333, test loss:0.59761775, test precision: 0.6028421839940165,test recall: 0.5616724738675958,test f1: 0.5815295815295815\n",
      "train accuracy: 0.6901242114285715, test accuracy:0.6746920492721165 train loss:0.58097335, test loss:0.59943759, test precision: 0.6035901271503366,test recall: 0.5608061153578874,test f1: 0.5814121037463977\n",
      "train accuracy: 0.6939703275, test accuracy:0.6746920492721165 train loss:0.5817427, test loss:0.59856558, test precision: 0.6028421839940165,test recall: 0.5608907446068198,test f1: 0.5811103100216294\n",
      "train accuracy: 0.6901626967857143, test accuracy:0.6763717805151176 train loss:0.5867232, test loss:0.59540844, test precision: 0.5961106955871354,test recall: 0.5640481245576787,test f1: 0.5796363636363636\n",
      "train accuracy: 0.6919089621428572, test accuracy:0.6752519596864501 train loss:0.58405816, test loss:0.5968045, test precision: 0.6028421839940165,test recall: 0.5616724738675958,test f1: 0.5815295815295815\n",
      "train accuracy: 0.6964093282142857, test accuracy:0.6746920492721165 train loss:0.57918431, test loss:0.59818065, test precision: 0.6035901271503366,test recall: 0.5608061153578874,test f1: 0.5814121037463977\n",
      "train accuracy: 0.6859100800000001, test accuracy:0.6752519596864501 train loss:0.58559659, test loss:0.59633809, test precision: 0.6028421839940165,test recall: 0.5616724738675958,test f1: 0.5815295815295815\n",
      "train accuracy: 0.6879089053571429, test accuracy:0.6752519596864501 train loss:0.58507587, test loss:0.59696186, test precision: 0.6035901271503366,test recall: 0.5615866388308977,test f1: 0.5818312905551549\n",
      "train accuracy: 0.6890370025, test accuracy:0.6752519596864501 train loss:0.58443476, test loss:0.5965516, test precision: 0.6035901271503366,test recall: 0.5615866388308977,test f1: 0.5818312905551549\n",
      "train accuracy: 0.6875986189285713, test accuracy:0.6752519596864501 train loss:0.58881277, test loss:0.59693992, test precision: 0.6035901271503366,test recall: 0.5615866388308977,test f1: 0.5818312905551549\n",
      "train accuracy: 0.6912883900000001, test accuracy:0.6721724524076148 train loss:0.58205823, test loss:0.597413, test precision: 0.605833956619297,test recall: 0.5570839064649243,test f1: 0.5804371193120745\n",
      "train accuracy: 0.6906124935714286, test accuracy:0.6749720044792833 train loss:0.58291557, test loss:0.59643745, test precision: 0.6035901271503366,test recall: 0.5611961057023644,test f1: 0.5816216216216217\n",
      "train accuracy: 0.69416997, test accuracy:0.6724524076147816 train loss:0.57921143, test loss:0.59848362, test precision: 0.6110695587135377,test recall: 0.5569188820722563,test f1: 0.5827389443651926\n",
      "train accuracy: 0.6895421225, test accuracy:0.671892497200448 train loss:0.58260886, test loss:0.59943157, test precision: 0.6133133881824981,test recall: 0.5559322033898305,test f1: 0.5832147937411095\n",
      "train accuracy: 0.6909516428571428, test accuracy:0.6732922732362822 train loss:0.58498473, test loss:0.5971759, test precision: 0.6095736724008975,test recall: 0.5582191780821918,test f1: 0.5827672506256705\n",
      "train accuracy: 0.6903118260714285, test accuracy:0.6749720044792833 train loss:0.585278, test loss:0.59646446, test precision: 0.6073298429319371,test recall: 0.5607734806629834,test f1: 0.5831238779174147\n",
      "train accuracy: 0.6804451789285715, test accuracy:0.6749720044792833 train loss:0.58924226, test loss:0.59641343, test precision: 0.6073298429319371,test recall: 0.5607734806629834,test f1: 0.5831238779174147\n",
      "train accuracy: 0.6944489882142857, test accuracy:0.6760918253079508 train loss:0.58069606, test loss:0.59412408, test precision: 0.606581899775617,test recall: 0.5624133148404993,test f1: 0.5836631881971933\n",
      "train accuracy: 0.6957286210714285, test accuracy:0.6760918253079508 train loss:0.57721839, test loss:0.59492201, test precision: 0.6073298429319371,test recall: 0.5623268698060941,test f1: 0.5839626033800791\n",
      "train accuracy: 0.6901458596428572, test accuracy:0.6758118701007839 train loss:0.5844146, test loss:0.59526145, test precision: 0.6073298429319371,test recall: 0.5619377162629757,test f1: 0.5837526959022286\n",
      "train accuracy: 0.69140625, test accuracy:0.6763717805151176 train loss:0.58395582, test loss:0.59376484, test precision: 0.606581899775617,test recall: 0.5628036086051353,test f1: 0.5838732901367891\n",
      "train accuracy: 0.6872089560714286, test accuracy:0.6774916013437849 train loss:0.58552107, test loss:0.59349042, test precision: 0.606581899775617,test recall: 0.5643702157272095,test f1: 0.5847152126892573\n",
      "train accuracy: 0.6856791682142858, test accuracy:0.6760918253079508 train loss:0.58991626, test loss:0.59559202, test precision: 0.6088257292445775,test recall: 0.5621546961325967,test f1: 0.584560143626571\n",
      "train accuracy: 0.6932487296428571, test accuracy:0.6772116461366181 train loss:0.58090849, test loss:0.59195739, test precision: 0.605833956619297,test recall: 0.564066852367688,test f1: 0.5842048323115759\n",
      "train accuracy: 0.6928783110714285, test accuracy:0.6772116461366181 train loss:0.57878364, test loss:0.59238827, test precision: 0.605833956619297,test recall: 0.564066852367688,test f1: 0.5842048323115759\n",
      "train accuracy: 0.6930538982142858, test accuracy:0.6763717805151176 train loss:0.57680908, test loss:0.59416902, test precision: 0.605833956619297,test recall: 0.5628908964558721,test f1: 0.5835734870317002\n",
      "train accuracy: 0.6903262582142856, test accuracy:0.6772116461366181 train loss:0.58487684, test loss:0.59274423, test precision: 0.605833956619297,test recall: 0.564066852367688,test f1: 0.5842048323115759\n",
      "train accuracy: 0.6894435032142857, test accuracy:0.6774916013437849 train loss:0.58016784, test loss:0.59601146, test precision: 0.6118175018698578,test recall: 0.5637491385251551,test f1: 0.5868005738880918\n",
      "train accuracy: 0.6944297446428571, test accuracy:0.6774916013437849 train loss:0.57850271, test loss:0.59341127, test precision: 0.606581899775617,test recall: 0.5643702157272095,test f1: 0.5847152126892573\n",
      "train accuracy: 0.6943335321428571, test accuracy:0.6774916013437849 train loss:0.57551696, test loss:0.59257454, test precision: 0.606581899775617,test recall: 0.5643702157272095,test f1: 0.5847152126892573\n",
      "train accuracy: 0.6933569682142856, test accuracy:0.6777715565509519 train loss:0.57809623, test loss:0.5941087, test precision: 0.6110695587135377,test recall: 0.5642265193370166,test f1: 0.5867145421903053\n",
      "train accuracy: 0.6932727828571429, test accuracy:0.6774916013437849 train loss:0.57871501, test loss:0.59474695, test precision: 0.6110695587135377,test recall: 0.5638371290545203,test f1: 0.5865039483129935\n",
      "train accuracy: 0.6858595671428571, test accuracy:0.6822508398656215 train loss:0.5822157, test loss:0.58963144, test precision: 0.6050860134629769,test recall: 0.5713276836158192,test f1: 0.5877224845622956\n",
      "train accuracy: 0.68845732, test accuracy:0.6760918253079508 train loss:0.58000153, test loss:0.59250551, test precision: 0.605833956619297,test recall: 0.5625,test f1: 0.583363341735686\n",
      "train accuracy: 0.693840442142857, test accuracy:0.6763717805151176 train loss:0.57568581, test loss:0.59463608, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.694064134642857, test accuracy:0.6805711086226204 train loss:0.57606461, test loss:0.5918979, test precision: 0.6080777860882572,test recall: 0.5685314685314685,test f1: 0.5876400433682689\n",
      "train accuracy: 0.6948867567857143, test accuracy:0.6774916013437849 train loss:0.57836393, test loss:0.59274679, test precision: 0.6110695587135377,test recall: 0.5638371290545203,test f1: 0.5865039483129935\n",
      "train accuracy: 0.689349694642857, test accuracy:0.6774916013437849 train loss:0.58100337, test loss:0.59372854, test precision: 0.6110695587135377,test recall: 0.5638371290545203,test f1: 0.5865039483129935\n",
      "train accuracy: 0.689561365357143, test accuracy:0.6774916013437849 train loss:0.58261218, test loss:0.59349006, test precision: 0.6110695587135377,test recall: 0.5638371290545203,test f1: 0.5865039483129935\n",
      "train accuracy: 0.6960340985714286, test accuracy:0.6805711086226204 train loss:0.57395937, test loss:0.59176636, test precision: 0.6103216155572176,test recall: 0.5682451253481894,test f1: 0.5885322755138839\n",
      "train accuracy: 0.6885631542857142, test accuracy:0.6805711086226204 train loss:0.57771237, test loss:0.59078246, test precision: 0.6080777860882572,test recall: 0.5685314685314685,test f1: 0.5876400433682689\n",
      "train accuracy: 0.6874110025, test accuracy:0.6805711086226204 train loss:0.57990031, test loss:0.59075582, test precision: 0.6080777860882572,test recall: 0.5685314685314685,test f1: 0.5876400433682689\n",
      "train accuracy: 0.6933016467857142, test accuracy:0.6816909294512878 train loss:0.57432292, test loss:0.59099013, test precision: 0.6080777860882572,test recall: 0.5701262272089762,test f1: 0.5884907709011943\n",
      "train accuracy: 0.6899871075, test accuracy:0.6805711086226204 train loss:0.58129824, test loss:0.59176314, test precision: 0.6103216155572176,test recall: 0.5682451253481894,test f1: 0.5885322755138839\n",
      "train accuracy: 0.6894964217857142, test accuracy:0.6772116461366181 train loss:0.57970795, test loss:0.5932284, test precision: 0.6110695587135377,test recall: 0.5634482758620689,test f1: 0.5862935055615357\n",
      "train accuracy: 0.6892919689285714, test accuracy:0.6878499440089586 train loss:0.58222017, test loss:0.59096473, test precision: 0.6095736724008975,test recall: 0.5788352272727273,test f1: 0.5938069216757741\n",
      "train accuracy: 0.6972151121428573, test accuracy:0.6900895856662934 train loss:0.5760916, test loss:0.58814424, test precision: 0.5961106955871354,test recall: 0.5843108504398827,test f1: 0.5901517956312476\n",
      "train accuracy: 0.6951970449999999, test accuracy:0.6878499440089586 train loss:0.57978205, test loss:0.58960122, test precision: 0.6088257292445775,test recall: 0.5789473684210527,test f1: 0.5935107546481954\n",
      "train accuracy: 0.6982085128571428, test accuracy:0.6867301231802911 train loss:0.57328341, test loss:0.59055477, test precision: 0.6088257292445775,test recall: 0.577304964539007,test f1: 0.5926465234801601\n",
      "train accuracy: 0.6926642353571429, test accuracy:0.687010078387458 train loss:0.57762146, test loss:0.58993, test precision: 0.6088257292445775,test recall: 0.5777146912704045,test f1: 0.5928623452294247\n",
      "train accuracy: 0.6942854257142858, test accuracy:0.6886898096304591 train loss:0.5788693, test loss:0.58923995, test precision: 0.6088257292445775,test recall: 0.5801853171774768,test f1: 0.5941605839416059\n",
      "train accuracy: 0.6947352232142858, test accuracy:0.6836506159014558 train loss:0.58113779, test loss:0.59190243, test precision: 0.6110695587135377,test recall: 0.5725297827610372,test f1: 0.5911722141823444\n",
      "train accuracy: 0.6916010821428572, test accuracy:0.6836506159014558 train loss:0.58014935, test loss:0.5935384, test precision: 0.6110695587135377,test recall: 0.5725297827610372,test f1: 0.5911722141823444\n",
      "train accuracy: 0.7004286292857144, test accuracy:0.6878499440089586 train loss:0.57442101, test loss:0.58945262, test precision: 0.6088257292445775,test recall: 0.5789473684210527,test f1: 0.5935107546481954\n",
      "train accuracy: 0.6993245835714286, test accuracy:0.6878499440089586 train loss:0.57550672, test loss:0.58951253, test precision: 0.6088257292445775,test recall: 0.5789473684210527,test f1: 0.5935107546481954\n",
      "train accuracy: 0.6944802571428571, test accuracy:0.6878499440089586 train loss:0.5776366, test loss:0.59011209, test precision: 0.6088257292445775,test recall: 0.5789473684210527,test f1: 0.5935107546481954\n",
      "train accuracy: 0.6912739578571429, test accuracy:0.6912094064949608 train loss:0.581732, test loss:0.58704752, test precision: 0.5856394913986537,test recall: 0.5878378378378378,test f1: 0.5867366054702136\n",
      "train accuracy: 0.6915409482142857, test accuracy:0.6878499440089586 train loss:0.58302591, test loss:0.58943301, test precision: 0.6088257292445775,test recall: 0.5789473684210527,test f1: 0.5935107546481954\n",
      "train accuracy: 0.6932102450000001, test accuracy:0.6833706606942889 train loss:0.57732336, test loss:0.59036118, test precision: 0.6103216155572176,test recall: 0.5722300140252454,test f1: 0.5906623235613463\n",
      "train accuracy: 0.6969577439285715, test accuracy:0.6844904815229563 train loss:0.57648464, test loss:0.58914196, test precision: 0.6103216155572176,test recall: 0.5738396624472574,test f1: 0.5915186661833998\n",
      "train accuracy: 0.6954664403571428, test accuracy:0.6844904815229563 train loss:0.57813957, test loss:0.58952677, test precision: 0.6103216155572176,test recall: 0.5738396624472574,test f1: 0.5915186661833998\n",
      "train accuracy: 0.6985645014285715, test accuracy:0.6898096304591266 train loss:0.57621514, test loss:0.58763325, test precision: 0.5983545250560958,test recall: 0.5835156819839533,test f1: 0.5908419497784343\n",
      "train accuracy: 0.6948482725, test accuracy:0.688969764837626 train loss:0.58010747, test loss:0.58827096, test precision: 0.5983545250560958,test recall: 0.5822416302765647,test f1: 0.5901881224640354\n",
      "train accuracy: 0.6979246842857142, test accuracy:0.6842105263157895 train loss:0.57273912, test loss:0.59002846, test precision: 0.6028421839940165,test recall: 0.5744832501781896,test f1: 0.5883211678832118\n",
      "train accuracy: 0.7080919989285714, test accuracy:0.6909294512877939 train loss:0.56584015, test loss:0.58698851, test precision: 0.5878833208676141,test recall: 0.5870052277819268,test f1: 0.5874439461883408\n",
      "train accuracy: 0.6928253939285716, test accuracy:0.688969764837626 train loss:0.57737573, test loss:0.58838725, test precision: 0.5983545250560958,test recall: 0.5822416302765647,test f1: 0.5901881224640354\n",
      "train accuracy: 0.6915962710714286, test accuracy:0.688969764837626 train loss:0.58025119, test loss:0.58804196, test precision: 0.5983545250560958,test recall: 0.5822416302765647,test f1: 0.5901881224640354\n",
      "train accuracy: 0.6927388, test accuracy:0.6864501679731243 train loss:0.57396778, test loss:0.58886194, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.6995242267857142, test accuracy:0.6864501679731243 train loss:0.57370282, test loss:0.58812863, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.697265625, test accuracy:0.6864501679731243 train loss:0.57404738, test loss:0.58788151, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.6997984342857143, test accuracy:0.6864501679731243 train loss:0.57181619, test loss:0.58851314, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.7003276067857142, test accuracy:0.6864501679731243 train loss:0.57450161, test loss:0.58764338, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.6976360446428572, test accuracy:0.6864501679731243 train loss:0.57690563, test loss:0.59008634, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.6967653167857143, test accuracy:0.6864501679731243 train loss:0.57405747, test loss:0.58975685, test precision: 0.6103216155572176,test recall: 0.5766784452296819,test f1: 0.5930232558139534\n",
      "train accuracy: 0.6966137814285714, test accuracy:0.6920492721164614 train loss:0.57284244, test loss:0.58463758, test precision: 0.587135377711294,test recall: 0.5888972243060765,test f1: 0.5880149812734083\n",
      "train accuracy: 0.7061557103571429, test accuracy:0.6920492721164614 train loss:0.56591448, test loss:0.58460456, test precision: 0.587135377711294,test recall: 0.5888972243060765,test f1: 0.5880149812734083\n",
      "train accuracy: 0.6944465832142857, test accuracy:0.6884098544232923 train loss:0.57672963, test loss:0.58805168, test precision: 0.5983545250560958,test recall: 0.5813953488372093,test f1: 0.5897530409141173\n",
      "train accuracy: 0.6942589671428571, test accuracy:0.6886898096304591 train loss:0.57531605, test loss:0.58684599, test precision: 0.5976065818997757,test recall: 0.5819373634377276,test f1: 0.5896678966789668\n",
      "train accuracy: 0.6968326664285713, test accuracy:0.6878499440089586 train loss:0.57357715, test loss:0.58752298, test precision: 0.5991024682124159,test recall: 0.5804347826086956,test f1: 0.589620905410379\n",
      "train accuracy: 0.6966642935714286, test accuracy:0.6906494960806271 train loss:0.5730415, test loss:0.58626026, test precision: 0.587135377711294,test recall: 0.5866965620328849,test f1: 0.5869158878504673\n",
      "train accuracy: 0.6968879889285714, test accuracy:0.6884098544232923 train loss:0.57143674, test loss:0.58681518, test precision: 0.5983545250560958,test recall: 0.5813953488372093,test f1: 0.5897530409141173\n",
      "train accuracy: 0.6952716103571428, test accuracy:0.6875699888017918 train loss:0.57319376, test loss:0.5882917, test precision: 0.599850411368736,test recall: 0.5798987707881417,test f1: 0.5897058823529411\n",
      "train accuracy: 0.6922024135714286, test accuracy:0.6867301231802911 train loss:0.57655827, test loss:0.5883159, test precision: 0.600598354525056,test recall: 0.5785302593659942,test f1: 0.5893577981651376\n",
      "train accuracy: 0.6956612725, test accuracy:0.6942889137737962 train loss:0.57064304, test loss:0.58435917, test precision: 0.5856394913986537,test recall: 0.5927327781983346,test f1: 0.5891647855530473\n",
      "train accuracy: 0.6929552803571429, test accuracy:0.6819708846584547 train loss:0.57144134, test loss:0.59100229, test precision: 0.6148092744951383,test recall: 0.5696465696465697,test f1: 0.5913669064748202\n",
      "train accuracy: 0.6949132160714286, test accuracy:0.6903695408734603 train loss:0.57366878, test loss:0.58559626, test precision: 0.5878833208676141,test recall: 0.5861297539149888,test f1: 0.5870052277819269\n",
      "train accuracy: 0.6995747378571429, test accuracy:0.6942889137737962 train loss:0.5696985, test loss:0.58469355, test precision: 0.5856394913986537,test recall: 0.5927327781983346,test f1: 0.5891647855530473\n",
      "train accuracy: 0.699788812142857, test accuracy:0.6942889137737962 train loss:0.57566094, test loss:0.58432174, test precision: 0.5856394913986537,test recall: 0.5927327781983346,test f1: 0.5891647855530473\n",
      "train accuracy: 0.6944754460714285, test accuracy:0.6903695408734603 train loss:0.5769199, test loss:0.58530295, test precision: 0.5878833208676141,test recall: 0.5861297539149888,test f1: 0.5870052277819269\n",
      "train accuracy: 0.6945836871428571, test accuracy:0.6903695408734603 train loss:0.57292424, test loss:0.58708411, test precision: 0.5878833208676141,test recall: 0.5861297539149888,test f1: 0.5870052277819269\n",
      "train accuracy: 0.6936889046428572, test accuracy:0.6881298992161254 train loss:0.57584623, test loss:0.58795136, test precision: 0.6192969334330591,test recall: 0.5778087927424983,test f1: 0.5978339350180505\n",
      "train accuracy: 0.7005609221428571, test accuracy:0.6928891377379619 train loss:0.57041885, test loss:0.58540547, test precision: 0.5856394913986537,test recall: 0.5904977375565611,test f1: 0.5880585805482539\n",
      "train accuracy: 0.6982445928571429, test accuracy:0.6842105263157895 train loss:0.5718382, test loss:0.58893353, test precision: 0.6215407629020194,test recall: 0.5719201651754989,test f1: 0.5956989247311828\n",
      "train accuracy: 0.6999114842857143, test accuracy:0.6861702127659575 train loss:0.56921173, test loss:0.58776408, test precision: 0.6095736724008975,test recall: 0.5763790664780764,test f1: 0.5925118138858597\n",
      "train accuracy: 0.6991273475, test accuracy:0.6934490481522956 train loss:0.57108817, test loss:0.58427978, test precision: 0.5856394913986537,test recall: 0.5913897280966768,test f1: 0.588500563697858\n",
      "train accuracy: 0.6987352789285713, test accuracy:0.6934490481522956 train loss:0.57541818, test loss:0.58395803, test precision: 0.5856394913986537,test recall: 0.5913897280966768,test f1: 0.588500563697858\n",
      "train accuracy: 0.6854193928571428, test accuracy:0.6912094064949608 train loss:0.5820851, test loss:0.5863114, test precision: 0.5983545250560958,test recall: 0.5856515373352855,test f1: 0.5919348871624122\n",
      "train accuracy: 0.7023697285714287, test accuracy:0.6928891377379619 train loss:0.56886462, test loss:0.58559996, test precision: 0.5856394913986537,test recall: 0.5904977375565611,test f1: 0.5880585805482539\n",
      "train accuracy: 0.7039548382142858, test accuracy:0.6920492721164614 train loss:0.57018887, test loss:0.58607042, test precision: 0.5983545250560958,test recall: 0.586940572267058,test f1: 0.5925925925925927\n",
      "train accuracy: 0.6939558964285714, test accuracy:0.6920492721164614 train loss:0.57366948, test loss:0.58572739, test precision: 0.5983545250560958,test recall: 0.586940572267058,test f1: 0.5925925925925927\n",
      "train accuracy: 0.6992043178571427, test accuracy:0.6920492721164614 train loss:0.57556728, test loss:0.58592767, test precision: 0.5983545250560958,test recall: 0.586940572267058,test f1: 0.5925925925925927\n",
      "train accuracy: 0.7061941967857143, test accuracy:0.6934490481522956 train loss:0.56462083, test loss:0.58404434, test precision: 0.5856394913986537,test recall: 0.5913897280966768,test f1: 0.588500563697858\n",
      "train accuracy: 0.6967701267857142, test accuracy:0.688969764837626 train loss:0.57337314, test loss:0.58584416, test precision: 0.5991024682124159,test recall: 0.5821220930232558,test f1: 0.5904902322152599\n",
      "train accuracy: 0.6906605985714285, test accuracy:0.6917693169092946 train loss:0.57976676, test loss:0.58441335, test precision: 0.5968586387434555,test recall: 0.586764705882353,test f1: 0.5917686318131257\n",
      "train accuracy: 0.7019608232142857, test accuracy:0.6886898096304591 train loss:0.57114723, test loss:0.58625728, test precision: 0.6013462976813763,test recall: 0.5813449023861171,test f1: 0.5911764705882353\n",
      "train accuracy: 0.6960172607142857, test accuracy:0.6923292273236282 train loss:0.57515283, test loss:0.58224815, test precision: 0.5863874345549738,test recall: 0.5894736842105263,test f1: 0.5879265091863517\n",
      "train accuracy: 0.7017587750000001, test accuracy:0.6923292273236282 train loss:0.5668618, test loss:0.58424187, test precision: 0.600598354525056,test recall: 0.5869883040935673,test f1: 0.5937153419593346\n",
      "train accuracy: 0.7013065721428572, test accuracy:0.687010078387458 train loss:0.56916267, test loss:0.59013295, test precision: 0.6424831712789828,test recall: 0.5730486991327551,test f1: 0.6057827926657264\n",
      "train accuracy: 0.7015374853571429, test accuracy:0.6886898096304591 train loss:0.56792115, test loss:0.58586574, test precision: 0.6013462976813763,test recall: 0.5813449023861171,test f1: 0.5911764705882353\n",
      "train accuracy: 0.6979944385714285, test accuracy:0.6920492721164614 train loss:0.57086605, test loss:0.58536804, test precision: 0.5983545250560958,test recall: 0.586940572267058,test f1: 0.5925925925925927\n",
      "train accuracy: 0.7028315489285715, test accuracy:0.694568868980963 train loss:0.57113421, test loss:0.58311403, test precision: 0.5878833208676141,test recall: 0.5927601809954751,test f1: 0.5903116785580172\n",
      "train accuracy: 0.698232565357143, test accuracy:0.6923292273236282 train loss:0.57424067, test loss:0.58731288, test precision: 0.6178010471204188,test recall: 0.5841584158415841,test f1: 0.6005089058524172\n",
      "train accuracy: 0.7025092357142857, test accuracy:0.6923292273236282 train loss:0.56890908, test loss:0.58736449, test precision: 0.6178010471204188,test recall: 0.5841584158415841,test f1: 0.6005089058524172\n",
      "train accuracy: 0.6980978674999999, test accuracy:0.6912094064949608 train loss:0.57341953, test loss:0.58828759, test precision: 0.6282722513089005,test recall: 0.5809128630705395,test f1: 0.6036651095939635\n",
      "train accuracy: 0.7009794482142856, test accuracy:0.6959686450167973 train loss:0.57152304, test loss:0.5845086, test precision: 0.587135377711294,test recall: 0.5951478392721758,test f1: 0.5911144578313253\n",
      "train accuracy: 0.7022350292857142, test accuracy:0.6906494960806271 train loss:0.56350831, test loss:0.58535504, test precision: 0.5968586387434555,test recall: 0.5850439882697948,test f1: 0.5908922621251388\n",
      "train accuracy: 0.6977154214285715, test accuracy:0.6937290033594625 train loss:0.57230182, test loss:0.58498049, test precision: 0.5961106955871354,test recall: 0.5899333826794967,test f1: 0.5930059523809523\n",
      "train accuracy: 0.6975566703571429, test accuracy:0.6959686450167973 train loss:0.57418201, test loss:0.58289409, test precision: 0.587135377711294,test recall: 0.5951478392721758,test f1: 0.5911144578313253\n",
      "train accuracy: 0.7021099517857142, test accuracy:0.696528555431131 train loss:0.56772369, test loss:0.58241647, test precision: 0.587135377711294,test recall: 0.5960516324981018,test f1: 0.5915599095704598\n",
      "train accuracy: 0.6987112267857143, test accuracy:0.6940089585666294 train loss:0.56950477, test loss:0.58348507, test precision: 0.5983545250560958,test recall: 0.5899705014749262,test f1: 0.5941329372447085\n",
      "train accuracy: 0.6978861996428571, test accuracy:0.6962486002239642 train loss:0.56716704, test loss:0.58310503, test precision: 0.5893792071802543,test recall: 0.595166163141994,test f1: 0.5922585494175121\n",
      "train accuracy: 0.7040775085714286, test accuracy:0.6968085106382979 train loss:0.56714441, test loss:0.58446413, test precision: 0.6133133881824981,test recall: 0.5916305916305916,test f1: 0.6022769004774146\n",
      "train accuracy: 0.7028099028571428, test accuracy:0.6903695408734603 train loss:0.56859988, test loss:0.58561325, test precision: 0.6282722513089005,test recall: 0.5797101449275363,test f1: 0.6030150753768844\n",
      "train accuracy: 0.7111900592857143, test accuracy:0.6906494960806271 train loss:0.56097993, test loss:0.58550882, test precision: 0.6275243081525804,test recall: 0.5802213001383126,test f1: 0.6029464606539705\n",
      "train accuracy: 0.6986775517857142, test accuracy:0.6926091825307951 train loss:0.56795992, test loss:0.58436298, test precision: 0.6245325355272999,test recall: 0.583508036338225,test f1: 0.6033236994219653\n",
      "train accuracy: 0.7006884039285713, test accuracy:0.6993281075027995 train loss:0.57209086, test loss:0.58312088, test precision: 0.6020942408376964,test recall: 0.5976243504083147,test f1: 0.5998509687034277\n",
      "train accuracy: 0.6998537553571429, test accuracy:0.6993281075027995 train loss:0.56993113, test loss:0.58278406, test precision: 0.6020942408376964,test recall: 0.5976243504083147,test f1: 0.5998509687034277\n",
      "train accuracy: 0.7057636442857145, test accuracy:0.6909294512877939 train loss:0.56961591, test loss:0.58597195, test precision: 0.6282722513089005,test recall: 0.580511402902557,test f1: 0.6034482758620691\n",
      "train accuracy: 0.7039837025000001, test accuracy:0.6923292273236282 train loss:0.56921089, test loss:0.58536845, test precision: 0.6170531039640987,test recall: 0.5842776203966006,test f1: 0.6002182611858857\n",
      "train accuracy: 0.7077889278571429, test accuracy:0.6993281075027995 train loss:0.56418129, test loss:0.58216345, test precision: 0.6020942408376964,test recall: 0.5976243504083147,test f1: 0.5998509687034277\n",
      "train accuracy: 0.7076181496428572, test accuracy:0.6979283314669653 train loss:0.56499891, test loss:0.58158332, test precision: 0.6028421839940165,test recall: 0.5952732644017725,test f1: 0.5990338164251208\n",
      "train accuracy: 0.6985861492857143, test accuracy:0.6948488241881299 train loss:0.57629367, test loss:0.58457589, test precision: 0.605833956619297,test recall: 0.5899490167516388,test f1: 0.5977859778597787\n",
      "train accuracy: 0.6986053921428572, test accuracy:0.6968085106382979 train loss:0.57239779, test loss:0.58541149, test precision: 0.6050860134629769,test recall: 0.593108504398827,test f1: 0.5990373935579416\n",
      "train accuracy: 0.7040967525, test accuracy:0.6998880179171333 train loss:0.56603499, test loss:0.58082289, test precision: 0.6013462976813763,test recall: 0.5986597170513775,test f1: 0.6\n",
      "train accuracy: 0.7055640025000001, test accuracy:0.6998880179171333 train loss:0.56660458, test loss:0.58048666, test precision: 0.6013462976813763,test recall: 0.5986597170513775,test f1: 0.6\n",
      "train accuracy: 0.698482719642857, test accuracy:0.6959686450167973 train loss:0.57360742, test loss:0.58574718, test precision: 0.6073298429319371,test recall: 0.5914056809905317,test f1: 0.5992619926199262\n",
      "train accuracy: 0.7062398982142858, test accuracy:0.6962486002239642 train loss:0.56816517, test loss:0.5837996, test precision: 0.6043380703066566,test recall: 0.592375366568915,test f1: 0.5982969270640504\n",
      "train accuracy: 0.6999090789285715, test accuracy:0.6962486002239642 train loss:0.57420394, test loss:0.58329254, test precision: 0.6050860134629769,test recall: 0.5922401171303074,test f1: 0.5985941546429893\n",
      "train accuracy: 0.7003709014285714, test accuracy:0.6959686450167973 train loss:0.57230459, test loss:0.58410442, test precision: 0.605833956619297,test recall: 0.591672753834916,test f1: 0.5986696230598669\n",
      "train accuracy: 0.6996396825000001, test accuracy:0.6959686450167973 train loss:0.57081555, test loss:0.58344227, test precision: 0.605833956619297,test recall: 0.591672753834916,test f1: 0.5986696230598669\n",
      "train accuracy: 0.7013979753571428, test accuracy:0.6962486002239642 train loss:0.56752142, test loss:0.58288634, test precision: 0.6050860134629769,test recall: 0.5922401171303074,test f1: 0.5985941546429893\n",
      "train accuracy: 0.7000509924999999, test accuracy:0.6968085106382979 train loss:0.56979309, test loss:0.58231133, test precision: 0.6050860134629769,test recall: 0.593108504398827,test f1: 0.5990373935579416\n",
      "train accuracy: 0.705727562142857, test accuracy:0.6968085106382979 train loss:0.56395605, test loss:0.58000296, test precision: 0.6020942408376964,test recall: 0.5936578171091446,test f1: 0.597846268102488\n",
      "train accuracy: 0.6996060075, test accuracy:0.6968085106382979 train loss:0.57136215, test loss:0.58153057, test precision: 0.6020942408376964,test recall: 0.5936578171091446,test f1: 0.597846268102488\n",
      "train accuracy: 0.7051983921428572, test accuracy:0.6937290033594625 train loss:0.56594925, test loss:0.5842846, test precision: 0.6200448765893792,test recall: 0.5858657243816254,test f1: 0.602470930232558\n",
      "train accuracy: 0.7065117000000001, test accuracy:0.6951287793952967 train loss:0.56540149, test loss:0.58426911, test precision: 0.6185489902767389,test recall: 0.5881934566145093,test f1: 0.6029894276339773\n",
      "train accuracy: 0.7029638432142857, test accuracy:0.6954087346024636 train loss:0.56909123, test loss:0.58299035, test precision: 0.6163051608077786,test recall: 0.5889921372408864,test f1: 0.6023391812865497\n",
      "train accuracy: 0.7083878542857143, test accuracy:0.6954087346024636 train loss:0.56512178, test loss:0.58256495, test precision: 0.6163051608077786,test recall: 0.5889921372408864,test f1: 0.6023391812865497\n",
      "train accuracy: 0.7068917410714286, test accuracy:0.6951287793952967 train loss:0.56440393, test loss:0.58338618, test precision: 0.6185489902767389,test recall: 0.5881934566145093,test f1: 0.6029894276339773\n",
      "train accuracy: 0.7006282703571428, test accuracy:0.6962486002239642 train loss:0.57198551, test loss:0.58224958, test precision: 0.6043380703066566,test recall: 0.592375366568915,test f1: 0.5982969270640504\n",
      "train accuracy: 0.6993462317857143, test accuracy:0.6951287793952967 train loss:0.56871817, test loss:0.58433694, test precision: 0.6185489902767389,test recall: 0.5881934566145093,test f1: 0.6029894276339773\n",
      "train accuracy: 0.7033366685714286, test accuracy:0.6962486002239642 train loss:0.56673169, test loss:0.58120275, test precision: 0.6035901271503366,test recall: 0.5925110132158591,test f1: 0.5979992589848092\n",
      "train accuracy: 0.7063818110714287, test accuracy:0.6996080627099664 train loss:0.56471585, test loss:0.58095795, test precision: 0.6020942408376964,test recall: 0.5980683506686478,test f1: 0.6000745434215431\n",
      "train accuracy: 0.7044792, test accuracy:0.6959686450167973 train loss:0.56986194, test loss:0.58339864, test precision: 0.605833956619297,test recall: 0.591672753834916,test f1: 0.5986696230598669\n",
      "train accuracy: 0.7016697778571429, test accuracy:0.6959686450167973 train loss:0.56590075, test loss:0.58392769, test precision: 0.6073298429319371,test recall: 0.5914056809905317,test f1: 0.5992619926199262\n",
      "train accuracy: 0.7066079125, test accuracy:0.6962486002239642 train loss:0.56389267, test loss:0.58036393, test precision: 0.6035901271503366,test recall: 0.5925110132158591,test f1: 0.5979992589848092\n",
      "train accuracy: 0.6991706435714286, test accuracy:0.6962486002239642 train loss:0.56890895, test loss:0.58137649, test precision: 0.6043380703066566,test recall: 0.592375366568915,test f1: 0.5982969270640504\n",
      "train accuracy: 0.7027617953571428, test accuracy:0.6962486002239642 train loss:0.56814369, test loss:0.58129215, test precision: 0.6043380703066566,test recall: 0.592375366568915,test f1: 0.5982969270640504\n",
      "train accuracy: 0.7051262310714286, test accuracy:0.6951287793952967 train loss:0.56636268, test loss:0.58137363, test precision: 0.6148092744951383,test recall: 0.5888252148997135,test f1: 0.601536772777168\n",
      "train accuracy: 0.6980064653571428, test accuracy:0.6920492721164614 train loss:0.56977158, test loss:0.5857203, test precision: 0.6237845923709798,test recall: 0.5828092243186582,test f1: 0.6026011560693642\n",
      "train accuracy: 0.7061316575000001, test accuracy:0.6920492721164614 train loss:0.56244482, test loss:0.58248603, test precision: 0.6215407629020194,test recall: 0.5831578947368421,test f1: 0.6017378711078928\n",
      "train accuracy: 0.7025284789285714, test accuracy:0.6934490481522956 train loss:0.56695511, test loss:0.58132052, test precision: 0.6192969334330591,test recall: 0.5855728429985856,test f1: 0.6019629225736096\n",
      "train accuracy: 0.6925680228571428, test accuracy:0.6942889137737962 train loss:0.57403638, test loss:0.58224159, test precision: 0.6185489902767389,test recall: 0.5869410929737402,test f1: 0.6023306627822287\n",
      "train accuracy: 0.6939583007142857, test accuracy:0.700447928331467 train loss:0.57264807, test loss:0.58005548, test precision: 0.600598354525056,test recall: 0.5997012696041822,test f1: 0.6001494768310912\n",
      "train accuracy: 0.7038249507142859, test accuracy:0.6937290033594625 train loss:0.56439202, test loss:0.58284414, test precision: 0.6185489902767389,test recall: 0.5861091424521616,test f1: 0.6018922852983989\n",
      "train accuracy: 0.7018934728571428, test accuracy:0.6954087346024636 train loss:0.56908253, test loss:0.58204013, test precision: 0.6080777860882572,test recall: 0.5904139433551199,test f1: 0.5991156963890937\n",
      "train accuracy: 0.7044719832142857, test accuracy:0.696528555431131 train loss:0.56752977, test loss:0.5808444, test precision: 0.606581899775617,test recall: 0.5924032140248356,test f1: 0.5994087213599409\n",
      "train accuracy: 0.7041881546428571, test accuracy:0.6954087346024636 train loss:0.56651746, test loss:0.58191854, test precision: 0.6080777860882572,test recall: 0.5904139433551199,test f1: 0.5991156963890937\n",
      "train accuracy: 0.6973882957142857, test accuracy:0.7010078387458006 train loss:0.57048983, test loss:0.57926649, test precision: 0.6013462976813763,test recall: 0.6004480955937267,test f1: 0.6008968609865472\n",
      "train accuracy: 0.7047918917857144, test accuracy:0.6942889137737962 train loss:0.56255924, test loss:0.58176196, test precision: 0.6185489902767389,test recall: 0.5869410929737402,test f1: 0.6023306627822287\n",
      "train accuracy: 0.6996036028571428, test accuracy:0.696528555431131 train loss:0.56646646, test loss:0.58100688, test precision: 0.606581899775617,test recall: 0.5924032140248356,test f1: 0.5994087213599409\n",
      "train accuracy: 0.70489051, test accuracy:0.6979283314669653 train loss:0.57005412, test loss:0.58039677, test precision: 0.606581899775617,test recall: 0.594574780058651,test f1: 0.6005183265457239\n",
      "train accuracy: 0.7033174257142857, test accuracy:0.6948488241881299 train loss:0.56372483, test loss:0.58096242, test precision: 0.6080777860882572,test recall: 0.5895576504713561,test f1: 0.5986745213549338\n",
      "train accuracy: 0.7001616371428572, test accuracy:0.6942889137737962 train loss:0.56754164, test loss:0.58071584, test precision: 0.6088257292445775,test recall: 0.5885755603759942,test f1: 0.598529411764706\n",
      "train accuracy: 0.7042482871428574, test accuracy:0.6942889137737962 train loss:0.56154393, test loss:0.58143908, test precision: 0.6110695587135377,test recall: 0.5881929445644348,test f1: 0.5994130594277329\n",
      "train accuracy: 0.7030624617857144, test accuracy:0.6940089585666294 train loss:0.56648587, test loss:0.58120489, test precision: 0.6095736724008975,test recall: 0.588023088023088,test f1: 0.5986044803525524\n",
      "train accuracy: 0.7055904603571429, test accuracy:0.6942889137737962 train loss:0.56726455, test loss:0.58026963, test precision: 0.6095736724008975,test recall: 0.5884476534296029,test f1: 0.5988243938280675\n",
      "train accuracy: 0.7018934728571429, test accuracy:0.6951287793952967 train loss:0.56736045, test loss:0.57828778, test precision: 0.6073298429319371,test recall: 0.5901162790697675,test f1: 0.598599336527829\n",
      "train accuracy: 0.7005753542857142, test accuracy:0.6942889137737962 train loss:0.56529564, test loss:0.58031297, test precision: 0.6095736724008975,test recall: 0.5884476534296029,test f1: 0.5988243938280675\n",
      "train accuracy: 0.6991417792857142, test accuracy:0.6926091825307951 train loss:0.57165648, test loss:0.58230507, test precision: 0.6215407629020194,test recall: 0.583977512297962,test f1: 0.6021739130434782\n",
      "train accuracy: 0.7044479299999998, test accuracy:0.6931690929451287 train loss:0.5645347, test loss:0.58207458, test precision: 0.6215407629020194,test recall: 0.5847994370161858,test f1: 0.602610587382161\n",
      "train accuracy: 0.7022951628571429, test accuracy:0.6934490481522956 train loss:0.57010208, test loss:0.58045596, test precision: 0.6200448765893792,test recall: 0.58545197740113,test f1: 0.6022520886305849\n",
      "train accuracy: 0.7024899932142858, test accuracy:0.6937290033594625 train loss:0.57181823, test loss:0.58035594, test precision: 0.6215407629020194,test recall: 0.5856236786469344,test f1: 0.6030478955007256\n",
      "train accuracy: 0.7068003385714287, test accuracy:0.6948488241881299 train loss:0.56633904, test loss:0.57917559, test precision: 0.6095736724008975,test recall: 0.589298626174982,test f1: 0.599264705882353\n",
      "train accuracy: 0.7079524878571428, test accuracy:0.6926091825307951 train loss:0.56020115, test loss:0.58481091, test precision: 0.62528047868362,test recall: 0.5833914863921842,test f1: 0.603610108303249\n",
      "train accuracy: 0.7018405550000001, test accuracy:0.6928891377379619 train loss:0.56588439, test loss:0.58308333, test precision: 0.6230366492146597,test recall: 0.5841514726507714,test f1: 0.6029677886355411\n",
      "train accuracy: 0.6995651174999999, test accuracy:0.6937290033594625 train loss:0.56798735, test loss:0.58046156, test precision: 0.6215407629020194,test recall: 0.5856236786469344,test f1: 0.6030478955007256\n",
      "train accuracy: 0.7032669125000001, test accuracy:0.6956886898096305 train loss:0.56519386, test loss:0.57799476, test precision: 0.6088257292445775,test recall: 0.590711175616836,test f1: 0.5996316758747697\n",
      "train accuracy: 0.7116711253571429, test accuracy:0.698488241881299 train loss:0.56331517, test loss:0.57757932, test precision: 0.6043380703066566,test recall: 0.5958702064896755,test f1: 0.6000742666171557\n",
      "train accuracy: 0.7063144639285716, test accuracy:0.6940089585666294 train loss:0.56303941, test loss:0.58256984, test precision: 0.6133133881824981,test recall: 0.5873925501432665,test f1: 0.6000731796560556\n",
      "train accuracy: 0.709869535, test accuracy:0.694568868980963 train loss:0.55964108, test loss:0.57925445, test precision: 0.6095736724008975,test recall: 0.5888728323699421,test f1: 0.5990444689452407\n",
      "train accuracy: 0.7016601567857144, test accuracy:0.6940089585666294 train loss:0.56692608, test loss:0.58328968, test precision: 0.6133133881824981,test recall: 0.5873925501432665,test f1: 0.6000731796560556\n",
      "train accuracy: 0.7024298596428572, test accuracy:0.6959686450167973 train loss:0.56725145, test loss:0.58095288, test precision: 0.6095736724008975,test recall: 0.5910079767947788,test f1: 0.6001472754050073\n",
      "train accuracy: 0.7024442917857142, test accuracy:0.6942889137737962 train loss:0.56888796, test loss:0.58100057, test precision: 0.6118175018698578,test recall: 0.5880661394680087,test f1: 0.5997067448680351\n",
      "train accuracy: 0.6988844096428571, test accuracy:0.6940089585666294 train loss:0.56638997, test loss:0.58271724, test precision: 0.6133133881824981,test recall: 0.5873925501432665,test f1: 0.6000731796560556\n",
      "train accuracy: 0.7085514171428572, test accuracy:0.6942889137737962 train loss:0.56236029, test loss:0.58241928, test precision: 0.6118175018698578,test recall: 0.5880661394680087,test f1: 0.5997067448680351\n",
      "train accuracy: 0.7000870714285714, test accuracy:0.7001679731243001 train loss:0.56865922, test loss:0.57827336, test precision: 0.6050860134629769,test recall: 0.5983727810650887,test f1: 0.6017106731126814\n",
      "train accuracy: 0.7034136385714286, test accuracy:0.6951287793952967 train loss:0.56604133, test loss:0.58080578, test precision: 0.6110695587135377,test recall: 0.5894660894660895,test f1: 0.6000734484024972\n",
      "train accuracy: 0.7099416946428571, test accuracy:0.6968085106382979 train loss:0.56031466, test loss:0.58113551, test precision: 0.6088257292445775,test recall: 0.5924308588064047,test f1: 0.6005164146071561\n",
      "train accuracy: 0.6990768349999998, test accuracy:0.6942889137737962 train loss:0.57088029, test loss:0.58233678, test precision: 0.6118175018698578,test recall: 0.5880661394680087,test f1: 0.5997067448680351\n",
      "train accuracy: 0.7044431182142858, test accuracy:0.6942889137737962 train loss:0.56261862, test loss:0.58235389, test precision: 0.6118175018698578,test recall: 0.5880661394680087,test f1: 0.5997067448680351\n",
      "train accuracy: 0.7004839525000001, test accuracy:0.6948488241881299 train loss:0.57155055, test loss:0.57908857, test precision: 0.6103216155572176,test recall: 0.5891696750902528,test f1: 0.5995591476855254\n",
      "train accuracy: 0.7002434185714286, test accuracy:0.7015677491601344 train loss:0.56618877, test loss:0.57656968, test precision: 0.6043380703066566,test recall: 0.6007434944237918,test f1: 0.6025354213273676\n",
      "train accuracy: 0.6992885046428572, test accuracy:0.6931690929451287 train loss:0.57095121, test loss:0.58049655, test precision: 0.6222887060583395,test recall: 0.5846802529866479,test f1: 0.6028985507246376\n",
      "train accuracy: 0.7040726992857141, test accuracy:0.6928891377379619 train loss:0.56792701, test loss:0.58087975, test precision: 0.6237845923709798,test recall: 0.5840336134453782,test f1: 0.603254972875226\n",
      "train accuracy: 0.7025669646428572, test accuracy:0.6928891377379619 train loss:0.57116327, test loss:0.58152413, test precision: 0.6237845923709798,test recall: 0.5840336134453782,test f1: 0.603254972875226\n",
      "train accuracy: 0.6938476557142856, test accuracy:0.6928891377379619 train loss:0.5738874, test loss:0.5826593, test precision: 0.6237845923709798,test recall: 0.5840336134453782,test f1: 0.603254972875226\n",
      "train accuracy: 0.7105213785714286, test accuracy:0.6954087346024636 train loss:0.56395811, test loss:0.57837695, test precision: 0.6192969334330591,test recall: 0.5884861407249466,test f1: 0.6034985422740524\n",
      "train accuracy: 0.7093403639285716, test accuracy:0.696528555431131 train loss:0.56281064, test loss:0.57885605, test precision: 0.6088257292445775,test recall: 0.592,test f1: 0.6002949852507374\n",
      "train accuracy: 0.7049674785714286, test accuracy:0.694568868980963 train loss:0.56134458, test loss:0.58042288, test precision: 0.6215407629020194,test recall: 0.586864406779661,test f1: 0.6037050490374137\n",
      "train accuracy: 0.7042170178571429, test accuracy:0.6928891377379619 train loss:0.56490486, test loss:0.58273464, test precision: 0.6237845923709798,test recall: 0.5840336134453782,test f1: 0.603254972875226\n",
      "train accuracy: 0.7045128746428571, test accuracy:0.6962486002239642 train loss:0.56517047, test loss:0.57965028, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7038033014285714, test accuracy:0.696528555431131 train loss:0.56505688, test loss:0.57795978, test precision: 0.6088257292445775,test recall: 0.592,test f1: 0.6002949852507374\n",
      "train accuracy: 0.7039500271428573, test accuracy:0.6979283314669653 train loss:0.56619482, test loss:0.57792187, test precision: 0.6073298429319371,test recall: 0.5944363103953147,test f1: 0.6008139104698483\n",
      "train accuracy: 0.701410002857143, test accuracy:0.6962486002239642 train loss:0.570412, test loss:0.57952553, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7085634421428572, test accuracy:0.6956886898096305 train loss:0.56263513, test loss:0.5807991, test precision: 0.6110695587135377,test recall: 0.5903179190751445,test f1: 0.6005145167217933\n",
      "train accuracy: 0.7008423446428571, test accuracy:0.6962486002239642 train loss:0.5664364, test loss:0.57901609, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7011983335714286, test accuracy:0.6956886898096305 train loss:0.5645666, test loss:0.58075303, test precision: 0.6110695587135377,test recall: 0.5903179190751445,test f1: 0.6005145167217933\n",
      "train accuracy: 0.7033342642857142, test accuracy:0.6979283314669653 train loss:0.56994917, test loss:0.57744002, test precision: 0.6073298429319371,test recall: 0.5944363103953147,test f1: 0.6008139104698483\n",
      "train accuracy: 0.7116494767857143, test accuracy:0.6962486002239642 train loss:0.56075347, test loss:0.57935393, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7067137471428572, test accuracy:0.6962486002239642 train loss:0.56590245, test loss:0.57970852, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7036686032142858, test accuracy:0.6962486002239642 train loss:0.56389727, test loss:0.57900006, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7052416864285714, test accuracy:0.6962486002239642 train loss:0.56485002, test loss:0.57897758, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7071875971428572, test accuracy:0.6962486002239642 train loss:0.55907959, test loss:0.5789699, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7078490614285714, test accuracy:0.6962486002239642 train loss:0.56373272, test loss:0.57954544, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7055591914285715, test accuracy:0.6979283314669653 train loss:0.56195322, test loss:0.57808512, test precision: 0.6073298429319371,test recall: 0.5944363103953147,test f1: 0.6008139104698483\n",
      "train accuracy: 0.7112694350000001, test accuracy:0.6956886898096305 train loss:0.56230085, test loss:0.58113962, test precision: 0.6110695587135377,test recall: 0.5903179190751445,test f1: 0.6005145167217933\n",
      "train accuracy: 0.7107498857142858, test accuracy:0.6962486002239642 train loss:0.55695653, test loss:0.57946211, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7102351439285713, test accuracy:0.6976483762597985 train loss:0.55824805, test loss:0.57757455, test precision: 0.6088257292445775,test recall: 0.5937272064186725,test f1: 0.601181683899557\n",
      "train accuracy: 0.7038898946428571, test accuracy:0.6962486002239642 train loss:0.56145619, test loss:0.57995635, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.702227812857143, test accuracy:0.6962486002239642 train loss:0.5672921, test loss:0.57899958, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7068195810714285, test accuracy:0.694568868980963 train loss:0.56393507, test loss:0.58149052, test precision: 0.6133133881824981,test recall: 0.5882352941176471,test f1: 0.6005126327352619\n",
      "train accuracy: 0.7051839589285713, test accuracy:0.694568868980963 train loss:0.56350276, test loss:0.57999086, test precision: 0.6133133881824981,test recall: 0.5882352941176471,test f1: 0.6005126327352619\n",
      "train accuracy: 0.6978356864285713, test accuracy:0.6931690929451287 train loss:0.5710385, test loss:0.58256453, test precision: 0.6297681376215407,test recall: 0.5835065835065835,test f1: 0.6057553956834533\n",
      "train accuracy: 0.7075724485714286, test accuracy:0.694568868980963 train loss:0.56085699, test loss:0.57925361, test precision: 0.6163051608077786,test recall: 0.5877318116975749,test f1: 0.6016794450529391\n",
      "train accuracy: 0.7077143617857143, test accuracy:0.6934490481522956 train loss:0.56054044, test loss:0.57992995, test precision: 0.6237845923709798,test recall: 0.5848527349228612,test f1: 0.6036916395222585\n",
      "train accuracy: 0.7073439417857142, test accuracy:0.6951287793952967 train loss:0.56381849, test loss:0.58017439, test precision: 0.6215407629020194,test recall: 0.5876944837340877,test f1: 0.604143947655398\n",
      "train accuracy: 0.7057227532142857, test accuracy:0.6951287793952967 train loss:0.56024603, test loss:0.57781684, test precision: 0.6215407629020194,test recall: 0.5876944837340877,test f1: 0.604143947655398\n",
      "train accuracy: 0.7060017689285712, test accuracy:0.6951287793952967 train loss:0.56224697, test loss:0.57970405, test precision: 0.6245325355272999,test recall: 0.5872011251758087,test f1: 0.6052917723812976\n",
      "train accuracy: 0.7056890778571429, test accuracy:0.6962486002239642 train loss:0.56109704, test loss:0.57985479, test precision: 0.6140613313388182,test recall: 0.5906474820143884,test f1: 0.6021268793546022\n",
      "train accuracy: 0.7134679028571428, test accuracy:0.6976483762597985 train loss:0.55354765, test loss:0.57755333, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7035218792857144, test accuracy:0.6970884658454647 train loss:0.56205576, test loss:0.57931513, test precision: 0.6095736724008975,test recall: 0.5927272727272728,test f1: 0.6010324483775811\n",
      "train accuracy: 0.7043950117857143, test accuracy:0.6976483762597985 train loss:0.56441552, test loss:0.57885122, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7089603210714285, test accuracy:0.6976483762597985 train loss:0.56037043, test loss:0.5786919, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7028171174999999, test accuracy:0.6976483762597985 train loss:0.56341444, test loss:0.57731509, test precision: 0.6088257292445775,test recall: 0.5937272064186725,test f1: 0.601181683899557\n",
      "train accuracy: 0.7097829449999999, test accuracy:0.6976483762597985 train loss:0.55914021, test loss:0.57837635, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7053595475000002, test accuracy:0.6976483762597985 train loss:0.56483409, test loss:0.57824463, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7025284796428571, test accuracy:0.6976483762597985 train loss:0.56954601, test loss:0.57810897, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7102952789285715, test accuracy:0.6956886898096305 train loss:0.56039315, test loss:0.57976377, test precision: 0.6110695587135377,test recall: 0.5903179190751445,test f1: 0.6005145167217933\n",
      "train accuracy: 0.7083854492857142, test accuracy:0.6962486002239642 train loss:0.56141746, test loss:0.57907289, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7033775582142858, test accuracy:0.694568868980963 train loss:0.56293313, test loss:0.58241779, test precision: 0.6267763649962603,test recall: 0.586013986013986,test f1: 0.6057101554029636\n",
      "train accuracy: 0.6963973014285714, test accuracy:0.694568868980963 train loss:0.56743678, test loss:0.58183372, test precision: 0.6267763649962603,test recall: 0.586013986013986,test f1: 0.6057101554029636\n",
      "train accuracy: 0.7079428692857144, test accuracy:0.6976483762597985 train loss:0.56072001, test loss:0.577447, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7074834510714286, test accuracy:0.694568868980963 train loss:0.55999696, test loss:0.58323425, test precision: 0.6237845923709798,test recall: 0.5864978902953587,test f1: 0.6045668720550925\n",
      "train accuracy: 0.705232065357143, test accuracy:0.6962486002239642 train loss:0.56125623, test loss:0.57781774, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7088111910714285, test accuracy:0.7018477043673013 train loss:0.56048823, test loss:0.57493794, test precision: 0.606581899775617,test recall: 0.6007407407407407,test f1: 0.6036471901749162\n",
      "train accuracy: 0.7025501278571429, test accuracy:0.6956886898096305 train loss:0.5661306, test loss:0.58097947, test precision: 0.6133133881824981,test recall: 0.5899280575539568,test f1: 0.6013934726806014\n",
      "train accuracy: 0.7037479782142856, test accuracy:0.6926091825307951 train loss:0.56211725, test loss:0.58466965, test precision: 0.6297681376215407,test recall: 0.5826989619377163,test f1: 0.6053199137311287\n",
      "train accuracy: 0.70508053, test accuracy:0.6962486002239642 train loss:0.56305757, test loss:0.57855213, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7051767439285715, test accuracy:0.698488241881299 train loss:0.56356128, test loss:0.57533932, test precision: 0.6080777860882572,test recall: 0.5951683748169839,test f1: 0.6015538290788013\n",
      "train accuracy: 0.7106584825000001, test accuracy:0.6962486002239642 train loss:0.55711782, test loss:0.57873291, test precision: 0.6133133881824981,test recall: 0.590778097982709,test f1: 0.601834862385321\n",
      "train accuracy: 0.7074305335714285, test accuracy:0.694568868980963 train loss:0.56091964, test loss:0.58015358, test precision: 0.6237845923709798,test recall: 0.5864978902953587,test f1: 0.6045668720550925\n",
      "train accuracy: 0.7099561267857143, test accuracy:0.6962486002239642 train loss:0.55787924, test loss:0.57985145, test precision: 0.6133133881824981,test recall: 0.590778097982709,test f1: 0.601834862385321\n",
      "train accuracy: 0.7025645589285714, test accuracy:0.694568868980963 train loss:0.56245011, test loss:0.5809868, test precision: 0.6237845923709798,test recall: 0.5864978902953587,test f1: 0.6045668720550925\n",
      "train accuracy: 0.7076542292857143, test accuracy:0.6976483762597985 train loss:0.56144016, test loss:0.5770905, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7087125739285715, test accuracy:0.6962486002239642 train loss:0.5606486, test loss:0.57840872, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7063481378571429, test accuracy:0.6962486002239642 train loss:0.55749755, test loss:0.58048362, test precision: 0.6133133881824981,test recall: 0.590778097982709,test f1: 0.601834862385321\n",
      "train accuracy: 0.7064467560714286, test accuracy:0.6962486002239642 train loss:0.56333379, test loss:0.57815301, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7004069814285715, test accuracy:0.6962486002239642 train loss:0.5667256, test loss:0.58028084, test precision: 0.6133133881824981,test recall: 0.590778097982709,test f1: 0.601834862385321\n",
      "train accuracy: 0.7086067392857143, test accuracy:0.6962486002239642 train loss:0.56148741, test loss:0.57892877, test precision: 0.6110695587135377,test recall: 0.5911722141823444,test f1: 0.6009562339095255\n",
      "train accuracy: 0.7082723996428572, test accuracy:0.698488241881299 train loss:0.56247585, test loss:0.57593936, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.7047510014285715, test accuracy:0.6956886898096305 train loss:0.56260507, test loss:0.578623, test precision: 0.6133133881824981,test recall: 0.5899280575539568,test f1: 0.6013934726806014\n",
      "train accuracy: 0.7044575514285716, test accuracy:0.6976483762597985 train loss:0.56464526, test loss:0.57694805, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.6954640349999999, test accuracy:0.6976483762597985 train loss:0.57071326, test loss:0.57640129, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7057901021428572, test accuracy:0.7001679731243001 train loss:0.55880181, test loss:0.57599801, test precision: 0.6080777860882572,test recall: 0.5977941176470588,test f1: 0.6028921023359288\n",
      "train accuracy: 0.7112261392857143, test accuracy:0.6976483762597985 train loss:0.55939592, test loss:0.57694697, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7111756275000001, test accuracy:0.6959686450167973 train loss:0.55961906, test loss:0.57674426, test precision: 0.6148092744951383,test recall: 0.5900933237616655,test f1: 0.6021978021978022\n",
      "train accuracy: 0.7058406125000001, test accuracy:0.6959686450167973 train loss:0.55976925, test loss:0.57863742, test precision: 0.6170531039640987,test recall: 0.5897069335239457,test f1: 0.6030701754385965\n",
      "train accuracy: 0.7077191746428572, test accuracy:0.6959686450167973 train loss:0.56178952, test loss:0.57692432, test precision: 0.6118175018698578,test recall: 0.5906137184115523,test f1: 0.6010286554004407\n",
      "train accuracy: 0.702723310357143, test accuracy:0.6976483762597985 train loss:0.56011292, test loss:0.57641602, test precision: 0.6095736724008975,test recall: 0.593590677348871,test f1: 0.6014760147601476\n",
      "train accuracy: 0.7038033010714286, test accuracy:0.696528555431131 train loss:0.56274729, test loss:0.57820368, test precision: 0.6185489902767389,test recall: 0.5902926481084939,test f1: 0.6040905770635501\n",
      "train accuracy: 0.69667151, test accuracy:0.6959686450167973 train loss:0.5682626, test loss:0.58220202, test precision: 0.6185489902767389,test recall: 0.5894511760513186,test f1: 0.6036496350364964\n",
      "train accuracy: 0.7041737225000001, test accuracy:0.6959686450167973 train loss:0.56166981, test loss:0.57942039, test precision: 0.6185489902767389,test recall: 0.5894511760513186,test f1: 0.6036496350364964\n",
      "train accuracy: 0.7058069385714286, test accuracy:0.6979283314669653 train loss:0.56106595, test loss:0.57866609, test precision: 0.6155572176514585,test recall: 0.5929394812680115,test f1: 0.6040366972477065\n",
      "train accuracy: 0.7069687114285715, test accuracy:0.6979283314669653 train loss:0.56334698, test loss:0.57828128, test precision: 0.6155572176514585,test recall: 0.5929394812680115,test f1: 0.6040366972477065\n",
      "train accuracy: 0.7044286857142856, test accuracy:0.6979283314669653 train loss:0.55992595, test loss:0.57710224, test precision: 0.612565445026178,test recall: 0.5934782608695652,test f1: 0.6028708133971291\n",
      "train accuracy: 0.7034449078571428, test accuracy:0.6979283314669653 train loss:0.56232881, test loss:0.57829165, test precision: 0.612565445026178,test recall: 0.5934782608695652,test f1: 0.6028708133971291\n",
      "train accuracy: 0.7021219792857144, test accuracy:0.6976483762597985 train loss:0.56573457, test loss:0.57749695, test precision: 0.6118175018698578,test recall: 0.593183466279913,test f1: 0.6023564064801178\n",
      "train accuracy: 0.7051117989285715, test accuracy:0.6973684210526315 train loss:0.55932457, test loss:0.57928872, test precision: 0.6155572176514585,test recall: 0.5920863309352518,test f1: 0.6035936927026035\n",
      "train accuracy: 0.7145118149999999, test accuracy:0.6973684210526315 train loss:0.55302791, test loss:0.5802241, test precision: 0.6155572176514585,test recall: 0.5920863309352518,test f1: 0.6035936927026035\n",
      "train accuracy: 0.7076518246428571, test accuracy:0.6996080627099664 train loss:0.56031175, test loss:0.57560861, test precision: 0.6080777860882572,test recall: 0.5969162995594713,test f1: 0.6024453501296776\n",
      "train accuracy: 0.7114955357142857, test accuracy:0.6962486002239642 train loss:0.55758786, test loss:0.57891095, test precision: 0.6178010471204188,test recall: 0.59,test f1: 0.6035805626598465\n",
      "train accuracy: 0.7116182071428572, test accuracy:0.6979283314669653 train loss:0.55594281, test loss:0.57868683, test precision: 0.612565445026178,test recall: 0.5934782608695652,test f1: 0.6028708133971291\n",
      "train accuracy: 0.7021171689285713, test accuracy:0.6987681970884658 train loss:0.56371619, test loss:0.57657349, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.7003709017857143, test accuracy:0.6979283314669653 train loss:0.56746562, test loss:0.57744014, test precision: 0.612565445026178,test recall: 0.5934782608695652,test f1: 0.6028708133971291\n",
      "train accuracy: 0.6934435610714286, test accuracy:0.6956886898096305 train loss:0.57516082, test loss:0.58000255, test precision: 0.6148092744951383,test recall: 0.5896700143472023,test f1: 0.6019772976931527\n",
      "train accuracy: 0.7082339135714285, test accuracy:0.6973684210526315 train loss:0.55789613, test loss:0.57918417, test precision: 0.612565445026178,test recall: 0.5926193921852387,test f1: 0.6024273630011034\n",
      "train accuracy: 0.7102904675, test accuracy:0.7029675251959686 train loss:0.5597955, test loss:0.57465768, test precision: 0.605833956619297,test recall: 0.6026785714285714,test f1: 0.6042521447221186\n",
      "train accuracy: 0.7043276642857142, test accuracy:0.6987681970884658 train loss:0.56579299, test loss:0.57595915, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.6982085124999999, test accuracy:0.6976483762597985 train loss:0.56431837, test loss:0.5792082, test precision: 0.6110695587135377,test recall: 0.5933188090050835,test f1: 0.6020633750921149\n",
      "train accuracy: 0.7081569428571429, test accuracy:0.6987681970884658 train loss:0.56008524, test loss:0.57513738, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.7078442514285713, test accuracy:0.6973684210526315 train loss:0.5618667, test loss:0.57797736, test precision: 0.6103216155572176,test recall: 0.5930232558139535,test f1: 0.6015481017323996\n",
      "train accuracy: 0.7097204057142859, test accuracy:0.6979283314669653 train loss:0.55851493, test loss:0.57718372, test precision: 0.6103216155572176,test recall: 0.5938864628820961,test f1: 0.6019918849133162\n",
      "train accuracy: 0.7038850832142859, test accuracy:0.6996080627099664 train loss:0.56585407, test loss:0.5753454, test precision: 0.6095736724008975,test recall: 0.5966325036603221,test f1: 0.6030336662967073\n",
      "train accuracy: 0.6988579503571429, test accuracy:0.6982082866741322 train loss:0.57054749, test loss:0.57773161, test precision: 0.6110695587135377,test recall: 0.5941818181818181,test f1: 0.6025073746312684\n",
      "train accuracy: 0.7083662067857144, test accuracy:0.6982082866741322 train loss:0.55710416, test loss:0.5768066, test precision: 0.6110695587135377,test recall: 0.5941818181818181,test f1: 0.6025073746312684\n",
      "train accuracy: 0.7048231607142857, test accuracy:0.6976483762597985 train loss:0.56107321, test loss:0.57834303, test precision: 0.6110695587135377,test recall: 0.5933188090050835,test f1: 0.6020633750921149\n",
      "train accuracy: 0.7120343299999999, test accuracy:0.7021276595744681 train loss:0.55679709, test loss:0.57368374, test precision: 0.606581899775617,test recall: 0.6011860637509266,test f1: 0.6038719285182428\n",
      "train accuracy: 0.7070601142857144, test accuracy:0.7015677491601344 train loss:0.56266738, test loss:0.57558674, test precision: 0.6095736724008975,test recall: 0.5997056659308315,test f1: 0.60459940652819\n",
      "train accuracy: 0.7093042824999999, test accuracy:0.6990481522956327 train loss:0.56171208, test loss:0.57667649, test precision: 0.6110695587135377,test recall: 0.5954810495626822,test f1: 0.6031746031746031\n",
      "train accuracy: 0.6979776014285713, test accuracy:0.7015677491601344 train loss:0.56488742, test loss:0.57641363, test precision: 0.6095736724008975,test recall: 0.5997056659308315,test f1: 0.60459940652819\n",
      "train accuracy: 0.7099705578571428, test accuracy:0.6973684210526315 train loss:0.55989731, test loss:0.57713157, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7027040674999999, test accuracy:0.6954087346024636 train loss:0.56423273, test loss:0.57988894, test precision: 0.6170531039640987,test recall: 0.588865096359743,test f1: 0.6026296566837108\n",
      "train accuracy: 0.6971694114285715, test accuracy:0.6976483762597985 train loss:0.56777909, test loss:0.57817763, test precision: 0.6170531039640987,test recall: 0.5922469490308686,test f1: 0.6043956043956044\n",
      "train accuracy: 0.7038369767857143, test accuracy:0.6990481522956327 train loss:0.56170696, test loss:0.57741851, test precision: 0.6110695587135377,test recall: 0.5954810495626822,test f1: 0.6031746031746031\n",
      "train accuracy: 0.7093596064285714, test accuracy:0.698488241881299 train loss:0.55978742, test loss:0.57919699, test precision: 0.6110695587135377,test recall: 0.5946142649199417,test f1: 0.6027296200663962\n",
      "train accuracy: 0.7102928725000001, test accuracy:0.6973684210526315 train loss:0.55802112, test loss:0.57868332, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7024707510714286, test accuracy:0.6973684210526315 train loss:0.56196134, test loss:0.57615358, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7046307328571428, test accuracy:0.6951287793952967 train loss:0.56131181, test loss:0.57990974, test precision: 0.6185489902767389,test recall: 0.5881934566145093,test f1: 0.6029894276339773\n",
      "train accuracy: 0.7046692189285715, test accuracy:0.6990481522956327 train loss:0.56689892, test loss:0.57734162, test precision: 0.6110695587135377,test recall: 0.5954810495626822,test f1: 0.6031746031746031\n",
      "train accuracy: 0.7019944971428572, test accuracy:0.6973684210526315 train loss:0.56560212, test loss:0.57694656, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7036349299999999, test accuracy:0.7015677491601344 train loss:0.56248914, test loss:0.57537234, test precision: 0.6095736724008975,test recall: 0.5997056659308315,test f1: 0.60459940652819\n",
      "train accuracy: 0.7035603642857142, test accuracy:0.6954087346024636 train loss:0.56263206, test loss:0.57929265, test precision: 0.6170531039640987,test recall: 0.588865096359743,test f1: 0.6026296566837108\n",
      "train accuracy: 0.7066439932142857, test accuracy:0.6954087346024636 train loss:0.55867534, test loss:0.57975501, test precision: 0.6170531039640987,test recall: 0.588865096359743,test f1: 0.6026296566837108\n",
      "train accuracy: 0.7011646585714286, test accuracy:0.6976483762597985 train loss:0.57029416, test loss:0.57675874, test precision: 0.6133133881824981,test recall: 0.5929139551699205,test f1: 0.6029411764705883\n",
      "train accuracy: 0.7096290028571428, test accuracy:0.6970884658454647 train loss:0.55573325, test loss:0.57870787, test precision: 0.6140613313388182,test recall: 0.5919250180245134,test f1: 0.6027900146842878\n",
      "train accuracy: 0.7134847410714286, test accuracy:0.6976483762597985 train loss:0.55427209, test loss:0.57700676, test precision: 0.6140613313388182,test recall: 0.5927797833935018,test f1: 0.6032329169728141\n",
      "train accuracy: 0.70919845, test accuracy:0.7001679731243001 train loss:0.55815921, test loss:0.57541353, test precision: 0.6110695587135377,test recall: 0.5972222222222222,test f1: 0.6040665434380776\n",
      "train accuracy: 0.7105045410714287, test accuracy:0.6976483762597985 train loss:0.5553066, test loss:0.57836461, test precision: 0.6140613313388182,test recall: 0.5927797833935018,test f1: 0.6032329169728141\n",
      "train accuracy: 0.7079115982142857, test accuracy:0.6990481522956327 train loss:0.55988343, test loss:0.57653046, test precision: 0.6110695587135377,test recall: 0.5954810495626822,test f1: 0.6031746031746031\n",
      "train accuracy: 0.7043276628571429, test accuracy:0.6973684210526315 train loss:0.56557629, test loss:0.57791179, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7129772182142856, test accuracy:0.6973684210526315 train loss:0.555008, test loss:0.57589591, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7030263821428572, test accuracy:0.6970884658454647 train loss:0.56694912, test loss:0.57850736, test precision: 0.6140613313388182,test recall: 0.5919250180245134,test f1: 0.6027900146842878\n",
      "train accuracy: 0.7093668221428572, test accuracy:0.6951287793952967 train loss:0.55928025, test loss:0.57927781, test precision: 0.6155572176514585,test recall: 0.5886981402002861,test f1: 0.6018281535648996\n",
      "train accuracy: 0.7076710667857142, test accuracy:0.6973684210526315 train loss:0.55856866, test loss:0.57848883, test precision: 0.6155572176514585,test recall: 0.5920863309352518,test f1: 0.6035936927026035\n",
      "train accuracy: 0.7078634932142858, test accuracy:0.6973684210526315 train loss:0.56139196, test loss:0.57647645, test precision: 0.6133133881824981,test recall: 0.5924855491329479,test f1: 0.6027195883866225\n",
      "train accuracy: 0.7039139464285714, test accuracy:0.6976483762597985 train loss:0.56088506, test loss:0.57740027, test precision: 0.6140613313388182,test recall: 0.5927797833935018,test f1: 0.6032329169728141\n",
      "train accuracy: 0.7053836014285715, test accuracy:0.6954087346024636 train loss:0.56292209, test loss:0.57903463, test precision: 0.6170531039640987,test recall: 0.588865096359743,test f1: 0.6026296566837108\n",
      "train accuracy: 0.70750991, test accuracy:0.6968085106382979 train loss:0.55722018, test loss:0.57873535, test precision: 0.6133133881824981,test recall: 0.5916305916305916,test f1: 0.6022769004774146\n",
      "train accuracy: 0.7023937803571428, test accuracy:0.6976483762597985 train loss:0.56295569, test loss:0.57897639, test precision: 0.6133133881824981,test recall: 0.5929139551699205,test f1: 0.6029411764705883\n",
      "train accuracy: 0.7086524396428571, test accuracy:0.6979283314669653 train loss:0.55989994, test loss:0.5784148, test precision: 0.6140613313388182,test recall: 0.5932080924855492,test f1: 0.603454612274899\n",
      "train accuracy: 0.6997719746428571, test accuracy:0.6970884658454647 train loss:0.56546786, test loss:0.57821345, test precision: 0.6133133881824981,test recall: 0.592057761732852,test f1: 0.6024981631153564\n",
      "train accuracy: 0.7014893789285715, test accuracy:0.6970884658454647 train loss:0.56975342, test loss:0.57713681, test precision: 0.6133133881824981,test recall: 0.592057761732852,test f1: 0.6024981631153564\n",
      "train accuracy: 0.7041472653571427, test accuracy:0.6948488241881299 train loss:0.56366185, test loss:0.57892334, test precision: 0.6170531039640987,test recall: 0.5880256593014968,test f1: 0.6021897810218978\n",
      "train accuracy: 0.6990599985714285, test accuracy:0.7012877939529675 train loss:0.56177531, test loss:0.57635558, test precision: 0.6088257292445775,test recall: 0.5994108983799705,test f1: 0.6040816326530613\n",
      "train accuracy: 0.7110697935714286, test accuracy:0.7029675251959686 train loss:0.55627925, test loss:0.575216, test precision: 0.606581899775617,test recall: 0.6025260029717682,test f1: 0.604547148714126\n",
      "train accuracy: 0.7060089864285715, test accuracy:0.6987681970884658 train loss:0.55908588, test loss:0.57755172, test precision: 0.6110695587135377,test recall: 0.5950473415877641,test f1: 0.6029520295202953\n",
      "train accuracy: 0.7051430689285715, test accuracy:0.6987681970884658 train loss:0.56213615, test loss:0.57759684, test precision: 0.6110695587135377,test recall: 0.5950473415877641,test f1: 0.6029520295202953\n",
      "train accuracy: 0.7055471639285714, test accuracy:0.700447928331467 train loss:0.56078854, test loss:0.57644331, test precision: 0.6080777860882572,test recall: 0.5982339955849889,test f1: 0.6031157270029673\n",
      "train accuracy: 0.7082483457142856, test accuracy:0.700447928331467 train loss:0.55865051, test loss:0.57481349, test precision: 0.6080777860882572,test recall: 0.5982339955849889,test f1: 0.6031157270029673\n",
      "train accuracy: 0.7105839164285713, test accuracy:0.6976483762597985 train loss:0.55640964, test loss:0.57597697, test precision: 0.6110695587135377,test recall: 0.5933188090050835,test f1: 0.6020633750921149\n",
      "train accuracy: 0.7012199825, test accuracy:0.6934490481522956 train loss:0.5646281, test loss:0.58041811, test precision: 0.6275243081525804,test recall: 0.5842618384401114,test f1: 0.6051208077893977\n",
      "train accuracy: 0.7101581742857144, test accuracy:0.6962486002239642 train loss:0.55753239, test loss:0.57635057, test precision: 0.6170531039640987,test recall: 0.5901287553648069,test f1: 0.6032906764168191\n",
      "train accuracy: 0.7064010549999999, test accuracy:0.6962486002239642 train loss:0.55871179, test loss:0.5773893, test precision: 0.6170531039640987,test recall: 0.5901287553648069,test f1: 0.6032906764168191\n",
      "train accuracy: 0.7069687114285715, test accuracy:0.6934490481522956 train loss:0.55863542, test loss:0.57980639, test precision: 0.6275243081525804,test recall: 0.5842618384401114,test f1: 0.6051208077893977\n",
      "train accuracy: 0.7012344135714285, test accuracy:0.6993281075027995 train loss:0.56604895, test loss:0.57605112, test precision: 0.6110695587135377,test recall: 0.5959153902261123,test f1: 0.6033973412112259\n",
      "train accuracy: 0.7030744878571428, test accuracy:0.6993281075027995 train loss:0.56242665, test loss:0.57702947, test precision: 0.6110695587135377,test recall: 0.5959153902261123,test f1: 0.6033973412112259\n",
      "train accuracy: 0.7066512092857142, test accuracy:0.6968085106382979 train loss:0.55835465, test loss:0.57801455, test precision: 0.6222887060583395,test recall: 0.5900709219858156,test f1: 0.6057517291590826\n",
      "train accuracy: 0.7054942467857143, test accuracy:0.6962486002239642 train loss:0.56131263, test loss:0.57848728, test precision: 0.62528047868362,test recall: 0.5887323943661972,test f1: 0.6064562930721799\n",
      "train accuracy: 0.7068941471428573, test accuracy:0.6962486002239642 train loss:0.55980902, test loss:0.57859457, test precision: 0.6222887060583395,test recall: 0.5892351274787535,test f1: 0.6053110221898872\n",
      "train accuracy: 0.7082579667857143, test accuracy:0.7012877939529675 train loss:0.56037647, test loss:0.5748018, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.714078855357143, test accuracy:0.6987681970884658 train loss:0.55639908, test loss:0.57541794, test precision: 0.6080777860882572,test recall: 0.5956043956043956,test f1: 0.6017764618800887\n",
      "train accuracy: 0.7053739796428572, test accuracy:0.6942889137737962 train loss:0.56298165, test loss:0.57974243, test precision: 0.6275243081525804,test recall: 0.5854849965108164,test f1: 0.6057761732851986\n",
      "train accuracy: 0.7059175832142858, test accuracy:0.694568868980963 train loss:0.5601748, test loss:0.58122879, test precision: 0.6357516828721017,test recall: 0.5845942228335625,test f1: 0.6091006807595843\n",
      "train accuracy: 0.7008062657142858, test accuracy:0.6956886898096305 train loss:0.56213925, test loss:0.57910728, test precision: 0.6170531039640987,test recall: 0.5892857142857143,test f1: 0.6028498355864085\n",
      "train accuracy: 0.7065910750000001, test accuracy:0.6979283314669653 train loss:0.55666364, test loss:0.57731825, test precision: 0.6118175018698578,test recall: 0.5936139332365747,test f1: 0.6025782688766114\n",
      "train accuracy: 0.7074642096428573, test accuracy:0.6979283314669653 train loss:0.55909126, test loss:0.57673359, test precision: 0.6118175018698578,test recall: 0.5936139332365747,test f1: 0.6025782688766114\n",
      "train accuracy: 0.7110264975, test accuracy:0.6962486002239642 train loss:0.55636697, test loss:0.57824153, test precision: 0.62528047868362,test recall: 0.5887323943661972,test f1: 0.6064562930721799\n",
      "train accuracy: 0.7082627775, test accuracy:0.6962486002239642 train loss:0.55917721, test loss:0.57889068, test precision: 0.62528047868362,test recall: 0.5887323943661972,test f1: 0.6064562930721799\n",
      "train accuracy: 0.7075700432142858, test accuracy:0.6996080627099664 train loss:0.55878846, test loss:0.57583565, test precision: 0.6080777860882572,test recall: 0.5969162995594713,test f1: 0.6024453501296776\n",
      "train accuracy: 0.7108917989285715, test accuracy:0.6998880179171333 train loss:0.55933724, test loss:0.57685775, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7071034089285714, test accuracy:0.6973684210526315 train loss:0.55879595, test loss:0.5793348, test precision: 0.6148092744951383,test recall: 0.5922190201729106,test f1: 0.603302752293578\n",
      "train accuracy: 0.70722127, test accuracy:0.7012877939529675 train loss:0.55999906, test loss:0.57671595, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7071491117857143, test accuracy:0.7012877939529675 train loss:0.55936674, test loss:0.57433033, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7037359535714286, test accuracy:0.7007278835386338 train loss:0.56149375, test loss:0.57667762, test precision: 0.6088257292445775,test recall: 0.5985294117647059,test f1: 0.603633667037449\n",
      "train accuracy: 0.7106440507142857, test accuracy:0.7007278835386338 train loss:0.5599773, test loss:0.5769248, test precision: 0.6088257292445775,test recall: 0.5985294117647059,test f1: 0.603633667037449\n",
      "train accuracy: 0.7167439582142857, test accuracy:0.7001679731243001 train loss:0.55392307, test loss:0.57783258, test precision: 0.6088257292445775,test recall: 0.5976505139500734,test f1: 0.6031863653204891\n",
      "train accuracy: 0.7101244989285714, test accuracy:0.7015677491601344 train loss:0.55524523, test loss:0.57500643, test precision: 0.6080777860882572,test recall: 0.6,test f1: 0.6040118870728083\n",
      "train accuracy: 0.7066439910714285, test accuracy:0.7024076147816349 train loss:0.55936522, test loss:0.57441396, test precision: 0.6073298429319371,test recall: 0.6014814814814815,test f1: 0.6043915147004094\n",
      "train accuracy: 0.7088352450000001, test accuracy:0.7010078387458006 train loss:0.55812154, test loss:0.57631022, test precision: 0.6088257292445775,test recall: 0.5989698307579102,test f1: 0.6038575667655787\n",
      "train accuracy: 0.7100090450000002, test accuracy:0.6990481522956327 train loss:0.55647979, test loss:0.5780769, test precision: 0.6118175018698578,test recall: 0.5953420669577875,test f1: 0.6034673552194761\n",
      "train accuracy: 0.7105839164285713, test accuracy:0.6987681970884658 train loss:0.5559307, test loss:0.57776344, test precision: 0.6110695587135377,test recall: 0.5950473415877641,test f1: 0.6029520295202953\n",
      "train accuracy: 0.7017996639285714, test accuracy:0.7001679731243001 train loss:0.56395328, test loss:0.57871407, test precision: 0.6088257292445775,test recall: 0.5976505139500734,test f1: 0.6031863653204891\n",
      "train accuracy: 0.7093716335714285, test accuracy:0.7015677491601344 train loss:0.55769677, test loss:0.57469583, test precision: 0.6088257292445775,test recall: 0.599852616064849,test f1: 0.6043058648849295\n",
      "train accuracy: 0.708767895357143, test accuracy:0.698488241881299 train loss:0.55750809, test loss:0.57876265, test precision: 0.6118175018698578,test recall: 0.5944767441860465,test f1: 0.6030224843346847\n",
      "train accuracy: 0.7066271542857142, test accuracy:0.6998880179171333 train loss:0.56002445, test loss:0.57575238, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7121161103571428, test accuracy:0.6998880179171333 train loss:0.55762823, test loss:0.57614595, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7131383732142857, test accuracy:0.6998880179171333 train loss:0.55728102, test loss:0.5762127, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7050781260714285, test accuracy:0.698488241881299 train loss:0.5590192, test loss:0.58034813, test precision: 0.6118175018698578,test recall: 0.5944767441860465,test f1: 0.6030224843346847\n",
      "train accuracy: 0.7122941039285714, test accuracy:0.6998880179171333 train loss:0.55378544, test loss:0.57740438, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7104901103571428, test accuracy:0.698488241881299 train loss:0.55800114, test loss:0.57849586, test precision: 0.6118175018698578,test recall: 0.5944767441860465,test f1: 0.6030224843346847\n",
      "train accuracy: 0.7137445164285714, test accuracy:0.6990481522956327 train loss:0.55438157, test loss:0.57658452, test precision: 0.6118175018698578,test recall: 0.5953420669577875,test f1: 0.6034673552194761\n",
      "train accuracy: 0.7108797728571429, test accuracy:0.698488241881299 train loss:0.55726827, test loss:0.57751048, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.704419065357143, test accuracy:0.698488241881299 train loss:0.55845367, test loss:0.57842314, test precision: 0.6118175018698578,test recall: 0.5944767441860465,test f1: 0.6030224843346847\n",
      "train accuracy: 0.7120487600000001, test accuracy:0.6998880179171333 train loss:0.55392766, test loss:0.5755927, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7057901010714287, test accuracy:0.6998880179171333 train loss:0.56209856, test loss:0.57661766, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7031803221428572, test accuracy:0.698488241881299 train loss:0.56231817, test loss:0.57819009, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.70426753, test accuracy:0.6990481522956327 train loss:0.56122769, test loss:0.57733697, test precision: 0.6088257292445775,test recall: 0.595900439238653,test f1: 0.6022937476877543\n",
      "train accuracy: 0.7101846332142857, test accuracy:0.6998880179171333 train loss:0.55690782, test loss:0.57504022, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7062928153571428, test accuracy:0.6990481522956327 train loss:0.56294814, test loss:0.57662642, test precision: 0.6088257292445775,test recall: 0.595900439238653,test f1: 0.6022937476877543\n",
      "train accuracy: 0.7041039678571429, test accuracy:0.6990481522956327 train loss:0.56288236, test loss:0.57642609, test precision: 0.6088257292445775,test recall: 0.595900439238653,test f1: 0.6022937476877543\n",
      "train accuracy: 0.7159886867857143, test accuracy:0.6996080627099664 train loss:0.55357606, test loss:0.57518303, test precision: 0.6080777860882572,test recall: 0.5969162995594713,test f1: 0.6024453501296776\n",
      "train accuracy: 0.7083469635714286, test accuracy:0.6990481522956327 train loss:0.5558247, test loss:0.57647568, test precision: 0.6088257292445775,test recall: 0.595900439238653,test f1: 0.6022937476877543\n",
      "train accuracy: 0.7138984564285714, test accuracy:0.6998880179171333 train loss:0.5562442, test loss:0.57496423, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7043204471428571, test accuracy:0.698488241881299 train loss:0.56391723, test loss:0.57807577, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.703264509642857, test accuracy:0.6998880179171333 train loss:0.56190853, test loss:0.57657939, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7118178478571429, test accuracy:0.6990481522956327 train loss:0.55039072, test loss:0.57623321, test precision: 0.6088257292445775,test recall: 0.595900439238653,test f1: 0.6022937476877543\n",
      "train accuracy: 0.6979150628571429, test accuracy:0.698488241881299 train loss:0.56491443, test loss:0.57774061, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.7056794564285714, test accuracy:0.698488241881299 train loss:0.56173309, test loss:0.57751423, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.7089049978571429, test accuracy:0.6998880179171333 train loss:0.5566553, test loss:0.57617319, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7115147782142858, test accuracy:0.6998880179171333 train loss:0.55306702, test loss:0.57606012, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.710951932857143, test accuracy:0.6998880179171333 train loss:0.55248582, test loss:0.57532483, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7074064814285714, test accuracy:0.6970884658454647 train loss:0.55717313, test loss:0.57989591, test precision: 0.6222887060583395,test recall: 0.5904897090134847,test f1: 0.605972323379461\n",
      "train accuracy: 0.7097612964285716, test accuracy:0.6959686450167973 train loss:0.55456603, test loss:0.58200461, test precision: 0.6379955123410621,test recall: 0.5862542955326461,test f1: 0.6110315186246418\n",
      "train accuracy: 0.7104107335714286, test accuracy:0.6998880179171333 train loss:0.55598356, test loss:0.57360178, test precision: 0.6080777860882572,test recall: 0.5973548861131521,test f1: 0.6026686434395849\n",
      "train accuracy: 0.7088568925, test accuracy:0.6998880179171333 train loss:0.55677703, test loss:0.57442844, test precision: 0.6080777860882572,test recall: 0.5973548861131521,test f1: 0.6026686434395849\n",
      "train accuracy: 0.7063818117857144, test accuracy:0.698488241881299 train loss:0.55659092, test loss:0.57780331, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.7024635346428572, test accuracy:0.698488241881299 train loss:0.56144199, test loss:0.57754213, test precision: 0.6088257292445775,test recall: 0.5950292397660819,test f1: 0.6018484288354898\n",
      "train accuracy: 0.7076758778571428, test accuracy:0.7015677491601344 train loss:0.55956924, test loss:0.57510185, test precision: 0.6080777860882572,test recall: 0.6,test f1: 0.6040118870728083\n",
      "train accuracy: 0.702716095357143, test accuracy:0.7018477043673013 train loss:0.56232237, test loss:0.57656765, test precision: 0.6088257292445775,test recall: 0.6002949852507374,test f1: 0.604530263646491\n",
      "train accuracy: 0.7040125646428571, test accuracy:0.6987681970884658 train loss:0.56146028, test loss:0.57817394, test precision: 0.6170531039640987,test recall: 0.593952483801296,test f1: 0.6052824651504036\n",
      "train accuracy: 0.7121377575, test accuracy:0.6968085106382979 train loss:0.55418649, test loss:0.57880843, test precision: 0.6275243081525804,test recall: 0.589185393258427,test f1: 0.6077508149221297\n",
      "train accuracy: 0.7069181989285713, test accuracy:0.7018477043673013 train loss:0.55622127, test loss:0.57567292, test precision: 0.6088257292445775,test recall: 0.6002949852507374,test f1: 0.604530263646491\n",
      "train accuracy: 0.7059680964285715, test accuracy:0.6968085106382979 train loss:0.56175441, test loss:0.57786107, test precision: 0.6275243081525804,test recall: 0.589185393258427,test f1: 0.6077508149221297\n",
      "train accuracy: 0.7108942042857143, test accuracy:0.6993281075027995 train loss:0.55333935, test loss:0.57671469, test precision: 0.6088257292445775,test recall: 0.5963369963369963,test f1: 0.6025166543301259\n",
      "train accuracy: 0.7118082267857143, test accuracy:0.7012877939529675 train loss:0.55420909, test loss:0.57480794, test precision: 0.6080777860882572,test recall: 0.5995575221238938,test f1: 0.6037875974749349\n",
      "train accuracy: 0.7100427174999998, test accuracy:0.6987681970884658 train loss:0.55777025, test loss:0.57739317, test precision: 0.6200448765893792,test recall: 0.5934144595561919,test f1: 0.606437454279444\n",
      "train accuracy: 0.7064611875000001, test accuracy:0.6996080627099664 train loss:0.55821258, test loss:0.57555145, test precision: 0.6110695587135377,test recall: 0.5963503649635037,test f1: 0.6036202438123385\n",
      "train accuracy: 0.7161065467857143, test accuracy:0.7001679731243001 train loss:0.55205255, test loss:0.5727914, test precision: 0.6073298429319371,test recall: 0.5979381443298969,test f1: 0.6025974025974026\n",
      "train accuracy: 0.7164625349999999, test accuracy:0.6976483762597985 train loss:0.54993428, test loss:0.57652408, test precision: 0.6140613313388182,test recall: 0.5927797833935018,test f1: 0.6032329169728141\n",
      "train accuracy: 0.7029806803571429, test accuracy:0.6970884658454647 train loss:0.55793011, test loss:0.57856709, test precision: 0.6222887060583395,test recall: 0.5904897090134847,test f1: 0.605972323379461\n",
      "train accuracy: 0.7115412367857142, test accuracy:0.6998880179171333 train loss:0.55575499, test loss:0.57525462, test precision: 0.6118175018698578,test recall: 0.5966447848285923,test f1: 0.604135893648449\n",
      "train accuracy: 0.7144588975, test accuracy:0.6998880179171333 train loss:0.55090974, test loss:0.57621467, test precision: 0.6088257292445775,test recall: 0.5972120322817315,test f1: 0.602962962962963\n",
      "train accuracy: 0.7098358607142857, test accuracy:0.6993281075027995 train loss:0.55575744, test loss:0.57732922, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7108244507142858, test accuracy:0.6993281075027995 train loss:0.55986285, test loss:0.57739651, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7003540628571429, test accuracy:0.698488241881299 train loss:0.56155407, test loss:0.57870924, test precision: 0.6200448765893792,test recall: 0.5929899856938483,test f1: 0.6062157221206582\n",
      "train accuracy: 0.7115171835714286, test accuracy:0.6987681970884658 train loss:0.55543319, test loss:0.57827085, test precision: 0.6200448765893792,test recall: 0.5934144595561919,test f1: 0.606437454279444\n",
      "train accuracy: 0.7073776174999999, test accuracy:0.6998880179171333 train loss:0.55724934, test loss:0.57623398, test precision: 0.6103216155572176,test recall: 0.5969275786393563,test f1: 0.6035502958579883\n",
      "train accuracy: 0.7054485450000001, test accuracy:0.6993281075027995 train loss:0.56041196, test loss:0.57724231, test precision: 0.6118175018698578,test recall: 0.5957756737072105,test f1: 0.6036900369003689\n",
      "train accuracy: 0.7072765935714286, test accuracy:0.6976483762597985 train loss:0.55800695, test loss:0.58028895, test precision: 0.6267763649962603,test recall: 0.5905567300916138,test f1: 0.6081277213352686\n",
      "train accuracy: 0.7095496264285713, test accuracy:0.6998880179171333 train loss:0.55370064, test loss:0.57630938, test precision: 0.6103216155572176,test recall: 0.5969275786393563,test f1: 0.6035502958579883\n",
      "train accuracy: 0.7105718903571429, test accuracy:0.6996080627099664 train loss:0.55924714, test loss:0.57534641, test precision: 0.6103216155572176,test recall: 0.5964912280701754,test f1: 0.6033271719038816\n",
      "train accuracy: 0.705669835357143, test accuracy:0.6990481522956327 train loss:0.56185697, test loss:0.57646918, test precision: 0.6103216155572176,test recall: 0.5956204379562043,test f1: 0.6028814185445142\n",
      "train accuracy: 0.7068965510714286, test accuracy:0.6993281075027995 train loss:0.55873809, test loss:0.57611322, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.7078851410714285, test accuracy:0.6996080627099664 train loss:0.55425735, test loss:0.57623273, test precision: 0.6103216155572176,test recall: 0.5964912280701754,test f1: 0.6033271719038816\n",
      "train accuracy: 0.7068532560714286, test accuracy:0.6996080627099664 train loss:0.5582128, test loss:0.57601327, test precision: 0.6103216155572176,test recall: 0.5964912280701754,test f1: 0.6033271719038816\n",
      "train accuracy: 0.7044888192857144, test accuracy:0.6993281075027995 train loss:0.56147665, test loss:0.57654315, test precision: 0.6103216155572176,test recall: 0.5960555149744339,test f1: 0.6031042128603105\n",
      "train accuracy: 0.7072693767857142, test accuracy:0.6987681970884658 train loss:0.55947468, test loss:0.57708448, test precision: 0.6103216155572176,test recall: 0.5951859956236324,test f1: 0.6026587887740029\n",
      "train accuracy: 0.7121618117857144, test accuracy:0.6998880179171333 train loss:0.55550591, test loss:0.57526898, test precision: 0.6103216155572176,test recall: 0.5969275786393563,test f1: 0.6035502958579883\n",
      "train accuracy: 0.7102712246428571, test accuracy:0.7001679731243001 train loss:0.55337369, test loss:0.57455903, test precision: 0.6103216155572176,test recall: 0.5973645680819912,test f1: 0.6037735849056604\n",
      "train accuracy: 0.7046692192857142, test accuracy:0.6962486002239642 train loss:0.56029297, test loss:0.57938546, test precision: 0.6305160807778609,test recall: 0.5878661087866108,test f1: 0.6084446048357993\n",
      "train accuracy: 0.710316925, test accuracy:0.6959686450167973 train loss:0.55321746, test loss:0.58136594, test precision: 0.6454749439042633,test recall: 0.5850847457627119,test f1: 0.6137980085348507\n",
      "train accuracy: 0.7086837089285715, test accuracy:0.6987681970884658 train loss:0.55676418, test loss:0.57599717, test precision: 0.6110695587135377,test recall: 0.5950473415877641,test f1: 0.6029520295202953\n",
      "train accuracy: 0.7007677792857143, test accuracy:0.698488241881299 train loss:0.56447698, test loss:0.57722443, test precision: 0.6118175018698578,test recall: 0.5944767441860465,test f1: 0.6030224843346847\n",
      "train accuracy: 0.7067786903571428, test accuracy:0.6998880179171333 train loss:0.55929647, test loss:0.57539999, test precision: 0.6103216155572176,test recall: 0.5969275786393563,test f1: 0.6035502958579883\n",
      "train accuracy: 0.7045922496428573, test accuracy:0.6982082866741322 train loss:0.55677704, test loss:0.57935542, test precision: 0.6200448765893792,test recall: 0.592566118656183,test f1: 0.6059941520467836\n",
      "train accuracy: 0.7133139614285715, test accuracy:0.698488241881299 train loss:0.55413006, test loss:0.57652688, test precision: 0.6103216155572176,test recall: 0.5947521865889213,test f1: 0.602436323366556\n",
      "train accuracy: 0.7065501850000001, test accuracy:0.7010078387458006 train loss:0.55693773, test loss:0.57417053, test precision: 0.6020942408376964,test recall: 0.6002982848620433,test f1: 0.6011949215832711\n",
      "train accuracy: 0.7058622610714285, test accuracy:0.7012877939529675 train loss:0.55940801, test loss:0.57203048, test precision: 0.599850411368736,test recall: 0.6011994002998501,test f1: 0.600524148259079\n",
      "train accuracy: 0.7116326389285713, test accuracy:0.6982082866741322 train loss:0.55717014, test loss:0.57805079, test precision: 0.6103216155572176,test recall: 0.5943190094683175,test f1: 0.6022140221402212\n"
=======
      "train accuracy: 0.5219994848214285, test accuracy:0.4132138857782755 train loss:0.69270934, test loss:58.67861176, test precision: 0.9708302169035153,test recall: 0.38688524590163936,test f1: 0.5532821824381927\n",
      "train accuracy: 0.4977034683928571, test accuracy:0.37430011198208285 train loss:0.69299841, test loss:62.56999207, test precision: 1.0,test recall: 0.37430011198208285,test f1: 0.5447137909961296\n",
      "train accuracy: 0.499189775, test accuracy:0.38101903695408734 train loss:0.69207559, test loss:61.89809799, test precision: 0.9970082273747195,test recall: 0.3765536723163842,test f1: 0.5466475292187821\n",
      "train accuracy: 0.5019101991071429, test accuracy:0.39669652855543114 train loss:0.69107486, test loss:60.33034897, test precision: 0.9506357516828721,test recall: 0.3782738095238095,test f1: 0.5411965084096232\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\u001b[33m[W 2023-04-03 12:28:26,574]\u001b[0m Trial 9 failed with parameters: {'n_layers': 3, 'n_units_l0': 591, 'n_units_l1': 763, 'n_units_l2': 364, 'optimizer': 'Adam'} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\harit\\AppData\\Local\\Temp\\ipykernel_12732\\1914250171.py\", line 107, in objective\n",
      "    for batch_idx, (data, target) in enumerate(test_loader):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 628, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 671, in _next_data\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 61, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 265, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in collate\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 143, in <listcomp>\n",
      "    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 120, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 163, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-03 12:28:26,587]\u001b[0m Trial 9 failed with value None.\u001b[0m\n"
=======
      "\u001b[32m[I 2023-04-03 00:56:29,915]\u001b[0m Trial 3 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.55097441625, test accuracy:0.4832026875699888 train loss:0.69023864, test loss:51.67973328, test precision: 0.8354525056095736,test recall: 0.4072183740430186,test f1: 0.5475490196078431\n",
      "train accuracy: 0.49461817482142856, test accuracy:0.6256998880179171 train loss:0.6963396, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4940333103571429, test accuracy:0.6256998880179171 train loss:0.69603981, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.49400648178571427, test accuracy:0.6256998880179171 train loss:0.69551378, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5048613496428571, test accuracy:0.6256998880179171 train loss:0.69378972, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.49595960678571427, test accuracy:0.6256998880179171 train loss:0.69475901, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4997531764285714, test accuracy:0.6256998880179171 train loss:0.69398804, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5002682864285715, test accuracy:0.6256998880179171 train loss:0.69352323, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5004238925, test accuracy:0.6256998880179171 train loss:0.69322115, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5018136160714286, test accuracy:0.6256998880179171 train loss:0.69284184, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5049686641071428, test accuracy:0.6256998880179171 train loss:0.69211616, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4962547217857143, test accuracy:0.6256998880179171 train loss:0.69301271, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5029779791071428, test accuracy:0.6256998880179171 train loss:0.69189585, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5061222957142857, test accuracy:0.6256998880179171 train loss:0.69131024, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4928528503571429, test accuracy:0.6256998880179171 train loss:0.69258911, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4941352592857143, test accuracy:0.6256998880179171 train loss:0.692245, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5020336108928571, test accuracy:0.6256998880179171 train loss:0.69086617, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5020389766071428, test accuracy:0.6256998880179171 train loss:0.69080345, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5048667153571429, test accuracy:0.6256998880179171 train loss:0.69040637, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4946825635714286, test accuracy:0.6256998880179171 train loss:0.69098434, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5075066535714285, test accuracy:0.6256998880179171 train loss:0.68946154, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.49935611267857144, test accuracy:0.6256998880179171 train loss:0.69003604, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5021892169642858, test accuracy:0.6256998880179171 train loss:0.68947558, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.49594350964285716, test accuracy:0.6256998880179171 train loss:0.69009744, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.50316041375, test accuracy:0.6256998880179171 train loss:0.68897609, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5057520603571428, test accuracy:0.6256998880179171 train loss:0.68839714, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.4991200205357143, test accuracy:0.6256998880179171 train loss:0.68865227, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5001341432142857, test accuracy:0.6256998880179171 train loss:0.68835355, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-03 00:56:43,575]\u001b[0m Trial 4 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.5035360148214286, test accuracy:0.6256998880179171 train loss:0.68785549, test loss:37.43001175, test precision: 0.0,test recall: 0.0,test f1: 0.0\n",
      "train accuracy: 0.5034501630357143, test accuracy:0.4050951847704367 train loss:0.69291269, test loss:59.49048233, test precision: 0.9850411368735976,test recall: 0.3848626534190532,test f1: 0.5534776213490229\n",
      "train accuracy: 0.5204112294642858, test accuracy:0.4230123180291153 train loss:0.69266137, test loss:57.69876862, test precision: 0.9483919222139118,test recall: 0.3889570552147239,test f1: 0.5516641287796389\n",
      "train accuracy: 0.5414126889285714, test accuracy:0.47368421052631576 train loss:0.69242863, test loss:52.63158035, test precision: 0.8698578908002992,test recall: 0.40536772394562565,test f1: 0.553019495958155\n",
      "train accuracy: 0.5574025583928571, test accuracy:0.48292273236282196 train loss:0.69216854, test loss:51.70772934, test precision: 0.837696335078534,test recall: 0.4072727272727273,test f1: 0.5480792757523856\n",
      "train accuracy: 0.5596186041071428, test accuracy:0.48180291153415455 train loss:0.69192582, test loss:51.81970978, test precision: 0.8212415856394913,test recall: 0.4051660516605166,test f1: 0.5426241660489252\n",
      "train accuracy: 0.558851305, test accuracy:0.48152295632698766 train loss:0.69169701, test loss:51.84770584, test precision: 0.8204936424831712,test recall: 0.4049464747139166,test f1: 0.5422639644092931\n",
      "train accuracy: 0.5641365469642857, test accuracy:0.486562150055991 train loss:0.69145017, test loss:51.34378815, test precision: 0.8152580403889305,test recall: 0.4071722076951812,test f1: 0.5430991529646239\n",
      "train accuracy: 0.5570967119642857, test accuracy:0.4868421052631579 train loss:0.69133563, test loss:51.31579208, test precision: 0.8152580403889305,test recall: 0.40732436472346784,test f1: 0.5432344879142785\n",
      "train accuracy: 0.5624785371428571, test accuracy:0.49272116461366183 train loss:0.69105371, test loss:50.7278862, test precision: 0.8077786088257293,test recall: 0.4098671726755218,test f1: 0.5438066465256797\n",
      "train accuracy: 0.5746480082142857, test accuracy:0.513437849944009 train loss:0.69066379, test loss:48.65621567, test precision: 0.7554225878833208,test recall: 0.41718298223874434,test f1: 0.5375199574241618\n",
      "train accuracy: 0.5968567566071429, test accuracy:0.5512318029115342 train loss:0.69038543, test loss:44.87681961, test precision: 0.6948391922213911,test recall: 0.4373822975517891,test f1: 0.5368390638543774\n",
      "train accuracy: 0.5983967205357142, test accuracy:0.5506718924972005 train loss:0.69026799, test loss:44.93281174, test precision: 0.6888556469708302,test recall: 0.4364928909952607,test f1: 0.5343777197563098\n",
      "train accuracy: 0.6123100532142857, test accuracy:0.5512318029115342 train loss:0.68973391, test loss:44.87681961, test precision: 0.6993268511593119,test recall: 0.43773408239700373,test f1: 0.5384393895767348\n",
      "train accuracy: 0.6107915521428572, test accuracy:0.5926651735722285 train loss:0.68963125, test loss:40.73348236, test precision: 0.643979057591623,test recall: 0.46793478260869564,test f1: 0.5420207743153919\n",
      "train accuracy: 0.6161841089285715, test accuracy:0.5926651735722285 train loss:0.68957002, test loss:40.73348236, test precision: 0.637247569184742,test recall: 0.4676180021953897,test f1: 0.5394112060778727\n",
      "train accuracy: 0.6280852935714286, test accuracy:0.606942889137738 train loss:0.68919168, test loss:39.30571365, test precision: 0.6305160807778609,test recall: 0.48088990302338847,test f1: 0.5456310679611651\n",
      "train accuracy: 0.6297647664285714, test accuracy:0.6072228443449048 train loss:0.68872089, test loss:39.27771759, test precision: 0.6275243081525804,test recall: 0.48107798165137616,test f1: 0.5446283674131774\n",
      "train accuracy: 0.63427734375, test accuracy:0.6201007838745801 train loss:0.68820983, test loss:37.98992157, test precision: 0.6028421839940165,test recall: 0.49387254901960786,test f1: 0.5429437521050859\n",
      "train accuracy: 0.6441180889285715, test accuracy:0.6256998880179171 train loss:0.6878189, test loss:37.43001175, test precision: 0.5938668661181751,test recall: 0.5,test f1: 0.5429059829059829\n",
      "train accuracy: 0.6418698489285715, test accuracy:0.6438969764837627 train loss:0.68773948, test loss:35.61030197, test precision: 0.5833956619296934,test recall: 0.5217391304347826,test f1: 0.5508474576271186\n",
      "train accuracy: 0.6515710851785714, test accuracy:0.6436170212765957 train loss:0.68703401, test loss:35.63829803, test precision: 0.5639491398653702,test recall: 0.5221606648199446,test f1: 0.5422509888529305\n",
      "train accuracy: 0.6454917153571429, test accuracy:0.6433370660694289 train loss:0.68665784, test loss:35.6662941, test precision: 0.56245325355273,test recall: 0.5218598195697433,test f1: 0.5413966882649388\n",
      "train accuracy: 0.6524725275, test accuracy:0.6447368421052632 train loss:0.6859261, test loss:35.5263176, test precision: 0.5602094240837696,test recall: 0.5237762237762238,test f1: 0.5413805565594506\n",
      "train accuracy: 0.6559334219642857, test accuracy:0.6452967525195968 train loss:0.68511955, test loss:35.47032547, test precision: 0.5594614809274495,test recall: 0.5245441795231417,test f1: 0.5414404632645675\n",
      "train accuracy: 0.6468116844642857, test accuracy:0.6455767077267637 train loss:0.68520137, test loss:35.44232941, test precision: 0.5594614809274495,test recall: 0.5249122807017544,test f1: 0.5416364952932659\n",
      "train accuracy: 0.65234375, test accuracy:0.6472564389697648 train loss:0.68444533, test loss:35.27435684, test precision: 0.556469708302169,test recall: 0.5272856130403969,test f1: 0.5414847161572052\n",
      "train accuracy: 0.6516193767857142, test accuracy:0.6472564389697648 train loss:0.68379641, test loss:35.27435684, test precision: 0.5587135377711294,test recall: 0.5271700776287932,test f1: 0.542483660130719\n",
      "train accuracy: 0.6613903675, test accuracy:0.6556550951847704 train loss:0.68274229, test loss:34.4344902, test precision: 0.531787584143605,test recall: 0.5406844106463878,test f1: 0.5361990950226245\n",
      "train accuracy: 0.6515764508928571, test accuracy:0.6550951847704367 train loss:0.68278706, test loss:34.49048233, test precision: 0.531787584143605,test recall: 0.5398633257403189,test f1: 0.5357950263752825\n",
      "train accuracy: 0.6503530648214285, test accuracy:0.6534154535274356 train loss:0.68259152, test loss:34.6584549, test precision: 0.537023186237846,test recall: 0.537023186237846,test f1: 0.537023186237846\n",
      "train accuracy: 0.6522739955357143, test accuracy:0.6438969764837627 train loss:0.68134555, test loss:35.61030197, test precision: 0.5385190725504861,test recall: 0.5236363636363637,test f1: 0.5309734513274336\n",
      "train accuracy: 0.6516301082142857, test accuracy:0.6500559910414334 train loss:0.68025284, test loss:34.99440384, test precision: 0.5385190725504861,test recall: 0.532150776053215,test f1: 0.5353159851301116\n",
      "train accuracy: 0.6554719694642858, test accuracy:0.643057110862262 train loss:0.67920497, test loss:35.69429016, test precision: 0.5646970830216903,test recall: 0.5214088397790055,test f1: 0.5421903052064633\n",
      "train accuracy: 0.6495804, test accuracy:0.643057110862262 train loss:0.6790476, test loss:35.69429016, test precision: 0.5646970830216903,test recall: 0.5214088397790055,test f1: 0.5421903052064633\n",
      "train accuracy: 0.6496769832142857, test accuracy:0.6483762597984323 train loss:0.67828487, test loss:35.1623764, test precision: 0.5646970830216903,test recall: 0.5283414975507348,test f1: 0.5459146782357194\n",
      "train accuracy: 0.6490169985714286, test accuracy:0.6503359462486002 train loss:0.67734413, test loss:34.96640778, test precision: 0.5609573672400897,test recall: 0.5311614730878187,test f1: 0.5456529647144416\n",
      "train accuracy: 0.6499452696428571, test accuracy:0.6517357222844344 train loss:0.67675408, test loss:34.82642746, test precision: 0.537023186237846,test recall: 0.5346239761727476,test f1: 0.5358208955223881\n",
      "train accuracy: 0.6562017083928572, test accuracy:0.6587346024636058 train loss:0.67580798, test loss:34.12654114, test precision: 0.5160807778608826,test recall: 0.5467511885895404,test f1: 0.5309734513274337\n",
      "train accuracy: 0.6579884958928571, test accuracy:0.6567749160134378 train loss:0.67452993, test loss:34.32250977, test precision: 0.5168287210172027,test recall: 0.5436664044059796,test f1: 0.5299079754601227\n",
      "train accuracy: 0.6490706558928572, test accuracy:0.6570548712206047 train loss:0.67482972, test loss:34.2945137, test precision: 0.5168287210172027,test recall: 0.5440944881889764,test f1: 0.5301112389719984\n",
      "train accuracy: 0.65367981625, test accuracy:0.6615341545352743 train loss:0.67292584, test loss:33.84658432, test precision: 0.5145848915482424,test recall: 0.5512820512820513,test f1: 0.5323017408123791\n",
      "train accuracy: 0.6578704498214286, test accuracy:0.6615341545352743 train loss:0.67185984, test loss:33.84658432, test precision: 0.5145848915482424,test recall: 0.5512820512820513,test f1: 0.5323017408123791\n",
      "train accuracy: 0.6624152214285715, test accuracy:0.6615341545352743 train loss:0.67052144, test loss:33.84658432, test precision: 0.5145848915482424,test recall: 0.5512820512820513,test f1: 0.5323017408123791\n",
      "train accuracy: 0.6509647578571428, test accuracy:0.6606942889137738 train loss:0.67057648, test loss:33.93057251, test precision: 0.5168287210172027,test recall: 0.5497215592680986,test f1: 0.5327679259830377\n",
      "train accuracy: 0.6602367358928571, test accuracy:0.6623740201567749 train loss:0.66853705, test loss:33.76259995, test precision: 0.531039640987285,test recall: 0.5508145849495734,test f1: 0.5407463823305407\n",
      "train accuracy: 0.6695355425, test accuracy:0.6623740201567749 train loss:0.66642016, test loss:33.76259995, test precision: 0.531039640987285,test recall: 0.5508145849495734,test f1: 0.5407463823305407\n",
      "train accuracy: 0.6580689817857143, test accuracy:0.6615341545352743 train loss:0.66685278, test loss:33.84658432, test precision: 0.5332834704562454,test recall: 0.5493066255778121,test f1: 0.5411764705882354\n",
      "train accuracy: 0.6594855339285715, test accuracy:0.6629339305711086 train loss:0.66503331, test loss:33.70660782, test precision: 0.5325355272999253,test recall: 0.5515104570100697,test f1: 0.5418569254185693\n",
      "train accuracy: 0.66187864875, test accuracy:0.6612541993281075 train loss:0.66395657, test loss:33.87458038, test precision: 0.5340314136125655,test recall: 0.5488086087624904,test f1: 0.5413191811978773\n",
      "train accuracy: 0.6582192221428571, test accuracy:0.6612541993281075 train loss:0.66444051, test loss:33.87458038, test precision: 0.5340314136125655,test recall: 0.5488086087624904,test f1: 0.5413191811978773\n",
      "train accuracy: 0.6583855598214285, test accuracy:0.6626539753639418 train loss:0.66224628, test loss:33.73460388, test precision: 0.5332834704562454,test recall: 0.5510046367851623,test f1: 0.5419992398327632\n",
      "train accuracy: 0.6631288633928571, test accuracy:0.6626539753639418 train loss:0.66087906, test loss:33.73460388, test precision: 0.5332834704562454,test recall: 0.5510046367851623,test f1: 0.5419992398327632\n",
      "train accuracy: 0.6602528330357142, test accuracy:0.6626539753639418 train loss:0.65942557, test loss:33.73460388, test precision: 0.5332834704562454,test recall: 0.5510046367851623,test f1: 0.5419992398327632\n",
      "train accuracy: 0.6536315246428571, test accuracy:0.6606942889137738 train loss:0.66087959, test loss:33.93057251, test precision: 0.5661929693343306,test recall: 0.5449964002879769,test f1: 0.5553925165077036\n",
      "train accuracy: 0.6692189646428571, test accuracy:0.6592945128779395 train loss:0.65701702, test loss:34.07054901, test precision: 0.5669409124906507,test recall: 0.5429799426934098,test f1: 0.5547017929015734\n",
      "train accuracy: 0.6572855855357143, test accuracy:0.6592945128779395 train loss:0.65714746, test loss:34.07054901, test precision: 0.5699326851159312,test recall: 0.5427350427350427,test f1: 0.5560014593214155\n",
      "train accuracy: 0.6651893028571428, test accuracy:0.6578947368421053 train loss:0.65563666, test loss:34.21052933, test precision: 0.5714285714285714,test recall: 0.5406935598018401,test f1: 0.5556363636363636\n",
      "train accuracy: 0.6599523523214286, test accuracy:0.6578947368421053 train loss:0.65511819, test loss:34.21052933, test precision: 0.5714285714285714,test recall: 0.5406935598018401,test f1: 0.5556363636363636\n",
      "train accuracy: 0.6579616673214286, test accuracy:0.6581746920492721 train loss:0.65557179, test loss:34.18253326, test precision: 0.575168287210172,test recall: 0.5407876230661041,test f1: 0.5574483508517578\n",
      "train accuracy: 0.66514101125, test accuracy:0.6578947368421053 train loss:0.65251114, test loss:34.21052933, test precision: 0.5714285714285714,test recall: 0.5406935598018401,test f1: 0.5556363636363636\n",
      "train accuracy: 0.6691009185714286, test accuracy:0.6590145576707727 train loss:0.65032011, test loss:34.09854507, test precision: 0.5766641735228123,test recall: 0.5418130709768095,test f1: 0.558695652173913\n",
      "train accuracy: 0.66689023875, test accuracy:0.6590145576707727 train loss:0.65017536, test loss:34.09854507, test precision: 0.5781600598354525,test recall: 0.5416958654519972,test f1: 0.5593342981186686\n",
      "train accuracy: 0.6714940333928572, test accuracy:0.6570548712206047 train loss:0.64818005, test loss:34.2945137, test precision: 0.581151832460733,test recall: 0.5388349514563107,test f1: 0.5591939546599496\n",
      "train accuracy: 0.6723847441071429, test accuracy:0.6576147816349384 train loss:0.64725198, test loss:34.23852158, test precision: 0.5826477187733732,test recall: 0.5394736842105263,test f1: 0.5602301330456669\n",
      "train accuracy: 0.6658600189285714, test accuracy:0.6576147816349384 train loss:0.64751323, test loss:34.23852158, test precision: 0.5826477187733732,test recall: 0.5394736842105263,test f1: 0.5602301330456669\n",
      "train accuracy: 0.6669224330357143, test accuracy:0.6576147816349384 train loss:0.64627613, test loss:34.23852158, test precision: 0.5826477187733732,test recall: 0.5394736842105263,test f1: 0.5602301330456669\n",
      "train accuracy: 0.6697448058928571, test accuracy:0.6573348264277715 train loss:0.6438567, test loss:34.26651764, test precision: 0.5833956619296934,test recall: 0.5390463026952315,test f1: 0.5603448275862069\n",
      "train accuracy: 0.6580797132142857, test accuracy:0.6573348264277715 train loss:0.64695943, test loss:34.26651764, test precision: 0.5833956619296934,test recall: 0.5390463026952315,test f1: 0.5603448275862069\n",
      "train accuracy: 0.6627747253571429, test accuracy:0.6573348264277715 train loss:0.64333181, test loss:34.26651764, test precision: 0.5833956619296934,test recall: 0.5390463026952315,test f1: 0.5603448275862069\n",
      "train accuracy: 0.6640249398214285, test accuracy:0.6573348264277715 train loss:0.64181514, test loss:34.26651764, test precision: 0.5833956619296934,test recall: 0.5390463026952315,test f1: 0.5603448275862069\n",
      "train accuracy: 0.6670995021428572, test accuracy:0.6592945128779395 train loss:0.64152814, test loss:34.07054901, test precision: 0.5796559461480928,test recall: 0.541958041958042,test f1: 0.5601734730755331\n",
      "train accuracy: 0.6681136246428572, test accuracy:0.6595744680851063 train loss:0.63900338, test loss:34.04255295, test precision: 0.5804038893044129,test recall: 0.5422781271837875,test f1: 0.5606936416184972\n",
      "train accuracy: 0.6637083619642857, test accuracy:0.6601343784994401 train loss:0.64076123, test loss:33.98656464, test precision: 0.5789080029917726,test recall: 0.5431578947368421,test f1: 0.560463432295438\n",
      "train accuracy: 0.6596411401785715, test accuracy:0.6595744680851063 train loss:0.64164388, test loss:34.04255295, test precision: 0.5796559461480928,test recall: 0.5423372988103569,test f1: 0.5603759942154736\n",
      "train accuracy: 0.66204498625, test accuracy:0.6592945128779395 train loss:0.63892231, test loss:34.07054901, test precision: 0.5796559461480928,test recall: 0.541958041958042,test f1: 0.5601734730755331\n",
      "train accuracy: 0.6644327351785714, test accuracy:0.6618141097424413 train loss:0.63643902, test loss:33.81859207, test precision: 0.5789080029917726,test recall: 0.5454545454545454,test f1: 0.5616835994194483\n",
      "train accuracy: 0.6675716860714286, test accuracy:0.6615341545352743 train loss:0.63628663, test loss:33.84658432, test precision: 0.5789080029917726,test recall: 0.5450704225352113,test f1: 0.5614798694232862\n",
      "train accuracy: 0.6674321771428572, test accuracy:0.6615341545352743 train loss:0.63484388, test loss:33.84658432, test precision: 0.5789080029917726,test recall: 0.5450704225352113,test f1: 0.5614798694232862\n",
      "train accuracy: 0.6675341260714286, test accuracy:0.6598544232922733 train loss:0.63573403, test loss:34.0145607, test precision: 0.5983545250560958,test recall: 0.5412719891745602,test f1: 0.5683836589698046\n",
      "train accuracy: 0.6750676082142857, test accuracy:0.6612541993281075 train loss:0.63044182, test loss:33.87458038, test precision: 0.5976065818997757,test recall: 0.5431679129843644,test f1: 0.5690883190883191\n",
      "train accuracy: 0.6635259271428572, test accuracy:0.6618141097424413 train loss:0.6351734, test loss:33.81859207, test precision: 0.5976065818997757,test recall: 0.5439074200136147,test f1: 0.5694939415538134\n",
      "train accuracy: 0.6686877575, test accuracy:0.6620940649496081 train loss:0.63232501, test loss:33.79059601, test precision: 0.5976065818997757,test recall: 0.5442779291553134,test f1: 0.5696969696969697\n",
      "train accuracy: 0.6686823917857143, test accuracy:0.6618141097424413 train loss:0.63210959, test loss:33.81859207, test precision: 0.5976065818997757,test recall: 0.5439074200136147,test f1: 0.5694939415538134\n",
      "train accuracy: 0.6706945398214286, test accuracy:0.6618141097424413 train loss:0.62963604, test loss:33.81859207, test precision: 0.5976065818997757,test recall: 0.5439074200136147,test f1: 0.5694939415538134\n",
      "train accuracy: 0.6701901614285715, test accuracy:0.6618141097424413 train loss:0.63016326, test loss:33.81859207, test precision: 0.5976065818997757,test recall: 0.5439074200136147,test f1: 0.5694939415538134\n",
      "train accuracy: 0.6685697116071428, test accuracy:0.6618141097424413 train loss:0.62767547, test loss:33.81859207, test precision: 0.5976065818997757,test recall: 0.5439074200136147,test f1: 0.5694939415538134\n",
      "train accuracy: 0.6685375171428571, test accuracy:0.6632138857782754 train loss:0.62839997, test loss:33.67861176, test precision: 0.5938668661181751,test recall: 0.546079779917469,test f1: 0.5689716947330706\n",
      "train accuracy: 0.6653771033928572, test accuracy:0.6632138857782754 train loss:0.62798293, test loss:33.67861176, test precision: 0.5908750934928946,test recall: 0.5463347164591977,test f1: 0.5677326625943225\n",
      "train accuracy: 0.6696965144642857, test accuracy:0.6609742441209406 train loss:0.62558276, test loss:33.90257645, test precision: 0.5961106955871354,test recall: 0.5429155313351499,test f1: 0.568270944741533\n",
      "train accuracy: 0.6751427283928572, test accuracy:0.6606942889137738 train loss:0.62311527, test loss:33.93057251, test precision: 0.5976065818997757,test recall: 0.5424304141208418,test f1: 0.5686832740213524\n",
      "train accuracy: 0.6669224330357143, test accuracy:0.6578947368421053 train loss:0.62654303, test loss:34.21052933, test precision: 0.606581899775617,test recall: 0.5381552753815527,test f1: 0.570323488045007\n",
      "train accuracy: 0.6704960078571428, test accuracy:0.658454647256439 train loss:0.62393641, test loss:34.1545372, test precision: 0.6028421839940165,test recall: 0.5391304347826087,test f1: 0.5692090395480226\n",
      "train accuracy: 0.6723364526785715, test accuracy:0.6595744680851063 train loss:0.62191259, test loss:34.04255295, test precision: 0.6013462976813763,test recall: 0.5406859448554135,test f1: 0.5694050991501417\n",
      "train accuracy: 0.66357421875, test accuracy:0.6587346024636058 train loss:0.62649223, test loss:34.12654114, test precision: 0.6013462976813763,test recall: 0.5395973154362416,test f1: 0.568800848956491\n",
      "train accuracy: 0.6694604223214285, test accuracy:0.6592945128779395 train loss:0.62387041, test loss:34.07054901, test precision: 0.6020942408376964,test recall: 0.540268456375839,test f1: 0.5695083126989743\n",
      "train accuracy: 0.6733344780357143, test accuracy:0.6595744680851063 train loss:0.61867669, test loss:34.04255295, test precision: 0.6020942408376964,test recall: 0.5406312961719275,test f1: 0.5697098372257609\n",
      "train accuracy: 0.6759583191071429, test accuracy:0.6590145576707727 train loss:0.61684499, test loss:34.09854507, test precision: 0.6028421839940165,test recall: 0.5398526456798393,test f1: 0.5696113074204947\n",
      "train accuracy: 0.6686662946428571, test accuracy:0.6587346024636058 train loss:0.6238291, test loss:34.12654114, test precision: 0.6035901271503366,test recall: 0.5394385026737968,test f1: 0.5697140840098834\n",
      "train accuracy: 0.6721754807142857, test accuracy:0.6587346024636058 train loss:0.62095666, test loss:34.12654114, test precision: 0.6035901271503366,test recall: 0.5394385026737968,test f1: 0.5697140840098834\n",
      "train accuracy: 0.6746490814285714, test accuracy:0.6587346024636058 train loss:0.62094163, test loss:34.12654114, test precision: 0.6035901271503366,test recall: 0.5394385026737968,test f1: 0.5697140840098834\n",
      "train accuracy: 0.67610319375, test accuracy:0.6576147816349384 train loss:0.61757525, test loss:34.23852158, test precision: 0.6050860134629769,test recall: 0.5378989361702128,test f1: 0.5695177754311862\n",
      "train accuracy: 0.6688916551785714, test accuracy:0.658454647256439 train loss:0.621384, test loss:34.1545372, test precision: 0.6050860134629769,test recall: 0.5389740173217855,test f1: 0.5701198026779423\n",
      "train accuracy: 0.6643361521428571, test accuracy:0.6598544232922733 train loss:0.62130548, test loss:34.0145607, test precision: 0.6013462976813763,test recall: 0.5410497981157469,test f1: 0.5696068012752391\n",
      "train accuracy: 0.6738388564285714, test accuracy:0.660414333706607 train loss:0.61736597, test loss:33.95856857, test precision: 0.600598354525056,test recall: 0.5418353576248313,test f1: 0.5697055693508336\n",
      "train accuracy: 0.6699326064285714, test accuracy:0.660414333706607 train loss:0.61803273, test loss:33.95856857, test precision: 0.600598354525056,test recall: 0.5418353576248313,test f1: 0.5697055693508336\n",
      "train accuracy: 0.6694121308928571, test accuracy:0.660414333706607 train loss:0.61885563, test loss:33.95856857, test precision: 0.600598354525056,test recall: 0.5418353576248313,test f1: 0.5697055693508336\n",
      "train accuracy: 0.6690257983928571, test accuracy:0.660414333706607 train loss:0.61946733, test loss:33.95856857, test precision: 0.600598354525056,test recall: 0.5418353576248313,test f1: 0.5697055693508336\n",
      "train accuracy: 0.6772407280357143, test accuracy:0.6612541993281075 train loss:0.61104543, test loss:33.87458038, test precision: 0.6035901271503366,test recall: 0.5427034297242771,test f1: 0.571529745042493\n",
      "train accuracy: 0.6692404275, test accuracy:0.6609742441209406 train loss:0.61646403, test loss:33.90257645, test precision: 0.6035901271503366,test recall: 0.5423387096774194,test f1: 0.5713274336283185\n",
      "train accuracy: 0.6691545758928571, test accuracy:0.6612541993281075 train loss:0.61570208, test loss:33.87458038, test precision: 0.6035901271503366,test recall: 0.5427034297242771,test f1: 0.571529745042493\n",
      "train accuracy: 0.6779704669642858, test accuracy:0.6609742441209406 train loss:0.61333828, test loss:33.90257645, test precision: 0.6035901271503366,test recall: 0.5423387096774194,test f1: 0.5713274336283185\n",
      "train accuracy: 0.6777182778571429, test accuracy:0.6615341545352743 train loss:0.61297017, test loss:33.84658432, test precision: 0.6035901271503366,test recall: 0.5430686406460296,test f1: 0.5717321997874601\n",
      "train accuracy: 0.6711828210714286, test accuracy:0.6615341545352743 train loss:0.61713435, test loss:33.84658432, test precision: 0.6035901271503366,test recall: 0.5430686406460296,test f1: 0.5717321997874601\n",
      "train accuracy: 0.6723847441071429, test accuracy:0.6601343784994401 train loss:0.61278871, test loss:33.98656464, test precision: 0.6035901271503366,test recall: 0.5412474849094567,test f1: 0.5707213578500707\n",
      "train accuracy: 0.6757275926785714, test accuracy:0.6609742441209406 train loss:0.60912093, test loss:33.90257645, test precision: 0.6035901271503366,test recall: 0.5423387096774194,test f1: 0.5713274336283185\n",
      "train accuracy: 0.6738173935714286, test accuracy:0.6623740201567749 train loss:0.61133753, test loss:33.76259995, test precision: 0.600598354525056,test recall: 0.5444067796610169,test f1: 0.5711237553342816\n",
      "train accuracy: 0.6709467291071428, test accuracy:0.6623740201567749 train loss:0.61355867, test loss:33.76259995, test precision: 0.600598354525056,test recall: 0.5444067796610169,test f1: 0.5711237553342816\n",
      "train accuracy: 0.6683926425, test accuracy:0.6640537513997761 train loss:0.61313785, test loss:33.59462738, test precision: 0.600598354525056,test recall: 0.5466303607896529,test f1: 0.5723449750534568\n",
      "train accuracy: 0.6721808464285715, test accuracy:0.6640537513997761 train loss:0.61309102, test loss:33.59462738, test precision: 0.600598354525056,test recall: 0.5466303607896529,test f1: 0.5723449750534568\n",
      "train accuracy: 0.6705550308928572, test accuracy:0.6640537513997761 train loss:0.61276458, test loss:33.59462738, test precision: 0.600598354525056,test recall: 0.5466303607896529,test f1: 0.5723449750534568\n",
      "train accuracy: 0.6722398694642857, test accuracy:0.666013437849944 train loss:0.61270983, test loss:33.39865875, test precision: 0.5976065818997757,test recall: 0.5495185694635488,test f1: 0.5725546399140093\n",
      "train accuracy: 0.6759797819642858, test accuracy:0.6632138857782754 train loss:0.61250332, test loss:33.67861176, test precision: 0.600598354525056,test recall: 0.545516304347826,test f1: 0.5717337130651478\n",
      "train accuracy: 0.6782065591071429, test accuracy:0.6632138857782754 train loss:0.60938152, test loss:33.67861176, test precision: 0.600598354525056,test recall: 0.545516304347826,test f1: 0.5717337130651478\n",
      "train accuracy: 0.6769831730357143, test accuracy:0.6651735722284434 train loss:0.60954422, test loss:33.48264313, test precision: 0.5976065818997757,test recall: 0.5483870967741935,test f1: 0.5719398711524695\n",
      "train accuracy: 0.6747671273214285, test accuracy:0.6662933930571109 train loss:0.60971101, test loss:33.37066269, test precision: 0.5968586387434555,test recall: 0.5499655410062027,test f1: 0.5724533715925395\n",
      "train accuracy: 0.6729749742857143, test accuracy:0.6688129899216125 train loss:0.61201928, test loss:33.11870193, test precision: 0.5923709798055348,test recall: 0.5538461538461539,test f1: 0.5724611492591254\n",
      "train accuracy: 0.6795748196428572, test accuracy:0.6674132138857782 train loss:0.60639057, test loss:33.25867844, test precision: 0.5953627524308153,test recall: 0.5516285516285516,test f1: 0.5726618705035972\n",
      "train accuracy: 0.6748583448214286, test accuracy:0.6657334826427772 train loss:0.60981788, test loss:33.426651, test precision: 0.5938668661181751,test recall: 0.5494809688581315,test f1: 0.5708123652048885\n",
      "train accuracy: 0.6748851733928571, test accuracy:0.6657334826427772 train loss:0.60971407, test loss:33.426651, test precision: 0.5938668661181751,test recall: 0.5494809688581315,test f1: 0.5708123652048885\n",
      "train accuracy: 0.6826332846428571, test accuracy:0.666013437849944 train loss:0.60497336, test loss:33.39865875, test precision: 0.5938668661181751,test recall: 0.5498614958448753,test f1: 0.5710176195613089\n",
      "train accuracy: 0.6720842633928571, test accuracy:0.666013437849944 train loss:0.61169674, test loss:33.39865875, test precision: 0.5931189229618549,test recall: 0.5499306518723994,test f1: 0.5707088880892406\n",
      "train accuracy: 0.6820859803571429, test accuracy:0.666013437849944 train loss:0.60445305, test loss:33.39865875, test precision: 0.5931189229618549,test recall: 0.5499306518723994,test f1: 0.5707088880892406\n",
      "train accuracy: 0.6655863667857143, test accuracy:0.6668533034714446 train loss:0.61493853, test loss:33.31467056, test precision: 0.5923709798055348,test recall: 0.5511482254697286,test f1: 0.5710165825522712\n",
      "train accuracy: 0.6813133155357143, test accuracy:0.6693729003359462 train loss:0.60650632, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6796177455357143, test accuracy:0.6693729003359462 train loss:0.60789863, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6797411573214286, test accuracy:0.6693729003359462 train loss:0.60553313, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6807821085714286, test accuracy:0.6693729003359462 train loss:0.6054556, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6714779360714286, test accuracy:0.6693729003359462 train loss:0.61303877, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6782065591071429, test accuracy:0.6693729003359462 train loss:0.60625969, test loss:33.06270981, test precision: 0.605833956619297,test recall: 0.5532786885245902,test f1: 0.5783648696893966\n",
      "train accuracy: 0.6776538891071429, test accuracy:0.6693729003359462 train loss:0.60766032, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.676591475, test accuracy:0.6693729003359462 train loss:0.60825013, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6761944110714285, test accuracy:0.6693729003359462 train loss:0.60976673, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.67903288125, test accuracy:0.6693729003359462 train loss:0.6071463, test loss:33.06270981, test precision: 0.606581899775617,test recall: 0.553206002728513,test f1: 0.5786657153050303\n",
      "train accuracy: 0.6777504721428571, test accuracy:0.6693729003359462 train loss:0.60770964, test loss:33.06270981, test precision: 0.605833956619297,test recall: 0.5532786885245902,test f1: 0.5783648696893966\n",
      "train accuracy: 0.6848278675, test accuracy:0.6693729003359462 train loss:0.60387785, test loss:33.06270981, test precision: 0.605833956619297,test recall: 0.5532786885245902,test f1: 0.5783648696893966\n",
      "train accuracy: 0.6854502919642858, test accuracy:0.6702127659574468 train loss:0.6011184, test loss:32.97872543, test precision: 0.6043380703066566,test recall: 0.5545641729581332,test f1: 0.5783822476735863\n",
      "train accuracy: 0.6842000773214286, test accuracy:0.671892497200448 train loss:0.60049194, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6789899553571429, test accuracy:0.671892497200448 train loss:0.60670067, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6780455871428571, test accuracy:0.671892497200448 train loss:0.6053267, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6767900067857143, test accuracy:0.671892497200448 train loss:0.60734535, test loss:32.81075287, test precision: 0.605833956619297,test recall: 0.5567010309278351,test f1: 0.5802292263610316\n",
      "train accuracy: 0.6875107314285714, test accuracy:0.671892497200448 train loss:0.60105952, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.67881288625, test accuracy:0.671892497200448 train loss:0.60623833, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6778148608928571, test accuracy:0.671892497200448 train loss:0.60636334, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6818230598214285, test accuracy:0.671892497200448 train loss:0.60281894, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6800899296428572, test accuracy:0.671892497200448 train loss:0.60404441, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6832879035714285, test accuracy:0.671892497200448 train loss:0.60117267, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6746651785714286, test accuracy:0.6724524076147816 train loss:0.60908896, test loss:32.75476074, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6760280735714286, test accuracy:0.671892497200448 train loss:0.60484918, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6790489783928572, test accuracy:0.671892497200448 train loss:0.60304633, test loss:32.81075287, test precision: 0.6043380703066566,test recall: 0.5568573397656789,test f1: 0.5796269727403157\n",
      "train accuracy: 0.6787055717857143, test accuracy:0.6724524076147816 train loss:0.60456234, test loss:32.75476074, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6755934494642857, test accuracy:0.6724524076147816 train loss:0.60835427, test loss:32.75476074, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6779382726785714, test accuracy:0.6721724524076148 train loss:0.60471275, test loss:32.78275681, test precision: 0.6043380703066566,test recall: 0.5572413793103448,test f1: 0.5798349479727304\n",
      "train accuracy: 0.68030455875, test accuracy:0.6724524076147816 train loss:0.60272765, test loss:32.75476074, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6847795758928571, test accuracy:0.6724524076147816 train loss:0.59863348, test loss:32.75476074, test precision: 0.605833956619297,test recall: 0.5574673090158293,test f1: 0.5806451612903226\n",
      "train accuracy: 0.6778148608928571, test accuracy:0.6727323628219485 train loss:0.60214072, test loss:32.72676468, test precision: 0.605833956619297,test recall: 0.5578512396694215,test f1: 0.5808533524560775\n",
      "train accuracy: 0.6843342205357142, test accuracy:0.6724524076147816 train loss:0.59970157, test loss:32.75476074, test precision: 0.6050860134629769,test recall: 0.5575465196416265,test f1: 0.5803443328550932\n",
      "train accuracy: 0.6823542667857143, test accuracy:0.6732922732362822 train loss:0.59843907, test loss:32.67077255, test precision: 0.6020942408376964,test recall: 0.5590277777777778,test f1: 0.5797623334533669\n",
      "train accuracy: 0.6822469523214286, test accuracy:0.6730123180291153 train loss:0.60104138, test loss:32.69876862, test precision: 0.6035901271503366,test recall: 0.558477508650519,test f1: 0.5801581595974119\n",
      "train accuracy: 0.6806640625, test accuracy:0.6738521836506159 train loss:0.60347341, test loss:32.61478424, test precision: 0.6035901271503366,test recall: 0.5596393897364771,test f1: 0.5807844548398705\n",
      "train accuracy: 0.6874570741071429, test accuracy:0.66993281075028 train loss:0.60110143, test loss:33.0067215, test precision: 0.6043380703066566,test recall: 0.5541838134430727,test f1: 0.5781753130590339\n",
      "train accuracy: 0.6842912946428571, test accuracy:0.6704927211646137 train loss:0.60014224, test loss:32.95072937, test precision: 0.6088257292445775,test recall: 0.5544959128065395,test f1: 0.5803921568627451\n",
      "train accuracy: 0.6859654017857143, test accuracy:0.6702127659574468 train loss:0.59838085, test loss:32.97872543, test precision: 0.6043380703066566,test recall: 0.5545641729581332,test f1: 0.5783822476735863\n",
      "train accuracy: 0.6750300480357143, test accuracy:0.6704927211646137 train loss:0.60460448, test loss:32.95072937, test precision: 0.6088257292445775,test recall: 0.5544959128065395,test f1: 0.5803921568627451\n",
      "train accuracy: 0.6824186555357142, test accuracy:0.6704927211646137 train loss:0.60153184, test loss:32.95072937, test precision: 0.6088257292445775,test recall: 0.5544959128065395,test f1: 0.5803921568627451\n",
      "train accuracy: 0.6829820569642857, test accuracy:0.66993281075028 train loss:0.60151477, test loss:33.0067215, test precision: 0.6020942408376964,test recall: 0.5544077134986226,test f1: 0.5772678379347437\n",
      "train accuracy: 0.6900594523214286, test accuracy:0.6713325867861142 train loss:0.59465689, test loss:32.86674118, test precision: 0.6080777860882572,test recall: 0.5557074504442926,test f1: 0.5807142857142857\n",
      "train accuracy: 0.6829552283928572, test accuracy:0.6710526315789473 train loss:0.60230629, test loss:32.89473724, test precision: 0.6080777860882572,test recall: 0.555327868852459,test f1: 0.5805069617993573\n",
      "train accuracy: 0.6800148094642857, test accuracy:0.671612541993281 train loss:0.60282207, test loss:32.83874512, test precision: 0.6118175018698578,test recall: 0.5557065217391305,test f1: 0.5824136703453185\n",
      "train accuracy: 0.6806747939285714, test accuracy:0.6710526315789473 train loss:0.6001504, test loss:32.89473724, test precision: 0.6118175018698578,test recall: 0.5549525101763908,test f1: 0.5819992885094274\n",
      "train accuracy: 0.6807982057142857, test accuracy:0.6724524076147816 train loss:0.60429646, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.68505859375, test accuracy:0.6724524076147816 train loss:0.59743271, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.6926725617857142, test accuracy:0.6732922732362822 train loss:0.59493747, test loss:32.67077255, test precision: 0.6163051608077786,test recall: 0.557510148849797,test f1: 0.5854351687388988\n",
      "train accuracy: 0.6819947630357143, test accuracy:0.671892497200448 train loss:0.60256304, test loss:32.81075287, test precision: 0.6110695587135377,test recall: 0.5561606535057863,test f1: 0.5823235923022095\n",
      "train accuracy: 0.6855146807142857, test accuracy:0.6707726763717805 train loss:0.59810174, test loss:32.92273331, test precision: 0.606581899775617,test recall: 0.5550992470910335,test f1: 0.5796997855611151\n",
      "train accuracy: 0.6819303742857142, test accuracy:0.6727323628219485 train loss:0.60210172, test loss:32.72676468, test precision: 0.6163051608077786,test recall: 0.5567567567567567,test f1: 0.5850195243166489\n",
      "train accuracy: 0.6859707675, test accuracy:0.6721724524076148 train loss:0.59779962, test loss:32.78275681, test precision: 0.6110695587135377,test recall: 0.5565395095367848,test f1: 0.5825311942959003\n",
      "train accuracy: 0.6791509271428572, test accuracy:0.6724524076147816 train loss:0.60305709, test loss:32.75476074, test precision: 0.612565445026178,test recall: 0.5567641060503059,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6846186041071428, test accuracy:0.6727323628219485 train loss:0.60137174, test loss:32.72676468, test precision: 0.6178010471204188,test recall: 0.5566037735849056,test f1: 0.58560794044665\n",
      "train accuracy: 0.6879185267857143, test accuracy:0.6724524076147816 train loss:0.59635537, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.6853429773214286, test accuracy:0.6724524076147816 train loss:0.5992069, test loss:32.75476074, test precision: 0.612565445026178,test recall: 0.5567641060503059,test f1: 0.5833333333333334\n",
      "train accuracy: 0.6846025067857143, test accuracy:0.6732922732362822 train loss:0.59928584, test loss:32.67077255, test precision: 0.6155572176514585,test recall: 0.5575880758807588,test f1: 0.5851404194809812\n",
      "train accuracy: 0.6844951923214285, test accuracy:0.6727323628219485 train loss:0.59855686, test loss:32.72676468, test precision: 0.6178010471204188,test recall: 0.5566037735849056,test f1: 0.58560794044665\n",
      "train accuracy: 0.6805835766071429, test accuracy:0.6724524076147816 train loss:0.60147337, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.6824347526785715, test accuracy:0.6727323628219485 train loss:0.59757262, test loss:32.72676468, test precision: 0.6178010471204188,test recall: 0.5566037735849056,test f1: 0.58560794044665\n",
      "train accuracy: 0.6877790178571429, test accuracy:0.6724524076147816 train loss:0.59545271, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.6790006867857142, test accuracy:0.6724524076147816 train loss:0.60221223, test loss:32.75476074, test precision: 0.6163051608077786,test recall: 0.5563808237677245,test f1: 0.5848119233498935\n",
      "train accuracy: 0.6932091346428572, test accuracy:0.6727323628219485 train loss:0.59067527, test loss:32.72676468, test precision: 0.6178010471204188,test recall: 0.5566037735849056,test f1: 0.58560794044665\n",
      "train accuracy: 0.6778094951785715, test accuracy:0.6727323628219485 train loss:0.60137731, test loss:32.72676468, test precision: 0.6178010471204188,test recall: 0.5566037735849056,test f1: 0.58560794044665\n",
      "train accuracy: 0.6813025841071428, test accuracy:0.6727323628219485 train loss:0.59874615, test loss:32.72676468, test precision: 0.6155572176514585,test recall: 0.5568335588633289,test f1: 0.5847246891651866\n",
      "train accuracy: 0.6790543441071428, test accuracy:0.6730123180291153 train loss:0.60168419, test loss:32.69876862, test precision: 0.6148092744951383,test recall: 0.5572881355932203,test f1: 0.5846372688477951\n",
      "train accuracy: 0.6859332075, test accuracy:0.6730123180291153 train loss:0.59870837, test loss:32.69876862, test precision: 0.6148092744951383,test recall: 0.5572881355932203,test f1: 0.5846372688477951\n",
      "train accuracy: 0.6852624914285714, test accuracy:0.6730123180291153 train loss:0.59810476, test loss:32.69876862, test precision: 0.6170531039640987,test recall: 0.5570560432140446,test f1: 0.5855216465578424\n",
      "train accuracy: 0.6910896719642857, test accuracy:0.6730123180291153 train loss:0.5939401, test loss:32.69876862, test precision: 0.6148092744951383,test recall: 0.5572881355932203,test f1: 0.5846372688477951\n",
      "train accuracy: 0.6826386503571429, test accuracy:0.671892497200448 train loss:0.59887609, test loss:32.81075287, test precision: 0.6088257292445775,test recall: 0.556390977443609,test f1: 0.5814285714285714\n",
      "train accuracy: 0.68349180125, test accuracy:0.6727323628219485 train loss:0.59474813, test loss:32.72676468, test precision: 0.6118175018698578,test recall: 0.5572207084468664,test f1: 0.5832442067736185\n",
      "train accuracy: 0.6837278932142857, test accuracy:0.6724524076147816 train loss:0.59774447, test loss:32.75476074, test precision: 0.6088257292445775,test recall: 0.5571526351813826,test f1: 0.581844174410293\n",
      "train accuracy: 0.6900487208928572, test accuracy:0.6732922732362822 train loss:0.58992977, test loss:32.67077255, test precision: 0.6140613313388182,test recall: 0.5577445652173914,test f1: 0.5845496618013527\n",
      "train accuracy: 0.6806533310714286, test accuracy:0.6730123180291153 train loss:0.5979154, test loss:32.69876862, test precision: 0.6163051608077786,test recall: 0.5571331981068289,test f1: 0.5852272727272728\n",
      "train accuracy: 0.6801865126785714, test accuracy:0.6732922732362822 train loss:0.5991675, test loss:32.67077255, test precision: 0.6140613313388182,test recall: 0.5577445652173914,test f1: 0.5845496618013527\n",
      "train accuracy: 0.6855576064285714, test accuracy:0.673572228443449 train loss:0.59479804, test loss:32.64277649, test precision: 0.6148092744951383,test recall: 0.5580448065173116,test f1: 0.5850533807829181\n",
      "train accuracy: 0.6929408482142857, test accuracy:0.6732922732362822 train loss:0.58956635, test loss:32.67077255, test precision: 0.6140613313388182,test recall: 0.5577445652173914,test f1: 0.5845496618013527\n",
      "train accuracy: 0.6727013221428572, test accuracy:0.6732922732362822 train loss:0.60408771, test loss:32.67077255, test precision: 0.6140613313388182,test recall: 0.5577445652173914,test f1: 0.5845496618013527\n",
      "train accuracy: 0.6857346755357143, test accuracy:0.6732922732362822 train loss:0.59295454, test loss:32.67077255, test precision: 0.6140613313388182,test recall: 0.5577445652173914,test f1: 0.5845496618013527\n",
      "train accuracy: 0.683851305, test accuracy:0.671892497200448 train loss:0.59501685, test loss:32.81075287, test precision: 0.6140613313388182,test recall: 0.5558564658090724,test f1: 0.5835110163468372\n",
      "train accuracy: 0.6829713255357143, test accuracy:0.671892497200448 train loss:0.59636497, test loss:32.81075287, test precision: 0.6140613313388182,test recall: 0.5558564658090724,test f1: 0.5835110163468372\n",
      "train accuracy: 0.6861532023214286, test accuracy:0.6721724524076148 train loss:0.59585293, test loss:32.78275681, test precision: 0.6170531039640987,test recall: 0.5559299191374663,test f1: 0.5848989719957461\n",
      "train accuracy: 0.68043333625, test accuracy:0.671892497200448 train loss:0.59760447, test loss:32.81075287, test precision: 0.6170531039640987,test recall: 0.5555555555555556,test f1: 0.5846917080085047\n",
      "train accuracy: 0.6839908139285714, test accuracy:0.6721724524076148 train loss:0.5953629, test loss:32.78275681, test precision: 0.6148092744951383,test recall: 0.5561569688768606,test f1: 0.5840142095914742\n",
      "train accuracy: 0.6863034426785715, test accuracy:0.671892497200448 train loss:0.59298774, test loss:32.81075287, test precision: 0.6148092744951383,test recall: 0.5557809330628803,test f1: 0.5838068181818182\n",
      "train accuracy: 0.6791884873214286, test accuracy:0.6724524076147816 train loss:0.595155, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.6841249571428571, test accuracy:0.6721724524076148 train loss:0.59562882, test loss:32.78275681, test precision: 0.6148092744951383,test recall: 0.5561569688768606,test f1: 0.5840142095914742\n",
      "train accuracy: 0.6763500171428571, test accuracy:0.6721724524076148 train loss:0.59716514, test loss:32.78275681, test precision: 0.6148092744951383,test recall: 0.5561569688768606,test f1: 0.5840142095914742\n",
      "train accuracy: 0.6886750944642858, test accuracy:0.6721724524076148 train loss:0.59347814, test loss:32.78275681, test precision: 0.6148092744951383,test recall: 0.5561569688768606,test f1: 0.5840142095914742\n",
      "train accuracy: 0.6835508241071429, test accuracy:0.6724524076147816 train loss:0.59212438, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.686099545, test accuracy:0.673572228443449 train loss:0.592216, test loss:32.64277649, test precision: 0.6148092744951383,test recall: 0.5580448065173116,test f1: 0.5850533807829181\n",
      "train accuracy: 0.6890345982142857, test accuracy:0.6724524076147816 train loss:0.59247704, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.6831108344642857, test accuracy:0.6724524076147816 train loss:0.59652097, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.6854395603571428, test accuracy:0.6724524076147816 train loss:0.58968801, test loss:32.75476074, test precision: 0.6155572176514585,test recall: 0.5564570655848546,test f1: 0.5845170454545454\n",
      "train accuracy: 0.6861746651785714, test accuracy:0.673572228443449 train loss:0.59072486, test loss:32.64277649, test precision: 0.6148092744951383,test recall: 0.5580448065173116,test f1: 0.5850533807829181\n",
      "train accuracy: 0.6835025326785714, test accuracy:0.6738521836506159 train loss:0.59300537, test loss:32.61478424, test precision: 0.6148092744951383,test recall: 0.5584239130434783,test f1: 0.5852616589533642\n",
      "train accuracy: 0.6793387276785714, test accuracy:0.6738521836506159 train loss:0.59323357, test loss:32.61478424, test precision: 0.6148092744951383,test recall: 0.5584239130434783,test f1: 0.5852616589533642\n",
      "train accuracy: 0.6834757039285714, test accuracy:0.6727323628219485 train loss:0.59554532, test loss:32.72676468, test precision: 0.6155572176514585,test recall: 0.5568335588633289,test f1: 0.5847246891651866\n",
      "train accuracy: 0.6795587225, test accuracy:0.6730123180291153 train loss:0.59701247, test loss:32.69876862, test precision: 0.6170531039640987,test recall: 0.5570560432140446,test f1: 0.5855216465578424\n",
      "train accuracy: 0.6903170071428572, test accuracy:0.6730123180291153 train loss:0.58863035, test loss:32.69876862, test precision: 0.6148092744951383,test recall: 0.5572881355932203,test f1: 0.5846372688477951\n",
      "train accuracy: 0.6860619848214285, test accuracy:0.6730123180291153 train loss:0.59125153, test loss:32.69876862, test precision: 0.6148092744951383,test recall: 0.5572881355932203,test f1: 0.5846372688477951\n",
      "train accuracy: 0.6840712998214286, test accuracy:0.673572228443449 train loss:0.59482503, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6899896978571428, test accuracy:0.6727323628219485 train loss:0.59075818, test loss:32.72676468, test precision: 0.6155572176514585,test recall: 0.5568335588633289,test f1: 0.5847246891651866\n",
      "train accuracy: 0.6884497339285715, test accuracy:0.673572228443449 train loss:0.59046656, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6825849932142857, test accuracy:0.673572228443449 train loss:0.59507964, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.68229524375, test accuracy:0.673572228443449 train loss:0.59355882, test loss:32.64277649, test precision: 0.6088257292445775,test recall: 0.5586822237474263,test f1: 0.5826771653543308\n",
      "train accuracy: 0.6812381953571428, test accuracy:0.6727323628219485 train loss:0.59193387, test loss:32.72676468, test precision: 0.6155572176514585,test recall: 0.5568335588633289,test f1: 0.5847246891651866\n",
      "train accuracy: 0.6754378433928572, test accuracy:0.6730123180291153 train loss:0.59872411, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6827405992857143, test accuracy:0.6730123180291153 train loss:0.59270697, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6792797046428571, test accuracy:0.6727323628219485 train loss:0.59681263, test loss:32.72676468, test precision: 0.6080777860882572,test recall: 0.5576131687242798,test f1: 0.5817531305903397\n",
      "train accuracy: 0.6843181232142858, test accuracy:0.6727323628219485 train loss:0.58853241, test loss:32.72676468, test precision: 0.6163051608077786,test recall: 0.5567567567567567,test f1: 0.5850195243166489\n",
      "train accuracy: 0.6863517342857143, test accuracy:0.6732922732362822 train loss:0.59018421, test loss:32.67077255, test precision: 0.6103216155572176,test recall: 0.5581395348837209,test f1: 0.5830653804930331\n",
      "train accuracy: 0.68717805625, test accuracy:0.6730123180291153 train loss:0.58969075, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6843234889285714, test accuracy:0.6730123180291153 train loss:0.59261004, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6916262448214285, test accuracy:0.6730123180291153 train loss:0.58753463, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6847903073214285, test accuracy:0.6727323628219485 train loss:0.59373907, test loss:32.72676468, test precision: 0.6073298429319371,test recall: 0.5576923076923077,test f1: 0.581453634085213\n",
      "train accuracy: 0.68340058375, test accuracy:0.6730123180291153 train loss:0.5917785, test loss:32.69876862, test precision: 0.6080777860882572,test recall: 0.5579958819492107,test f1: 0.5819613457408733\n",
      "train accuracy: 0.6836796016071428, test accuracy:0.6727323628219485 train loss:0.59160204, test loss:32.72676468, test precision: 0.6163051608077786,test recall: 0.5567567567567567,test f1: 0.5850195243166489\n",
      "train accuracy: 0.6848117701785714, test accuracy:0.6730123180291153 train loss:0.59092515, test loss:32.69876862, test precision: 0.6088257292445775,test recall: 0.5579163810829335,test f1: 0.5822603719599428\n",
      "train accuracy: 0.6858634530357143, test accuracy:0.671612541993281 train loss:0.58982141, test loss:32.83874512, test precision: 0.6163051608077786,test recall: 0.555256064690027,test f1: 0.5841900035448423\n",
      "train accuracy: 0.6773587741071428, test accuracy:0.6732922732362822 train loss:0.59336768, test loss:32.67077255, test precision: 0.6103216155572176,test recall: 0.5581395348837209,test f1: 0.5830653804930331\n",
      "train accuracy: 0.6846937242857143, test accuracy:0.6730123180291153 train loss:0.58949302, test loss:32.69876862, test precision: 0.6080777860882572,test recall: 0.5579958819492107,test f1: 0.5819613457408733\n",
      "train accuracy: 0.68414642, test accuracy:0.6730123180291153 train loss:0.59135275, test loss:32.69876862, test precision: 0.6080777860882572,test recall: 0.5579958819492107,test f1: 0.5819613457408733\n",
      "train accuracy: 0.6828908396428571, test accuracy:0.6730123180291153 train loss:0.59572204, test loss:32.69876862, test precision: 0.6080777860882572,test recall: 0.5579958819492107,test f1: 0.5819613457408733\n",
      "train accuracy: 0.6889863066071429, test accuracy:0.671892497200448 train loss:0.59145414, test loss:32.81075287, test precision: 0.6080777860882572,test recall: 0.5564681724845996,test f1: 0.5811293781272338\n",
      "train accuracy: 0.6858849158928572, test accuracy:0.671892497200448 train loss:0.58998795, test loss:32.81075287, test precision: 0.6080777860882572,test recall: 0.5564681724845996,test f1: 0.5811293781272338\n",
      "train accuracy: 0.68584199, test accuracy:0.6738521836506159 train loss:0.58762009, test loss:32.61478424, test precision: 0.6035901271503366,test recall: 0.5596393897364771,test f1: 0.5807844548398705\n",
      "train accuracy: 0.68131868125, test accuracy:0.6746920492721165 train loss:0.59555066, test loss:32.53079605, test precision: 0.605833956619297,test recall: 0.5605536332179931,test f1: 0.582314881380302\n",
      "train accuracy: 0.6838030133928571, test accuracy:0.6746920492721165 train loss:0.59138708, test loss:32.53079605, test precision: 0.605833956619297,test recall: 0.5605536332179931,test f1: 0.582314881380302\n",
      "train accuracy: 0.683298635, test accuracy:0.6763717805151176 train loss:0.59227239, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6842698317857143, test accuracy:0.6760918253079508 train loss:0.59475604, test loss:32.39081955, test precision: 0.6118175018698578,test recall: 0.5618131868131868,test f1: 0.585750089509488\n",
      "train accuracy: 0.6928335335714285, test accuracy:0.6763717805151176 train loss:0.58548638, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.68480103875, test accuracy:0.6760918253079508 train loss:0.59003904, test loss:32.39081955, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6895228794642857, test accuracy:0.6760918253079508 train loss:0.58803299, test loss:32.39081955, test precision: 0.6110695587135377,test recall: 0.561898211829436,test f1: 0.5854532425653888\n",
      "train accuracy: 0.6864483173214285, test accuracy:0.6786114221724524 train loss:0.58851792, test loss:32.1388588, test precision: 0.6073298429319371,test recall: 0.5658536585365853,test f1: 0.5858585858585857\n",
      "train accuracy: 0.6943627660714285, test accuracy:0.6786114221724524 train loss:0.58365258, test loss:32.1388588, test precision: 0.6073298429319371,test recall: 0.5658536585365853,test f1: 0.5858585858585857\n",
      "train accuracy: 0.6855522407142857, test accuracy:0.6786114221724524 train loss:0.59041643, test loss:32.1388588, test precision: 0.6088257292445775,test recall: 0.5656706045865184,test f1: 0.5864553314121038\n",
      "train accuracy: 0.6971475789285714, test accuracy:0.6786114221724524 train loss:0.58144856, test loss:32.1388588, test precision: 0.6088257292445775,test recall: 0.5656706045865184,test f1: 0.5864553314121038\n",
      "train accuracy: 0.6861156421428571, test accuracy:0.6788913773796192 train loss:0.58854785, test loss:32.11086273, test precision: 0.6073298429319371,test recall: 0.5662482566248257,test f1: 0.5860700108264164\n",
      "train accuracy: 0.6817801339285714, test accuracy:0.6788913773796192 train loss:0.59294439, test loss:32.11086273, test precision: 0.605833956619297,test recall: 0.5664335664335665,test f1: 0.5854716299241055\n",
      "train accuracy: 0.6856756525, test accuracy:0.6786114221724524 train loss:0.59242868, test loss:32.1388588, test precision: 0.605833956619297,test recall: 0.5660377358490566,test f1: 0.5852601156069364\n",
      "train accuracy: 0.6868346496428571, test accuracy:0.6786114221724524 train loss:0.59185764, test loss:32.1388588, test precision: 0.605833956619297,test recall: 0.5660377358490566,test f1: 0.5852601156069364\n",
      "train accuracy: 0.68714049625, test accuracy:0.6791713325867861 train loss:0.58914774, test loss:32.08286667, test precision: 0.6088257292445775,test recall: 0.5664578983994433,test f1: 0.5868781542898343\n",
      "train accuracy: 0.6762158739285714, test accuracy:0.6791713325867861 train loss:0.59507512, test loss:32.08286667, test precision: 0.6088257292445775,test recall: 0.5664578983994433,test f1: 0.5868781542898343\n",
      "train accuracy: 0.6850317651785715, test accuracy:0.6788913773796192 train loss:0.59262434, test loss:32.11086273, test precision: 0.6073298429319371,test recall: 0.5662482566248257,test f1: 0.5860700108264164\n",
      "train accuracy: 0.6903331044642858, test accuracy:0.6800111982082867 train loss:0.58670693, test loss:31.99888039, test precision: 0.605833956619297,test recall: 0.5680224403927069,test f1: 0.5863192182410423\n",
      "train accuracy: 0.6852302969642857, test accuracy:0.6788913773796192 train loss:0.58899887, test loss:32.11086273, test precision: 0.6073298429319371,test recall: 0.5662482566248257,test f1: 0.5860700108264164\n",
      "train accuracy: 0.67597441625, test accuracy:0.6791713325867861 train loss:0.60084429, test loss:32.08286667, test precision: 0.6088257292445775,test recall: 0.5664578983994433,test f1: 0.5868781542898343\n",
      "train accuracy: 0.6876985319642858, test accuracy:0.6788913773796192 train loss:0.58759656, test loss:32.11086273, test precision: 0.6088257292445775,test recall: 0.5660639777468707,test f1: 0.5866666666666667\n",
      "train accuracy: 0.6863088083928571, test accuracy:0.6780515117581187 train loss:0.59153296, test loss:32.19485092, test precision: 0.6088257292445775,test recall: 0.5648854961832062,test f1: 0.586033117350612\n",
      "train accuracy: 0.6832932692857143, test accuracy:0.6780515117581187 train loss:0.59197846, test loss:32.19485092, test precision: 0.6095736724008975,test recall: 0.5647955647955648,test f1: 0.5863309352517985\n",
      "train accuracy: 0.6875375601785715, test accuracy:0.6780515117581187 train loss:0.5899401, test loss:32.19485092, test precision: 0.6088257292445775,test recall: 0.5648854961832062,test f1: 0.586033117350612\n",
      "train accuracy: 0.6893941019642857, test accuracy:0.6788913773796192 train loss:0.58688687, test loss:32.11086273, test precision: 0.6088257292445775,test recall: 0.5660639777468707,test f1: 0.5866666666666667\n",
      "train accuracy: 0.6866683121428572, test accuracy:0.6788913773796192 train loss:0.58947455, test loss:32.11086273, test precision: 0.6088257292445775,test recall: 0.5660639777468707,test f1: 0.5866666666666667\n",
      "train accuracy: 0.6905209048214286, test accuracy:0.6780515117581187 train loss:0.58720086, test loss:32.19485092, test precision: 0.6088257292445775,test recall: 0.5648854961832062,test f1: 0.586033117350612\n",
      "train accuracy: 0.6966378348214286, test accuracy:0.6791713325867861 train loss:0.58311809, test loss:32.08286667, test precision: 0.6073298429319371,test recall: 0.5666434054431263,test f1: 0.5862815884476534\n",
      "train accuracy: 0.6898501889285714, test accuracy:0.6791713325867861 train loss:0.58644582, test loss:32.08286667, test precision: 0.6073298429319371,test recall: 0.5666434054431263,test f1: 0.5862815884476534\n",
      "train accuracy: 0.6839210594642857, test accuracy:0.6791713325867861 train loss:0.58964809, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6919267255357143, test accuracy:0.6780515117581187 train loss:0.58619593, test loss:32.19485092, test precision: 0.6095736724008975,test recall: 0.5647955647955648,test f1: 0.5863309352517985\n",
      "train accuracy: 0.6915457589285714, test accuracy:0.6791713325867861 train loss:0.5886689, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6899467719642857, test accuracy:0.6802911534154535 train loss:0.58236696, test loss:31.97088623, test precision: 0.6095736724008975,test recall: 0.5679442508710801,test f1: 0.588023088023088\n",
      "train accuracy: 0.6891150841071428, test accuracy:0.6780515117581187 train loss:0.58651666, test loss:32.19485092, test precision: 0.6095736724008975,test recall: 0.5647955647955648,test f1: 0.5863309352517985\n",
      "train accuracy: 0.6789792239285715, test accuracy:0.6791713325867861 train loss:0.59345359, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6862336882142858, test accuracy:0.6780515117581187 train loss:0.58829754, test loss:32.19485092, test precision: 0.6095736724008975,test recall: 0.5647955647955648,test f1: 0.5863309352517985\n",
      "train accuracy: 0.6938047303571429, test accuracy:0.6791713325867861 train loss:0.58232104, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6820967119642857, test accuracy:0.6780515117581187 train loss:0.59355459, test loss:32.19485092, test precision: 0.6095736724008975,test recall: 0.5647955647955648,test f1: 0.5863309352517985\n",
      "train accuracy: 0.6882672991071429, test accuracy:0.6791713325867861 train loss:0.58527458, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6917925825, test accuracy:0.6791713325867861 train loss:0.58387244, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6885033910714285, test accuracy:0.6763717805151176 train loss:0.58582665, test loss:32.36282349, test precision: 0.6110695587135377,test recall: 0.5622849277357193,test f1: 0.5856630824372759\n",
      "train accuracy: 0.6898555546428572, test accuracy:0.6791713325867861 train loss:0.58570461, test loss:32.08286667, test precision: 0.6095736724008975,test recall: 0.56636553161918,test f1: 0.5871757925072046\n",
      "train accuracy: 0.6875268285714285, test accuracy:0.6766517357222844 train loss:0.58836983, test loss:32.33482742, test precision: 0.6110695587135377,test recall: 0.5626721763085399,test f1: 0.5858730727859448\n",
      "train accuracy: 0.6873819539285714, test accuracy:0.6763717805151176 train loss:0.58641852, test loss:32.36282349, test precision: 0.6118175018698578,test recall: 0.5621993127147766,test f1: 0.5859598853868195\n",
      "train accuracy: 0.6867380666071429, test accuracy:0.6760918253079508 train loss:0.58561284, test loss:32.39081955, test precision: 0.6118175018698578,test recall: 0.5618131868131868,test f1: 0.585750089509488\n",
      "train accuracy: 0.6904672476785715, test accuracy:0.6777715565509519 train loss:0.58382729, test loss:32.22284698, test precision: 0.6110695587135377,test recall: 0.5642265193370166,test f1: 0.5867145421903053\n",
      "train accuracy: 0.6823649982142858, test accuracy:0.6777715565509519 train loss:0.58843694, test loss:32.22284698, test precision: 0.6110695587135377,test recall: 0.5642265193370166,test f1: 0.5867145421903053\n",
      "train accuracy: 0.6921037946428571, test accuracy:0.6780515117581187 train loss:0.5827412, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6936222957142857, test accuracy:0.6780515117581187 train loss:0.58128944, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6870331816071429, test accuracy:0.6780515117581187 train loss:0.58620516, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6941320398214286, test accuracy:0.6780515117581187 train loss:0.57922678, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6968310010714286, test accuracy:0.6780515117581187 train loss:0.58109965, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6904618817857143, test accuracy:0.6783314669652856 train loss:0.58376767, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6896516569642858, test accuracy:0.6780515117581187 train loss:0.58557794, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6909555289285715, test accuracy:0.6780515117581187 train loss:0.58347252, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.68629271125, test accuracy:0.6780515117581187 train loss:0.58897459, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6900594523214286, test accuracy:0.6777715565509519 train loss:0.58405968, test loss:32.22284698, test precision: 0.6110695587135377,test recall: 0.5642265193370166,test f1: 0.5867145421903053\n",
      "train accuracy: 0.6935203467857143, test accuracy:0.6777715565509519 train loss:0.58253478, test loss:32.22284698, test precision: 0.6110695587135377,test recall: 0.5642265193370166,test f1: 0.5867145421903053\n",
      "train accuracy: 0.6857883326785714, test accuracy:0.6780515117581187 train loss:0.58562998, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6959510216071428, test accuracy:0.6783314669652856 train loss:0.57922059, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6901774982142858, test accuracy:0.6777715565509519 train loss:0.58527814, test loss:32.22284698, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6925276871428572, test accuracy:0.6783314669652856 train loss:0.58552208, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6836474073214286, test accuracy:0.6780515117581187 train loss:0.58567762, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6949744591071428, test accuracy:0.6777715565509519 train loss:0.57983561, test loss:32.22284698, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6852785885714285, test accuracy:0.6777715565509519 train loss:0.5873858, test loss:32.22284698, test precision: 0.6095736724008975,test recall: 0.564404432132964,test f1: 0.5861201006832075\n",
      "train accuracy: 0.6897428742857142, test accuracy:0.6783314669652856 train loss:0.5812489, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.68535370875, test accuracy:0.6780515117581187 train loss:0.58439485, test loss:32.19485092, test precision: 0.6110695587135377,test recall: 0.5646164478230823,test f1: 0.5869252873563219\n",
      "train accuracy: 0.6945130066071429, test accuracy:0.6774916013437849 train loss:0.57996595, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6865449003571429, test accuracy:0.6769316909294513 train loss:0.5822442, test loss:32.30683136, test precision: 0.6148092744951383,test recall: 0.5626283367556468,test f1: 0.5875625446747677\n",
      "train accuracy: 0.6863892942857143, test accuracy:0.6769316909294513 train loss:0.58769078, test loss:32.30683136, test precision: 0.6148092744951383,test recall: 0.5626283367556468,test f1: 0.5875625446747677\n",
      "train accuracy: 0.692806705, test accuracy:0.6772116461366181 train loss:0.58197902, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.687242445, test accuracy:0.6774916013437849 train loss:0.58673108, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6886375342857143, test accuracy:0.6769316909294513 train loss:0.58187238, test loss:32.30683136, test precision: 0.6148092744951383,test recall: 0.5626283367556468,test f1: 0.5875625446747677\n",
      "train accuracy: 0.6856810182142857, test accuracy:0.6772116461366181 train loss:0.58672666, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6940032623214286, test accuracy:0.6783314669652856 train loss:0.58028508, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.69303743125, test accuracy:0.6783314669652856 train loss:0.58024275, test loss:32.16685486, test precision: 0.6110695587135377,test recall: 0.5650069156293223,test f1: 0.5871361839741286\n",
      "train accuracy: 0.6891687414285714, test accuracy:0.6777715565509519 train loss:0.58558552, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6834059494642857, test accuracy:0.6777715565509519 train loss:0.59096064, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6965895432142857, test accuracy:0.6777715565509519 train loss:0.57863598, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6870492789285715, test accuracy:0.6777715565509519 train loss:0.58952816, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6824776785714286, test accuracy:0.6777715565509519 train loss:0.5880732, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6844361692857143, test accuracy:0.6777715565509519 train loss:0.58236867, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.687757555, test accuracy:0.6774916013437849 train loss:0.58328997, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6928335335714285, test accuracy:0.6774916013437849 train loss:0.58215948, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6867756267857142, test accuracy:0.6777715565509519 train loss:0.58467303, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6854127317857143, test accuracy:0.6777715565509519 train loss:0.58160022, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6787055717857143, test accuracy:0.6774916013437849 train loss:0.59169796, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6942500858928572, test accuracy:0.6777715565509519 train loss:0.5801615, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6817318423214286, test accuracy:0.6772116461366181 train loss:0.58831212, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6898340916071428, test accuracy:0.6777715565509519 train loss:0.58250567, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6931340144642857, test accuracy:0.6777715565509519 train loss:0.58160968, test loss:32.22284698, test precision: 0.6148092744951383,test recall: 0.5637860082304527,test f1: 0.5881932021466906\n",
      "train accuracy: 0.6854288289285714, test accuracy:0.6783314669652856 train loss:0.58657135, test loss:32.16685486, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6871029360714286, test accuracy:0.6783314669652856 train loss:0.58280973, test loss:32.16685486, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6954412775, test accuracy:0.6783314669652856 train loss:0.57927058, test loss:32.16685486, test precision: 0.6148092744951383,test recall: 0.5645604395604396,test f1: 0.5886143931256713\n",
      "train accuracy: 0.6995299621428571, test accuracy:0.6772116461366181 train loss:0.57383752, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6864375858928572, test accuracy:0.6769316909294513 train loss:0.58260736, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6915940505357143, test accuracy:0.6774916013437849 train loss:0.58232855, test loss:32.25083923, test precision: 0.6148092744951383,test recall: 0.5633995887594243,test f1: 0.5879828326180258\n",
      "train accuracy: 0.6832288805357143, test accuracy:0.6772116461366181 train loss:0.58674758, test loss:32.2788353, test precision: 0.6155572176514585,test recall: 0.5629274965800274,test f1: 0.5880671668453019\n",
      "train accuracy: 0.6837493560714286, test accuracy:0.6769316909294513 train loss:0.58459829, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6907355339285715, test accuracy:0.6769316909294513 train loss:0.57944753, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6860512533928571, test accuracy:0.6769316909294513 train loss:0.58413323, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6923076923214285, test accuracy:0.6769316909294513 train loss:0.57984351, test loss:32.30683136, test precision: 0.6140613313388182,test recall: 0.5627141877998629,test f1: 0.5872675250357654\n",
      "train accuracy: 0.6909394316071429, test accuracy:0.6769316909294513 train loss:0.57966274, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6949744591071428, test accuracy:0.6766517357222844 train loss:0.57867896, test loss:32.33482742, test precision: 0.6155572176514585,test recall: 0.5621584699453552,test f1: 0.5876472688325598\n",
      "train accuracy: 0.6834220467857143, test accuracy:0.6769316909294513 train loss:0.58173774, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6854020003571428, test accuracy:0.6769316909294513 train loss:0.58386472, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.69310182, test accuracy:0.6772116461366181 train loss:0.58177372, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6909018716071429, test accuracy:0.6772116461366181 train loss:0.58021117, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6870814732142857, test accuracy:0.6769316909294513 train loss:0.58358442, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6892975189285714, test accuracy:0.6763717805151176 train loss:0.58284635, test loss:32.36282349, test precision: 0.6155572176514585,test recall: 0.5617747440273038,test f1: 0.5874375446109922\n",
      "train accuracy: 0.6845381182142857, test accuracy:0.6769316909294513 train loss:0.5865636, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6878970639285714, test accuracy:0.6772116461366181 train loss:0.58291953, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6856541896428572, test accuracy:0.6769316909294513 train loss:0.58535719, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.6852571257142858, test accuracy:0.6772116461366181 train loss:0.58461108, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.682745965, test accuracy:0.6772116461366181 train loss:0.58496234, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6906389508928571, test accuracy:0.6772116461366181 train loss:0.5784907, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6971958705357143, test accuracy:0.6772116461366181 train loss:0.57384432, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6891741071428571, test accuracy:0.6772116461366181 train loss:0.58129386, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6898877489285714, test accuracy:0.6772116461366181 train loss:0.57960987, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.69140625, test accuracy:0.6769316909294513 train loss:0.57885856, test loss:32.30683136, test precision: 0.6140613313388182,test recall: 0.5627141877998629,test f1: 0.5872675250357654\n",
      "train accuracy: 0.6930749914285714, test accuracy:0.6772116461366181 train loss:0.57643611, test loss:32.2788353, test precision: 0.6140613313388182,test recall: 0.5631001371742113,test f1: 0.5874776386404293\n",
      "train accuracy: 0.6897589714285715, test accuracy:0.6772116461366181 train loss:0.58074815, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6863624657142857, test accuracy:0.6774916013437849 train loss:0.57984509, test loss:32.25083923, test precision: 0.6178010471204188,test recall: 0.5630538513974097,test f1: 0.5891583452211127\n",
      "train accuracy: 0.6827513307142857, test accuracy:0.6774916013437849 train loss:0.58530935, test loss:32.25083923, test precision: 0.6178010471204188,test recall: 0.5630538513974097,test f1: 0.5891583452211127\n",
      "train accuracy: 0.6885194883928571, test accuracy:0.6772116461366181 train loss:0.57941257, test loss:32.2788353, test precision: 0.6178010471204188,test recall: 0.5626702997275205,test f1: 0.5889483065953655\n",
      "train accuracy: 0.6832181491071428, test accuracy:0.6774916013437849 train loss:0.58114525, test loss:32.25083923, test precision: 0.6170531039640987,test recall: 0.5631399317406144,test f1: 0.5888650963597432\n",
      "train accuracy: 0.6863249055357142, test accuracy:0.6774916013437849 train loss:0.58273548, test loss:32.25083923, test precision: 0.6133133881824981,test recall: 0.563573883161512,test f1: 0.5873925501432665\n",
      "train accuracy: 0.6874678057142857, test accuracy:0.6772116461366181 train loss:0.58299637, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6864429516071429, test accuracy:0.6772116461366181 train loss:0.58172777, test loss:32.2788353, test precision: 0.6148092744951383,test recall: 0.563013698630137,test f1: 0.5877726135144797\n",
      "train accuracy: 0.6902740814285714, test accuracy:0.6769316909294513 train loss:0.58211792, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.696160285, test accuracy:0.6766517357222844 train loss:0.57160023, test loss:32.33482742, test precision: 0.6133133881824981,test recall: 0.5624142661179699,test f1: 0.5867620751341681\n",
      "train accuracy: 0.6912345467857143, test accuracy:0.6769316909294513 train loss:0.58040036, test loss:32.30683136, test precision: 0.6133133881824981,test recall: 0.5628002745367193,test f1: 0.5869720830350752\n",
      "train accuracy: 0.6956559066071428, test accuracy:0.6769316909294513 train loss:0.57552356, test loss:32.30683136, test precision: 0.6155572176514585,test recall: 0.5625427204374572,test f1: 0.5878571428571429\n",
      "train accuracy: 0.68467226125, test accuracy:0.6774916013437849 train loss:0.58096377, test loss:32.25083923, test precision: 0.6178010471204188,test recall: 0.5630538513974097,test f1: 0.5891583452211127\n",
      "train accuracy: 0.6927369505357143, test accuracy:0.6774916013437849 train loss:0.57792936, test loss:32.25083923, test precision: 0.6178010471204188,test recall: 0.5630538513974097,test f1: 0.5891583452211127\n",
      "train accuracy: 0.6865288032142857, test accuracy:0.6763717805151176 train loss:0.58397463, test loss:32.36282349, test precision: 0.6140613313388182,test recall: 0.5619438740588638,test f1: 0.5868477483917084\n",
      "train accuracy: 0.6844898266071429, test accuracy:0.6763717805151176 train loss:0.5817092, test loss:32.36282349, test precision: 0.6140613313388182,test recall: 0.5619438740588638,test f1: 0.5868477483917084\n",
      "train accuracy: 0.69091796875, test accuracy:0.6774916013437849 train loss:0.57875949, test loss:32.25083923, test precision: 0.6185489902767389,test recall: 0.5629680054458815,test f1: 0.5894511760513185\n",
      "train accuracy: 0.6897267771428571, test accuracy:0.6774916013437849 train loss:0.58022955, test loss:32.25083923, test precision: 0.6178010471204188,test recall: 0.5630538513974097,test f1: 0.5891583452211127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-04-03 01:00:29,200]\u001b[0m Trial 5 failed with parameters: {'n_layers': 2, 'n_units_l0': 276, 'n_units_l1': 253, 'optimizer': 'Adam'} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\harit\\AppData\\Local\\Temp\\ipykernel_40304\\1611855755.py\", line 89, in objective\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\", line 489, in backward\n",
      "    self, gradient, retain_graph, create_graph, inputs=inputs\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 199, in backward\n",
      "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-04-03 01:00:29,207]\u001b[0m Trial 5 failed with value None.\u001b[0m\n"
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
<<<<<<< HEAD
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12732\\1914250171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHyperbandPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqlite:///optuna.sqlite3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_if_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mpruned_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
=======
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40304\\1611855755.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mpruner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHyperbandPruner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_factor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"minimize\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTPESampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sqlite:///optuna.sqlite3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpruner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_if_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[0mpruned_trials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m         )\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             )\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
<<<<<<< HEAD
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12732\\1914250171.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                 \u001b[1;31m# # Limiting validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;31m# if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Handle `CustomType` automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \"\"\"\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
=======
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40304\\1611855755.py\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
>>>>>>> 792e44c08b67f0a201c341b71cfcd442fcc1a7ff
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optuna create model\n",
    "\n",
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "from optuna.samplers import TPESampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from optuna.integration.tensorboard import TensorBoardCallback\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Empty CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Assign device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE = device\n",
    "\n",
    "#N_TRAIN_EXAMPLES = len(train_loader.dataset.tensors[0])\n",
    "#N_VALID_EXAMPLES = len(test_loader.dataset.tensors[0])\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3) #อย่าลืมบวก 1 เพราะ append ไปก่อนเข้า loop แล้ว\n",
    "    layers = []\n",
    "    in_features = train_loader.dataset.tensors[0].shape[1]\n",
    "    layers.append(nn.Linear(in_features, 512)) # 1024 nodes in the first layer เพื่อบังคับไม่ให้ layer แรกเล็กเกินไป\n",
    "    in_features = 512 #จำนวนที่จะ input เข้าไปยัง hidden layer ที่ 2\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 5, 1024) \n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "       \n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        #p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5) (ไม่ต้อง optimize)\n",
    "        #layers.append(nn.Dropout(p)) (ไม่ต้องใส่ dropout)\n",
    "\n",
    "        in_features = out_features\n",
    "    #layers.append(nn.Linear(in_features, 2048)) #เพิ่มเพ่อบังคับให้ layer สุดท้าย 2048 ตามผลของ optuna\n",
    "    #layers.append(nn.Sigmoid()) \n",
    "    layers.append(nn.Linear(in_features, CLASSES)) #รับ 2048 แล้วออกมาเป็น 1 output ผ่าน sigmoid\n",
    "    layers.append(nn.Sigmoid())\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\"]) #ให้เลือกแค่ Adam อย่างเดียว ไม่ได้ลบไว้เพราะเผื่อจะใส่ SGD ให้ optuna ลองเลือก\n",
    "    #lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True) (ไม่ต้อง optimize)\n",
    "    lr = LEARNING_RATE #ใช้ lr ที่ define ไว้ (ไม่ต้อง optimize)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    run_name = \"trial-%d\" % trial.number\n",
    "    run_dir = os.path.join(dirname, run_name) # This is the dir used in tensorboard_callback of optuna\n",
    "\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = []\n",
    "        running_train_acc = []\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # # Limiting training data for faster epochs.\n",
    "            # if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "            #     break\n",
    "\n",
    "\n",
    "            data = data.float().to(device)\n",
    "            target = target.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            output = output.flatten()\n",
    "            \n",
    "            loss = loss_fn(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss.append(loss.item()) \n",
    "\n",
    "            with torch.no_grad():\n",
    "                target = target.flatten()\n",
    "                output = torch.round(output)\n",
    "                correct = (output == target).sum().item()\n",
    "                train_acc = correct/len(target)\n",
    "                train_acc = round(train_acc, 8)\n",
    "                running_train_acc.append(train_acc)\n",
    "        train_acc = np.mean(running_train_acc)\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # # Limiting validation data.\n",
    "                # if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                #     break\n",
    "                data = data.float().to(device)\n",
    "                target = target.float().to(device)               \n",
    "                output = model(data)\n",
    "                output = output.flatten()\n",
    "                data = data.flatten()\n",
    "                test_loss = loss_fn(output, target)\n",
    "                output = torch.round(output)\n",
    "                correct = (output == target).sum().item()\n",
    "                \n",
    "                # # Get the index of the max log-probability.\n",
    "                # pred = output.argmax(dim=1, keepdim=True)\n",
    "                # correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        #accuracy = correct/len(valid_loader.dataset)\n",
    "            test_acc = correct / len(test_loader.dataset) #min(len(test_loader.dataset),N_VALID_EXAMPLES)\n",
    "            train_loss = np.mean(running_loss)\n",
    "\n",
    "            \n",
    "            output = output.cpu().detach().numpy()\n",
    "            target = target.cpu().detach().numpy()\n",
    "        \n",
    "            test_loss = test_loss.cpu().detach().numpy()\n",
    "   \n",
    "\n",
    "\n",
    "            test_precision = precision_score(output, target, zero_division=0)\n",
    "            test_f1_score = f1_score(output, target, zero_division=0)\n",
    "            test_recall_score = recall_score(output, target, zero_division=0)\n",
    "\n",
    "        print(f\"train accuracy: {train_acc}, test accuracy:{test_acc} train loss:{round(train_loss,8)}, test loss:{round(test_loss.item(),8)}, test precision: {test_precision},test recall: {test_recall_score},test f1: {test_f1_score}\")\n",
    "        with tf.summary.create_file_writer(run_dir).as_default():\n",
    "            tf.summary.scalar(\"train loss\", train_loss, step=epoch)\n",
    "            tf.summary.scalar(\"test loss\", test_loss, step=epoch) \n",
    "            tf.summary.scalar(\"train acc\", train_acc, step=epoch)\n",
    "            tf.summary.scalar(\"test acc\", test_acc, step=epoch)\n",
    "            tf.summary.scalar(\"test Precision\", test_precision, step=epoch)\n",
    "            tf.summary.scalar(\"test f1_score\", test_f1_score, step=epoch)\n",
    "            tf.summary.scalar(\"test recall_score\", test_recall_score, step=epoch)\n",
    "        trial.report(test_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    torch.save(model.state_dict(),f\"../4 - Training & Testing/{dirname}/{'trial-%d_model.pt' % trial.number}\")\n",
    "    return train_loss\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tensorboard_callback = TensorBoardCallback(dirname = dirname, metric_name=\"target\")\n",
    "    pruner = optuna.pruners.HyperbandPruner(min_resource=1, max_resource=EPOCHS, reduction_factor=3)\n",
    "    study = optuna.create_study(study_name = dirname, directions=[\"minimize\"],sampler=TPESampler(),storage='sqlite:///optuna.sqlite3',pruner=pruner, load_if_exists=True)\n",
    "    study.optimize(objective, n_trials=1000, timeout=None)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ของเก่า"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' must be tuple of SymInts, but found element of type Tensor at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9824\\1608667430.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of SymInts, but found element of type Tensor at pos 2"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    with torch.no_grad():\n",
    "        input = x[0].float().to(device)\n",
    "        x = nn.Linear(input,1024)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , Train Loss: 50.4695717, Test Loss: 64.59366608, Train_Accuracy: 51.785714000000006, Test_Accuracy: 35.406333000000004\n",
      "1 Not yet >3 epoch, Train Loss: 49.90880882, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n",
      "2 Not yet >3 epoch, Train Loss: 50.6832535, Test Loss: 64.59366608, Train_Accuracy: 51.785714000000006, Test_Accuracy: 35.406333000000004\n",
      "3 Not yet >3 epoch, Train Loss: 50.43554008, Test Loss: 64.59366608, Train_Accuracy: 45.535714, Test_Accuracy: 35.406333000000004\n",
      "4 Not yet >3 epoch, Train Loss: 50.76627834, Test Loss: 64.59366608, Train_Accuracy: 47.321428999999995, Test_Accuracy: 35.406333000000004\n",
      "5 UP!!, Train Loss: 50.07077529, Test Loss: 64.59366608, Train_Accuracy: 59.821429, Test_Accuracy: 35.406333000000004\n",
      "6 Down, Train Loss: 49.43243687, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n",
      "7 UP!!, Train Loss: 50.49814899, Test Loss: 64.59366608, Train_Accuracy: 48.214286, Test_Accuracy: 35.406333000000004\n",
      "8 UP!!, Train Loss: 50.90374565, Test Loss: 64.59366608, Train_Accuracy: 50.892857, Test_Accuracy: 35.406333000000004\n",
      "9 Down, Train Loss: 49.21738899, Test Loss: 64.59366608, Train_Accuracy: 44.642857, Test_Accuracy: 35.406333000000004\n",
      "10 Down, Train Loss: 50.17149395, Test Loss: 64.59366608, Train_Accuracy: 43.75, Test_Accuracy: 35.406333000000004\n",
      "11 UP!!, Train Loss: 50.03266553, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n",
      "12 Down, Train Loss: 50.31576659, Test Loss: 64.59366608, Train_Accuracy: 49.107143, Test_Accuracy: 35.406333000000004\n",
      "13 UP!!, Train Loss: 50.01769382, Test Loss: 64.59366608, Train_Accuracy: 63.392857, Test_Accuracy: 35.406333000000004\n",
      "14 Down, Train Loss: 49.73731492, Test Loss: 64.59366608, Train_Accuracy: 47.321428999999995, Test_Accuracy: 35.406333000000004\n",
      "15 UP!!, Train Loss: 50.0993576, Test Loss: 64.59366608, Train_Accuracy: 47.321428999999995, Test_Accuracy: 35.406333000000004\n",
      "16 UP!!, Train Loss: 50.18238244, Test Loss: 64.59366608, Train_Accuracy: 61.607143, Test_Accuracy: 35.406333000000004\n",
      "17 Down, Train Loss: 49.82714504, Test Loss: 64.59366608, Train_Accuracy: 57.142857, Test_Accuracy: 35.406333000000004\n",
      "18 Down, Train Loss: 49.80264594, Test Loss: 64.59366608, Train_Accuracy: 48.214286, Test_Accuracy: 35.406333000000004\n",
      "19 UP!!, Train Loss: 49.93603009, Test Loss: 64.59366608, Train_Accuracy: 54.464285999999994, Test_Accuracy: 35.406333000000004\n",
      "20 UP!!, Train Loss: 50.3048781, Test Loss: 64.59366608, Train_Accuracy: 50.0, Test_Accuracy: 35.406333000000004\n",
      "21 Down, Train Loss: 49.70328838, Test Loss: 64.59366608, Train_Accuracy: 44.642857, Test_Accuracy: 35.406333000000004\n",
      "22 Down, Train Loss: 50.13338419, Test Loss: 64.59366608, Train_Accuracy: 56.25, Test_Accuracy: 35.406333000000004\n",
      "23 UP!!, Train Loss: 50.37837545, Test Loss: 64.59366608, Train_Accuracy: 45.535714, Test_Accuracy: 35.406333000000004\n",
      "24 Down, Train Loss: 50.13610631, Test Loss: 64.59366608, Train_Accuracy: 54.464285999999994, Test_Accuracy: 35.406333000000004\n",
      "25 Down, Train Loss: 50.04219297, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n",
      "26 UP!!, Train Loss: 50.11569037, Test Loss: 64.59366608, Train_Accuracy: 55.357143, Test_Accuracy: 35.406333000000004\n",
      "27 UP!!, Train Loss: 50.12249565, Test Loss: 64.59366608, Train_Accuracy: 50.892857, Test_Accuracy: 35.406333000000004\n",
      "28 Down, Train Loss: 49.91833626, Test Loss: 64.59366608, Train_Accuracy: 47.321428999999995, Test_Accuracy: 35.406333000000004\n",
      "29 Down, Train Loss: 49.97277879, Test Loss: 64.59366608, Train_Accuracy: 49.107143, Test_Accuracy: 35.406333000000004\n",
      "30 UP!!, Train Loss: 50.50495431, Test Loss: 64.59366608, Train_Accuracy: 43.75, Test_Accuracy: 35.406333000000004\n",
      "31 Down, Train Loss: 50.10888504, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n",
      "32 Down, Train Loss: 50.32801614, Test Loss: 64.59366608, Train_Accuracy: 53.571429, Test_Accuracy: 35.406333000000004\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33120\\880742667.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "trend = \"\"\n",
    "\n",
    "#trainAcc,testAcc,trainLoss = TrainTest()\n",
    "\n",
    "\n",
    "allepoch_train_loss = []\n",
    "allepoch_test_loss = []\n",
    "allepoch_test_acc = []\n",
    "allepoch_train_acc = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for epoch_i in range(epochs):\n",
    "    #print(f\"Epochs: {epoch_i+1}\")\n",
    "    #print(\"----\")\n",
    "    #batch_no = 0\n",
    "    running_loss = [] #clear running loss ทุกครั้ง\n",
    "    running_train_acc = []\n",
    "    for batch in train_loader:\n",
    "\n",
    "        model.train().to(device)\n",
    "\n",
    "        #batch_no += train_loader.batch_size\n",
    "\n",
    "        train_data, train_label = batch\n",
    "        train_data = train_data.float().to(device)\n",
    "        train_label = train_label.float().to(device)\n",
    "        #train_label = train_label.reshape((len(train_label)),1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_data)\n",
    "        outputs = outputs.flatten()\n",
    "        loss = loss_fn(outputs, train_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item()) \n",
    "        \n",
    "        #if batch_no % 100 == 0:\n",
    "            #print(f\"Loss: {loss.item():>e} Batch: {batch_no:>5d}/{train_loader.batch_size*len(train_loader):>5d}\")\n",
    "\n",
    "\n",
    "        #train accuracy\n",
    "        with torch.no_grad():\n",
    "            #outputs = model(train_data)\n",
    "            #outputs_sigmoid = torch.sigmoid(outputs)\n",
    "            outputs = torch.round(outputs)\n",
    "            #_, predicted = torch.max(outputs, 1)\n",
    "            #train_label = torch.max(train_label, 1)\n",
    "            outputs = outputs.flatten()\n",
    "            train_label = train_label.flatten()\n",
    "            correct = (outputs == train_label).sum().item()\n",
    "            train_accuracy = correct/len(train_label)\n",
    "            train_accuracy = round(train_accuracy, 8)\n",
    "            running_train_acc.append(train_accuracy)\n",
    "        train_acc = np.mean(running_train_acc)\n",
    "        allepoch_train_acc.append(train_acc)\n",
    "        \n",
    "    model.eval()\n",
    "    #test accuracy\n",
    "    testacc = []\n",
    "    for batch in test_loader:\n",
    "        test_data, test_label = batch\n",
    "        test_label = test_label.float().to(device)\n",
    "        test_data = test_data.float().to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(test_data).to(device)\n",
    "            \n",
    "            #outputs_sigmoid = torch.sigmoid(outputs)\n",
    "            \n",
    "            #test_label = torch.max(test_label, 1)\\\n",
    "            outputs = outputs.flatten()\n",
    "            test_label = test_label.flatten()\n",
    "            #_, predicted = torch.max(outputs, 1)\n",
    "            test_loss = loss_fn(outputs, test_label)\n",
    "\n",
    "            outputs = torch.round(outputs)\n",
    "            correct = (outputs == test_label).sum().item()\n",
    "            test_loss = round(test_loss.item(),8)\n",
    "            test_accuracy = correct/len(test_label)\n",
    "            test_accuracy = round(test_accuracy,8)\n",
    "            allepoch_test_acc.append(test_accuracy)\n",
    "            allepoch_test_loss.append(test_loss)\n",
    "    \n",
    "    train_loss = round(np.mean(running_loss),8)\n",
    "    allepoch_train_loss.append(train_loss)\n",
    "\n",
    "    writer.add_scalars('Accuracy', {\n",
    "        'train accuracy':train_accuracy*100,\n",
    "        'test accuracy': test_accuracy*100\n",
    "        }, epoch_i+1)\n",
    "    \n",
    "\n",
    "    writer.add_scalars('Loss', {\n",
    "        'train loss':np.mean(running_loss),\n",
    "        'test loss': test_loss\n",
    "        }, epoch_i+1)\n",
    "\n",
    "\n",
    "    print(f\"{epoch_i} {trend}, Train Loss: {train_loss}, Test Loss: {test_loss}, Train_Accuracy: {train_accuracy*100}, Test_Accuracy: {test_accuracy*100}\")\n",
    "\n",
    "    if epoch_i > 3:\n",
    "        if allepoch_train_loss[epoch_i-2] - allepoch_train_loss[epoch_i-1] <= 0:\n",
    "            count += 1\n",
    "            trend = \"Down\"\n",
    "        else:\n",
    "            trend = \"UP!!\"\n",
    "            count = 0\n",
    "\n",
    "        if count == 20:\n",
    "            print(f\"Early Stopped, loss not increasing for {count} times\")\n",
    "            break\n",
    "    else:\n",
    "        trend = \"Not yet >3 epoch\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def visualise_dataloader(dl, id_to_label=None, with_outputs=True):\n",
    "    total_num_images = len(dl.dataset)\n",
    "    idxs_seen = []\n",
    "    class_0_batch_counts = []\n",
    "    class_1_batch_counts = []\n",
    "\n",
    "    for i, batch in enumerate(dl):\n",
    "\n",
    "        idxs = batch[0][:, 0].tolist()\n",
    "        classes = batch[0][:, 1]\n",
    "        class_ids, class_counts = classes.unique(return_counts=True)\n",
    "        class_ids = set(class_ids.tolist())\n",
    "        class_counts = class_counts.tolist()\n",
    "\n",
    "        idxs_seen.extend(idxs)\n",
    "\n",
    "        if len(class_ids) == 2:\n",
    "            class_0_batch_counts.append(class_counts[0])\n",
    "            class_1_batch_counts.append(class_counts[1])\n",
    "        elif len(class_ids) == 1 and 0 in class_ids:\n",
    "            class_0_batch_counts.append(class_counts[0])\n",
    "            class_1_batch_counts.append(0)\n",
    "        elif len(class_ids) == 1 and 1 in class_ids:\n",
    "            class_0_batch_counts.append(0)\n",
    "            class_1_batch_counts.append(class_counts[0])\n",
    "        else:\n",
    "            raise ValueError(\"More than two classes detected\")\n",
    "\n",
    "    if with_outputs:\n",
    "        fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "\n",
    "        ind = np.arange(len(class_0_batch_counts))\n",
    "        width = 0.35\n",
    "\n",
    "        ax.bar(\n",
    "            ind,\n",
    "            class_0_batch_counts,\n",
    "            width,\n",
    "            label=(id_to_label[0] if id_to_label is not None else \"0\"),\n",
    "        )\n",
    "        ax.bar(\n",
    "            ind + width,\n",
    "            class_1_batch_counts,\n",
    "            width,\n",
    "            label=(id_to_label[1] if id_to_label is not None else \"1\"),\n",
    "        )\n",
    "        ax.set_xticks(ind, ind + 1)\n",
    "        ax.set_xlabel(\"Batch index\", fontsize=12)\n",
    "        ax.set_ylabel(\"No. of images in batch\", fontsize=12)\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        num_images_seen = len(idxs_seen)\n",
    "\n",
    "        print(\n",
    "            f'Avg Proportion of {(id_to_label[0] if id_to_label is not None else \"Class 0\")} per batch: {(np.array(class_0_batch_counts) / 10).mean()}'\n",
    "        )\n",
    "        print(\n",
    "            f'Avg Proportion of {(id_to_label[1] if id_to_label is not None else \"Class 1\")} per batch: {(np.array(class_1_batch_counts) / 10).mean()}'\n",
    "        )\n",
    "        print(\"=============\")\n",
    "        print(f\"Num. unique images seen: {len(set(idxs_seen))}/{total_num_images}\")\n",
    "    return class_0_batch_counts, class_1_batch_counts, idxs_seen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Proportion of NoADR per batch: 12.109756097560975\n",
      "Avg Proportion of ADR per batch: 0.6707317073170732\n",
      "=============\n",
      "Num. unique images seen: 2/10480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([121,\n",
       "  120,\n",
       "  114,\n",
       "  125,\n",
       "  118,\n",
       "  119,\n",
       "  120,\n",
       "  124,\n",
       "  124,\n",
       "  118,\n",
       "  123,\n",
       "  126,\n",
       "  122,\n",
       "  115,\n",
       "  122,\n",
       "  120,\n",
       "  122,\n",
       "  125,\n",
       "  120,\n",
       "  120,\n",
       "  120,\n",
       "  126,\n",
       "  117,\n",
       "  120,\n",
       "  123,\n",
       "  124,\n",
       "  122,\n",
       "  122,\n",
       "  122,\n",
       "  119,\n",
       "  121,\n",
       "  121,\n",
       "  121,\n",
       "  123,\n",
       "  120,\n",
       "  123,\n",
       "  113,\n",
       "  124,\n",
       "  120,\n",
       "  125,\n",
       "  123,\n",
       "  118,\n",
       "  123,\n",
       "  121,\n",
       "  120,\n",
       "  120,\n",
       "  122,\n",
       "  121,\n",
       "  125,\n",
       "  123,\n",
       "  124,\n",
       "  126,\n",
       "  124,\n",
       "  123,\n",
       "  124,\n",
       "  122,\n",
       "  123,\n",
       "  122,\n",
       "  121,\n",
       "  123,\n",
       "  122,\n",
       "  118,\n",
       "  120,\n",
       "  123,\n",
       "  119,\n",
       "  123,\n",
       "  122,\n",
       "  124,\n",
       "  123,\n",
       "  116,\n",
       "  117,\n",
       "  120,\n",
       "  121,\n",
       "  123,\n",
       "  122,\n",
       "  121,\n",
       "  112,\n",
       "  121,\n",
       "  124,\n",
       "  122,\n",
       "  117,\n",
       "  108],\n",
       " [7,\n",
       "  8,\n",
       "  14,\n",
       "  3,\n",
       "  10,\n",
       "  9,\n",
       "  8,\n",
       "  4,\n",
       "  4,\n",
       "  10,\n",
       "  5,\n",
       "  2,\n",
       "  6,\n",
       "  13,\n",
       "  6,\n",
       "  8,\n",
       "  6,\n",
       "  3,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  2,\n",
       "  11,\n",
       "  8,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  9,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  5,\n",
       "  8,\n",
       "  5,\n",
       "  15,\n",
       "  4,\n",
       "  8,\n",
       "  3,\n",
       "  5,\n",
       "  10,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  6,\n",
       "  7,\n",
       "  3,\n",
       "  5,\n",
       "  4,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  4,\n",
       "  6,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  5,\n",
       "  6,\n",
       "  10,\n",
       "  8,\n",
       "  5,\n",
       "  9,\n",
       "  5,\n",
       "  6,\n",
       "  4,\n",
       "  5,\n",
       "  12,\n",
       "  11,\n",
       "  8,\n",
       "  7,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  16,\n",
       "  7,\n",
       "  4,\n",
       "  6,\n",
       "  11,\n",
       "  4],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  ...])"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualise_dataloader(train_loader,{0:\"NoADR\",1:\"ADR\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    8460\n",
       "1.0    4641\n",
       "Name: ADR, dtype: int64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 1/df['ADR'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "to_plot = pd.DataFrame(train_loader.dataset.tensors[1].numpy()).value_counts()\n",
    "to_plot2  = pd.DataFrame(test_loader.dataset.tensors[1].numpy()).value_counts()\n",
    "\n",
    "def get_distribution(tensor):\n",
    "    df = pd.DataFrame(tensor.numpy()).value_counts()\n",
    "    fig, ax =plt.subplots()\n",
    "    ax.bar([0,1],df.values)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "get_distribution(train_loader.dataset.tensors[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLkAAANECAYAAABckP2EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMhUlEQVR4nO39e5iVdaH//78GhgEUBxRlBhJ0LBXPFprO1sqUIis7yMfUj+4k7aRoKpVJO220A2qf1DTELMJOZtneWlZqREFXhifK0jKyIrU47Q7MKMVAzPr94c/1dTjJwMDwZh6P61pX3od1r/eaudc9i2f3uldNpVKpBAAAAAAK1qenBwAAAAAAm0vkAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCANiKJkyYkD333HOrPNaee+6ZCRMmVKdvvvnm1NTU5KGHHtoqj3/MMcfkmGOO2SqPBQAgcgEA24TnAsxztwEDBmTEiBEZN25crrvuujz99NObvO2f/exnaWlpybJly7pvwElaWlo6jXmHHXbIqFGjcsIJJ2TGjBlpb2/vlsf5zW9+k5aWlvzpT3/qlu11p215bABA71Lb0wMAAHi+yy+/PE1NTVm1alUWL16c2bNn54ILLsjVV1+d73znOzn44IO7vM2f/exnueyyyzJhwoQMGTKk28c8bdq0DBo0KO3t7fnLX/6Se+65J2eeeWauvfbafPe7383IkSOr637+859PR0dHl7b/m9/8JpdddlmOOeaYLp0FNn/+/PTps2X/P80Nje0HP/jBFn1sAIDnE7kAgG3K8ccfn8MOO6w6PXny5PzoRz/KG9/4xrzpTW/KY489loEDB/bgCNf2f/7P/8muu+5anb700kvzta99LW9/+9tz0kkn5b777qsu69ev3xYdS6VSyYoVKzJw4MD0799/iz7WC6mrq+vRxwcAehcfVwQAtnnHHntsLrnkkjzxxBP56le/Wp3/q1/9KhMmTMhee+2VAQMGpLGxMWeeeWb+9re/VddpaWnJBz/4wSRJU1NT9aOFz328bsaMGTn22GMzbNiw9O/fP/vvv3+mTZu22WM+7bTT8s53vjP3339/Zs6cWZ2/rmty3XrrrRkzZkx22mmn1NfX56CDDspnPvOZJM9+jPOkk05Kkrz61a+ujn/27NlJnr3u1hvf+Mbcc889OeywwzJw4MB87nOfqy57/jW5nvPPf/4z73nPezJ06NDU19fn7W9/e/7xj390WqempiYtLS1r3ff523yhsa3rmlxLly7NWWedlYaGhgwYMCCHHHJIvvSlL3Va509/+lNqamry//7f/8tNN92UF7/4xenfv38OP/zwPPjgg+v8eQMAOJMLACjCf/7nf+bDH/5wfvCDH+Rd73pXkmTmzJn54x//mHe84x1pbGzMr3/969x000359a9/nfvuuy81NTU58cQT87vf/S5f//rXc80111TPuNptt92SPPtRwwMOOCBvetObUltbmzvvvDPnnHNOOjo6MnHixM0e80033ZQf/OAHec1rXrPOdWbOnJlTTz01xx13XK688sokyWOPPZZ77703559/fl75ylfmfe97X6677rp8+MMfzn777Zck1f9Nnv1Y4qmnnpr3vOc9ede73pV99913g+M699xzM2TIkLS0tGT+/PmZNm1annjiicyePTs1NTUb/fw2ZmzP969//SvHHHNMfv/73+fcc89NU1NTbrvttkyYMCHLli3L+eef32n9W265JU8//XTe8573pKamJldddVVOPPHE/PGPf9ziZ8QBAOURuQCAIuy+++4ZPHhw/vCHP1TnnXPOOXn/+9/fab0jjzwyp556an7605/mFa94RQ4++OC87GUvy9e//vW85S1vWessqjlz5nT6+OO5556b173udbn66qs3O3IdeOCBSdJpzGv63ve+l/r6+txzzz3p27fvWsv32muvvOIVr8h1112X17zmNev8tsLf//73ufvuuzNu3LiNGlddXV1mzZpVDUV77LFHLrrootx5551505vetFHb2NixPd9NN92Uxx57LF/96ldz2mmnJUne+9735lWvelU+8pGP5Mwzz8xOO+1UXf/JJ5/M448/np133jlJsu++++bNb35z7rnnnrzxjW/c6HECAL2DjysCAMUYNGhQp29ZfH6cWrFiRf7617/myCOPTJL8/Oc/36htPn8bra2t+etf/5pXvepV+eMf/5jW1tbNHm+SDX4z5JAhQ7J8+fJOH2nsqqampo0OXEny7ne/u9OZUGeffXZqa2vz/e9/f5PHsDG+//3vp7GxMaeeemp1Xr9+/fK+970vzzzzTObMmdNp/ZNPPrkauJLkFa94RZLkj3/84xYdJwBQJpELACjGM8880+lMn7///e85//zz09DQkIEDB2a33XZLU1NTkmx0oLr33nszduzY7LjjjhkyZEh22223fPjDH+7SNjY03iSdxrymc845J/vss0+OP/747L777jnzzDNz9913d+lxnnvOG2vvvffuND1o0KAMHz68ep2yLeWJJ57I3nvvvdY3Pj738cYnnnii0/xRo0Z1mn4ueK15/TAAgMTHFQGAQvz5z39Oa2trXvKSl1Tnve1tb8vPfvazfPCDH8yhhx6aQYMGpaOjI6973evS0dHxgtv8wx/+kOOOOy6jR4/O1VdfnZEjR6auri7f//73c80112zUNjbk0UcfTZJOY17TsGHD8vDDD+eee+7JXXfdlbvuuiszZszI29/+9rUuyL4+W/PbJlevXr3VHmtdH99Mnv0GSQCANYlcAEARvvKVryRJ9WN5//jHPzJr1qxcdtllufTSS6vrPf7442vdd30XU7/zzjvT3t6e73znO53OGvrxj3+8Rca8PnV1dTnhhBNywgknpKOjI+ecc04+97nP5ZJLLslLXvKSLl0MfmM8/vjjefWrX12dfuaZZ7Jo0aK8/vWvr87beeeds2zZsk73W7lyZRYtWtRpXlfGtscee+RXv/pVOjo6Op3N9dvf/ra6HABgU/m4IgCwzfvRj36Uj33sY2lqaqpesPy5s3zWPKvn2muvXev+O+64Y5KsFW3WtY3W1tbMmDFjs8d8yy235Atf+EKam5tz3HHHrXe9v/3tb52m+/Tpk4MPPjhJ0t7evsHxb6qbbropq1atqk5PmzYt//73v3P88cdX5734xS/OT37yk7Xut+aZXF0Z2+tf//osXrw43/jGN6rz/v3vf+f666/PoEGD8qpXvWpTng4AQBJncgEA25i77rorv/3tb/Pvf/87S5YsyY9+9KPMnDkze+yxR77zne9kwIABSZL6+vq88pWvzFVXXZVVq1blRS96UX7wgx9kwYIFa21zzJgxSZL/+q//yimnnJJ+/frlhBNOyGtf+9rqWVTvec978swzz+Tzn/98hg0bttYZSxvyrW99K4MGDcrKlSvzl7/8Jffcc0/uvffeHHLIIbnttts2eN93vvOd+fvf/55jjz02u+++e5544olcf/31OfTQQ6vXqjr00EPTt2/fXHnllWltbU3//v1z7LHHZtiwYRs9xudbuXJljjvuuLztbW/L/Pnzc8MNN+Too4/u9M2K73znO/Pe974348ePz2te85r88pe/zD333JNdd92107a6MrZ3v/vd+dznPpcJEyZk3rx52XPPPfOtb30r9957b6699toNXrsMAOCFiFwAwDbluY8e1tXVZZdddslBBx2Ua6+9Nu94xzvWiiC33HJLzjvvvEydOjWVSiWvfe1rc9ddd2XEiBGd1jv88MPzsY99LDfeeGPuvvvudHR0ZMGCBdl3333zrW99Kx/5yEfygQ98II2NjTn77LOz22675cwzz9zoMZ999tlJkgEDBmTXXXfNoYcemi9+8Yv5v//3/6Z///4bvO/pp5+em266KTfccEOWLVuWxsbGnHzyyWlpaal+pK+xsTE33nhjpkyZkrPOOiurV6/Oj3/8402OXJ/97Gfzta99LZdeemlWrVqVU089Ndddd12njx6+613vyoIFCzJ9+vTcfffdecUrXpGZM2eudVZaV8Y2cODAzJ49OxdffHG+9KUvpa2tLfvuu29mzJiRCRMmbNJzAQB4Tk3FlTsBAAAAKJxrcgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKF5tTw9gTR0dHVm4cGF22mmn1NTU9PRwAAAAAOhBlUolTz/9dEaMGJE+fdZ/vtY2F7kWLlyYkSNH9vQwAAAAANiGPPXUU9l9993Xu3ybi1w77bRTkmcHXl9f38OjAQAAAKAntbW1ZeTIkdVmtD7bXOR67iOK9fX1IhcAAAAASfKCl7Vy4XkAAAAAitelyLV69epccsklaWpqysCBA/PiF784H/vYx1KpVKrrVCqVXHrppRk+fHgGDhyYsWPH5vHHH+/2gQMAAADAc7oUua688spMmzYtn/3sZ/PYY4/lyiuvzFVXXZXrr7++us5VV12V6667LjfeeGPuv//+7Ljjjhk3blxWrFjR7YMHAAAAgCSpqTz/NKwX8MY3vjENDQ2ZPn16dd748eMzcODAfPWrX02lUsmIESPy/ve/Px/4wAeSJK2trWloaMjNN9+cU0455QUfo62tLYMHD05ra6trcgEAAABbxerVq7Nq1aqeHkav1K9fv/Tt23e9yze2FXXpwvP/8R//kZtuuim/+93vss8+++SXv/xlfvrTn+bqq69OkixYsCCLFy/O2LFjq/cZPHhwjjjiiMydO3edkau9vT3t7e2dBg4AAACwNVQqlSxevDjLli3r6aH0akOGDEljY+MLXlx+Q7oUuS6++OK0tbVl9OjR6du3b1avXp1PfOITOe2005IkixcvTpI0NDR0ul9DQ0N12ZqmTJmSyy67bFPGDgAAALBZngtcw4YNyw477LBZkYWuq1Qq+ec//5mlS5cmSYYPH77J2+pS5PrmN7+Zr33ta7nllltywAEH5OGHH84FF1yQESNG5IwzztikAUyePDmTJk2qTre1tWXkyJGbtC0AAACAjbV69epq4Bo6dGhPD6fXGjhwYJJk6dKlGTZs2AY/urghXYpcH/zgB3PxxRdXP3Z40EEH5YknnsiUKVNyxhlnpLGxMUmyZMmSTuVtyZIlOfTQQ9e5zf79+6d///6bNHgAAACATfXcNbh22GGHHh4Jz/0OVq1atcmRq0vfrvjPf/4zffp0vkvfvn3T0dGRJGlqakpjY2NmzZpVXd7W1pb7778/zc3NmzRAAAAAgC3JRxR7Xnf8Drp0JtcJJ5yQT3ziExk1alQOOOCA/OIXv8jVV1+dM888szqgCy64IB//+Mez9957p6mpKZdccklGjBiRt7zlLZs9WAAAAABYly5Fruuvvz6XXHJJzjnnnCxdujQjRozIe97znlx66aXVdS666KIsX7487373u7Ns2bIcffTRufvuuzNgwIBuHzwAAAAAJElNpVKp9PQgnq+trS2DBw9Oa2tr6uvre3o4AAAAwHZqxYoVWbBgQZqamtY6OadldstWG0fLMV1/rAkTJuRLX/pSpkyZkosvvrg6/4477shb3/rWdDX3fP3rX8/pp5+e9773vZk6dWqnZbNnz86rX/3qJM9+im+nnXbKXnvtlde85jW58MILO12XvaWlJZdddlmSpE+fPhkxYkSOP/74XHHFFdlll13W+/gb+l1sbCvq0jW5AAAAANg2DBgwIFdeeWX+8Y9/bPa2pk+fnosuuihf//rXs2LFinWuM3/+/CxcuDAPPvhgPvShD+WHP/xhDjzwwDzyyCOd1jvggAOyaNGiPPnkk5kxY0buvvvunH322Zs9xhcicgEAAAAUaOzYsWlsbMyUKVPWu85///d/54ADDkj//v2z55575tOf/vRa6yxYsCA/+9nPcvHFF2efffbJ//zP/6xzW8OGDUtjY2P22WefnHLKKbn33nuz2267rRWwamtr09jYmBe96EUZO3ZsTjrppMycOXPznuxGELkAAAAACtS3b9988pOfzPXXX58///nPay2fN29e3va2t+WUU07JI488kpaWllxyySW5+eabO603Y8aMvOENb8jgwYNz+umnZ/r06Rv1+AMHDsx73/ve3HvvvVm6dOk61/nTn/6Ue+65J3V1dV1+fl0lcgEAAAAU6q1vfWsOPfTQfPSjH11r2dVXX53jjjsul1xySfbZZ59MmDAh5557bj71qU9V1+no6MjNN9+c008/PUlyyimn5Kc//WkWLFiwUY8/evToJM/GrOc88sgjGTRoUAYOHJimpqb8+te/zoc+9KHNeJYbR+QCAAAAKNiVV16ZL33pS3nsscc6zX/sscdy1FFHdZp31FFH5fHHH8/q1auTJDNnzszy5cvz+te/Pkmy66675jWveU2++MUvbtRjP3eB+5qamuq8fffdNw8//HD12l3jxo3Leeedt8nPb2OJXAAAAAAFe+UrX5lx48Zl8uTJXb7v9OnT8/e//z0DBw5MbW1tamtr8/3vfz9f+tKX0tHR8YL3fy6s7bnnntV5dXV1eclLXpIDDzwwV1xxRfr27Vv9xsUtqXaLPwIAAAAAW9QVV1yRQw89NPvuu2913n777Zd7772303r33ntv9tlnn/Tt2zd/+9vf8u1vfzu33nprDjjggOo6q1evztFHH50f/OAHed3rXrfex/zXv/6Vm266Ka985Suz2267rXe9j3zkIzn22GNz9tlnZ8SIEZvxLDdM5AIAAAAo3EEHHZTTTjst1113XXXe+9///hx++OH52Mc+lpNPPjlz587NZz/72dxwww1Jkq985SsZOnRo3va2t3X6uGGSvP71r8/06dM7Ra6lS5dmxYoVefrppzNv3rxcddVV+etf/7reb2N8TnNzcw4++OB88pOfzGc/+9lufNad+bgiAAAAwHbg8ssv7/QRw5e97GX55je/mVtvvTUHHnhgLr300lx++eWZMGFCkuSLX/xi3vrWt64VuJJk/Pjx+c53vpO//vWv1Xn77rtvRowYkTFjxuSKK67I2LFj8+ijj2b//fd/wbFdeOGF+cIXvpCnnnpq85/oetRUnrtC2Daira0tgwcPTmtra+rr63t6OAAAAMB2asWKFVmwYEGampoyYMCAnh5Or7ah38XGtiJncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4tX29AAAAAAAtjktLUU81ty5c3P00Ufnda97Xb73ve9V5//pT39KU1NTdXrQoEEZNWpUjjnmmFxwwQXZe++9q8tuvvnmvOMd70iS1NTUpKGhIa985SvzqU99KqNGjdrksW1tzuQCAAAAKNT06dNz3nnn5Sc/+UkWLly41vIf/vCHWbRoUX75y1/mk5/8ZB577LEccsghmTVrVqf16uvrs2jRovzlL3/Jf//3f2f+/Pk56aSTttbT6BbO5ILtTMvslrXnHbP2PAAA6LXWPGtma56xA93omWeeyTe+8Y089NBDWbx4cW6++eZ8+MMf7rTO0KFD09jYmCTZa6+9csIJJ+S4447LWWedlT/84Q/p27dvkmfP4HpuveHDh+ess87K+973vrS1taW+vn7rPrFN5EwuAAAAgAJ985vfzOjRo7Pvvvvm9NNPzxe/+MVUKpUN3qdPnz45//zz88QTT2TevHnrXGfp0qW5/fbb07dv32oEK4HIBQAAAFCg6dOn5/TTT0+SvO51r0tra2vmzJnzgvcbPXp0kmev2/Wc1tbWDBo0KDvuuGMaGhry4x//OBMnTsyOO+64Rca+JYhcAAAAAIWZP39+HnjggZx66qlJktra2px88smZPn36C973ubO9ampqqvN22mmnPPzww3nooYfy6U9/Oi972cvyiU98YssMfgtxTS4AAACAwkyfPj3//ve/M2LEiOq8SqWS/v3757Of/ewG7/vYY48lSadvX+zTp09e8pKXJEn222+//OEPf8jZZ5+dr3zlK1tg9FuGM7kAAAAACvLvf/87X/7yl/PpT386Dz/8cPX2y1/+MiNGjMjXv/719d63o6Mj1113XZqamvLSl750vetdfPHF+cY3vpGf//znW+IpbBHO5AIAAAAoyHe/+9384x//yFlnnZXBgwd3WjZ+/PhMnz49r3vd65Ikf/vb37J48eL885//zKOPPpprr702DzzwQL73ve9t8KLyI0eOzFvf+tZceuml+e53v7tFn093cSYXAAAAQEGmT5+esWPHrhW4kmcj10MPPZS2trYkydixYzN8+PAcdNBBufjii7PffvvlV7/6VV796le/4ONceOGF+d73vpcHHnig25/DluBMLgAAAIA1tbT09AjW684771zvspe//OXVC8s/978vZMKECZkwYcJa84888siN3sa2QOQCANjKWma3dJ4+pmWd6wEAsPF8XBEAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAIBeraOjo6eH0Ot1x+/AtysCAAAAvVJdXV369OmThQsXZrfddktdXV1qamp6eli9SqVSycqVK/O///u/6dOnT+rq6jZ5WyIXAAAA0Cv16dMnTU1NWbRoURYuXNjTw+nVdthhh4waNSp9+mz6hw5FLgAAAKDXqqury6hRo/Lvf/87q1ev7unh9Ep9+/ZNbW3tZp9FJ3IBAAAAvVpNTU369euXfv369fRQ2AwiFwA9q6Vlw9ObutnZnbfTckz3bJdy2AcAAHoX364IAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8Wp7egD0vJbZLZ2nj2lZ53q8gJaWDU/Ddqi3Hz/WfP5J7/sZAACwAf6duFU5kwsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAULzanh4A69cyu6Xz9DEt61wPAKA03ucAAN3NmVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUr7anBwC9WkvLhqeTtMzuPK/lmLXXAVjTmseOxPEDtnkb8b6gy5ss6X3Eup5vN/wMgMKOBbAZnMkFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAAChebU8PAIBtVEvLhqd70rY8NoDCtcxu6Tx9TMs61+tV/N3pdbwO1sHrgAI4kwsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMXrUuTac889U1NTs9Zt4sSJSZIVK1Zk4sSJGTp0aAYNGpTx48dnyZIlW2TgAAAAAPCcLkWuBx98MIsWLareZs6cmSQ56aSTkiQXXnhh7rzzztx2222ZM2dOFi5cmBNPPLH7Rw0AAAAAz1PblZV32223TtNXXHFFXvziF+dVr3pVWltbM3369Nxyyy059thjkyQzZszIfvvtl/vuuy9HHnlk940aAAAAAJ5nk6/JtXLlynz1q1/NmWeemZqamsybNy+rVq3K2LFjq+uMHj06o0aNyty5c7tlsAAAAACwLl06k+v57rjjjixbtiwTJkxIkixevDh1dXUZMmRIp/UaGhqyePHi9W6nvb097e3t1em2trZNHRIAAAAAvdQmR67p06fn+OOPz4gRIzZrAFOmTMlll122WdsoQcvslrXnHbP2PIAtoqVl4+YBsM1a8/1kb3wv2S0/gzX//vl7CLDd2KSPKz7xxBP54Q9/mHe+853VeY2NjVm5cmWWLVvWad0lS5aksbFxvduaPHlyWltbq7ennnpqU4YEAAAAQC+2SZFrxowZGTZsWN7whjdU540ZMyb9+vXLrFmzqvPmz5+fJ598Ms3NzevdVv/+/VNfX9/pBgAAAABd0eWPK3Z0dGTGjBk544wzUlv7/9198ODBOeusszJp0qTssssuqa+vz3nnnZfm5mbfrAgAAADAFtXlyPXDH/4wTz75ZM4888y1ll1zzTXp06dPxo8fn/b29owbNy433HBDtwwUAAAAANany5Hrta99bSqVyjqXDRgwIFOnTs3UqVM3e2AAAAAAsLE26ZpcAAAAALAtEbkAAAAAKJ7IBQAAAEDxunxNLugVWlo2PM12p2V2S+fpY1rWuV73P/A6Hsf+BrCWNY/TyVY8VsP2Zlt+r7stj42twz7AZnAmFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMWr7ekB0L1aZrd0nj6mZZ3rAQAboaVl4+ZtRzblvYT3H7B9WfM1nWzjr+s1j8vb+XF6Lb3wb9XW4u9beZzJBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAoXm1PDwDoeS2zW9aed8za8154Qy0bnu6u+7zQJtd4Ppv0XOiVttV9p9teo9uqdb3u15i3rf5uIOkFr1HYVFvgfR7AhjiTCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOLV9vQAALqspWXD01tJy+zOj9tyTM+MA+gdHHNg+9Mtr+tt5H0RwLbAmVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOLV9vQAKFPL7JbO08e0rHO9DW9kHfdZ1zygM6+d7c+av79t6ff5AmPrlr8HhfMz6AW25dfotqoX/q1yLMC/kXrwdVDwcXrNn1ni+LE5nMkFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8Wp7egCwIS2zW9aYXnOFlqxpU+4DANuj3v43cc3n/+y8NWesvQ4A25/e/jext3AmFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeLU9PQC2Ey0tLzivZfYa01tqLLCd8drZvqz5+0y2nd9pt4xtI/4ebPfWfL697fkXblt+jW7L/K1aB8cC/Btpi70O/NxYH2dyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAULzanh4AwIa0zG5Ze95WH8VGamnZuHkA3WHN44vjDZRvI17Xa743WnsNgN7LmVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOLV9vQAgG1US8sGp1tmr7E8ydpz1li+CffpFms+l/XNgzW9wOugR23LY3sBax4LWta51gttZB33KuhnQC9Q8GsUNkWPvc8DeB5ncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHhdjlx/+ctfcvrpp2fo0KEZOHBgDjrooDz00EPV5ZVKJZdeemmGDx+egQMHZuzYsXn88ce7ddAAAAAA8Hxdilz/+Mc/ctRRR6Vfv36566678pvf/Caf/vSns/POO1fXueqqq3LdddflxhtvzP33358dd9wx48aNy4oVK7p98AAAAACQJLVdWfnKK6/MyJEjM2PGjOq8pqam6n9XKpVce+21+chHPpI3v/nNSZIvf/nLaWhoyB133JFTTjmlm4YNAAAAAP+fLp3J9Z3vfCeHHXZYTjrppAwbNiwvfelL8/nPf766fMGCBVm8eHHGjh1bnTd48OAcccQRmTt3bveNGgAAAACep0uR649//GOmTZuWvffeO/fcc0/OPvvsvO9978uXvvSlJMnixYuTJA0NDZ3u19DQUF22pvb29rS1tXW6AQAAAEBXdOnjih0dHTnssMPyyU9+Mkny0pe+NI8++mhuvPHGnHHGGZs0gClTpuSyyy7bpPuyEVpaNm4eAJCW2S2dp3tkFNuYNd83bMz7iE25D7Bt20Ze12sep5Ped6z2t6oHbSOvA9avS2dyDR8+PPvvv3+nefvtt1+efPLJJEljY2OSZMmSJZ3WWbJkSXXZmiZPnpzW1tbq7amnnurKkAAAAACga5HrqKOOyvz58zvN+93vfpc99tgjybMXoW9sbMysWbOqy9va2nL//fenubl5ndvs379/6uvrO90AAAAAoCu69HHFCy+8MP/xH/+RT37yk3nb296WBx54IDfddFNuuummJElNTU0uuOCCfPzjH8/ee++dpqamXHLJJRkxYkTe8pa3bInxAwAAAEDXItfhhx+e22+/PZMnT87ll1+epqamXHvttTnttNOq61x00UVZvnx53v3ud2fZsmU5+uijc/fdd2fAgAHdPngAAAAASLoYuZLkjW98Y974xjeud3lNTU0uv/zyXH755Zs1MAAAAADYWF26JhcAAAAAbItELgAAAACKJ3IBAAAAULwuX5MLtkcts1s6T/fIKNimtLRs3Lyubta+BtB91jwud8NxGrZH2+r7jzXHlWw7Y2Pr2Vb3T8rkTC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKV9vTA+jVWlo2PA2wiVpmt3Se7pFRALBFreu9Y297P7kR76f9TQToPZzJBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAoXm1PDwCAbUPL7JbO0z0yinXblscGsN1radm4edsRf3dYi9eB1wFFcCYXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxavt6QFAb9Iyu6Xz9CZtpGXD0wDr4/gB24w13xMkm/i+oMsPvI5H6aFjQbe8LwI2zTZ0LKDr1vk3ZPaaM9ZepzdwJhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHi1PT0AuqClZePmAQCUZs33NN7jAABd5EwuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAilfb0wNgG9TSsnHzermW2S2dp3tkFLCNWfNY0RuPHX4GAAC90pr/Rkz8O3FrcyYXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxavt6QEA0Lu0zG7pPL3VHrhlw9Ns/9b1O7cfAABsN5zJBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAoXm1PDwAAoNdradnwNAAAL8iZXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABSvtqcHAGwFLS0bngYAgO1Uy+yWtedt9VEAW4MzuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAULwuRa6WlpbU1NR0uo0ePbq6fMWKFZk4cWKGDh2aQYMGZfz48VmyZEm3DxoAAAAAnq/LZ3IdcMABWbRoUfX205/+tLrswgsvzJ133pnbbrstc+bMycKFC3PiiSd264ABAAAAYE21Xb5DbW0aGxvXmt/a2prp06fnlltuybHHHpskmTFjRvbbb7/cd999OfLIIzd/tAAAAACwDl0+k+vxxx/PiBEjstdee+W0007Lk08+mSSZN29eVq1albFjx1bXHT16dEaNGpW5c+eud3vt7e1pa2vrdAMAAACAruhS5DriiCNy88035+677860adOyYMGCvOIVr8jTTz+dxYsXp66uLkOGDOl0n4aGhixevHi925wyZUoGDx5cvY0cOXKTnggAAAAAvVeXPq54/PHHV//74IMPzhFHHJE99tgj3/zmNzNw4MBNGsDkyZMzadKk6nRbW5vQBQAAAECXdPnjis83ZMiQ7LPPPvn973+fxsbGrFy5MsuWLeu0zpIlS9Z5Da/n9O/fP/X19Z1uAAAAANAVmxW5nnnmmfzhD3/I8OHDM2bMmPTr1y+zZs2qLp8/f36efPLJNDc3b/ZAAQAAAGB9uvRxxQ984AM54YQTsscee2ThwoX56Ec/mr59++bUU0/N4MGDc9ZZZ2XSpEnZZZddUl9fn/POOy/Nzc2+WREAAACALapLkevPf/5zTj311Pztb3/LbrvtlqOPPjr33XdfdttttyTJNddckz59+mT8+PFpb2/PuHHjcsMNN2yRgQMAAADAc7oUuW699dYNLh8wYECmTp2aqVOnbtagAAAAAKArNuuaXAAAAACwLRC5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAirdZkeuKK65ITU1NLrjgguq8FStWZOLEiRk6dGgGDRqU8ePHZ8mSJZs7TgAAAABYr02OXA8++GA+97nP5eCDD+40/8ILL8ydd96Z2267LXPmzMnChQtz4oknbvZAAQAAAGB9NilyPfPMMznttNPy+c9/PjvvvHN1fmtra6ZPn56rr746xx57bMaMGZMZM2bkZz/7We67775uGzQAAAAAPN8mRa6JEyfmDW94Q8aOHdtp/rx587Jq1apO80ePHp1Ro0Zl7ty569xWe3t72traOt0AAAAAoCtqu3qHW2+9NT//+c/z4IMPrrVs8eLFqaury5AhQzrNb2hoyOLFi9e5vSlTpuSyyy7r6jAAAAAAoKpLZ3I99dRTOf/88/O1r30tAwYM6JYBTJ48Oa2trdXbU0891S3bBQAAAKD36FLkmjdvXpYuXZqXvexlqa2tTW1tbebMmZPrrrsutbW1aWhoyMqVK7Ns2bJO91uyZEkaGxvXuc3+/funvr6+0w0AAAAAuqJLH1c87rjj8sgjj3Sa9453vCOjR4/Ohz70oYwcOTL9+vXLrFmzMn78+CTJ/Pnz8+STT6a5ubn7Rg0AAAAAz9OlyLXTTjvlwAMP7DRvxx13zNChQ6vzzzrrrEyaNCm77LJL6uvrc95556W5uTlHHnlk940aAAAAAJ6nyxeefyHXXHNN+vTpk/Hjx6e9vT3jxo3LDTfc0N0PAwAAAABVmx25Zs+e3Wl6wIABmTp1aqZOnbq5mwYAAACAjdKlC88DAAAAwLZI5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAAChelyLXtGnTcvDBB6e+vj719fVpbm7OXXfdVV2+YsWKTJw4MUOHDs2gQYMyfvz4LFmypNsHDQAAAADP16XItfvuu+eKK67IvHnz8tBDD+XYY4/Nm9/85vz6179Oklx44YW58847c9ttt2XOnDlZuHBhTjzxxC0ycAAAAAB4Tm1XVj7hhBM6TX/iE5/ItGnTct9992X33XfP9OnTc8stt+TYY49NksyYMSP77bdf7rvvvhx55JHdN2oAAAAAeJ5NvibX6tWrc+utt2b58uVpbm7OvHnzsmrVqowdO7a6zujRozNq1KjMnTu3WwYLAAAAAOvSpTO5kuSRRx5Jc3NzVqxYkUGDBuX222/P/vvvn4cffjh1dXUZMmRIp/UbGhqyePHi9W6vvb097e3t1em2trauDgkAAACAXq7LZ3Ltu+++efjhh3P//ffn7LPPzhlnnJHf/OY3mzyAKVOmZPDgwdXbyJEjN3lbAAAAAPROXY5cdXV1eclLXpIxY8ZkypQpOeSQQ/KZz3wmjY2NWblyZZYtW9Zp/SVLlqSxsXG925s8eXJaW1urt6eeeqrLTwIAAACA3m2Tr8n1nI6OjrS3t2fMmDHp169fZs2aVV02f/78PPnkk2lubl7v/fv375/6+vpONwAAAADoii5dk2vy5Mk5/vjjM2rUqDz99NO55ZZbMnv27Nxzzz0ZPHhwzjrrrEyaNCm77LJL6uvrc95556W5udk3KwIAAACwRXUpci1dujRvf/vbs2jRogwePDgHH3xw7rnnnrzmNa9JklxzzTXp06dPxo8fn/b29owbNy433HDDFhk4AAAAADynS5Fr+vTpG1w+YMCATJ06NVOnTt2sQQEAAABAV2z2NbkAAAAAoKeJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMXrUuSaMmVKDj/88Oy0004ZNmxY3vKWt2T+/Pmd1lmxYkUmTpyYoUOHZtCgQRk/fnyWLFnSrYMGAAAAgOfrUuSaM2dOJk6cmPvuuy8zZ87MqlWr8trXvjbLly+vrnPhhRfmzjvvzG233ZY5c+Zk4cKFOfHEE7t94AAAAADwnNqurHz33Xd3mr755pszbNiwzJs3L6985SvT2tqa6dOn55Zbbsmxxx6bJJkxY0b222+/3HfffTnyyCO7b+QAAAAA8P+3Wdfkam1tTZLssssuSZJ58+Zl1apVGTt2bHWd0aNHZ9SoUZk7d+7mPBQAAAAArFeXzuR6vo6OjlxwwQU56qijcuCBByZJFi9enLq6ugwZMqTTug0NDVm8ePE6t9Pe3p729vbqdFtb26YOCQAAAIBeapPP5Jo4cWIeffTR3HrrrZs1gClTpmTw4MHV28iRIzdrewAAAAD0PpsUuc4999x897vfzY9//OPsvvvu1fmNjY1ZuXJlli1b1mn9JUuWpLGxcZ3bmjx5clpbW6u3p556alOGBAAAAEAv1qXIValUcu655+b222/Pj370ozQ1NXVaPmbMmPTr1y+zZs2qzps/f36efPLJNDc3r3Ob/fv3T319facbAAAAAHRFl67JNXHixNxyyy359re/nZ122ql6na3Bgwdn4MCBGTx4cM4666xMmjQpu+yyS+rr63PeeeelubnZNysCAAAAsMV0KXJNmzYtSXLMMcd0mj9jxoxMmDAhSXLNNdekT58+GT9+fNrb2zNu3LjccMMN3TJYAAAAAFiXLkWuSqXygusMGDAgU6dOzdSpUzd5UAAAAADQFZv87YoAAAAAsK0QuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQvC5Hrp/85Cc54YQTMmLEiNTU1OSOO+7otLxSqeTSSy/N8OHDM3DgwIwdOzaPP/54d40XAAAAANbS5ci1fPnyHHLIIZk6deo6l1911VW57rrrcuONN+b+++/PjjvumHHjxmXFihWbPVgAAAAAWJfart7h+OOPz/HHH7/OZZVKJddee20+8pGP5M1vfnOS5Mtf/nIaGhpyxx135JRTTtm80QIAAADAOnTrNbkWLFiQxYsXZ+zYsdV5gwcPzhFHHJG5c+eu8z7t7e1pa2vrdAMAAACArujWyLV48eIkSUNDQ6f5DQ0N1WVrmjJlSgYPHly9jRw5sjuHBAAAAEAv0OPfrjh58uS0trZWb0899VRPDwkAAACAwnRr5GpsbEySLFmypNP8JUuWVJetqX///qmvr+90AwAAAICu6NbI1dTUlMbGxsyaNas6r62tLffff3+am5u786EAAAAAoKrL3674zDPP5Pe//311esGCBXn44Yezyy67ZNSoUbngggvy8Y9/PHvvvXeamppyySWXZMSIEXnLW97SneMGAAAAgKouR66HHnoor371q6vTkyZNSpKcccYZufnmm3PRRRdl+fLlefe7351ly5bl6KOPzt13350BAwZ036gBAAAA4Hm6HLmOOeaYVCqV9S6vqanJ5Zdfnssvv3yzBgYAAAAAG6vHv10RAAAAADaXyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFA8kQsAAACA4olcAAAAABRP5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8UQuAAAAAIoncgEAAABQPJELAAAAgOKJXAAAAAAUT+QCAAAAoHgiFwAAAADFE7kAAAAAKJ7IBQAAAEDxRC4AAAAAiidyAQAAAFC8LRa5pk6dmj333DMDBgzIEUcckQceeGBLPRQAAAAAvdwWiVzf+MY3MmnSpHz0ox/Nz3/+8xxyyCEZN25cli5duiUeDgAAAIBebotErquvvjrvete78o53vCP7779/brzxxuywww754he/uCUeDgAAAIBerra7N7hy5crMmzcvkydPrs7r06dPxo4dm7lz5661fnt7e9rb26vTra2tSZK2trbuHlqPal/evta8tjVnrfGc17zPWuu7z1rru0/37Gvb232K2qe35fsU9DrYWvcp6XWwte5T1D69te5T0D69Ld+npNfB1rpPUa+DrXWfgvbpbfk+Jb0OttZ9inodbK37FLRPb637bMv7dOmea0SVSmWD69VUXmiNLlq4cGFe9KIX5Wc/+1mam5ur8y+66KLMmTMn999/f6f1W1pactlll3XnEAAAAADYzjz11FPZfffd17u828/k6qrJkydn0qRJ1emOjo78/e9/z9ChQ1NTU9ODI+t+bW1tGTlyZJ566qnU19f39HDoIfYD7AMk9gPsA9gHeJb9APsAif3ghVQqlTz99NMZMWLEBtfr9si16667pm/fvlmyZEmn+UuWLEljY+Na6/fv3z/9+/fvNG/IkCHdPaxtSn19vZ0W+wH2AZLYD7APYB/gWfYD7AMk9oMNGTx48Auu0+0Xnq+rq8uYMWMya9as6ryOjo7MmjWr08cXAQAAAKC7bJGPK06aNClnnHFGDjvssLz85S/Ptddem+XLl+cd73jHlng4AAAAAHq5LRK5Tj755Pzv//5vLr300ixevDiHHnpo7r777jQ0NGyJhytG//7989GPfnStj2fSu9gPsA+Q2A+wD2Af4Fn2A+wDJPaD7tLt364IAAAAAFtbt1+TCwAAAAC2NpELAAAAgOKJXAAAAAAUT+QCAAAAoHgi11Y0derU7LnnnhkwYECOOOKIPPDAAz09JLagn/zkJznhhBMyYsSI1NTU5I477ui0vFKp5NJLL83w4cMzcODAjB07No8//njPDJZuN2XKlBx++OHZaaedMmzYsLzlLW/J/PnzO62zYsWKTJw4MUOHDs2gQYMyfvz4LFmypIdGzJYwbdq0HHzwwamvr099fX2am5tz1113VZfbB3qfK664IjU1Nbnggguq8+wH27+WlpbU1NR0uo0ePbq63D7QO/zlL3/J6aefnqFDh2bgwIE56KCD8tBDD1WXe2+4/dtzzz3XOhbU1NRk4sSJSRwLeoPVq1fnkksuSVNTUwYOHJgXv/jF+djHPpbnfx+gY8HmEbm2km984xuZNGlSPvrRj+bnP/95DjnkkIwbNy5Lly7t6aGxhSxfvjyHHHJIpk6dus7lV111Va677rrceOONuf/++7Pjjjtm3LhxWbFixVYeKVvCnDlzMnHixNx3332ZOXNmVq1alde+9rVZvnx5dZ0LL7wwd955Z2677bbMmTMnCxcuzIknntiDo6a77b777rniiisyb968PPTQQzn22GPz5je/Ob/+9a+T2Ad6mwcffDCf+9zncvDBB3eabz/oHQ444IAsWrSoevvpT39aXWYf2P794x//yFFHHZV+/frlrrvuym9+85t8+tOfzs4771xdx3vD7d+DDz7Y6Tgwc+bMJMlJJ52UxLGgN7jyyiszbdq0fPazn81jjz2WK6+8MldddVWuv/766jqOBZupwlbx8pe/vDJx4sTq9OrVqysjRoyoTJkypQdHxdaSpHL77bdXpzs6OiqNjY2VT33qU9V5y5Ytq/Tv37/y9a9/vQdGyJa2dOnSSpLKnDlzKpXKs7/vfv36VW677bbqOo899lglSWXu3Lk9NUy2gp133rnyhS98wT7Qyzz99NOVvffeuzJz5szKq171qsr5559fqVQcC3qLj370o5VDDjlkncvsA73Dhz70ocrRRx+93uXeG/ZO559/fuXFL35xpaOjw7Ggl3jDG95QOfPMMzvNO/HEEyunnXZapVJxLOgOzuTaClauXJl58+Zl7Nix1Xl9+vTJ2LFjM3fu3B4cGT1lwYIFWbx4cad9YvDgwTniiCPsE9up1tbWJMkuu+ySJJk3b15WrVrVaR8YPXp0Ro0aZR/YTq1evTq33nprli9fnubmZvtALzNx4sS84Q1v6PT7ThwLepPHH388I0aMyF577ZXTTjstTz75ZBL7QG/xne98J4cddlhOOumkDBs2LC996Uvz+c9/vrrce8PeZ+XKlfnqV7+aM888MzU1NY4FvcR//Md/ZNasWfnd736XJPnlL3+Zn/70pzn++OOTOBZ0h9qeHkBv8Ne//jWrV69OQ0NDp/kNDQ357W9/20OjoictXrw4Sda5Tzy3jO1HR0dHLrjgghx11FE58MADkzy7D9TV1WXIkCGd1rUPbH8eeeSRNDc3Z8WKFRk0aFBuv/327L///nn44YftA73Erbfemp///Od58MEH11rmWNA7HHHEEbn55puz7777ZtGiRbnsssvyile8Io8++qh9oJf44x//mGnTpmXSpEn58Ic/nAcffDDve9/7UldXlzPOOMN7w17ojjvuyLJlyzJhwoQk/h70FhdffHHa2toyevTo9O3bN6tXr84nPvGJnHbaaUn8O7E7iFwAW9jEiRPz6KOPdrr+Cr3Hvvvum4cffjitra351re+lTPOOCNz5szp6WGxlTz11FM5//zzM3PmzAwYMKCnh0MPee7/oU+Sgw8+OEcccUT22GOPfPOb38zAgQN7cGRsLR0dHTnssMPyyU9+Mkny0pe+NI8++mhuvPHGnHHGGT08OnrC9OnTc/zxx2fEiBE9PRS2om9+85v52te+lltuuSUHHHBAHn744VxwwQUZMWKEY0E38XHFrWDXXXdN37591/pmjCVLlqSxsbGHRkVPeu73bp/Y/p177rn57ne/mx//+MfZfffdq/MbGxuzcuXKLFu2rNP69oHtT11dXV7ykpdkzJgxmTJlSg455JB85jOfsQ/0EvPmzcvSpUvzspe9LLW1tamtrc2cOXNy3XXXpba2Ng0NDfaDXmjIkCHZZ5998vvf/96xoJcYPnx49t9//07z9ttvv+rHVr037F2eeOKJ/PCHP8w73/nO6jzHgt7hgx/8YC6++OKccsopOeigg/Kf//mfufDCCzNlypQkjgXdQeTaCurq6jJmzJjMmjWrOq+joyOzZs1Kc3NzD46MntLU1JTGxsZO+0RbW1vuv/9++8R2olKp5Nxzz83tt9+eH/3oR2lqauq0fMyYMenXr1+nfWD+/Pl58skn7QPbuY6OjrS3t9sHeonjjjsujzzySB5++OHq7bDDDstpp51W/W/7Qe/zzDPP5A9/+EOGDx/uWNBLHHXUUZk/f36neb/73e+yxx57JPHesLeZMWNGhg0blje84Q3VeY4FvcM///nP9OnTOcP07ds3HR0dSRwLukVPX/m+t7j11lsr/fv3r9x8882V3/zmN5V3v/vdlSFDhlQWL17c00NjC3n66acrv/jFLyq/+MUvKkkqV199deUXv/hF5YknnqhUKpXKFVdcURkyZEjl29/+duVXv/pV5c1vfnOlqamp8q9//auHR053OPvssyuDBw+uzJ49u7Jo0aLq7Z///Gd1nfe+972VUaNGVX70ox9VHnrooUpzc3Olubm5B0dNd7v44osrc+bMqSxYsKDyq1/9qnLxxRdXampqKj/4wQ8qlYp9oLd6/rcrVir2g97g/e9/f2X27NmVBQsWVO69997K2LFjK7vuumtl6dKllUrFPtAbPPDAA5Xa2trKJz7xicrjjz9e+drXvlbZYYcdKl/96ler63hv2DusXr26MmrUqMqHPvShtZY5Fmz/zjjjjMqLXvSiyne/+93KggULKv/zP/9T2XXXXSsXXXRRdR3Hgs0jcm1F119/fWXUqFGVurq6ystf/vLKfffd19NDYgv68Y9/XEmy1u2MM86oVCrPfj3sJZdcUmloaKj079+/ctxxx1Xmz5/fs4Om26zrd5+kMmPGjOo6//rXvyrnnHNOZeedd67ssMMOlbe+9a2VRYsW9dyg6XZnnnlmZY899qjU1dVVdtttt8pxxx1XDVyVin2gt1ozctkPtn8nn3xyZfjw4ZW6urrKi170osrJJ59c+f3vf19dbh/oHe68887KgQceWOnfv39l9OjRlZtuuqnTcu8Ne4d77rmnkmSdv1vHgu1fW1tb5fzzz6+MGjWqMmDAgMpee+1V+a//+q9Ke3t7dR3Hgs1TU6lUKj1yChkAAAAAdBPX5AIAAACgeCIXAAAAAMUTuQAAAAAonsgFAAAAQPFELgAAAACKJ3IBAAAAUDyRCwAAAIDiiVwAAAAAFE/kAgAAAKB4IhcAAAAAxRO5AAAAACieyAUAAABA8f5/t1x0BArJWtkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_distribution_graph(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
       "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81])"
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7,\n",
       " 1.7,\n",
       " 2.7,\n",
       " 3.7,\n",
       " 4.7,\n",
       " 5.7,\n",
       " 6.7,\n",
       " 7.7,\n",
       " 8.7,\n",
       " 9.7,\n",
       " 10.7,\n",
       " 11.7,\n",
       " 12.7,\n",
       " 13.7,\n",
       " 14.7,\n",
       " 15.7,\n",
       " 16.7,\n",
       " 17.7,\n",
       " 18.7,\n",
       " 19.7,\n",
       " 20.7,\n",
       " 21.7,\n",
       " 22.7,\n",
       " 23.7,\n",
       " 24.7,\n",
       " 25.7,\n",
       " 26.7,\n",
       " 27.7,\n",
       " 28.7,\n",
       " 29.7,\n",
       " 30.7,\n",
       " 31.7,\n",
       " 32.7,\n",
       " 33.7,\n",
       " 34.7,\n",
       " 35.7,\n",
       " 36.7,\n",
       " 37.7,\n",
       " 38.7,\n",
       " 39.7,\n",
       " 40.7,\n",
       " 41.7,\n",
       " 42.7,\n",
       " 43.7,\n",
       " 44.7,\n",
       " 45.7,\n",
       " 46.7,\n",
       " 47.7,\n",
       " 48.7,\n",
       " 49.7,\n",
       " 50.7,\n",
       " 51.7,\n",
       " 52.7,\n",
       " 53.7,\n",
       " 54.7,\n",
       " 55.7,\n",
       " 56.7,\n",
       " 57.7,\n",
       " 58.7,\n",
       " 59.7,\n",
       " 60.7,\n",
       " 61.7,\n",
       " 62.7,\n",
       " 63.7,\n",
       " 64.7,\n",
       " 65.7,\n",
       " 66.7,\n",
       " 67.7,\n",
       " 68.7,\n",
       " 69.7,\n",
       " 70.7,\n",
       " 71.7,\n",
       " 72.7,\n",
       " 73.7,\n",
       " 74.7,\n",
       " 75.7,\n",
       " 76.7,\n",
       " 77.7,\n",
       " 78.7,\n",
       " 79.7,\n",
       " 80.7,\n",
       " 81.7]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x - 0.3 for x in batch_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tocount[0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjsklEQVR4nO3dfXBU1cHH8V9CsgkCuyG87JKaICgSUEBECetLtRgNlLE4ZFQsWkSUjo1YSFtrpgqi1uBLheoEUCcGHcUUOoLSKqhRsNokaJQWARE0TxPEXSo22YDNguQ8f3S47cqLbLI5YcP3M3NH9t6zN+dwWfi62d0kGGOMAAAALEns6AkAAICTC/EBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq5I6egLf1tLSol27dqlHjx5KSEjo6OkAAIDjYIxRU1OTMjIylJh47Oc2Trj42LVrlzIzMzt6GgAAoBXq6+t16qmnHnPMCRcfPXr0kPSfybvd7g6eDQAAOB6hUEiZmZnOv+PHcsLFx6FvtbjdbuIDAIA4czwvmeAFpwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVSR09AdtOu/PPHT0F4IT1f/MndPQUAJwEonrm47TTTlNCQsJhW0FBgSSpublZBQUF6tWrl7p37678/HwFg8F2mTgAAIhPUcXHe++9py+++MLZXn/9dUnS1VdfLUmaPXu2Vq9erRUrVmj9+vXatWuXJk2aFPtZAwCAuBXVt1369OkTcXv+/Pk6/fTTdckll6ixsVGlpaVatmyZxo4dK0kqKyvTkCFDVFVVpTFjxsRu1gAAIG61+gWn+/fv13PPPaebbrpJCQkJqqmp0YEDB5Sbm+uMyc7OVlZWliorK496nnA4rFAoFLEBAIDOq9XxsWrVKjU0NOjGG2+UJAUCAblcLqWlpUWM83q9CgQCRz1PcXGxPB6Ps2VmZrZ2SgAAIA60Oj5KS0s1fvx4ZWRktGkCRUVFamxsdLb6+vo2nQ8AAJzYWvVW23/84x9644039OKLLzr7fD6f9u/fr4aGhohnP4LBoHw+31HPlZKSopSUlNZMAwAAxKFWPfNRVlamvn37asKE/34mwKhRo5ScnKyKigpn37Zt21RXVye/39/2mQIAgE4h6mc+WlpaVFZWpqlTpyop6b9393g8mj59ugoLC5Weni63262ZM2fK7/fzThcAAOCIOj7eeOMN1dXV6aabbjrs2IIFC5SYmKj8/HyFw2Hl5eVp0aJFMZkoAADoHBKMMaajJ/G/QqGQPB6PGhsb5Xa7Y35+Pl4dODo+Xh1Aa0Xz7zc/WA4AAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWRR0fn3/+ua6//nr16tVLXbt21bBhw/T+++87x40xmjNnjvr166euXbsqNzdX27dvj+mkAQBA/IoqPv71r3/pwgsvVHJysl599VVt2bJFv/vd79SzZ09nzEMPPaTHHntMS5YsUXV1tbp166a8vDw1NzfHfPIAACD+JEUz+MEHH1RmZqbKysqcfQMGDHB+bYzRwoULddddd2nixImSpGeffVZer1erVq3S5MmTYzRtAAAQr6J65uPll1/Weeedp6uvvlp9+/bVyJEj9dRTTznHa2trFQgElJub6+zzeDzKyclRZWXlEc8ZDocVCoUiNgAA0HlFFR+fffaZFi9erEGDBmnt2rW69dZbdfvtt+uZZ56RJAUCAUmS1+uNuJ/X63WOfVtxcbE8Ho+zZWZmtmYdAAAgTkQVHy0tLTr33HP1wAMPaOTIkZoxY4ZuueUWLVmypNUTKCoqUmNjo7PV19e3+lwAAODEF1V89OvXT0OHDo3YN2TIENXV1UmSfD6fJCkYDEaMCQaDzrFvS0lJkdvtjtgAAEDnFVV8XHjhhdq2bVvEvk8++UT9+/eX9J8Xn/p8PlVUVDjHQ6GQqqur5ff7YzBdAAAQ76J6t8vs2bN1wQUX6IEHHtA111yjDRs26Mknn9STTz4pSUpISNCsWbN0//33a9CgQRowYIDuvvtuZWRk6KqrrmqP+QMAgDgTVXycf/75WrlypYqKinTvvfdqwIABWrhwoaZMmeKMueOOO7Rv3z7NmDFDDQ0Nuuiii7RmzRqlpqbGfPIAACD+JBhjTEdP4n+FQiF5PB41Nja2y+s/TrvzzzE/J9BZ/N/8CR09BQBxKpp/v/nZLgAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFZF9QmnABAP+DBB4Ng6+gMFeeYDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVRxcc999yjhISEiC07O9s53tzcrIKCAvXq1Uvdu3dXfn6+gsFgzCcNAADiV9TPfJx11ln64osvnO2dd95xjs2ePVurV6/WihUrtH79eu3atUuTJk2K6YQBAEB8S4r6DklJ8vl8h+1vbGxUaWmpli1bprFjx0qSysrKNGTIEFVVVWnMmDFtny0AAIh7UT/zsX37dmVkZGjgwIGaMmWK6urqJEk1NTU6cOCAcnNznbHZ2dnKyspSZWXlUc8XDocVCoUiNgAA0HlFFR85OTlaunSp1qxZo8WLF6u2tlYXX3yxmpqaFAgE5HK5lJaWFnEfr9erQCBw1HMWFxfL4/E4W2ZmZqsWAgAA4kNU33YZP3688+vhw4crJydH/fv31/Lly9W1a9dWTaCoqEiFhYXO7VAoRIAAANCJtemttmlpaTrzzDO1Y8cO+Xw+7d+/Xw0NDRFjgsHgEV8jckhKSorcbnfEBgAAOq82xcfevXv16aefql+/fho1apSSk5NVUVHhHN+2bZvq6urk9/vbPFEAANA5RPVtl1/+8pe68sor1b9/f+3atUtz585Vly5ddN1118nj8Wj69OkqLCxUenq63G63Zs6cKb/fzztdAACAI6r42Llzp6677jrt2bNHffr00UUXXaSqqir16dNHkrRgwQIlJiYqPz9f4XBYeXl5WrRoUbtMHAAAxKeo4qO8vPyYx1NTU1VSUqKSkpI2TQoAAHRe/GwXAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWNWm+Jg/f74SEhI0a9YsZ19zc7MKCgrUq1cvde/eXfn5+QoGg22dJwAA6CRaHR/vvfeennjiCQ0fPjxi/+zZs7V69WqtWLFC69ev165duzRp0qQ2TxQAAHQOrYqPvXv3asqUKXrqqafUs2dPZ39jY6NKS0v16KOPauzYsRo1apTKysr017/+VVVVVTGbNAAAiF+tio+CggJNmDBBubm5Eftramp04MCBiP3Z2dnKyspSZWXlEc8VDocVCoUiNgAA0HklRXuH8vJyffDBB3rvvfcOOxYIBORyuZSWlhax3+v1KhAIHPF8xcXFmjdvXrTTAAAAcSqqZz7q6+v185//XM8//7xSU1NjMoGioiI1NjY6W319fUzOCwAATkxRxUdNTY12796tc889V0lJSUpKStL69ev12GOPKSkpSV6vV/v371dDQ0PE/YLBoHw+3xHPmZKSIrfbHbEBAIDOK6pvu1x22WXatGlTxL5p06YpOztbv/71r5WZmank5GRVVFQoPz9fkrRt2zbV1dXJ7/fHbtYAACBuRRUfPXr00Nlnnx2xr1u3burVq5ezf/r06SosLFR6errcbrdmzpwpv9+vMWPGxG7WAAAgbkX9gtPvsmDBAiUmJio/P1/hcFh5eXlatGhRrL8MAACIU22Oj3Xr1kXcTk1NVUlJiUpKStp6agAA0Anxs10AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq6KKj8WLF2v48OFyu91yu93y+/169dVXnePNzc0qKChQr1691L17d+Xn5ysYDMZ80gAAIH5FFR+nnnqq5s+fr5qaGr3//vsaO3asJk6cqM2bN0uSZs+erdWrV2vFihVav369du3apUmTJrXLxAEAQHxKimbwlVdeGXH7t7/9rRYvXqyqqiqdeuqpKi0t1bJlyzR27FhJUllZmYYMGaKqqiqNGTMmdrMGAABxq9Wv+Th48KDKy8u1b98++f1+1dTU6MCBA8rNzXXGZGdnKysrS5WVlTGZLAAAiH9RPfMhSZs2bZLf71dzc7O6d++ulStXaujQodq4caNcLpfS0tIixnu9XgUCgaOeLxwOKxwOO7dDoVC0UwIAAHEk6mc+Bg8erI0bN6q6ulq33nqrpk6dqi1btrR6AsXFxfJ4PM6WmZnZ6nMBAIATX9Tx4XK5dMYZZ2jUqFEqLi7WiBEj9Pvf/14+n0/79+9XQ0NDxPhgMCifz3fU8xUVFamxsdHZ6uvro14EAACIH23+nI+WlhaFw2GNGjVKycnJqqiocI5t27ZNdXV18vv9R71/SkqK89bdQxsAAOi8onrNR1FRkcaPH6+srCw1NTVp2bJlWrdundauXSuPx6Pp06ersLBQ6enpcrvdmjlzpvx+P+90AQAAjqjiY/fu3frJT36iL774Qh6PR8OHD9fatWt1+eWXS5IWLFigxMRE5efnKxwOKy8vT4sWLWqXiQMAgPgUVXyUlpYe83hqaqpKSkpUUlLSpkkBAIDOi5/tAgAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuiio/i4mKdf/756tGjh/r27aurrrpK27ZtixjT3NysgoIC9erVS927d1d+fr6CwWBMJw0AAOJXVPGxfv16FRQUqKqqSq+//roOHDigK664Qvv27XPGzJ49W6tXr9aKFSu0fv167dq1S5MmTYr5xAEAQHxKimbwmjVrIm4vXbpUffv2VU1Njb7//e+rsbFRpaWlWrZsmcaOHStJKisr05AhQ1RVVaUxY8bEbuYAACAutek1H42NjZKk9PR0SVJNTY0OHDig3NxcZ0x2draysrJUWVl5xHOEw2GFQqGIDQAAdF6tjo+WlhbNmjVLF154oc4++2xJUiAQkMvlUlpaWsRYr9erQCBwxPMUFxfL4/E4W2ZmZmunBAAA4kCr46OgoEAfffSRysvL2zSBoqIiNTY2Olt9fX2bzgcAAE5sUb3m45DbbrtNf/rTn/T222/r1FNPdfb7fD7t379fDQ0NEc9+BINB+Xy+I54rJSVFKSkprZkGAACIQ1E982GM0W233aaVK1fqzTff1IABAyKOjxo1SsnJyaqoqHD2bdu2TXV1dfL7/bGZMQAAiGtRPfNRUFCgZcuW6aWXXlKPHj2c13F4PB517dpVHo9H06dPV2FhodLT0+V2uzVz5kz5/X7e6QIAACRFGR+LFy+WJF166aUR+8vKynTjjTdKkhYsWKDExETl5+crHA4rLy9PixYtislkAQBA/IsqPowx3zkmNTVVJSUlKikpafWkAABA58XPdgEAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVUcfH22+/rSuvvFIZGRlKSEjQqlWrIo4bYzRnzhz169dPXbt2VW5urrZv3x6r+QIAgDgXdXzs27dPI0aMUElJyRGPP/TQQ3rssce0ZMkSVVdXq1u3bsrLy1Nzc3ObJwsAAOJfUrR3GD9+vMaPH3/EY8YYLVy4UHfddZcmTpwoSXr22Wfl9Xq1atUqTZ48uW2zBQAAcS+mr/mora1VIBBQbm6us8/j8SgnJ0eVlZVHvE84HFYoFIrYAABA5xXT+AgEApIkr9cbsd/r9TrHvq24uFgej8fZMjMzYzklAABwgunwd7sUFRWpsbHR2err6zt6SgAAoB3FND58Pp8kKRgMRuwPBoPOsW9LSUmR2+2O2AAAQOcV0/gYMGCAfD6fKioqnH2hUEjV1dXy+/2x/FIAACBORf1ul71792rHjh3O7draWm3cuFHp6enKysrSrFmzdP/992vQoEEaMGCA7r77bmVkZOiqq66K5bwBAECcijo+3n//ff3gBz9wbhcWFkqSpk6dqqVLl+qOO+7Qvn37NGPGDDU0NOiiiy7SmjVrlJqaGrtZAwCAuBV1fFx66aUyxhz1eEJCgu69917de++9bZoYAADonDr83S4AAODkQnwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsKrd4qOkpESnnXaaUlNTlZOTow0bNrTXlwIAAHGkXeLjD3/4gwoLCzV37lx98MEHGjFihPLy8rR79+72+HIAACCOtEt8PProo7rllls0bdo0DR06VEuWLNEpp5yip59+uj2+HAAAiCNJsT7h/v37VVNTo6KiImdfYmKicnNzVVlZedj4cDiscDjs3G5sbJQkhUKhWE9NktQS/rpdzgt0Bu31uLONxzlwbO3xWD90TmPMd46NeXx8+eWXOnjwoLxeb8R+r9erjz/++LDxxcXFmjdv3mH7MzMzYz01AN/Bs7CjZwDAhvZ8rDc1Ncnj8RxzTMzjI1pFRUUqLCx0bre0tOirr75Sr169lJCQ0IEzsyMUCikzM1P19fVyu90dPR2rWPvJt/aTdd0Saz8Z136yrdsYo6amJmVkZHzn2JjHR+/evdWlSxcFg8GI/cFgUD6f77DxKSkpSklJidiXlpYW62md8Nxu90nxh/NIWPvJt/aTdd0Saz8Z134yrfu7nvE4JOYvOHW5XBo1apQqKiqcfS0tLaqoqJDf74/1lwMAAHGmXb7tUlhYqKlTp+q8887T6NGjtXDhQu3bt0/Tpk1rjy8HAADiSLvEx7XXXqt//vOfmjNnjgKBgM455xytWbPmsBeh4j/fdpo7d+5h33o6GbD2k2/tJ+u6JdZ+Mq79ZF338Ugwx/OeGAAAgBjhZ7sAAACriA8AAGAV8QEAAKwiPgAAgFXEhwVfffWVpkyZIrfbrbS0NE2fPl179+495viZM2dq8ODB6tq1q7KysnT77bc7P/fmkISEhMO28vLy9l7OMZWUlOi0005TamqqcnJytGHDhmOOX7FihbKzs5Wamqphw4bplVdeiThujNGcOXPUr18/de3aVbm5udq+fXt7LqFVoln3U089pYsvvlg9e/ZUz549lZube9j4G2+88bBrO27cuPZeRqtEs/alS5cetq7U1NSIMfFyzaXo1n7ppZce8TE7YcIEZ0w8XPe3335bV155pTIyMpSQkKBVq1Z9533WrVunc889VykpKTrjjDO0dOnSw8ZE+3eHbdGu+8UXX9Tll1+uPn36yO12y+/3a+3atRFj7rnnnsOud3Z2djuu4gRi0O7GjRtnRowYYaqqqsxf/vIXc8YZZ5jrrrvuqOM3bdpkJk2aZF5++WWzY8cOU1FRYQYNGmTy8/MjxkkyZWVl5osvvnC2f//73+29nKMqLy83LpfLPP3002bz5s3mlltuMWlpaSYYDB5x/Lvvvmu6dOliHnroIbNlyxZz1113meTkZLNp0yZnzPz5843H4zGrVq0yf/vb38yPfvQjM2DAgA5d57dFu+4f//jHpqSkxHz44Ydm69at5sYbbzQej8fs3LnTGTN16lQzbty4iGv71Vdf2VrScYt27WVlZcbtdkesKxAIRIyJh2tuTPRr37NnT8S6P/roI9OlSxdTVlbmjImH6/7KK6+Y3/zmN+bFF180kszKlSuPOf6zzz4zp5xyiiksLDRbtmwxjz/+uOnSpYtZs2aNMyba38uOEO26f/7zn5sHH3zQbNiwwXzyySemqKjIJCcnmw8++MAZM3fuXHPWWWdFXO9//vOf7bySEwPx0c62bNliJJn33nvP2ffqq6+ahIQE8/nnnx/3eZYvX25cLpc5cOCAs+94HgA2jR492hQUFDi3Dx48aDIyMkxxcfERx19zzTVmwoQJEftycnLMT3/6U2OMMS0tLcbn85mHH37YOd7Q0GBSUlLMCy+80A4raJ1o1/1t33zzjenRo4d55plnnH1Tp041EydOjPVUYy7atZeVlRmPx3PU88XLNTem7dd9wYIFpkePHmbv3r3Ovni57occz99Bd9xxhznrrLMi9l177bUmLy/Pud3W30vbWvt379ChQ828efOc23PnzjUjRoyI3cTiCN92aWeVlZVKS0vTeeed5+zLzc1VYmKiqqurj/s8jY2NcrvdSkqK/Fy4goIC9e7dW6NHj9bTTz99XD/KuD3s379fNTU1ys3NdfYlJiYqNzdXlZWVR7xPZWVlxHhJysvLc8bX1tYqEAhEjPF4PMrJyTnqOW1rzbq/7euvv9aBAweUnp4esX/dunXq27evBg8erFtvvVV79uyJ6dzbqrVr37t3r/r376/MzExNnDhRmzdvdo7FwzWXYnPdS0tLNXnyZHXr1i1i/4l+3aP1XY/zWPxexoOWlhY1NTUd9jjfvn27MjIyNHDgQE2ZMkV1dXUdNEO7iI92FggE1Ldv34h9SUlJSk9PVyAQOK5zfPnll7rvvvs0Y8aMiP333nuvli9frtdff135+fn62c9+pscffzxmc4/Gl19+qYMHDx72KbZer/eo6wwEAsccf+i/0ZzTttas+9t+/etfKyMjI+Iv33HjxunZZ59VRUWFHnzwQa1fv17jx4/XwYMHYzr/tmjN2gcPHqynn35aL730kp577jm1tLToggsu0M6dOyXFxzWX2n7dN2zYoI8++kg333xzxP54uO7ROtrjPBQK6d///ndMHkPx4JFHHtHevXt1zTXXOPtycnK0dOlSrVmzRosXL1Ztba0uvvhiNTU1deBM7WiXj1c/Gdx555168MEHjzlm69atbf46oVBIEyZM0NChQ3XPPfdEHLv77rudX48cOVL79u3Tww8/rNtvv73NXxd2zJ8/X+Xl5Vq3bl3ECy8nT57s/HrYsGEaPny4Tj/9dK1bt06XXXZZR0w1Jvx+f8QPmLzgggs0ZMgQPfHEE7rvvvs6cGZ2lZaWatiwYRo9enTE/s563U92y5Yt07x58/TSSy9F/M/o+PHjnV8PHz5cOTk56t+/v5YvX67p06d3xFSt4ZmPVvrFL36hrVu3HnMbOHCgfD6fdu/eHXHfb775Rl999ZV8Pt8xv0ZTU5PGjRunHj16aOXKlUpOTj7m+JycHO3cuVPhcLjN64tW79691aVLFwWDwYj9wWDwqOv0+XzHHH/ov9Gc07bWrPuQRx55RPPnz9drr72m4cOHH3PswIED1bt3b+3YsaPNc46Vtqz9kOTkZI0cOdJZVzxcc6lta9+3b5/Ky8uP6x+XE/G6R+toj3O3262uXbvG5M/Riay8vFw333yzli9ffti3n74tLS1NZ555Zlxf7+NFfLRSnz59lJ2dfczN5XLJ7/eroaFBNTU1zn3ffPNNtbS0KCcn56jnD4VCuuKKK+RyufTyyy8f9nbEI9m4caN69uzZIT/EyOVyadSoUaqoqHD2tbS0qKKiIuL/dP+X3++PGC9Jr7/+ujN+wIAB8vl8EWNCoZCqq6uPek7bWrNuSXrooYd03333ac2aNRGvBzqanTt3as+ePerXr19M5h0LrV37/zp48KA2bdrkrCserrnUtrWvWLFC4XBY119//Xd+nRPxukfrux7nsfhzdKJ64YUXNG3aNL3wwgsRb6k+mr179+rTTz+N6+t93Dr6Fa8ng3HjxpmRI0ea6upq884775hBgwZFvNV2586dZvDgwaa6utoYY0xjY6PJyckxw4YNMzt27Ih4G9Y333xjjDHm5ZdfNk899ZTZtGmT2b59u1m0aJE55ZRTzJw5czpkjcb85+1yKSkpZunSpWbLli1mxowZJi0tzXkr5Q033GDuvPNOZ/y7775rkpKSzCOPPGK2bt1q5s6de8S32qalpZmXXnrJ/P3vfzcTJ0484d52Ge2658+fb1wul/njH/8YcW2bmpqMMcY0NTWZX/7yl6aystLU1taaN954w5x77rlm0KBBprm5uUPWeDTRrn3evHlm7dq15tNPPzU1NTVm8uTJJjU11WzevNkZEw/X3Jjo137IRRddZK699trD9sfLdW9qajIffvih+fDDD40k8+ijj5oPP/zQ/OMf/zDGGHPnnXeaG264wRl/6K22v/rVr8zWrVtNSUnJEd9qe6zfyxNBtOt+/vnnTVJSkikpKYl4nDc0NDhjfvGLX5h169aZ2tpa8+6775rc3FzTu3dvs3v3buvrs434sGDPnj3muuuuM927dzdut9tMmzbN+YfGGGNqa2uNJPPWW28ZY4x56623jKQjbrW1tcaY/7xd95xzzjHdu3c33bp1MyNGjDBLliwxBw8e7IAV/tfjjz9usrKyjMvlMqNHjzZVVVXOsUsuucRMnTo1Yvzy5cvNmWeeaVwulznrrLPMn//854jjLS0t5u677zZer9ekpKSYyy67zGzbts3GUqISzbr79+9/xGs7d+5cY4wxX3/9tbniiitMnz59THJysunfv7+55ZZbTqi/iP9XNGufNWuWM9br9Zof/vCHEZ97YEz8XHNjov/z/vHHHxtJ5rXXXjvsXPFy3Y/299OhtU6dOtVccsklh93nnHPOMS6XywwcODDis00OOdbv5Ykg2nVfcsklxxxvzH/ectyvXz/jcrnM9773PXPttdeaHTt22F1YB0kwpoPemwkAAE5KvOYDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKz6fzMIT0S++L1GAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh4ElEQVR4nO3de3CU1eH/8U8gySZCdkO4JKQkGCoSQEBACeulWowGihSHTAWKFhmE1kYUolUzFRC0BtAK1QmgDASdiil05NYqaKNgtUnAiC03ETTfEoRdFJqrsiA5vz867K8rF9lkc8LC+zXzjOzznH1yDg8Lbze72QhjjBEAAIAlrVp6AgAA4NJCfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMCqyJaewHc1NDTo4MGDiouLU0REREtPBwAAnAdjjGpra5WcnKxWrc793MYFFx8HDx5USkpKS08DAAA0QmVlpbp06XLOMRdcfMTFxUn67+SdTmcLzwYAAJyPmpoapaSk+P8dP5cLLj5OfavF6XQSHwAAhJnzeckELzgFAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArIps6QnYdvljf23pKQAXrP+bM7ylpwDgEsAzHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWHXJ/Xh1ABc/PkYBOLeW/igFnvkAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFgVdHx88cUXuuuuu9S+fXvFxsaqT58++vDDD/3HjTGaMWOGOnfurNjYWGVmZmrv3r0hnTQAAAhfQcXHf/7zH11//fWKiorSm2++qV27dun3v/+92rVr5x8zb948Pf/881q8eLHKysrUpk0bZWVl6dixYyGfPAAACD9Bfart3LlzlZKSosLCQv++tLQ0/6+NMVqwYIEef/xxjRw5UpL0yiuvKDExUWvWrNGYMWNCNG0AABCugnrmY926dbrmmmv0s5/9TJ06dVL//v21ZMkS//GKigp5PB5lZmb697lcLmVkZKikpOSM5/T5fKqpqQnYAADAxSuo+Pj888+1aNEide/eXRs3btR9992nBx54QC+//LIkyePxSJISExMD7peYmOg/9l35+flyuVz+LSUlpTHrAAAAYSKo+GhoaNCAAQP09NNPq3///po8ebImTZqkxYsXN3oCeXl5qq6u9m+VlZWNPhcAALjwBRUfnTt3Vq9evQL29ezZU/v375ckJSUlSZK8Xm/AGK/X6z/2XQ6HQ06nM2ADAAAXr6Di4/rrr9eePXsC9n366afq2rWrpP+++DQpKUnFxcX+4zU1NSorK5Pb7Q7BdAEAQLgL6t0u06ZN03XXXaenn35ad955p7Zs2aKXXnpJL730kiQpIiJCU6dO1VNPPaXu3bsrLS1N06dPV3Jysu64447mmD8AAAgzQcXHtddeq9WrVysvL0+zZ89WWlqaFixYoHHjxvnHPPLII6qvr9fkyZNVVVWlG264QRs2bFBMTEzIJw8AAMJPUPEhSbfffrtuv/32sx6PiIjQ7NmzNXv27CZNDAAAXJz4bBcAAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVBxccTTzyhiIiIgC09Pd1//NixY8rJyVH79u3Vtm1bZWdny+v1hnzSAAAgfAX9zEfv3r116NAh//b+++/7j02bNk3r16/XqlWrtHnzZh08eFCjRo0K6YQBAEB4iwz6DpGRSkpKOm1/dXW1li5dqhUrVmjIkCGSpMLCQvXs2VOlpaUaPHhw02cLAADCXtDPfOzdu1fJycnq1q2bxo0bp/3790uSysvLdeLECWVmZvrHpqenKzU1VSUlJaGbMQAACGtBPfORkZGh5cuXq0ePHjp06JBmzZqlG2+8UTt27JDH41F0dLTi4+MD7pOYmCiPx3PWc/p8Pvl8Pv/tmpqa4FYAAADCSlDxMWzYMP+v+/btq4yMDHXt2lUrV65UbGxsoyaQn5+vWbNmNeq+AAAg/DTprbbx8fG68sortW/fPiUlJen48eOqqqoKGOP1es/4GpFT8vLyVF1d7d8qKyubMiUAAHCBa1J81NXV6bPPPlPnzp01cOBARUVFqbi42H98z5492r9/v9xu91nP4XA45HQ6AzYAAHDxCurbLg8//LBGjBihrl276uDBg5o5c6Zat26tsWPHyuVyaeLEicrNzVVCQoKcTqemTJkit9vNO10AAIBfUPFx4MABjR07VkeOHFHHjh11ww03qLS0VB07dpQkzZ8/X61atVJ2drZ8Pp+ysrK0cOHCZpk4AAAIT0HFR1FR0TmPx8TEqKCgQAUFBU2aFAAAuHjx2S4AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuaFB9z5sxRRESEpk6d6t937Ngx5eTkqH379mrbtq2ys7Pl9XqbOk8AAHCRaHR8bN26VS+++KL69u0bsH/atGlav369Vq1apc2bN+vgwYMaNWpUkycKAAAuDo2Kj7q6Oo0bN05LlixRu3bt/Purq6u1dOlSPffccxoyZIgGDhyowsJC/eMf/1BpaWnIJg0AAMJXo+IjJydHw4cPV2ZmZsD+8vJynThxImB/enq6UlNTVVJS0rSZAgCAi0JksHcoKirSRx99pK1bt552zOPxKDo6WvHx8QH7ExMT5fF4zng+n88nn8/nv11TUxPslAAAQBgJ6pmPyspKPfjgg3r11VcVExMTkgnk5+fL5XL5t5SUlJCcFwAAXJiCio/y8nIdPnxYAwYMUGRkpCIjI7V582Y9//zzioyMVGJioo4fP66qqqqA+3m9XiUlJZ3xnHl5eaqurvZvlZWVjV4MAAC48AX1bZdbbrlF27dvD9g3YcIEpaen69FHH1VKSoqioqJUXFys7OxsSdKePXu0f/9+ud3uM57T4XDI4XA0cvoAACDcBBUfcXFxuuqqqwL2tWnTRu3bt/fvnzhxonJzc5WQkCCn06kpU6bI7XZr8ODBoZs1AAAIW0G/4PT7zJ8/X61atVJ2drZ8Pp+ysrK0cOHCUH8ZAAAQppocH5s2bQq4HRMTo4KCAhUUFDT11AAA4CLEZ7sAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVBxceiRYvUt29fOZ1OOZ1Oud1uvfnmm/7jx44dU05Ojtq3b6+2bdsqOztbXq835JMGAADhK6j46NKli+bMmaPy8nJ9+OGHGjJkiEaOHKmdO3dKkqZNm6b169dr1apV2rx5sw4ePKhRo0Y1y8QBAEB4igxm8IgRIwJu/+53v9OiRYtUWlqqLl26aOnSpVqxYoWGDBkiSSosLFTPnj1VWlqqwYMHh27WAAAgbDX6NR8nT55UUVGR6uvr5Xa7VV5erhMnTigzM9M/Jj09XampqSopKTnreXw+n2pqagI2AABw8Qo6PrZv3662bdvK4XDoV7/6lVavXq1evXrJ4/EoOjpa8fHxAeMTExPl8XjOer78/Hy5XC7/lpKSEvQiAABA+Ag6Pnr06KGPP/5YZWVluu+++zR+/Hjt2rWr0RPIy8tTdXW1f6usrGz0uQAAwIUvqNd8SFJ0dLSuuOIKSdLAgQO1detW/eEPf9Do0aN1/PhxVVVVBTz74fV6lZSUdNbzORwOORyO4GcOAADCUpN/zkdDQ4N8Pp8GDhyoqKgoFRcX+4/t2bNH+/fvl9vtbuqXAQAAF4mgnvnIy8vTsGHDlJqaqtraWq1YsUKbNm3Sxo0b5XK5NHHiROXm5iohIUFOp1NTpkyR2+3mnS4AAMAvqPg4fPiwfvGLX+jQoUNyuVzq27evNm7cqFtvvVWSNH/+fLVq1UrZ2dny+XzKysrSwoULm2XiAAAgPAUVH0uXLj3n8ZiYGBUUFKigoKBJkwIAABcvPtsFAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBVUPGRn5+va6+9VnFxcerUqZPuuOMO7dmzJ2DMsWPHlJOTo/bt26tt27bKzs6W1+sN6aQBAED4Cio+Nm/erJycHJWWlurtt9/WiRMndNttt6m+vt4/Ztq0aVq/fr1WrVqlzZs36+DBgxo1alTIJw4AAMJTZDCDN2zYEHB7+fLl6tSpk8rLy/WjH/1I1dXVWrp0qVasWKEhQ4ZIkgoLC9WzZ0+VlpZq8ODBoZs5AAAIS016zUd1dbUkKSEhQZJUXl6uEydOKDMz0z8mPT1dqampKikpOeM5fD6fampqAjYAAHDxanR8NDQ0aOrUqbr++ut11VVXSZI8Ho+io6MVHx8fMDYxMVEej+eM58nPz5fL5fJvKSkpjZ0SAAAIA42Oj5ycHO3YsUNFRUVNmkBeXp6qq6v9W2VlZZPOBwAALmxBvebjlPvvv19/+ctf9N5776lLly7+/UlJSTp+/LiqqqoCnv3wer1KSko647kcDoccDkdjpgEAAMJQUM98GGN0//33a/Xq1XrnnXeUlpYWcHzgwIGKiopScXGxf9+ePXu0f/9+ud3u0MwYAACEtaCe+cjJydGKFSu0du1axcXF+V/H4XK5FBsbK5fLpYkTJyo3N1cJCQlyOp2aMmWK3G4373QBAACSgoyPRYsWSZJuvvnmgP2FhYW65557JEnz589Xq1atlJ2dLZ/Pp6ysLC1cuDAkkwUAAOEvqPgwxnzvmJiYGBUUFKigoKDRkwIAABcvPtsFAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBV0PHx3nvvacSIEUpOTlZERITWrFkTcNwYoxkzZqhz586KjY1VZmam9u7dG6r5AgCAMBd0fNTX16tfv34qKCg44/F58+bp+eef1+LFi1VWVqY2bdooKytLx44da/JkAQBA+IsM9g7Dhg3TsGHDznjMGKMFCxbo8ccf18iRIyVJr7zyihITE7VmzRqNGTOmabMFAABhL6Sv+aioqJDH41FmZqZ/n8vlUkZGhkpKSs54H5/Pp5qamoANAABcvEIaHx6PR5KUmJgYsD8xMdF/7Lvy8/Plcrn8W0pKSiinBAAALjAt/m6XvLw8VVdX+7fKysqWnhIAAGhGIY2PpKQkSZLX6w3Y7/V6/ce+y+FwyOl0BmwAAODiFdL4SEtLU1JSkoqLi/37ampqVFZWJrfbHcovBQAAwlTQ73apq6vTvn37/LcrKir08ccfKyEhQampqZo6daqeeuopde/eXWlpaZo+fbqSk5N1xx13hHLeAAAgTAUdHx9++KF+/OMf+2/n5uZKksaPH6/ly5frkUceUX19vSZPnqyqqirdcMMN2rBhg2JiYkI3awAAELaCjo+bb75ZxpizHo+IiNDs2bM1e/bsJk0MAABcnFr83S4AAODSQnwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBVs8VHQUGBLr/8csXExCgjI0Nbtmxpri8FAADCSLPEx5/+9Cfl5uZq5syZ+uijj9SvXz9lZWXp8OHDzfHlAABAGGmW+Hjuuec0adIkTZgwQb169dLixYt12WWXadmyZc3x5QAAQBiJDPUJjx8/rvLycuXl5fn3tWrVSpmZmSopKTltvM/nk8/n89+urq6WJNXU1IR6apKkBt/XzXJe4GLQXI8723icA+fWHI/1U+c0xnzv2JDHx1dffaWTJ08qMTExYH9iYqI++eST08bn5+dr1qxZp+1PSUkJ9dQAfA/XgpaeAQAbmvOxXltbK5fLdc4xIY+PYOXl5Sk3N9d/u6GhQUePHlX79u0VERHRgjOzo6amRikpKaqsrJTT6Wzp6VjF2i+9tV+q65ZY+6W49ktt3cYY1dbWKjk5+XvHhjw+OnTooNatW8vr9Qbs93q9SkpKOm28w+GQw+EI2BcfHx/qaV3wnE7nJfGH80xY+6W39kt13RJrvxTXfimt+/ue8Tgl5C84jY6O1sCBA1VcXOzf19DQoOLiYrnd7lB/OQAAEGaa5dsuubm5Gj9+vK655hoNGjRICxYsUH19vSZMmNAcXw4AAISRZomP0aNH68svv9SMGTPk8Xh09dVXa8OGDae9CBX//bbTzJkzT/vW06WAtV96a79U1y2x9ktx7Zfqus9HhDmf98QAAACECJ/tAgAArCI+AACAVcQHAACwivgAAABWER8WHD16VOPGjZPT6VR8fLwmTpyourq6c46fMmWKevToodjYWKWmpuqBBx7wf+7NKREREadtRUVFzb2ccyooKNDll1+umJgYZWRkaMuWLeccv2rVKqWnpysmJkZ9+vTRG2+8EXDcGKMZM2aoc+fOio2NVWZmpvbu3ducS2iUYNa9ZMkS3XjjjWrXrp3atWunzMzM08bfc889p13boUOHNvcyGiWYtS9fvvy0dcXExASMCZdrLgW39ptvvvmMj9nhw4f7x4TDdX/vvfc0YsQIJScnKyIiQmvWrPne+2zatEkDBgyQw+HQFVdcoeXLl582Jti/O2wLdt2vv/66br31VnXs2FFOp1Nut1sbN24MGPPEE0+cdr3T09ObcRUXEINmN3ToUNOvXz9TWlpq/v73v5srrrjCjB079qzjt2/fbkaNGmXWrVtn9u3bZ4qLi0337t1NdnZ2wDhJprCw0Bw6dMi/ffPNN829nLMqKioy0dHRZtmyZWbnzp1m0qRJJj4+3ni93jOO/+CDD0zr1q3NvHnzzK5du8zjjz9uoqKizPbt2/1j5syZY1wul1mzZo355z//aX7605+atLS0Fl3ndwW77p///OemoKDAbNu2zezevdvcc889xuVymQMHDvjHjB8/3gwdOjTg2h49etTWks5bsGsvLCw0TqczYF0ejydgTDhcc2OCX/uRI0cC1r1jxw7TunVrU1hY6B8TDtf9jTfeML/97W/N66+/biSZ1atXn3P8559/bi677DKTm5trdu3aZV544QXTunVrs2HDBv+YYH8vW0Kw637wwQfN3LlzzZYtW8ynn35q8vLyTFRUlPnoo4/8Y2bOnGl69+4dcL2//PLLZl7JhYH4aGa7du0ykszWrVv9+958800TERFhvvjii/M+z8qVK010dLQ5ceKEf9/5PABsGjRokMnJyfHfPnnypElOTjb5+flnHH/nnXea4cOHB+zLyMgwv/zlL40xxjQ0NJikpCTzzDPP+I9XVVUZh8NhXnvttWZYQeMEu+7v+vbbb01cXJx5+eWX/fvGjx9vRo4cGeqphlyway8sLDQul+us5wuXa25M06/7/PnzTVxcnKmrq/PvC5frfsr5/B30yCOPmN69ewfsGz16tMnKyvLfburvpW2N/bu3V69eZtasWf7bM2fONP369QvdxMII33ZpZiUlJYqPj9c111zj35eZmalWrVqprKzsvM9TXV0tp9OpyMjAnwuXk5OjDh06aNCgQVq2bNl5fZRxczh+/LjKy8uVmZnp39eqVStlZmaqpKTkjPcpKSkJGC9JWVlZ/vEVFRXyeDwBY1wulzIyMs56Ttsas+7v+vrrr3XixAklJCQE7N+0aZM6deqkHj166L777tORI0dCOvemauza6+rq1LVrV6WkpGjkyJHauXOn/1g4XHMpNNd96dKlGjNmjNq0aROw/0K/7sH6vsd5KH4vw0FDQ4Nqa2tPe5zv3btXycnJ6tatm8aNG6f9+/e30AztIj6amcfjUadOnQL2RUZGKiEhQR6P57zO8dVXX+nJJ5/U5MmTA/bPnj1bK1eu1Ntvv63s7Gz9+te/1gsvvBCyuQfjq6++0smTJ0/7KbaJiYlnXafH4znn+FP/DeactjVm3d/16KOPKjk5OeAv36FDh+qVV15RcXGx5s6dq82bN2vYsGE6efJkSOffFI1Ze48ePbRs2TKtXbtWf/zjH9XQ0KDrrrtOBw4ckBQe11xq+nXfsmWLduzYoXvvvTdgfzhc92Cd7XFeU1Ojb775JiSPoXDw7LPPqq6uTnfeead/X0ZGhpYvX64NGzZo0aJFqqio0I033qja2toWnKkdzfLj1S8Fjz32mObOnXvOMbt3727y16mpqdHw4cPVq1cvPfHEEwHHpk+f7v91//79VV9fr2eeeUYPPPBAk78u7JgzZ46Kioq0adOmgBdejhkzxv/rPn36qG/fvvrhD3+oTZs26ZZbbmmJqYaE2+0O+IDJ6667Tj179tSLL76oJ598sgVnZtfSpUvVp08fDRo0KGD/xXrdL3UrVqzQrFmztHbt2oD/GR02bJj/13379lVGRoa6du2qlStXauLEiS0xVWt45qORHnroIe3evfucW7du3ZSUlKTDhw8H3Pfbb7/V0aNHlZSUdM6vUVtbq6FDhyouLk6rV69WVFTUOcdnZGTowIED8vl8TV5fsDp06KDWrVvL6/UG7Pd6vWddZ1JS0jnHn/pvMOe0rTHrPuXZZ5/VnDlz9NZbb6lv377nHNutWzd16NBB+/bta/KcQ6Upaz8lKipK/fv3968rHK651LS119fXq6io6Lz+cbkQr3uwzvY4dzqdio2NDcmfowtZUVGR7r33Xq1cufK0bz99V3x8vK688sqwvt7ni/hopI4dOyo9Pf2cW3R0tNxut6qqqlReXu6/7zvvvKOGhgZlZGSc9fw1NTW67bbbFB0drXXr1p32dsQz+fjjj9WuXbsW+RCj6OhoDRw4UMXFxf59DQ0NKi4uDvg/3f/ldrsDxkvS22+/7R+flpampKSkgDE1NTUqKys76zlta8y6JWnevHl68skntWHDhoDXA53NgQMHdOTIEXXu3Dkk8w6Fxq79f508eVLbt2/3ryscrrnUtLWvWrVKPp9Pd9111/d+nQvxugfr+x7nofhzdKF67bXXNGHCBL322msBb6k+m7q6On322Wdhfb3PW0u/4vVSMHToUNO/f39TVlZm3n//fdO9e/eAt9oeOHDA9OjRw5SVlRljjKmurjYZGRmmT58+Zt++fQFvw/r222+NMcasW7fOLFmyxGzfvt3s3bvXLFy40Fx22WVmxowZLbJGY/77djmHw2GWL19udu3aZSZPnmzi4+P9b6W8++67zWOPPeYf/8EHH5jIyEjz7LPPmt27d5uZM2ee8a228fHxZu3ateZf//qXGTly5AX3tstg1z1nzhwTHR1t/vznPwdc29raWmOMMbW1tebhhx82JSUlpqKiwvztb38zAwYMMN27dzfHjh1rkTWeTbBrnzVrltm4caP57LPPTHl5uRkzZoyJiYkxO3fu9I8Jh2tuTPBrP+WGG24wo0ePPm1/uFz32tpas23bNrNt2zYjyTz33HNm27Zt5t///rcxxpjHHnvM3H333f7xp95q+5vf/Mbs3r3bFBQUnPGttuf6vbwQBLvuV1991URGRpqCgoKAx3lVVZV/zEMPPWQ2bdpkKioqzAcffGAyMzNNhw4dzOHDh62vzzbiw4IjR46YsWPHmrZt2xqn02kmTJjg/4fGGGMqKiqMJPPuu+8aY4x59913jaQzbhUVFcaY/75d9+qrrzZt27Y1bdq0Mf369TOLFy82J0+ebIEV/n8vvPCCSU1NNdHR0WbQoEGmtLTUf+ymm24y48ePDxi/cuVKc+WVV5ro6GjTu3dv89e//jXgeENDg5k+fbpJTEw0DofD3HLLLWbPnj02lhKUYNbdtWvXM17bmTNnGmOM+frrr81tt91mOnbsaKKiokzXrl3NpEmTLqi/iP9XMGufOnWqf2xiYqL5yU9+EvBzD4wJn2tuTPB/3j/55BMjybz11lunnStcrvvZ/n46tdbx48ebm2666bT7XH311SY6Otp069Yt4GebnHKu38sLQbDrvummm8453pj/vuW4c+fOJjo62vzgBz8wo0ePNvv27bO7sBYSYUwLvTcTAABcknjNBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABY9f8Asm+G5EwruJsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\multiprocessing\\util.py\", line 205, in __call__\n",
      "    def __call__(self, wr=None,\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1457, in _pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1758, in _pydevd_bundle.pydevd_cython.ThreadTracer.__call__\n",
      "  File \"c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\_pydev_bundle\\pydev_is_thread_alive.py\", line 10, in is_thread_alive\n",
      "    return not t._is_stopped\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh4ElEQVR4nO3de3CU1eH/8U8gySZCdkO4JKQkGCoSQEBACeulWowGihSHTAWKFhmE1kYUolUzFRC0BtAK1QmgDASdiil05NYqaKNgtUnAiC03ETTfEoRdFJqrsiA5vz867K8rF9lkc8LC+zXzjOzznH1yDg8Lbze72QhjjBEAAIAlrVp6AgAA4NJCfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMCqyJaewHc1NDTo4MGDiouLU0REREtPBwAAnAdjjGpra5WcnKxWrc793MYFFx8HDx5USkpKS08DAAA0QmVlpbp06XLOMRdcfMTFxUn67+SdTmcLzwYAAJyPmpoapaSk+P8dP5cLLj5OfavF6XQSHwAAhJnzeckELzgFAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArIps6QnYdvljf23pKQAXrP+bM7ylpwDgEsAzHwAAwCriAwAAWEV8AAAAq4gPAABgFfEBAACsIj4AAIBVxAcAALCK+AAAAFYRHwAAwCriAwAAWHXJ/Xh1ABc/PkYBOLeW/igFnvkAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFgVdHx88cUXuuuuu9S+fXvFxsaqT58++vDDD/3HjTGaMWOGOnfurNjYWGVmZmrv3r0hnTQAAAhfQcXHf/7zH11//fWKiorSm2++qV27dun3v/+92rVr5x8zb948Pf/881q8eLHKysrUpk0bZWVl6dixYyGfPAAACD9Bfart3LlzlZKSosLCQv++tLQ0/6+NMVqwYIEef/xxjRw5UpL0yiuvKDExUWvWrNGYMWNCNG0AABCugnrmY926dbrmmmv0s5/9TJ06dVL//v21ZMkS//GKigp5PB5lZmb697lcLmVkZKikpOSM5/T5fKqpqQnYAADAxSuo+Pj888+1aNEide/eXRs3btR9992nBx54QC+//LIkyePxSJISExMD7peYmOg/9l35+flyuVz+LSUlpTHrAAAAYSKo+GhoaNCAAQP09NNPq3///po8ebImTZqkxYsXN3oCeXl5qq6u9m+VlZWNPhcAALjwBRUfnTt3Vq9evQL29ezZU/v375ckJSUlSZK8Xm/AGK/X6z/2XQ6HQ06nM2ADAAAXr6Di4/rrr9eePXsC9n366afq2rWrpP+++DQpKUnFxcX+4zU1NSorK5Pb7Q7BdAEAQLgL6t0u06ZN03XXXaenn35ad955p7Zs2aKXXnpJL730kiQpIiJCU6dO1VNPPaXu3bsrLS1N06dPV3Jysu64447mmD8AAAgzQcXHtddeq9WrVysvL0+zZ89WWlqaFixYoHHjxvnHPPLII6qvr9fkyZNVVVWlG264QRs2bFBMTEzIJw8AAMJPUPEhSbfffrtuv/32sx6PiIjQ7NmzNXv27CZNDAAAXJz4bBcAAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVBxccTTzyhiIiIgC09Pd1//NixY8rJyVH79u3Vtm1bZWdny+v1hnzSAAAgfAX9zEfv3r116NAh//b+++/7j02bNk3r16/XqlWrtHnzZh08eFCjRo0K6YQBAEB4iwz6DpGRSkpKOm1/dXW1li5dqhUrVmjIkCGSpMLCQvXs2VOlpaUaPHhw02cLAADCXtDPfOzdu1fJycnq1q2bxo0bp/3790uSysvLdeLECWVmZvrHpqenKzU1VSUlJaGbMQAACGtBPfORkZGh5cuXq0ePHjp06JBmzZqlG2+8UTt27JDH41F0dLTi4+MD7pOYmCiPx3PWc/p8Pvl8Pv/tmpqa4FYAAADCSlDxMWzYMP+v+/btq4yMDHXt2lUrV65UbGxsoyaQn5+vWbNmNeq+AAAg/DTprbbx8fG68sortW/fPiUlJen48eOqqqoKGOP1es/4GpFT8vLyVF1d7d8qKyubMiUAAHCBa1J81NXV6bPPPlPnzp01cOBARUVFqbi42H98z5492r9/v9xu91nP4XA45HQ6AzYAAHDxCurbLg8//LBGjBihrl276uDBg5o5c6Zat26tsWPHyuVyaeLEicrNzVVCQoKcTqemTJkit9vNO10AAIBfUPFx4MABjR07VkeOHFHHjh11ww03qLS0VB07dpQkzZ8/X61atVJ2drZ8Pp+ysrK0cOHCZpk4AAAIT0HFR1FR0TmPx8TEqKCgQAUFBU2aFAAAuHjx2S4AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuIDwAAYBXxAQAArCI+AACAVcQHAACwivgAAABWER8AAMAq4gMAAFhFfAAAAKuaFB9z5sxRRESEpk6d6t937Ngx5eTkqH379mrbtq2ys7Pl9XqbOk8AAHCRaHR8bN26VS+++KL69u0bsH/atGlav369Vq1apc2bN+vgwYMaNWpUkycKAAAuDo2Kj7q6Oo0bN05LlixRu3bt/Purq6u1dOlSPffccxoyZIgGDhyowsJC/eMf/1BpaWnIJg0AAMJXo+IjJydHw4cPV2ZmZsD+8vJynThxImB/enq6UlNTVVJS0rSZAgCAi0JksHcoKirSRx99pK1bt552zOPxKDo6WvHx8QH7ExMT5fF4zng+n88nn8/nv11TUxPslAAAQBgJ6pmPyspKPfjgg3r11VcVExMTkgnk5+fL5XL5t5SUlJCcFwAAXJiCio/y8nIdPnxYAwYMUGRkpCIjI7V582Y9//zzioyMVGJioo4fP66qqqqA+3m9XiUlJZ3xnHl5eaqurvZvlZWVjV4MAAC48AX1bZdbbrlF27dvD9g3YcIEpaen69FHH1VKSoqioqJUXFys7OxsSdKePXu0f/9+ud3uM57T4XDI4XA0cvoAACDcBBUfcXFxuuqqqwL2tWnTRu3bt/fvnzhxonJzc5WQkCCn06kpU6bI7XZr8ODBoZs1AAAIW0G/4PT7zJ8/X61atVJ2drZ8Pp+ysrK0cOHCUH8ZAAAQppocH5s2bQq4HRMTo4KCAhUUFDT11AAA4CLEZ7sAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFVBxceiRYvUt29fOZ1OOZ1Oud1uvfnmm/7jx44dU05Ojtq3b6+2bdsqOztbXq835JMGAADhK6j46NKli+bMmaPy8nJ9+OGHGjJkiEaOHKmdO3dKkqZNm6b169dr1apV2rx5sw4ePKhRo0Y1y8QBAEB4igxm8IgRIwJu/+53v9OiRYtUWlqqLl26aOnSpVqxYoWGDBkiSSosLFTPnj1VWlqqwYMHh27WAAAgbDX6NR8nT55UUVGR6uvr5Xa7VV5erhMnTigzM9M/Jj09XampqSopKTnreXw+n2pqagI2AABw8Qo6PrZv3662bdvK4XDoV7/6lVavXq1evXrJ4/EoOjpa8fHxAeMTExPl8XjOer78/Hy5XC7/lpKSEvQiAABA+Ag6Pnr06KGPP/5YZWVluu+++zR+/Hjt2rWr0RPIy8tTdXW1f6usrGz0uQAAwIUvqNd8SFJ0dLSuuOIKSdLAgQO1detW/eEPf9Do0aN1/PhxVVVVBTz74fV6lZSUdNbzORwOORyO4GcOAADCUpN/zkdDQ4N8Pp8GDhyoqKgoFRcX+4/t2bNH+/fvl9vtbuqXAQAAF4mgnvnIy8vTsGHDlJqaqtraWq1YsUKbNm3Sxo0b5XK5NHHiROXm5iohIUFOp1NTpkyR2+3mnS4AAMAvqPg4fPiwfvGLX+jQoUNyuVzq27evNm7cqFtvvVWSNH/+fLVq1UrZ2dny+XzKysrSwoULm2XiAAAgPAUVH0uXLj3n8ZiYGBUUFKigoKBJkwIAABcvPtsFAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBVUPGRn5+va6+9VnFxcerUqZPuuOMO7dmzJ2DMsWPHlJOTo/bt26tt27bKzs6W1+sN6aQBAED4Cio+Nm/erJycHJWWlurtt9/WiRMndNttt6m+vt4/Ztq0aVq/fr1WrVqlzZs36+DBgxo1alTIJw4AAMJTZDCDN2zYEHB7+fLl6tSpk8rLy/WjH/1I1dXVWrp0qVasWKEhQ4ZIkgoLC9WzZ0+VlpZq8ODBoZs5AAAIS016zUd1dbUkKSEhQZJUXl6uEydOKDMz0z8mPT1dqampKikpOeM5fD6fampqAjYAAHDxanR8NDQ0aOrUqbr++ut11VVXSZI8Ho+io6MVHx8fMDYxMVEej+eM58nPz5fL5fJvKSkpjZ0SAAAIA42Oj5ycHO3YsUNFRUVNmkBeXp6qq6v9W2VlZZPOBwAALmxBvebjlPvvv19/+ctf9N5776lLly7+/UlJSTp+/LiqqqoCnv3wer1KSko647kcDoccDkdjpgEAAMJQUM98GGN0//33a/Xq1XrnnXeUlpYWcHzgwIGKiopScXGxf9+ePXu0f/9+ud3u0MwYAACEtaCe+cjJydGKFSu0du1axcXF+V/H4XK5FBsbK5fLpYkTJyo3N1cJCQlyOp2aMmWK3G4373QBAACSgoyPRYsWSZJuvvnmgP2FhYW65557JEnz589Xq1atlJ2dLZ/Pp6ysLC1cuDAkkwUAAOEvqPgwxnzvmJiYGBUUFKigoKDRkwIAABcvPtsFAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBV0PHx3nvvacSIEUpOTlZERITWrFkTcNwYoxkzZqhz586KjY1VZmam9u7dG6r5AgCAMBd0fNTX16tfv34qKCg44/F58+bp+eef1+LFi1VWVqY2bdooKytLx44da/JkAQBA+IsM9g7Dhg3TsGHDznjMGKMFCxbo8ccf18iRIyVJr7zyihITE7VmzRqNGTOmabMFAABhL6Sv+aioqJDH41FmZqZ/n8vlUkZGhkpKSs54H5/Pp5qamoANAABcvEIaHx6PR5KUmJgYsD8xMdF/7Lvy8/Plcrn8W0pKSiinBAAALjAt/m6XvLw8VVdX+7fKysqWnhIAAGhGIY2PpKQkSZLX6w3Y7/V6/ce+y+FwyOl0BmwAAODiFdL4SEtLU1JSkoqLi/37ampqVFZWJrfbHcovBQAAwlTQ73apq6vTvn37/LcrKir08ccfKyEhQampqZo6daqeeuopde/eXWlpaZo+fbqSk5N1xx13hHLeAAAgTAUdHx9++KF+/OMf+2/n5uZKksaPH6/ly5frkUceUX19vSZPnqyqqirdcMMN2rBhg2JiYkI3awAAELaCjo+bb75ZxpizHo+IiNDs2bM1e/bsJk0MAABcnFr83S4AAODSQnwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGBVs8VHQUGBLr/8csXExCgjI0Nbtmxpri8FAADCSLPEx5/+9Cfl5uZq5syZ+uijj9SvXz9lZWXp8OHDzfHlAABAGGmW+Hjuuec0adIkTZgwQb169dLixYt12WWXadmyZc3x5QAAQBiJDPUJjx8/rvLycuXl5fn3tWrVSpmZmSopKTltvM/nk8/n89+urq6WJNXU1IR6apKkBt/XzXJe4GLQXI8723icA+fWHI/1U+c0xnzv2JDHx1dffaWTJ08qMTExYH9iYqI++eST08bn5+dr1qxZp+1PSUkJ9dQAfA/XgpaeAQAbmvOxXltbK5fLdc4xIY+PYOXl5Sk3N9d/u6GhQUePHlX79u0VERHRgjOzo6amRikpKaqsrJTT6Wzp6VjF2i+9tV+q65ZY+6W49ktt3cYY1dbWKjk5+XvHhjw+OnTooNatW8vr9Qbs93q9SkpKOm28w+GQw+EI2BcfHx/qaV3wnE7nJfGH80xY+6W39kt13RJrvxTXfimt+/ue8Tgl5C84jY6O1sCBA1VcXOzf19DQoOLiYrnd7lB/OQAAEGaa5dsuubm5Gj9+vK655hoNGjRICxYsUH19vSZMmNAcXw4AAISRZomP0aNH68svv9SMGTPk8Xh09dVXa8OGDae9CBX//bbTzJkzT/vW06WAtV96a79U1y2x9ktx7Zfqus9HhDmf98QAAACECJ/tAgAArCI+AACAVcQHAACwivgAAABWER8WHD16VOPGjZPT6VR8fLwmTpyourq6c46fMmWKevToodjYWKWmpuqBBx7wf+7NKREREadtRUVFzb2ccyooKNDll1+umJgYZWRkaMuWLeccv2rVKqWnpysmJkZ9+vTRG2+8EXDcGKMZM2aoc+fOio2NVWZmpvbu3ducS2iUYNa9ZMkS3XjjjWrXrp3atWunzMzM08bfc889p13boUOHNvcyGiWYtS9fvvy0dcXExASMCZdrLgW39ptvvvmMj9nhw4f7x4TDdX/vvfc0YsQIJScnKyIiQmvWrPne+2zatEkDBgyQw+HQFVdcoeXLl582Jti/O2wLdt2vv/66br31VnXs2FFOp1Nut1sbN24MGPPEE0+cdr3T09ObcRUXEINmN3ToUNOvXz9TWlpq/v73v5srrrjCjB079qzjt2/fbkaNGmXWrVtn9u3bZ4qLi0337t1NdnZ2wDhJprCw0Bw6dMi/ffPNN829nLMqKioy0dHRZtmyZWbnzp1m0qRJJj4+3ni93jOO/+CDD0zr1q3NvHnzzK5du8zjjz9uoqKizPbt2/1j5syZY1wul1mzZo355z//aX7605+atLS0Fl3ndwW77p///OemoKDAbNu2zezevdvcc889xuVymQMHDvjHjB8/3gwdOjTg2h49etTWks5bsGsvLCw0TqczYF0ejydgTDhcc2OCX/uRI0cC1r1jxw7TunVrU1hY6B8TDtf9jTfeML/97W/N66+/biSZ1atXn3P8559/bi677DKTm5trdu3aZV544QXTunVrs2HDBv+YYH8vW0Kw637wwQfN3LlzzZYtW8ynn35q8vLyTFRUlPnoo4/8Y2bOnGl69+4dcL2//PLLZl7JhYH4aGa7du0ykszWrVv9+958800TERFhvvjii/M+z8qVK010dLQ5ceKEf9/5PABsGjRokMnJyfHfPnnypElOTjb5+flnHH/nnXea4cOHB+zLyMgwv/zlL40xxjQ0NJikpCTzzDPP+I9XVVUZh8NhXnvttWZYQeMEu+7v+vbbb01cXJx5+eWX/fvGjx9vRo4cGeqphlyway8sLDQul+us5wuXa25M06/7/PnzTVxcnKmrq/PvC5frfsr5/B30yCOPmN69ewfsGz16tMnKyvLfburvpW2N/bu3V69eZtasWf7bM2fONP369QvdxMII33ZpZiUlJYqPj9c111zj35eZmalWrVqprKzsvM9TXV0tp9OpyMjAnwuXk5OjDh06aNCgQVq2bNl5fZRxczh+/LjKy8uVmZnp39eqVStlZmaqpKTkjPcpKSkJGC9JWVlZ/vEVFRXyeDwBY1wulzIyMs56Ttsas+7v+vrrr3XixAklJCQE7N+0aZM6deqkHj166L777tORI0dCOvemauza6+rq1LVrV6WkpGjkyJHauXOn/1g4XHMpNNd96dKlGjNmjNq0aROw/0K/7sH6vsd5KH4vw0FDQ4Nqa2tPe5zv3btXycnJ6tatm8aNG6f9+/e30AztIj6amcfjUadOnQL2RUZGKiEhQR6P57zO8dVXX+nJJ5/U5MmTA/bPnj1bK1eu1Ntvv63s7Gz9+te/1gsvvBCyuQfjq6++0smTJ0/7KbaJiYlnXafH4znn+FP/DeactjVm3d/16KOPKjk5OeAv36FDh+qVV15RcXGx5s6dq82bN2vYsGE6efJkSOffFI1Ze48ePbRs2TKtXbtWf/zjH9XQ0KDrrrtOBw4ckBQe11xq+nXfsmWLduzYoXvvvTdgfzhc92Cd7XFeU1Ojb775JiSPoXDw7LPPqq6uTnfeead/X0ZGhpYvX64NGzZo0aJFqqio0I033qja2toWnKkdzfLj1S8Fjz32mObOnXvOMbt3727y16mpqdHw4cPVq1cvPfHEEwHHpk+f7v91//79VV9fr2eeeUYPPPBAk78u7JgzZ46Kioq0adOmgBdejhkzxv/rPn36qG/fvvrhD3+oTZs26ZZbbmmJqYaE2+0O+IDJ6667Tj179tSLL76oJ598sgVnZtfSpUvVp08fDRo0KGD/xXrdL3UrVqzQrFmztHbt2oD/GR02bJj/13379lVGRoa6du2qlStXauLEiS0xVWt45qORHnroIe3evfucW7du3ZSUlKTDhw8H3Pfbb7/V0aNHlZSUdM6vUVtbq6FDhyouLk6rV69WVFTUOcdnZGTowIED8vl8TV5fsDp06KDWrVvL6/UG7Pd6vWddZ1JS0jnHn/pvMOe0rTHrPuXZZ5/VnDlz9NZbb6lv377nHNutWzd16NBB+/bta/KcQ6Upaz8lKipK/fv3968rHK651LS119fXq6io6Lz+cbkQr3uwzvY4dzqdio2NDcmfowtZUVGR7r33Xq1cufK0bz99V3x8vK688sqwvt7ni/hopI4dOyo9Pf2cW3R0tNxut6qqqlReXu6/7zvvvKOGhgZlZGSc9fw1NTW67bbbFB0drXXr1p32dsQz+fjjj9WuXbsW+RCj6OhoDRw4UMXFxf59DQ0NKi4uDvg/3f/ldrsDxkvS22+/7R+flpampKSkgDE1NTUqKys76zlta8y6JWnevHl68skntWHDhoDXA53NgQMHdOTIEXXu3Dkk8w6Fxq79f508eVLbt2/3ryscrrnUtLWvWrVKPp9Pd9111/d+nQvxugfr+x7nofhzdKF67bXXNGHCBL322msBb6k+m7q6On322Wdhfb3PW0u/4vVSMHToUNO/f39TVlZm3n//fdO9e/eAt9oeOHDA9OjRw5SVlRljjKmurjYZGRmmT58+Zt++fQFvw/r222+NMcasW7fOLFmyxGzfvt3s3bvXLFy40Fx22WVmxowZLbJGY/77djmHw2GWL19udu3aZSZPnmzi4+P9b6W8++67zWOPPeYf/8EHH5jIyEjz7LPPmt27d5uZM2ee8a228fHxZu3ateZf//qXGTly5AX3tstg1z1nzhwTHR1t/vznPwdc29raWmOMMbW1tebhhx82JSUlpqKiwvztb38zAwYMMN27dzfHjh1rkTWeTbBrnzVrltm4caP57LPPTHl5uRkzZoyJiYkxO3fu9I8Jh2tuTPBrP+WGG24wo0ePPm1/uFz32tpas23bNrNt2zYjyTz33HNm27Zt5t///rcxxpjHHnvM3H333f7xp95q+5vf/Mbs3r3bFBQUnPGttuf6vbwQBLvuV1991URGRpqCgoKAx3lVVZV/zEMPPWQ2bdpkKioqzAcffGAyMzNNhw4dzOHDh62vzzbiw4IjR46YsWPHmrZt2xqn02kmTJjg/4fGGGMqKiqMJPPuu+8aY4x59913jaQzbhUVFcaY/75d9+qrrzZt27Y1bdq0Mf369TOLFy82J0+ebIEV/n8vvPCCSU1NNdHR0WbQoEGmtLTUf+ymm24y48ePDxi/cuVKc+WVV5ro6GjTu3dv89e//jXgeENDg5k+fbpJTEw0DofD3HLLLWbPnj02lhKUYNbdtWvXM17bmTNnGmOM+frrr81tt91mOnbsaKKiokzXrl3NpEmTLqi/iP9XMGufOnWqf2xiYqL5yU9+EvBzD4wJn2tuTPB/3j/55BMjybz11lunnStcrvvZ/n46tdbx48ebm2666bT7XH311SY6Otp069Yt4GebnHKu38sLQbDrvummm8453pj/vuW4c+fOJjo62vzgBz8wo0ePNvv27bO7sBYSYUwLvTcTAABcknjNBwAAsIr4AAAAVhEfAADAKuIDAABYRXwAAACriA8AAGAV8QEAAKwiPgAAgFXEBwAAsIr4AAAAVhEfAADAKuIDAABY9f8Asm+G5EwruJsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data,target in train_loader:\n",
    "\n",
    "    tocount = pd.DataFrame(target.numpy()).value_counts()\n",
    "    fig, ax =plt.subplots()\n",
    "    ax.bar([0,1],tocount.values)\n",
    "    plt.show()\n",
    "\n",
    "    #get_distribution(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_distribution(pd.DataFrame(test.numpy()).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,), (1.0,)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0,), (1.0,)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot.index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e6cf589e08>"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    data = test_loader.dataset.tensors[0].to(device)\n",
    "    predicted = model(data).to(device)\n",
    "    predicted = predicted.cpu()\n",
    "    predicted = predicted.flatten()\n",
    "    target = test_loader.dataset.tensors[1].flatten()\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, accuracy_score\n",
    "import seaborn as sn\n",
    "\n",
    "#classes = true_labels.keys()\n",
    "#classes = list(df_labels.columns)\n",
    "cf_matrix = confusion_matrix(target, predicted)\n",
    "#df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     #columns = [i for i in classes])\n",
    "#plt.figure(figsize = (12,7))\n",
    "#sn.heatmap(df_cm, annot=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix)\n",
    "disp.plot(xticks_rotation=90)\n",
    "#disp.figure_.savefig(f'../4 - Training & Testing/models/model_{numberofmodel}_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3540633346051126\n",
      "Accuracy: 0.3540633346051126\n",
      "f1_score: 0.5229642152719076\n",
      "recall_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision_score(target, predicted)}')\n",
    "print(f'Accuracy: {accuracy_score(target, predicted)}')\n",
    "print(f'f1_score: {f1_score(target, predicted)}')\n",
    "print(f'recall_score: {recall_score(target, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3540633346051126\n",
      "Accuracy: 0.3540633346051126\n",
      "f1_score: 0.5229642152719076\n",
      "recall_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision: {precision_score(target, predicted)}')\n",
    "print(f'Accuracy: {accuracy_score(target, predicted)}')\n",
    "print(f'f1_score: {f1_score(target, predicted)}')\n",
    "print(f'recall_score: {recall_score(target, predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:992: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  UndefinedMetricWarning,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "nn_fpr, nn_tpr, nn_thresholds = roc_curve(predicted, target)\n",
    "plt.plot(nn_fpr,nn_tpr,marker='.')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrozenTrial(number=3, state=TrialState.COMPLETE, values=[0.6459366653948875], datetime_start=datetime.datetime(2023, 3, 30, 1, 16, 35, 756185), datetime_complete=datetime.datetime(2023, 3, 30, 1, 16, 58, 526080), params={'lr': 0.0041130297587676085, 'n_layers': 8, 'n_units_l0': 1456, 'n_units_l1': 1579, 'n_units_l2': 1542, 'n_units_l3': 1024, 'n_units_l4': 936, 'n_units_l5': 1804, 'n_units_l6': 351, 'n_units_l7': 35, 'optimizer': 'Adam'}, user_attrs={}, system_attrs={}, intermediate_values={0: 0.6459366653948875, 1: 0.6459366653948875, 2: 0.6459366653948875, 3: 0.6459366653948875, 4: 0.6459366653948875, 5: 0.6459366653948875, 6: 0.6459366653948875, 7: 0.6459366653948875, 8: 0.6459366653948875, 9: 0.6459366653948875}, distributions={'lr': FloatDistribution(high=0.1, log=True, low=1e-05, step=None), 'n_layers': IntDistribution(high=10, log=False, low=3, step=1), 'n_units_l0': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l1': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l2': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l3': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l4': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l5': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l6': IntDistribution(high=2048, log=False, low=32, step=1), 'n_units_l7': IntDistribution(high=2048, log=False, low=32, step=1), 'optimizer': CategoricalDistribution(choices=('Adam', 'SGD'))}, trial_id=97, value=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\visualization\\_plotly_imports.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtry_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_imports\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplotly_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30248\\2869994356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_optimization_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\visualization\\_optimization_history.py\u001b[0m in \u001b[0;36mplot_optimization_history\u001b[1;34m(study, target, target_name, error_bar)\u001b[0m\n\u001b[0;32m    165\u001b[0m     \"\"\"\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m     \u001b[0m_imports\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[0minfo_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_optimization_history_info_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\optuna\\_imports.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deferred\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deferred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Tried to import 'plotly' but failed. Please make sure that the package is installed correctly to use this feature. Actual error: No module named 'plotly'."
     ]
    }
   ],
   "source": [
    "detailed_objective(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "test_tensor = torch.zeros(len(predicted),10)\n",
    "test_tensor\n",
    "count = 0\n",
    "for x in predicted:\n",
    "    test_tensor[count][x.item()] = 1\n",
    "    count += 1\n",
    "    print(test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "indices=tensor([9, 9, 4,  ..., 9, 8, 9]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saver\n",
    "from datetime import datetime\n",
    "numberofmodel = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate accuracy, precision, recall for each index by matching the value of test_tensor (prediction) and test_label (ground truth)\n",
    "predicted_dict = {}\n",
    "for x in range(predicted.shape[0]):\n",
    "    if torch.argmax(test_tensor[0]).item() in predicted_dict.keys():\n",
    "        predicted_dict[torch.argmax(test_tensor[0]).item()] += 1\n",
    "    else:\n",
    "        predicted_dict[torch.argmax(test_tensor[0]).item()] = 1\n",
    "\n",
    "label_dict = {}\n",
    "for x in test_loader.dataset:\n",
    "    if torch.argmax(x[1]).item() in label_dict.keys():\n",
    "        label_dict[torch.argmax(x[1]).item()] += 1\n",
    "    else:\n",
    "        label_dict[torch.argmax(x[1]).item()] = 1\n",
    "label_dict = dict(sorted(label_dict.items(), key=lambda item: item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'No_ADR',\n",
       " 1: 'ADR_AIU',\n",
       " 2: 'ADR_Agranulocytosis',\n",
       " 3: 'ADR_FDE',\n",
       " 4: 'ADR_Juandice',\n",
       " 5: 'ADR_MPeruption',\n",
       " 6: 'ADR_MPexanthema',\n",
       " 7: 'ADR_SJSI',\n",
       " 8: 'ADR_SJSII',\n",
       " 9: 'ADR_TEN'}"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = {'No_ADR': 0,\n",
    " 'ADR_AIU': 1,\n",
    " 'ADR_Agranulocytosis': 2,\n",
    " 'ADR_FDE': 3,\n",
    " 'ADR_Juandice': 4,\n",
    " 'ADR_MPeruption': 5,\n",
    " 'ADR_MPexanthema': 6,\n",
    " 'ADR_SJSI': 7,\n",
    " 'ADR_SJSII': 8,\n",
    " 'ADR_TEN': 9}\n",
    "\n",
    " #switch true_labels keys an values\n",
    "true_labels = {v: k for k, v in true_labels.items()}\n",
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADR_AIU',\n",
       " 'ADR_Agranulocytosis',\n",
       " 'ADR_FDE',\n",
       " 'ADR_Juandice',\n",
       " 'ADR_MPeruption',\n",
       " 'ADR_MPexanthema',\n",
       " 'ADR_SJSI',\n",
       " 'ADR_SJSII',\n",
       " 'ADR_TEN',\n",
       " 'No_ADR']"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{9: 2621}"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1, 4: 103, 5: 133, 6: 350, 7: 64, 8: 277, 9: 1693}"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'ADR_Agranulocytosis',\n",
       " 4: 'ADR_Juandice',\n",
       " 5: 'ADR_MPeruption',\n",
       " 6: 'ADR_MPexanthema',\n",
       " 7: 'ADR_SJSI',\n",
       " 8: 'ADR_SJSII',\n",
       " 9: 'ADR_TEN'}"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the keys in true_labels that are not the keys in label_dict\n",
    "true_labels = {k: v for k, v in true_labels.items() if k in label_dict.keys()}\n",
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = list(df_labels.columns)\n",
    "\n",
    "#remove the value in list(df_labels.columns) that got the sum of 0 in df_labels.sum(0)\n",
    "for x in list(df_labels.columns):\n",
    "    if df_labels[x].sum(0) == 0:\n",
    "        classes.remove(x)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "\n",
    "#classes = true_labels.keys()\n",
    "#classes = list(df_labels.columns)\n",
    "cf_matrix = confusion_matrix(test_label[1], predicted)\n",
    "#df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
    "                     #columns = [i for i in classes])\n",
    "#plt.figure(figsize = (12,7))\n",
    "#sn.heatmap(df_cm, annot=True)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix, display_labels=classes)\n",
    "disp.plot(xticks_rotation=90)\n",
    "disp.figure_.savefig(f'../4 - Training & Testing/models/model_{numberofmodel}_cf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "        ADR_FDE       0.00      0.00      0.00         1\n",
      " ADR_MPeruption       0.00      0.00      0.00       103\n",
      "ADR_MPexanthema       0.00      0.00      0.00       133\n",
      "       ADR_SJSI       0.40      0.01      0.02       350\n",
      "      ADR_SJSII       0.00      0.00      0.00        64\n",
      "        ADR_TEN       0.00      0.00      0.00       277\n",
      "         No_ADR       0.65      1.00      0.78      1693\n",
      "\n",
      "       accuracy                           0.65      2621\n",
      "      macro avg       0.15      0.14      0.12      2621\n",
      "   weighted avg       0.47      0.65      0.51      2621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\harit\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(test_label[1], predicted, target_names=classes)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"../4 - Training & Testing/models/model_{numberofmodel}.txt\",\"w\")\n",
    "f.writelines(str(model.parameters))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.writelines(str(optimizer))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.write(str(loss_fn))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.write(\"all_train_loss\"+ str(allepoch_train_loss))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.write(\"\"+str(allepoch_test_acc))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.write(\"all_train_loss\"+str(allepoch_train_acc))\n",
    "f.writelines(\"\\n------------------\\n\")\n",
    "f.write(cr)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numberofmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9824\\2200049820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34mf\"../4 - Training & Testing/models/model_{numberofmodel}.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'numberofmodel' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(),f\"../4 - Training & Testing/models/model_{numberofmodel}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,1)\n",
    "#plt.style.use('ggplot')\n",
    "\n",
    "ax[0].set_title(\"Training / Testing Accuracy\")\n",
    "ax[0].plot(allepoch_train_acc, 'red',label='Train',marker='o')\n",
    "ax[0].plot(allepoch_test_acc,'blue',label='Test',marker='o')\n",
    "ax[0].xaxis.set(ticks=range(0,len(allepoch_train_acc),1))\n",
    "ax[0].set_ylabel(\"Accuracy\")\n",
    "ax[0].legend()\n",
    "#ax[0].text(4,1,f\"Model: {numberofmodel}\")\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Training loss\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].plot(allepoch_train_loss,label = 'loss',color='green')\n",
    "ax[1].plot(allepoch_train_loss,label = 'loss',color='green')\n",
    "ax[1].xaxis.set(ticks=range(0,len(allepoch_train_acc),1))\n",
    "ax[1].set_ylabel(\"Loss\")\n",
    "ax[1].legend()\n",
    "#plt.show()\n",
    "\n",
    "plt.tight_layout()#h_pad = 3, w_pad=3)\n",
    "plt.savefig(f\"../4 - Training & Testing/models/model_{numberofmodel}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# ax.bar(list(correctresult.keys()),list(correctresult.values()),label=\"Correct\",bottom=list(wrongresult.values()))\n",
    "# ax.bar(list(wrongresult.keys()),list(wrongresult.values()),label=\"Wrong\")\n",
    "# ax.legend()\n",
    "# #plt.text(1,1,\"test\")\n",
    "# # for i in range(len(list(correctresult.keys()))):\n",
    "# #     plt.text(i,list(correctresult.values())[i],list(correctresult.values())[i])\n",
    "# # for i in range(len(list(wrongresult.keys()))):\n",
    "# #     plt.text(i,list(wrongresult.values())[i],list(wrongresult.values())[i])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e66a29805c7d19f665d21a677c79dfb3caac32461f5105693599daa5b8ef61be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
